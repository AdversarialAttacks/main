{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "os.chdir(\"..\")\n",
    "\n",
    "import torch\n",
    "import wandb\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from src.utils.download import download_models\n",
    "from src.utils.uap_helper import generate_adversarial_images_from_model_dataset, get_datamodule\n",
    "from src.utils.metrics import metrics, Metrics\n",
    "from src.data.mri import MRIDataModule\n",
    "from src.data.covidx import COVIDXDataModule\n",
    "from src.utils.evaluation import WeightsandBiasEval\n",
    "from src.models.imageclassifier import ImageClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENTITY = \"24FS_I4DS27\"\n",
    "PROJECT = \"baselines\"\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "transform = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.Resize((224, 224), antialias=True),\n",
    "    ]\n",
    ")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download models if not present\n",
    "models = download_models(ENTITY, PROJECT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5b0d3b0298c409981e95d65ff77a38b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Model:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---\n",
      "Model: efficientnet_v2_l - Dataset: covidx_data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62e742d1e58b429599bdae64cb18b4da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Universal Pertubation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97abae5bf6144f10ba78fa62ba94c252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0...\n",
      "Loss: 8.168862342834473, Norm: 0.0, InvBCE: 8.168862342834473\n",
      "Loss: 6.573144435882568, Norm: 0.0003871153458021581, InvBCE: 6.572757244110107\n",
      "Loss: 5.1448893547058105, Norm: 0.0007587328436784446, InvBCE: 5.144130706787109\n",
      "Loss: 3.9256417751312256, Norm: 0.0011199809378013015, InvBCE: 3.9245216846466064\n",
      "Loss: 2.9355862140655518, Norm: 0.0014689506497234106, InvBCE: 2.934117317199707\n",
      "Loss: 2.1747634410858154, Norm: 0.0018035381799563766, InvBCE: 2.172959804534912\n",
      "Loss: 1.623170256614685, Norm: 0.002121665747836232, InvBCE: 1.6210485696792603\n",
      "Loss: 1.2415130138397217, Norm: 0.002421632641926408, InvBCE: 1.239091396331787\n",
      "Loss: 0.985498309135437, Norm: 0.0027024217415601015, InvBCE: 0.9827958941459656\n",
      "Loss: 0.815651535987854, Norm: 0.002963785547763109, InvBCE: 0.8126877546310425\n",
      "Loss: 0.7019845843315125, Norm: 0.003206125693395734, InvBCE: 0.6987784504890442\n",
      "Loss: 0.6242859363555908, Norm: 0.0034302815329283476, InvBCE: 0.6208556294441223\n",
      "Loss: 0.5696697235107422, Norm: 0.0036373340990394354, InvBCE: 0.5660324096679688\n",
      "Loss: 0.530123233795166, Norm: 0.0038284638430923223, InvBCE: 0.5262947678565979\n",
      "Image fooled! Adding perturbation...\n",
      "Image 1...\n",
      "Loss: 0.6797394752502441, Norm: 0.0, InvBCE: 0.6757345795631409\n",
      "Image fooled! Adding perturbation...\n",
      "Image 2...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 3...\n",
      "Loss: 4.15983247756958, Norm: 0.0, InvBCE: 4.1557488441467285\n",
      "Loss: 3.1153781414031982, Norm: 0.00038460284122265875, InvBCE: 3.1112518310546875\n",
      "Loss: 2.4691500663757324, Norm: 0.0007458949694409966, InvBCE: 2.464951753616333\n",
      "Loss: 2.035006046295166, Norm: 0.0010892392601817846, InvBCE: 2.0307133197784424\n",
      "Loss: 1.7208768129348755, Norm: 0.0014152433723211288, InvBCE: 1.716472864151001\n",
      "Loss: 1.4795897006988525, Norm: 0.001725087407976389, InvBCE: 1.475062370300293\n",
      "Loss: 1.2840534448623657, Norm: 0.0020201648585498333, InvBCE: 1.2793939113616943\n",
      "Loss: 1.1175204515457153, Norm: 0.002301952801644802, InvBCE: 1.112722396850586\n",
      "Loss: 0.9704830050468445, Norm: 0.0025718682445585728, InvBCE: 0.9655422568321228\n",
      "Loss: 0.8388014435768127, Norm: 0.002831045538187027, InvBCE: 0.8337150812149048\n",
      "Loss: 0.7217419743537903, Norm: 0.003080136375501752, InvBCE: 0.7165083885192871\n",
      "Loss: 0.6197376251220703, Norm: 0.003319334704428911, InvBCE: 0.6143564581871033\n",
      "Loss: 0.5336136817932129, Norm: 0.0035482540261000395, InvBCE: 0.5280859470367432\n",
      "Loss: 0.46418026089668274, Norm: 0.0037665751297026873, InvBCE: 0.4585081934928894\n",
      "Loss: 0.4106937646865845, Norm: 0.003973687998950481, InvBCE: 0.40488097071647644\n",
      "Image fooled! Adding perturbation...\n",
      "Image 4...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 5...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 6...\n",
      "Loss: 3.1715004444122314, Norm: 0.0, InvBCE: 3.1655516624450684\n",
      "Loss: 3.068403720855713, Norm: 0.0003694309270940721, InvBCE: 3.0624823570251465\n",
      "Loss: 2.9472031593322754, Norm: 0.0007343179313465953, InvBCE: 2.9412875175476074\n",
      "Loss: 2.8047797679901123, Norm: 0.001096838153898716, InvBCE: 2.798848867416382\n",
      "Loss: 2.6376774311065674, Norm: 0.0014570571947842836, InvBCE: 2.6317105293273926\n",
      "Loss: 2.443382978439331, Norm: 0.0018150643445551395, InvBCE: 2.437361001968384\n",
      "Loss: 2.222351551055908, Norm: 0.0021712682209908962, InvBCE: 2.2162561416625977\n",
      "Loss: 1.9808037281036377, Norm: 0.0025263300631195307, InvBCE: 1.974617838859558\n",
      "Loss: 1.7331279516220093, Norm: 0.0028808703646063805, InvBCE: 1.7268352508544922\n",
      "Loss: 1.4997673034667969, Norm: 0.003234836272895336, InvBCE: 1.4933524131774902\n",
      "Loss: 1.3002941608428955, Norm: 0.0035873751621693373, InvBCE: 1.2937427759170532\n",
      "Loss: 1.1447762250900269, Norm: 0.003936117980629206, InvBCE: 1.1380761861801147\n",
      "Image fooled! Adding perturbation...\n",
      "Image 7...\n",
      "Loss: 2.3035948276519775, Norm: 0.0, InvBCE: 2.296736717224121\n",
      "Loss: 1.9053421020507812, Norm: 0.0003838375851046294, InvBCE: 1.8984755277633667\n",
      "Loss: 1.580855131149292, Norm: 0.0007601795950904489, InvBCE: 1.5739614963531494\n",
      "Loss: 1.3234434127807617, Norm: 0.0011282844934612513, InvBCE: 1.3165053129196167\n",
      "Loss: 1.1237831115722656, Norm: 0.0014848279533907771, InvBCE: 1.1167858839035034\n",
      "Loss: 0.9715805053710938, Norm: 0.001828707056120038, InvBCE: 0.9645107984542847\n",
      "Loss: 0.8569134473800659, Norm: 0.0021581484470516443, InvBCE: 0.8497605323791504\n",
      "Image fooled! Adding perturbation...\n",
      "Image 8...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 9...\n",
      "Loss: 1.7237803936004639, Norm: 0.0, InvBCE: 1.716536045074463\n",
      "Loss: 1.3183940649032593, Norm: 0.00038575223879888654, InvBCE: 1.311145305633545\n",
      "Loss: 1.05421781539917, Norm: 0.0007563949911855161, InvBCE: 1.046946406364441\n",
      "Loss: 0.882587194442749, Norm: 0.0011088878381997347, InvBCE: 0.8752774000167847\n",
      "Loss: 0.7686762809753418, Norm: 0.001441191416233778, InvBCE: 0.7613157629966736\n",
      "Image fooled! Adding perturbation...\n",
      "Image 10...\n",
      "Loss: 1.4681323766708374, Norm: 0.0, InvBCE: 1.4607117176055908\n",
      "Loss: 1.0258070230484009, Norm: 0.0003853145462926477, InvBCE: 1.0183546543121338\n",
      "Loss: 0.7650746703147888, Norm: 0.0007431202684529126, InvBCE: 0.7575802206993103\n",
      "Loss: 0.6069244146347046, Norm: 0.001076049404218793, InvBCE: 0.5993804931640625\n",
      "Image fooled! Adding perturbation...\n",
      "Image 11...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 12...\n",
      "Loss: 0.6830503940582275, Norm: 0.0, InvBCE: 0.6754521131515503\n",
      "Image fooled! Adding perturbation...\n",
      "Image 13...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 14...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 15...\n",
      "Loss: 23.406368255615234, Norm: 0.0, InvBCE: 23.398696899414062\n",
      "Loss: 19.10580062866211, Norm: 0.00038741741445846856, InvBCE: 19.098068237304688\n",
      "Loss: 13.23703384399414, Norm: 0.000756474444642663, InvBCE: 13.229227066040039\n",
      "Loss: 7.650238037109375, Norm: 0.0011150839272886515, InvBCE: 7.6423444747924805\n",
      "Loss: 4.238446235656738, Norm: 0.0014639742439612746, InvBCE: 4.23045539855957\n",
      "Loss: 2.6476197242736816, Norm: 0.0017937675584107637, InvBCE: 2.6395249366760254\n",
      "Loss: 1.923466444015503, Norm: 0.0020984183065593243, InvBCE: 1.915265679359436\n",
      "Loss: 1.5532162189483643, Norm: 0.0023773822467774153, InvBCE: 1.544910192489624\n",
      "Loss: 1.3363432884216309, Norm: 0.002632396761327982, InvBCE: 1.3279341459274292\n",
      "Loss: 1.1945817470550537, Norm: 0.002865754533559084, InvBCE: 1.186072826385498\n",
      "Loss: 1.093902587890625, Norm: 0.0030797100625932217, InvBCE: 1.085297703742981\n",
      "Loss: 1.0178518295288086, Norm: 0.0032763134222477674, InvBCE: 1.009155035018921\n",
      "Loss: 0.9578707814216614, Norm: 0.003457373008131981, InvBCE: 0.9490864872932434\n",
      "Loss: 0.9090304374694824, Norm: 0.003624468808993697, InvBCE: 0.9001628756523132\n",
      "Loss: 0.868206799030304, Norm: 0.003778986167162657, InvBCE: 0.8592602610588074\n",
      "Loss: 0.833314061164856, Norm: 0.003922143019735813, InvBCE: 0.8242926597595215\n",
      "Loss: 0.8029657006263733, Norm: 0.00405501713976264, InvBCE: 0.7938733696937561\n",
      "Loss: 0.7762062549591064, Norm: 0.004178566392511129, InvBCE: 0.7670467495918274\n",
      "Loss: 0.7523381114006042, Norm: 0.004293642472475767, InvBCE: 0.7431151270866394\n",
      "Loss: 0.7308388352394104, Norm: 0.004401008132845163, InvBCE: 0.7215557098388672\n",
      "Image 16...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 17...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 18...\n",
      "Loss: 0.5994517803192139, Norm: 0.0, InvBCE: 0.5917801856994629\n",
      "Image fooled! Adding perturbation...\n",
      "Image 19...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 20...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 21...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 22...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 23...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 24...\n",
      "Loss: 0.744041919708252, Norm: 0.0, InvBCE: 0.73630291223526\n",
      "Loss: 0.6645562648773193, Norm: 0.0003807872417382896, InvBCE: 0.6567438244819641\n",
      "Image fooled! Adding perturbation...\n",
      "Image 25...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 26...\n",
      "Loss: 1.4789886474609375, Norm: 0.0, InvBCE: 1.4710884094238281\n",
      "Loss: 1.477461576461792, Norm: 0.00030451774364337325, InvBCE: 1.469722867012024\n",
      "Loss: 1.475691318511963, Norm: 0.0006101586623117328, InvBCE: 1.4681031703948975\n",
      "Loss: 1.4736322164535522, Norm: 0.0009168752585537732, InvBCE: 1.4661827087402344\n",
      "Loss: 1.4712456464767456, Norm: 0.0012246681144461036, InvBCE: 1.4639220237731934\n",
      "Loss: 1.468510389328003, Norm: 0.0015335357747972012, InvBCE: 1.461298942565918\n",
      "Loss: 1.4654310941696167, Norm: 0.0018434590892866254, InvBCE: 1.458317518234253\n",
      "Loss: 1.4620362520217896, Norm: 0.00215438986197114, InvBCE: 1.4550052881240845\n",
      "Loss: 1.458377718925476, Norm: 0.0024661817587912083, InvBCE: 1.451413869857788\n",
      "Loss: 1.454529881477356, Norm: 0.002778565278276801, InvBCE: 1.4476170539855957\n",
      "Loss: 1.4505746364593506, Norm: 0.0030911609064787626, InvBCE: 1.4436967372894287\n",
      "Image fooled! Adding perturbation...\n",
      "Image 27...\n",
      "Loss: 7.0266923904418945, Norm: 0.0, InvBCE: 7.019833564758301\n",
      "Loss: 6.303489685058594, Norm: 0.00038688810309395194, InvBCE: 6.296557426452637\n",
      "Loss: 5.644509315490723, Norm: 0.0007689105113968253, InvBCE: 5.637484073638916\n",
      "Loss: 5.04865837097168, Norm: 0.001146143302321434, InvBCE: 5.041522979736328\n",
      "Loss: 4.513556957244873, Norm: 0.0015175003791227937, InvBCE: 4.506296157836914\n",
      "Loss: 4.035796165466309, Norm: 0.001881963456980884, InvBCE: 4.0283966064453125\n",
      "Loss: 3.611297607421875, Norm: 0.002238602377474308, InvBCE: 3.603748321533203\n",
      "Loss: 3.2355434894561768, Norm: 0.0025866131763905287, InvBCE: 3.2278356552124023\n",
      "Loss: 2.9038898944854736, Norm: 0.002925331937149167, InvBCE: 2.8960165977478027\n",
      "Loss: 2.6117990016937256, Norm: 0.003254231531172991, InvBCE: 2.603755235671997\n",
      "Loss: 2.3550078868865967, Norm: 0.0035729100927710533, InvBCE: 2.346790313720703\n",
      "Loss: 2.12961745262146, Norm: 0.003881077514961362, InvBCE: 2.1212244033813477\n",
      "Loss: 1.9320534467697144, Norm: 0.004178544040769339, InvBCE: 1.923484206199646\n",
      "Loss: 1.7590566873550415, Norm: 0.004465207923203707, InvBCE: 1.7503119707107544\n",
      "Loss: 1.6076819896697998, Norm: 0.004741044249385595, InvBCE: 1.5987634658813477\n",
      "Loss: 1.4752672910690308, Norm: 0.005006098188459873, InvBCE: 1.4661773443222046\n",
      "Loss: 1.3594346046447754, Norm: 0.005260474048554897, InvBCE: 1.3501763343811035\n",
      "Loss: 1.2580668926239014, Norm: 0.005504327826201916, InvBCE: 1.2486438751220703\n",
      "Loss: 1.1692955493927002, Norm: 0.005737858824431896, InvBCE: 1.1597119569778442\n",
      "Loss: 1.0914682149887085, Norm: 0.005961306393146515, InvBCE: 1.0817285776138306\n",
      "Image 28...\n",
      "Loss: 3.4872567653656006, Norm: 0.0, InvBCE: 3.480398178100586\n",
      "Loss: 3.08852219581604, Norm: 0.0003858775889966637, InvBCE: 3.0816245079040527\n",
      "Loss: 2.733362913131714, Norm: 0.0007662911666557193, InvBCE: 2.726405143737793\n",
      "Loss: 2.4202113151550293, Norm: 0.0011410388397052884, InvBCE: 2.4131743907928467\n",
      "Loss: 2.1463875770568848, Norm: 0.0015088076470419765, InvBCE: 2.139254570007324\n",
      "Loss: 1.9084863662719727, Norm: 0.0018683979287743568, InvBCE: 1.9012422561645508\n",
      "Loss: 1.7028393745422363, Norm: 0.002218759385868907, InvBCE: 1.6954715251922607\n",
      "Loss: 1.525846004486084, Norm: 0.0025590003933757544, InvBCE: 1.5183441638946533\n",
      "Loss: 1.3740594387054443, Norm: 0.0028883921913802624, InvBCE: 1.3664156198501587\n",
      "Loss: 1.2442317008972168, Norm: 0.003206372493878007, InvBCE: 1.2364399433135986\n",
      "Loss: 1.1333764791488647, Norm: 0.0035125447902828455, InvBCE: 1.1254329681396484\n",
      "Loss: 1.0388131141662598, Norm: 0.0038066657725721598, InvBCE: 1.0307154655456543\n",
      "Loss: 0.9581624269485474, Norm: 0.0040886299684643745, InvBCE: 0.9499099254608154\n",
      "Loss: 0.8893473148345947, Norm: 0.004358449950814247, InvBCE: 0.8809404969215393\n",
      "Loss: 0.8305745124816895, Norm: 0.00461623864248395, InvBCE: 0.8220149278640747\n",
      "Loss: 0.780301570892334, Norm: 0.0048621902242302895, InvBCE: 0.7715917229652405\n",
      "Loss: 0.7372162342071533, Norm: 0.005096565932035446, InvBCE: 0.7283592820167542\n",
      "Loss: 0.7002017498016357, Norm: 0.005319678690284491, InvBCE: 0.6912014484405518\n",
      "Loss: 0.6683166027069092, Norm: 0.005531882867217064, InvBCE: 0.6591771245002747\n",
      "Image fooled! Adding perturbation...\n",
      "Image 29...\n",
      "Loss: 0.6467954516410828, Norm: 0.0, InvBCE: 0.6375212669372559\n",
      "Loss: 0.5901402235031128, Norm: 0.00037489435635507107, InvBCE: 0.5807816982269287\n",
      "Image fooled! Adding perturbation...\n",
      "Image 30...\n",
      "Loss: 1.0241937637329102, Norm: 0.0, InvBCE: 1.0147422552108765\n",
      "Loss: 0.8463648557662964, Norm: 0.0003822855360340327, InvBCE: 0.8368752002716064\n",
      "Loss: 0.7288422584533691, Norm: 0.0007487527909688652, InvBCE: 0.7193015217781067\n",
      "Image fooled! Adding perturbation...\n",
      "Image 31...\n",
      "Loss: 809.8331298828125, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8329467773438, Norm: 0.00024413669598288834, InvBCE: 809.8235473632812\n",
      "Loss: 809.8327026367188, Norm: 0.000487750192405656, InvBCE: 809.8235473632812\n",
      "Loss: 809.8324584960938, Norm: 0.0007307861815206707, InvBCE: 809.8235473632812\n",
      "Loss: 809.8322143554688, Norm: 0.0009731866302900016, InvBCE: 809.8235473632812\n",
      "Loss: 809.83203125, Norm: 0.0012148896930739284, InvBCE: 809.8235473632812\n",
      "Loss: 809.831787109375, Norm: 0.0014558292459696531, InvBCE: 809.8235473632812\n",
      "Loss: 809.83154296875, Norm: 0.001695935265161097, InvBCE: 809.8235473632812\n",
      "Loss: 809.8313598632812, Norm: 0.0019351334776729345, InvBCE: 809.8235473632812\n",
      "Loss: 809.8311157226562, Norm: 0.0021733446046710014, InvBCE: 809.8235473632812\n",
      "Loss: 809.8309326171875, Norm: 0.0024104854092001915, InvBCE: 809.8235473632812\n",
      "Loss: 809.8306884765625, Norm: 0.002646466949954629, InvBCE: 809.8235473632812\n",
      "Loss: 809.8304443359375, Norm: 0.002881196327507496, InvBCE: 809.8235473632812\n",
      "Loss: 809.8302612304688, Norm: 0.0031145750544965267, InvBCE: 809.8235473632812\n",
      "Loss: 809.830078125, Norm: 0.0033464995212852955, InvBCE: 809.8235473632812\n",
      "Loss: 809.829833984375, Norm: 0.003576861694455147, InvBCE: 809.8235473632812\n",
      "Loss: 809.8296508789062, Norm: 0.003805547021329403, InvBCE: 809.8235473632812\n",
      "Loss: 809.8294067382812, Norm: 0.004032437689602375, InvBCE: 809.8235473632812\n",
      "Loss: 809.8292236328125, Norm: 0.004257408436387777, InvBCE: 809.8235473632812\n",
      "Loss: 809.8290405273438, Norm: 0.004480330739170313, InvBCE: 809.8235473632812\n",
      "Image 32...\n",
      "Loss: 1.832452654838562, Norm: 0.0, InvBCE: 1.8228496313095093\n",
      "Loss: 1.8297492265701294, Norm: 0.00030591190443374217, InvBCE: 1.8202848434448242\n",
      "Loss: 1.8254618644714355, Norm: 0.000609604874625802, InvBCE: 1.816122055053711\n",
      "Loss: 1.8184771537780762, Norm: 0.000910616887267679, InvBCE: 1.8092467784881592\n",
      "Loss: 1.8076890707015991, Norm: 0.0012091835960745811, InvBCE: 1.7985522747039795\n",
      "Loss: 1.792342185974121, Norm: 0.0015067768981680274, InvBCE: 1.7832826375961304\n",
      "Loss: 1.7725621461868286, Norm: 0.0018048291094601154, InvBCE: 1.7635632753372192\n",
      "Loss: 1.7482829093933105, Norm: 0.0021041249856352806, InvBCE: 1.7393287420272827\n",
      "Loss: 1.719421148300171, Norm: 0.002404597122222185, InvBCE: 1.710496425628662\n",
      "Loss: 1.6867456436157227, Norm: 0.00270620989613235, InvBCE: 1.6778360605239868\n",
      "Loss: 1.6514298915863037, Norm: 0.003009388456121087, InvBCE: 1.642521858215332\n",
      "Loss: 1.6147911548614502, Norm: 0.0033146929927170277, InvBCE: 1.6058720350265503\n",
      "Loss: 1.5781184434890747, Norm: 0.003622716059908271, InvBCE: 1.5691760778427124\n",
      "Loss: 1.5420877933502197, Norm: 0.003933347295969725, InvBCE: 1.5331108570098877\n",
      "Loss: 1.5068960189819336, Norm: 0.004245861433446407, InvBCE: 1.4978737831115723\n",
      "Loss: 1.4729679822921753, Norm: 0.004559192340821028, InvBCE: 1.4638901948928833\n",
      "Loss: 1.4409606456756592, Norm: 0.00487197982147336, InvBCE: 1.431817889213562\n",
      "Image fooled! Adding perturbation...\n",
      "Image 33...\n",
      "Loss: 1.4339959621429443, Norm: 0.0, InvBCE: 1.4247798919677734\n",
      "Loss: 1.2563364505767822, Norm: 0.0003830011992249638, InvBCE: 1.2470886707305908\n",
      "Loss: 1.1038368940353394, Norm: 0.0007578526856377721, InvBCE: 1.094543218612671\n",
      "Loss: 0.9768507480621338, Norm: 0.0011240171734243631, InvBCE: 0.9674986600875854\n",
      "Image fooled! Adding perturbation...\n",
      "Image 34...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 35...\n",
      "Loss: 1.8943958282470703, Norm: 0.0, InvBCE: 1.8849745988845825\n",
      "Loss: 1.725500464439392, Norm: 0.0003828004118986428, InvBCE: 1.7160398960113525\n",
      "Loss: 1.5802724361419678, Norm: 0.0007570649031549692, InvBCE: 1.5707581043243408\n",
      "Loss: 1.4551246166229248, Norm: 0.0011243995977565646, InvBCE: 1.4455429315567017\n",
      "Loss: 1.347392201423645, Norm: 0.001483609084971249, InvBCE: 1.3377310037612915\n",
      "Loss: 1.2545921802520752, Norm: 0.0018339782254770398, InvBCE: 1.2448410987854004\n",
      "Loss: 1.1746160984039307, Norm: 0.002175110625103116, InvBCE: 1.1647661924362183\n",
      "Loss: 1.1058615446090698, Norm: 0.0025066640228033066, InvBCE: 1.0959056615829468\n",
      "Loss: 1.046893835067749, Norm: 0.002828216413035989, InvBCE: 1.0368263721466064\n",
      "Loss: 0.9963200092315674, Norm: 0.003139320993795991, InvBCE: 0.9861366748809814\n",
      "Loss: 0.9528083801269531, Norm: 0.0034396806731820107, InvBCE: 0.9425061345100403\n",
      "Loss: 0.91524738073349, Norm: 0.0037290870677679777, InvBCE: 0.9048243761062622\n",
      "Image fooled! Adding perturbation...\n",
      "Image 36...\n",
      "Loss: 1.2331923246383667, Norm: 0.0, InvBCE: 1.222647786140442\n",
      "Loss: 0.899516224861145, Norm: 0.0003804424195550382, InvBCE: 0.8889367580413818\n",
      "Image fooled! Adding perturbation...\n",
      "Image 37...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 38...\n",
      "Loss: 1.5632306337356567, Norm: 0.0, InvBCE: 1.5526094436645508\n",
      "Loss: 1.5260722637176514, Norm: 0.000355313706677407, InvBCE: 1.5155129432678223\n",
      "Loss: 1.4931068420410156, Norm: 0.0007041455828584731, InvBCE: 1.4825979471206665\n",
      "Loss: 1.4647014141082764, Norm: 0.0010479154298081994, InvBCE: 1.4542326927185059\n",
      "Loss: 1.4401808977127075, Norm: 0.001385209267027676, InvBCE: 1.4297429323196411\n",
      "Image fooled! Adding perturbation...\n",
      "Image 39...\n",
      "Loss: 673.4961547851562, Norm: 0.0, InvBCE: 673.4857177734375\n",
      "Loss: 673.4959106445312, Norm: 0.00024333354667760432, InvBCE: 673.4857177734375\n",
      "Loss: 673.4956665039062, Norm: 0.0004861796332988888, InvBCE: 673.4857177734375\n",
      "Loss: 673.4954223632812, Norm: 0.0007284888415597379, InvBCE: 673.4857177734375\n",
      "Loss: 673.4952392578125, Norm: 0.0009702087845653296, InvBCE: 673.4857177734375\n",
      "Loss: 673.4949951171875, Norm: 0.001211283728480339, InvBCE: 673.4857177734375\n",
      "Loss: 673.4947509765625, Norm: 0.001451654825359583, InvBCE: 673.4857177734375\n",
      "Loss: 673.4945678710938, Norm: 0.00169125956017524, InvBCE: 673.4857177734375\n",
      "Loss: 673.4943237304688, Norm: 0.0019300320418551564, InvBCE: 673.4857177734375\n",
      "Loss: 673.494140625, Norm: 0.0021679026540368795, InvBCE: 673.4857177734375\n",
      "Loss: 673.493896484375, Norm: 0.002404798287898302, InvBCE: 673.4857177734375\n",
      "Loss: 673.4937133789062, Norm: 0.0026406417600810528, InvBCE: 673.4857177734375\n",
      "Loss: 673.4934692382812, Norm: 0.0028753518126904964, InvBCE: 673.4857177734375\n",
      "Loss: 673.4932861328125, Norm: 0.0031088441610336304, InvBCE: 673.4857177734375\n",
      "Loss: 673.4930419921875, Norm: 0.0033410298638045788, InvBCE: 673.4857177734375\n",
      "Loss: 673.4928588867188, Norm: 0.003571815323084593, InvBCE: 673.4857177734375\n",
      "Loss: 673.4926147460938, Norm: 0.0038011043798178434, InvBCE: 673.4857177734375\n",
      "Loss: 673.492431640625, Norm: 0.004028795287013054, InvBCE: 673.4857177734375\n",
      "Loss: 673.4922485351562, Norm: 0.004254783969372511, InvBCE: 673.4857177734375\n",
      "Loss: 673.4920043945312, Norm: 0.004478960298001766, InvBCE: 673.4857177734375\n",
      "Image 40...\n",
      "Loss: 16.260467529296875, Norm: 0.0, InvBCE: 16.250051498413086\n",
      "Loss: 13.423807144165039, Norm: 0.0003860057331621647, InvBCE: 13.413372993469238\n",
      "Loss: 10.281885147094727, Norm: 0.0007549436995759606, InvBCE: 10.271416664123535\n",
      "Loss: 8.696951866149902, Norm: 0.0010887469397857785, InvBCE: 8.686443328857422\n",
      "Loss: 7.5773444175720215, Norm: 0.0014076248044148088, InvBCE: 7.566786766052246\n",
      "Loss: 6.611868381500244, Norm: 0.0017138723051175475, InvBCE: 6.601254940032959\n",
      "Loss: 7.76616096496582, Norm: 0.002009375486522913, InvBCE: 7.7554850578308105\n",
      "Loss: 5.257543087005615, Norm: 0.0022237123921513557, InvBCE: 5.246816158294678\n",
      "Loss: 4.818667411804199, Norm: 0.0024160786997526884, InvBCE: 4.807892322540283\n",
      "Loss: 4.484475135803223, Norm: 0.0026190157514065504, InvBCE: 4.473646640777588\n",
      "Loss: 4.206705570220947, Norm: 0.0028268280439078808, InvBCE: 4.195818901062012\n",
      "Loss: 3.976130723953247, Norm: 0.0030356652569025755, InvBCE: 3.9651827812194824\n",
      "Loss: 3.7785439491271973, Norm: 0.0032429571729153395, InvBCE: 3.7675321102142334\n",
      "Loss: 3.616446018218994, Norm: 0.003447021124884486, InvBCE: 3.6053683757781982\n",
      "Loss: 3.47871470451355, Norm: 0.0036468275357037783, InvBCE: 3.4675698280334473\n",
      "Loss: 3.360538959503174, Norm: 0.003841717028990388, InvBCE: 3.3493258953094482\n",
      "Loss: 3.2583189010620117, Norm: 0.004031281918287277, InvBCE: 3.247036933898926\n",
      "Loss: 3.1688618659973145, Norm: 0.004215315915644169, InvBCE: 3.157510757446289\n",
      "Loss: 3.0891852378845215, Norm: 0.004393765237182379, InvBCE: 3.0777647495269775\n",
      "Loss: 3.0170109272003174, Norm: 0.0045666745863854885, InvBCE: 3.005521535873413\n",
      "Image 41...\n",
      "Loss: 1.9797320365905762, Norm: 0.0, InvBCE: 1.9693167209625244\n",
      "Loss: 1.9272915124893188, Norm: 0.00035919234505854547, InvBCE: 1.9169095754623413\n",
      "Loss: 1.871514081954956, Norm: 0.0007155676139518619, InvBCE: 1.8611522912979126\n",
      "Loss: 1.8151832818984985, Norm: 0.0010705712484195828, InvBCE: 1.8048282861709595\n",
      "Loss: 1.7599438428878784, Norm: 0.001423337496817112, InvBCE: 1.7495827674865723\n",
      "Loss: 1.7064152956008911, Norm: 0.0017730926629155874, InvBCE: 1.6960358619689941\n",
      "Loss: 1.6547613143920898, Norm: 0.0021192871499806643, InvBCE: 1.644351601600647\n",
      "Loss: 1.6051524877548218, Norm: 0.00246176915243268, InvBCE: 1.5947009325027466\n",
      "Loss: 1.5579708814620972, Norm: 0.00280071166343987, InvBCE: 1.5474663972854614\n",
      "Loss: 1.5137732028961182, Norm: 0.003136354498565197, InvBCE: 1.5032051801681519\n",
      "Loss: 1.4731194972991943, Norm: 0.0034688280429691076, InvBCE: 1.4624780416488647\n",
      "Loss: 1.4363740682601929, Norm: 0.003798087127506733, InvBCE: 1.4256500005722046\n",
      "Loss: 1.4035733938217163, Norm: 0.004123914521187544, InvBCE: 1.3927583694458008\n",
      "Image fooled! Adding perturbation...\n",
      "Image 42...\n",
      "Loss: 2.1479291915893555, Norm: 0.0, InvBCE: 2.1370155811309814\n",
      "Loss: 2.051557779312134, Norm: 0.0003651560109574348, InvBCE: 2.040623426437378\n",
      "Loss: 1.9394513368606567, Norm: 0.00072694499976933, InvBCE: 1.928483247756958\n",
      "Loss: 1.8366872072219849, Norm: 0.0010876444866880774, InvBCE: 1.8256734609603882\n",
      "Loss: 1.7494467496871948, Norm: 0.0014461755054071546, InvBCE: 1.738376498222351\n",
      "Loss: 1.675818920135498, Norm: 0.0018017060356214643, InvBCE: 1.6646820306777954\n",
      "Loss: 1.5674633979797363, Norm: 0.0021526289638131857, InvBCE: 1.556250810623169\n",
      "Loss: 1.5241670608520508, Norm: 0.0024954776745289564, InvBCE: 1.5128722190856934\n",
      "Loss: 1.488288402557373, Norm: 0.0028296567033976316, InvBCE: 1.4769057035446167\n",
      "Loss: 1.4229921102523804, Norm: 0.0031558843329548836, InvBCE: 1.411516547203064\n",
      "Loss: 1.3801442384719849, Norm: 0.003476356389001012, InvBCE: 1.3685697317123413\n",
      "Image fooled! Adding perturbation...\n",
      "Image 43...\n",
      "Loss: 809.835205078125, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8350219726562, Norm: 0.0002421973185846582, InvBCE: 809.8235473632812\n",
      "Loss: 809.8347778320312, Norm: 0.00048394539044238627, InvBCE: 809.8235473632812\n",
      "Loss: 809.8345336914062, Norm: 0.0007252008654177189, InvBCE: 809.8235473632812\n",
      "Loss: 809.8343505859375, Norm: 0.0009659181232564151, InvBCE: 809.8235473632812\n",
      "Loss: 809.8341064453125, Norm: 0.001206049113534391, InvBCE: 809.8235473632812\n",
      "Loss: 809.8338623046875, Norm: 0.0014455433702096343, InvBCE: 809.8235473632812\n",
      "Loss: 809.8336791992188, Norm: 0.0016843476332724094, InvBCE: 809.8235473632812\n",
      "Loss: 809.8334350585938, Norm: 0.0019224067218601704, InvBCE: 809.8235473632812\n",
      "Loss: 809.833251953125, Norm: 0.002159662311896682, InvBCE: 809.8235473632812\n",
      "Loss: 809.8330078125, Norm: 0.0023960541002452374, InvBCE: 809.8235473632812\n",
      "Loss: 809.832763671875, Norm: 0.0026315185241401196, InvBCE: 809.8235473632812\n",
      "Loss: 809.8325805664062, Norm: 0.002865989925339818, InvBCE: 809.8235473632812\n",
      "Loss: 809.8323364257812, Norm: 0.0030993998516350985, InvBCE: 809.8235473632812\n",
      "Loss: 809.8321533203125, Norm: 0.003331677755340934, InvBCE: 809.8235473632812\n",
      "Loss: 809.8319702148438, Norm: 0.003562749596312642, InvBCE: 809.8235473632812\n",
      "Loss: 809.8317260742188, Norm: 0.003792539471760392, InvBCE: 809.8235473632812\n",
      "Loss: 809.83154296875, Norm: 0.00402096938341856, InvBCE: 809.8235473632812\n",
      "Loss: 809.831298828125, Norm: 0.004247957840561867, InvBCE: 809.8235473632812\n",
      "Loss: 809.8311157226562, Norm: 0.004473422653973103, InvBCE: 809.8235473632812\n",
      "Image 44...\n",
      "Loss: 1.3595608472824097, Norm: 0.0, InvBCE: 1.347882866859436\n",
      "Loss: 1.2133476734161377, Norm: 0.00038113113259896636, InvBCE: 1.2015856504440308\n",
      "Loss: 1.0989477634429932, Norm: 0.0007529814029112458, InvBCE: 1.0870915651321411\n",
      "Loss: 1.0103453397750854, Norm: 0.0011148275807499886, InvBCE: 0.9983869791030884\n",
      "Loss: 0.9421093463897705, Norm: 0.0014650250086560845, InvBCE: 0.9300428628921509\n",
      "Loss: 0.8887263536453247, Norm: 0.001802720595151186, InvBCE: 0.8765476942062378\n",
      "Loss: 0.8461570739746094, Norm: 0.0021279247011989355, InvBCE: 0.8338635563850403\n",
      "Loss: 0.81080162525177, Norm: 0.0024409948382526636, InvBCE: 0.7983916997909546\n",
      "Loss: 0.7801588177680969, Norm: 0.002742778044193983, InvBCE: 0.7676317691802979\n",
      "Loss: 0.7533097863197327, Norm: 0.0030340959783643484, InvBCE: 0.7406653761863708\n",
      "Loss: 0.7292442321777344, Norm: 0.003315488575026393, InvBCE: 0.7164826393127441\n",
      "Image fooled! Adding perturbation...\n",
      "Image 45...\n",
      "Loss: 1.5008689165115356, Norm: 0.0, InvBCE: 1.4879902601242065\n",
      "Loss: 1.4804224967956543, Norm: 0.00035800060140900314, InvBCE: 1.4675313234329224\n",
      "Loss: 1.4610776901245117, Norm: 0.0007125973934307694, InvBCE: 1.4481669664382935\n",
      "Loss: 1.4427754878997803, Norm: 0.0010644426802173257, InvBCE: 1.4298384189605713\n",
      "Loss: 1.4254604578018188, Norm: 0.0014135421952232718, InvBCE: 1.4124904870986938\n",
      "Image fooled! Adding perturbation...\n",
      "Image 46...\n",
      "Loss: 2.537174940109253, Norm: 0.0, InvBCE: 2.524165630340576\n",
      "Loss: 2.060513973236084, Norm: 0.00038103267434053123, InvBCE: 2.0474979877471924\n",
      "Loss: 1.70013427734375, Norm: 0.0007480502245016396, InvBCE: 1.6871044635772705\n",
      "Loss: 1.424634337425232, Norm: 0.0011025252752006054, InvBCE: 1.4115840196609497\n",
      "Loss: 1.2110333442687988, Norm: 0.001443035900592804, InvBCE: 1.1979565620422363\n",
      "Loss: 1.0434479713439941, Norm: 0.0017687665531411767, InvBCE: 1.0303397178649902\n",
      "Loss: 0.9111685156822205, Norm: 0.002079433063045144, InvBCE: 0.8980247378349304\n",
      "Loss: 0.8064359426498413, Norm: 0.0023751333355903625, InvBCE: 0.7932534217834473\n",
      "Loss: 0.7231911420822144, Norm: 0.002656165510416031, InvBCE: 0.7099674940109253\n",
      "Loss: 0.6568673253059387, Norm: 0.002922958694398403, InvBCE: 0.6436008810997009\n",
      "Loss: 0.6039949655532837, Norm: 0.003175976686179638, InvBCE: 0.590684711933136\n",
      "Loss: 0.5612930655479431, Norm: 0.003415752202272415, InvBCE: 0.5479384660720825\n",
      "Loss: 0.5262274146080017, Norm: 0.0036429117899388075, InvBCE: 0.5128284096717834\n",
      "Loss: 0.49712711572647095, Norm: 0.0038581080734729767, InvBCE: 0.4836840033531189\n",
      "Image fooled! Adding perturbation...\n",
      "Image 47...\n",
      "Loss: 1.17768132686615, Norm: 0.0, InvBCE: 1.1641947031021118\n",
      "Image fooled! Adding perturbation...\n",
      "Image 48...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 49...\n",
      "Loss: 1.345641016960144, Norm: 0.0, InvBCE: 1.3321106433868408\n",
      "Image fooled! Adding perturbation...\n",
      "Image 50...\n",
      "Loss: 809.8370971679688, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8369140625, Norm: 0.00024144780763890594, InvBCE: 809.8235473632812\n",
      "Loss: 809.836669921875, Norm: 0.00048250806867145, InvBCE: 809.8235473632812\n",
      "Loss: 809.83642578125, Norm: 0.0007231457275338471, InvBCE: 809.8235473632812\n",
      "Loss: 809.8362426757812, Norm: 0.0009633239242248237, InvBCE: 809.8235473632812\n",
      "Loss: 809.8359985351562, Norm: 0.001203004503622651, InvBCE: 809.8235473632812\n",
      "Loss: 809.8357543945312, Norm: 0.0014421475352719426, InvBCE: 809.8235473632812\n",
      "Loss: 809.8355712890625, Norm: 0.001680711517110467, InvBCE: 809.8235473632812\n",
      "Loss: 809.8353271484375, Norm: 0.0019186532590538263, InvBCE: 809.8235473632812\n",
      "Loss: 809.8350830078125, Norm: 0.002155928174033761, InvBCE: 809.8235473632812\n",
      "Loss: 809.8348999023438, Norm: 0.0023924901615828276, InvBCE: 809.8235473632812\n",
      "Loss: 809.8346557617188, Norm: 0.002628291491419077, InvBCE: 809.8235473632812\n",
      "Loss: 809.83447265625, Norm: 0.0028632828034460545, InvBCE: 809.8235473632812\n",
      "Loss: 809.834228515625, Norm: 0.0030974135734140873, InvBCE: 809.8235473632812\n",
      "Loss: 809.8340454101562, Norm: 0.003330631647258997, InvBCE: 809.8235473632812\n",
      "Loss: 809.8338012695312, Norm: 0.0035628837067633867, InvBCE: 809.8235473632812\n",
      "Loss: 809.8336181640625, Norm: 0.0037941152695566416, InvBCE: 809.8235473632812\n",
      "Loss: 809.8333740234375, Norm: 0.00402426952496171, InvBCE: 809.8235473632812\n",
      "Loss: 809.8331909179688, Norm: 0.00425328966230154, InvBCE: 809.8235473632812\n",
      "Loss: 809.8330078125, Norm: 0.004481117241084576, InvBCE: 809.8235473632812\n",
      "Image 51...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 52...\n",
      "Loss: 1.3540962934494019, Norm: 0.0, InvBCE: 1.3405274152755737\n",
      "Loss: 1.321170687675476, Norm: 0.0003694486222229898, InvBCE: 1.3076177835464478\n",
      "Loss: 1.2889620065689087, Norm: 0.0007361735915765166, InvBCE: 1.275416374206543\n",
      "Loss: 1.2575054168701172, Norm: 0.0011005796259269118, InvBCE: 1.2439582347869873\n",
      "Loss: 1.2268664836883545, Norm: 0.00146241404581815, InvBCE: 1.2133092880249023\n",
      "Image fooled! Adding perturbation...\n",
      "Image 53...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 54...\n",
      "Loss: 1.460415005683899, Norm: 0.0, InvBCE: 1.446839451789856\n",
      "Image fooled! Adding perturbation...\n",
      "Image 55...\n",
      "Loss: 1.5712071657180786, Norm: 0.0, InvBCE: 1.557742714881897\n",
      "Loss: 1.4101436138153076, Norm: 0.0003786792221944779, InvBCE: 1.3966598510742188\n",
      "Loss: 1.2744473218917847, Norm: 0.0007472564466297626, InvBCE: 1.2609342336654663\n",
      "Loss: 1.163114309310913, Norm: 0.0011072764173150063, InvBCE: 1.149562954902649\n",
      "Loss: 1.0730187892913818, Norm: 0.0014568627811968327, InvBCE: 1.0594220161437988\n",
      "Image fooled! Adding perturbation...\n",
      "Image 56...\n",
      "Loss: 3.309417963027954, Norm: 0.0, InvBCE: 3.2957699298858643\n",
      "Loss: 2.5280866622924805, Norm: 0.0003832387155853212, InvBCE: 2.514380693435669\n",
      "Loss: 1.941176176071167, Norm: 0.0007532871095463634, InvBCE: 1.927406907081604\n",
      "Loss: 1.5111005306243896, Norm: 0.0011105862213298678, InvBCE: 1.4972639083862305\n",
      "Loss: 1.2015258073806763, Norm: 0.001452721655368805, InvBCE: 1.1876189708709717\n",
      "Loss: 0.9804178476333618, Norm: 0.0017779279733076692, InvBCE: 0.9664389491081238\n",
      "Loss: 0.8221201300621033, Norm: 0.002085267100483179, InvBCE: 0.8080684542655945\n",
      "Loss: 0.7075603604316711, Norm: 0.002374527044594288, InvBCE: 0.6934360265731812\n",
      "Loss: 0.6233017444610596, Norm: 0.0026460341177880764, InvBCE: 0.60910564661026\n",
      "Loss: 0.5601994395256042, Norm: 0.002900461433455348, InvBCE: 0.545932948589325\n",
      "Loss: 0.5120857357978821, Norm: 0.003138663014397025, InvBCE: 0.4977506697177887\n",
      "Loss: 0.47475892305374146, Norm: 0.0033615746069699526, InvBCE: 0.4603574275970459\n",
      "Loss: 0.44531893730163574, Norm: 0.003570150351151824, InvBCE: 0.43085330724716187\n",
      "Loss: 0.42173972725868225, Norm: 0.0037653231993317604, InvBCE: 0.40721240639686584\n",
      "Image fooled! Adding perturbation...\n",
      "Image 57...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 58...\n",
      "Loss: 1.6685428619384766, Norm: 0.0, InvBCE: 1.653956413269043\n",
      "Loss: 1.6307638883590698, Norm: 0.0003715117636602372, InvBCE: 1.6162232160568237\n",
      "Loss: 1.5902001857757568, Norm: 0.0007393356645479798, InvBCE: 1.5756981372833252\n",
      "Loss: 1.547118067741394, Norm: 0.0011042411206290126, InvBCE: 1.532647728919983\n",
      "Loss: 1.5030397176742554, Norm: 0.0014668579678982496, InvBCE: 1.4885942935943604\n",
      "Loss: 1.45876944065094, Norm: 0.0018271468579769135, InvBCE: 1.4443418979644775\n",
      "Loss: 1.415534496307373, Norm: 0.002184696029871702, InvBCE: 1.4011180400848389\n",
      "Image fooled! Adding perturbation...\n",
      "Image 59...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 60...\n",
      "Loss: 809.8379516601562, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8377075195312, Norm: 0.00024047076294664294, InvBCE: 809.8235473632812\n",
      "Loss: 809.8375244140625, Norm: 0.00048056719242595136, InvBCE: 809.8235473632812\n",
      "Loss: 809.8372802734375, Norm: 0.0007202562410384417, InvBCE: 809.8235473632812\n",
      "Loss: 809.8370361328125, Norm: 0.0009595037554390728, InvBCE: 809.8235473632812\n",
      "Loss: 809.8368530273438, Norm: 0.0011982738506048918, InvBCE: 809.8235473632812\n",
      "Loss: 809.8366088867188, Norm: 0.0014365296810865402, InvBCE: 809.8235473632812\n",
      "Loss: 809.83642578125, Norm: 0.0016742327716201544, InvBCE: 809.8235473632812\n",
      "Loss: 809.836181640625, Norm: 0.0019113437738269567, InvBCE: 809.8235473632812\n",
      "Loss: 809.8359375, Norm: 0.0021478214766830206, InvBCE: 809.8235473632812\n",
      "Loss: 809.8357543945312, Norm: 0.002383623970672488, InvBCE: 809.8235473632812\n",
      "Loss: 809.8355102539062, Norm: 0.0026187077164649963, InvBCE: 809.8235473632812\n",
      "Loss: 809.8353271484375, Norm: 0.0028530284762382507, InvBCE: 809.8235473632812\n",
      "Loss: 809.8350830078125, Norm: 0.003086540848016739, InvBCE: 809.8235473632812\n",
      "Loss: 809.8348999023438, Norm: 0.0033191973343491554, InvBCE: 809.8235473632812\n",
      "Loss: 809.8346557617188, Norm: 0.0035509513691067696, InvBCE: 809.8235473632812\n",
      "Loss: 809.83447265625, Norm: 0.0037817538250237703, InvBCE: 809.8235473632812\n",
      "Loss: 809.834228515625, Norm: 0.004011555574834347, InvBCE: 809.8235473632812\n",
      "Loss: 809.8340454101562, Norm: 0.004240305628627539, InvBCE: 809.8235473632812\n",
      "Loss: 809.8338623046875, Norm: 0.0044679539278149605, InvBCE: 809.8235473632812\n",
      "Image 61...\n",
      "Loss: 0.7653757929801941, Norm: 0.0, InvBCE: 0.7509637475013733\n",
      "Image fooled! Adding perturbation...\n",
      "Image 62...\n",
      "Loss: 2.0945706367492676, Norm: 0.0, InvBCE: 2.0801217555999756\n",
      "Loss: 1.7051920890808105, Norm: 0.0003844794991891831, InvBCE: 1.6907087564468384\n",
      "Loss: 1.4529894590377808, Norm: 0.000743072887416929, InvBCE: 1.4384610652923584\n",
      "Loss: 1.268280029296875, Norm: 0.0010880305198952556, InvBCE: 1.2536988258361816\n",
      "Loss: 1.1288527250289917, Norm: 0.0014196360716596246, InvBCE: 1.1142126321792603\n",
      "Loss: 1.0204787254333496, Norm: 0.0017379707423970103, InvBCE: 1.005774974822998\n",
      "Loss: 0.9345123171806335, Norm: 0.0020432579331099987, InvBCE: 0.9197413921356201\n",
      "Loss: 0.8650396466255188, Norm: 0.0023357782047241926, InvBCE: 0.8501988649368286\n",
      "Loss: 0.8082675337791443, Norm: 0.0026158529799431562, InvBCE: 0.7933551669120789\n",
      "Image fooled! Adding perturbation...\n",
      "Image 63...\n",
      "Loss: 1.90926992893219, Norm: 0.0, InvBCE: 1.894284963607788\n",
      "Loss: 1.8639920949935913, Norm: 0.00037107759271748364, InvBCE: 1.8490519523620605\n",
      "Loss: 1.8171272277832031, Norm: 0.0007399154710583389, InvBCE: 1.8022245168685913\n",
      "Loss: 1.7689481973648071, Norm: 0.0011077034287154675, InvBCE: 1.7540756464004517\n",
      "Loss: 1.7196227312088013, Norm: 0.0014745441731065512, InvBCE: 1.704772710800171\n",
      "Loss: 1.6692872047424316, Norm: 0.0018401461420580745, InvBCE: 1.6544525623321533\n",
      "Loss: 1.618062138557434, Norm: 0.002204200252890587, InvBCE: 1.6032359600067139\n",
      "Loss: 1.5662957429885864, Norm: 0.002566837938502431, InvBCE: 1.5514711141586304\n",
      "Loss: 1.5141894817352295, Norm: 0.0029279033187776804, InvBCE: 1.4993597269058228\n",
      "Loss: 1.4620745182037354, Norm: 0.003286688821390271, InvBCE: 1.4472339153289795\n",
      "Loss: 1.4104264974594116, Norm: 0.003643038449808955, InvBCE: 1.3955693244934082\n",
      "Loss: 1.3598250150680542, Norm: 0.003997217398136854, InvBCE: 1.3449450731277466\n",
      "Image fooled! Adding perturbation...\n",
      "Image 64...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 65...\n",
      "Loss: 1.609524130821228, Norm: 0.0, InvBCE: 1.5946154594421387\n",
      "Loss: 1.4437898397445679, Norm: 0.00037938845343887806, InvBCE: 1.4288609027862549\n",
      "Loss: 1.2943209409713745, Norm: 0.0007550395675934851, InvBCE: 1.2793632745742798\n",
      "Loss: 1.1619069576263428, Norm: 0.0011260593309998512, InvBCE: 1.1469128131866455\n",
      "Loss: 1.0469704866409302, Norm: 0.0014910585014149547, InvBCE: 1.0319329500198364\n",
      "Loss: 0.9492392539978027, Norm: 0.001848540036007762, InvBCE: 0.9341521859169006\n",
      "Image fooled! Adding perturbation...\n",
      "Image 66...\n",
      "Loss: 1.5496909618377686, Norm: 0.0, InvBCE: 1.5345492362976074\n",
      "Loss: 1.4970368146896362, Norm: 0.00037513780989684165, InvBCE: 1.4819159507751465\n",
      "Loss: 1.445960521697998, Norm: 0.000746538455132395, InvBCE: 1.4308522939682007\n",
      "Loss: 1.3970327377319336, Norm: 0.0011142803123220801, InvBCE: 1.3819293975830078\n",
      "Loss: 1.3508706092834473, Norm: 0.001477452926337719, InvBCE: 1.3357652425765991\n",
      "Image fooled! Adding perturbation...\n",
      "Image 67...\n",
      "Loss: 4.065278053283691, Norm: 0.0, InvBCE: 4.050164699554443\n",
      "Loss: 2.9926986694335938, Norm: 0.00038545261486433446, InvBCE: 2.977543354034424\n",
      "Loss: 2.2105441093444824, Norm: 0.0007573072798550129, InvBCE: 2.1953392028808594\n",
      "Loss: 1.671013593673706, Norm: 0.0011146392207592726, InvBCE: 1.6557533740997314\n",
      "Loss: 1.3091057538986206, Norm: 0.001453889301046729, InvBCE: 1.2937867641448975\n",
      "Loss: 1.0652339458465576, Norm: 0.0017731287516653538, InvBCE: 1.0498545169830322\n",
      "Loss: 0.897194504737854, Norm: 0.002072019036859274, InvBCE: 0.8817542791366577\n",
      "Loss: 0.7785764932632446, Norm: 0.002351101953536272, InvBCE: 0.7630760073661804\n",
      "Loss: 0.6929003000259399, Norm: 0.00261132069863379, InvBCE: 0.6773406863212585\n",
      "Loss: 0.6296440362930298, Norm: 0.0028537760954350233, InvBCE: 0.6140269041061401\n",
      "Loss: 0.5819301605224609, Norm: 0.003079634625464678, InvBCE: 0.5662574172019958\n",
      "Image fooled! Adding perturbation...\n",
      "Image 68...\n",
      "Loss: 1.450674295425415, Norm: 0.0, InvBCE: 1.4349479675292969\n",
      "Loss: 1.3754509687423706, Norm: 0.0003757942176889628, InvBCE: 1.3597546815872192\n",
      "Image fooled! Adding perturbation...\n",
      "Image 69...\n",
      "Loss: 3.7364349365234375, Norm: 0.0, InvBCE: 3.7207608222961426\n",
      "Loss: 3.1526527404785156, Norm: 0.00038299610605463386, InvBCE: 3.1369402408599854\n",
      "Loss: 2.6685407161712646, Norm: 0.0007573069306090474, InvBCE: 2.6527812480926514\n",
      "Loss: 2.27136492729187, Norm: 0.0011232227552682161, InvBCE: 2.2555508613586426\n",
      "Loss: 1.9471766948699951, Norm: 0.0014791588764637709, InvBCE: 1.931301474571228\n",
      "Loss: 1.6837774515151978, Norm: 0.0018240122590214014, InvBCE: 1.6678353548049927\n",
      "Loss: 1.470572829246521, Norm: 0.002156988950446248, InvBCE: 1.454559564590454\n",
      "Loss: 1.298540711402893, Norm: 0.0024775387719273567, InvBCE: 1.2824530601501465\n",
      "Loss: 1.1598734855651855, Norm: 0.0027852996718138456, InvBCE: 1.1437091827392578\n",
      "Loss: 1.047794222831726, Norm: 0.0030800949316471815, InvBCE: 1.0315518379211426\n",
      "Loss: 0.9567952752113342, Norm: 0.00336192618124187, InvBCE: 0.9404743313789368\n",
      "Loss: 0.8824918270111084, Norm: 0.003630915656685829, InvBCE: 0.866092324256897\n",
      "Loss: 0.8213343024253845, Norm: 0.003887312253937125, InvBCE: 0.8048567175865173\n",
      "Loss: 0.7705915570259094, Norm: 0.004131446126848459, InvBCE: 0.7540369033813477\n",
      "Loss: 0.7281550765037537, Norm: 0.004363715182989836, InvBCE: 0.7115246057510376\n",
      "Loss: 0.6923685073852539, Norm: 0.004584568552672863, InvBCE: 0.6756637692451477\n",
      "Loss: 0.6619112491607666, Norm: 0.004794497042894363, InvBCE: 0.6451339721679688\n",
      "Loss: 0.635738730430603, Norm: 0.004994023125618696, InvBCE: 0.6188908815383911\n",
      "Loss: 0.6130504012107849, Norm: 0.005183674860745668, InvBCE: 0.5961340665817261\n",
      "Loss: 0.5932395458221436, Norm: 0.0053639840334653854, InvBCE: 0.5762567520141602\n",
      "Image 70...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 71...\n",
      "Loss: 6.120460033416748, Norm: 0.0, InvBCE: 6.104785919189453\n",
      "Loss: 5.358191013336182, Norm: 0.0003805184387601912, InvBCE: 5.342459678649902\n",
      "Loss: 4.689567565917969, Norm: 0.0007539226207882166, InvBCE: 4.673771858215332\n",
      "Loss: 4.109312057495117, Norm: 0.0011207656934857368, InvBCE: 4.093445301055908\n",
      "Loss: 3.6098413467407227, Norm: 0.0014796266332268715, InvBCE: 3.593897581100464\n",
      "Loss: 3.1818480491638184, Norm: 0.001829350832849741, InvBCE: 3.165822744369507\n",
      "Loss: 2.8146770000457764, Norm: 0.0021691517904400826, InvBCE: 2.7985661029815674\n",
      "Loss: 2.4994699954986572, Norm: 0.0024985563941299915, InvBCE: 2.4832706451416016\n",
      "Loss: 2.2284188270568848, Norm: 0.002817300148308277, InvBCE: 2.2121288776397705\n",
      "Loss: 1.9952737092971802, Norm: 0.0031252854969352484, InvBCE: 1.9788917303085327\n",
      "Loss: 1.7948510646820068, Norm: 0.0034224912524223328, InvBCE: 1.7783762216567993\n",
      "Loss: 1.6220473051071167, Norm: 0.0037089595571160316, InvBCE: 1.60547935962677\n",
      "Loss: 1.4730273485183716, Norm: 0.003984762355685234, InvBCE: 1.4563665390014648\n",
      "Loss: 1.3443561792373657, Norm: 0.004250025376677513, InvBCE: 1.3276031017303467\n",
      "Loss: 1.233059287071228, Norm: 0.0045049116015434265, InvBCE: 1.216214895248413\n",
      "Loss: 1.1365256309509277, Norm: 0.004749615676701069, InvBCE: 1.1195913553237915\n",
      "Loss: 1.0527894496917725, Norm: 0.004984347149729729, InvBCE: 1.0357667207717896\n",
      "Loss: 0.9800646305084229, Norm: 0.005209347233176231, InvBCE: 0.9629554152488708\n",
      "Loss: 0.916681706905365, Norm: 0.005424845032393932, InvBCE: 0.8994879126548767\n",
      "Loss: 0.8613649606704712, Norm: 0.005631128791719675, InvBCE: 0.8440887331962585\n",
      "Image 72...\n",
      "Loss: 2.5331645011901855, Norm: 0.0, InvBCE: 2.5174903869628906\n",
      "Loss: 2.3438735008239746, Norm: 0.00038198669790290296, InvBCE: 2.3281517028808594\n",
      "Loss: 2.1630587577819824, Norm: 0.0007584089180454612, InvBCE: 2.1472818851470947\n",
      "Loss: 1.9943376779556274, Norm: 0.0011306211818009615, InvBCE: 1.978499412536621\n",
      "Loss: 1.840032696723938, Norm: 0.0014978130348026752, InvBCE: 1.824126958847046\n",
      "Loss: 1.7013078927993774, Norm: 0.0018589904066175222, InvBCE: 1.6853296756744385\n",
      "Loss: 1.578360676765442, Norm: 0.0022131246514618397, InvBCE: 1.5623058080673218\n",
      "Loss: 1.4706125259399414, Norm: 0.002559300744906068, InvBCE: 1.4544774293899536\n",
      "Loss: 1.3769445419311523, Norm: 0.0028967680409550667, InvBCE: 1.3607265949249268\n",
      "Loss: 1.2959157228469849, Norm: 0.0032249107025563717, InvBCE: 1.2796128988265991\n",
      "Loss: 1.2259496450424194, Norm: 0.003543261671438813, InvBCE: 1.209560513496399\n",
      "Loss: 1.1655309200286865, Norm: 0.0038514931220561266, InvBCE: 1.1490546464920044\n",
      "Loss: 1.1132901906967163, Norm: 0.004149394575506449, InvBCE: 1.096726417541504\n",
      "Loss: 1.0680450201034546, Norm: 0.004436877090483904, InvBCE: 1.051393985748291\n",
      "Image fooled! Adding perturbation...\n",
      "Image 73...\n",
      "Loss: 1.134860873222351, Norm: 0.0, InvBCE: 1.1181232929229736\n",
      "Image fooled! Adding perturbation...\n",
      "Image 74...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 75...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 76...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 77...\n",
      "Loss: 1.1827577352523804, Norm: 0.0, InvBCE: 1.1659431457519531\n",
      "Loss: 1.0716135501861572, Norm: 0.0003788632166106254, InvBCE: 1.0547444820404053\n",
      "Image fooled! Adding perturbation...\n",
      "Image 78...\n",
      "Loss: 1.4196916818618774, Norm: 0.0, InvBCE: 1.4027643203735352\n",
      "Loss: 1.3541499376296997, Norm: 0.0003755532088689506, InvBCE: 1.3372684717178345\n",
      "Image fooled! Adding perturbation...\n",
      "Image 79...\n",
      "Loss: 809.8403930664062, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8401489257812, Norm: 0.0002402724203420803, InvBCE: 809.8235473632812\n",
      "Loss: 809.8399658203125, Norm: 0.0004802196053788066, InvBCE: 809.8235473632812\n",
      "Loss: 809.8397216796875, Norm: 0.0007198139210231602, InvBCE: 809.8235473632812\n",
      "Loss: 809.8394775390625, Norm: 0.0009590266854502261, InvBCE: 809.8235473632812\n",
      "Loss: 809.8392944335938, Norm: 0.001197828445583582, InvBCE: 809.8235473632812\n",
      "Loss: 809.8390502929688, Norm: 0.0014361884677782655, InvBCE: 809.8235473632812\n",
      "Loss: 809.8388671875, Norm: 0.0016740757273510098, InvBCE: 809.8235473632812\n",
      "Loss: 809.838623046875, Norm: 0.0019114576280117035, InvBCE: 809.8235473632812\n",
      "Loss: 809.83837890625, Norm: 0.0021483013406395912, InvBCE: 809.8235473632812\n",
      "Loss: 809.8381958007812, Norm: 0.0023845727555453777, InvBCE: 809.8235473632812\n",
      "Loss: 809.8379516601562, Norm: 0.002620237646624446, InvBCE: 809.8235473632812\n",
      "Loss: 809.8377685546875, Norm: 0.002855260157957673, InvBCE: 809.8235473632812\n",
      "Loss: 809.8375244140625, Norm: 0.0030896044336259365, InvBCE: 809.8235473632812\n",
      "Loss: 809.8373413085938, Norm: 0.0033232341520488262, InvBCE: 809.8235473632812\n",
      "Loss: 809.8370971679688, Norm: 0.0035561115946620703, InvBCE: 809.8235473632812\n",
      "Loss: 809.8369140625, Norm: 0.0037881992757320404, InvBCE: 809.8235473632812\n",
      "Loss: 809.836669921875, Norm: 0.004019459709525108, InvBCE: 809.8235473632812\n",
      "Loss: 809.8364868164062, Norm: 0.004249852616339922, InvBCE: 809.8235473632812\n",
      "Loss: 809.8362426757812, Norm: 0.004479340277612209, InvBCE: 809.8235473632812\n",
      "Image 80...\n",
      "Loss: 0.814136266708374, Norm: 0.0, InvBCE: 0.7972944378852844\n",
      "Loss: 0.6634925603866577, Norm: 0.00038267963100224733, InvBCE: 0.6466253399848938\n",
      "Loss: 0.5644270777702332, Norm: 0.0007478717598132789, InvBCE: 0.5475296974182129\n",
      "Image fooled! Adding perturbation...\n",
      "Image 81...\n",
      "Loss: 1.4046872854232788, Norm: 0.0, InvBCE: 1.3877564668655396\n",
      "Loss: 1.200011134147644, Norm: 0.0003844290040433407, InvBCE: 1.1830500364303589\n",
      "Loss: 1.045797348022461, Norm: 0.0007588693988509476, InvBCE: 1.0288012027740479\n",
      "Loss: 0.9295070767402649, Norm: 0.0011219852603971958, InvBCE: 0.9124718308448792\n",
      "Loss: 0.841172456741333, Norm: 0.001471877214498818, InvBCE: 0.8240945339202881\n",
      "Loss: 0.7733320593833923, Norm: 0.0018074569525197148, InvBCE: 0.7562084197998047\n",
      "Image fooled! Adding perturbation...\n",
      "Image 82...\n",
      "Loss: 0.911156952381134, Norm: 0.0, InvBCE: 0.8939852714538574\n",
      "Loss: 0.7742387056350708, Norm: 0.0003813458897639066, InvBCE: 0.7570433020591736\n",
      "Image fooled! Adding perturbation...\n",
      "Image 83...\n",
      "Loss: 0.6178063154220581, Norm: 0.0, InvBCE: 0.6005812883377075\n",
      "Loss: 0.543138861656189, Norm: 0.0003797559184022248, InvBCE: 0.525860071182251\n",
      "Loss: 0.488264799118042, Norm: 0.0007484136149287224, InvBCE: 0.470929354429245\n",
      "Image fooled! Adding perturbation...\n",
      "Image 84...\n",
      "Loss: 1.4530892372131348, Norm: 0.0, InvBCE: 1.4356951713562012\n",
      "Loss: 1.2406034469604492, Norm: 0.00038437635521404445, InvBCE: 1.2231448888778687\n",
      "Loss: 1.074414849281311, Norm: 0.0007609962485730648, InvBCE: 1.0568852424621582\n",
      "Loss: 0.9447113275527954, Norm: 0.0011287120869383216, InvBCE: 0.9271048903465271\n",
      "Loss: 0.8430157899856567, Norm: 0.001485931919887662, InvBCE: 0.82532799243927\n",
      "Loss: 0.7625929117202759, Norm: 0.0018316047498956323, InvBCE: 0.744820237159729\n",
      "Loss: 0.6983257532119751, Norm: 0.0021651184652000666, InvBCE: 0.680465817451477\n",
      "Loss: 0.6464807987213135, Norm: 0.002486167475581169, InvBCE: 0.6285319924354553\n",
      "Loss: 0.6042395830154419, Norm: 0.0027946645859628916, InvBCE: 0.5862011313438416\n",
      "Loss: 0.5694332122802734, Norm: 0.003090700600296259, InvBCE: 0.5513050556182861\n",
      "Loss: 0.5404534935951233, Norm: 0.003374492982402444, InvBCE: 0.5222359895706177\n",
      "Loss: 0.5160967707633972, Norm: 0.0036463395226746798, InvBCE: 0.49779072403907776\n",
      "Image fooled! Adding perturbation...\n",
      "Image 85...\n",
      "Loss: 1.1082403659820557, Norm: 0.0, InvBCE: 1.0898470878601074\n",
      "Loss: 0.9971218705177307, Norm: 0.00038095240597613156, InvBCE: 0.9786785244941711\n",
      "Loss: 0.9075706601142883, Norm: 0.0007529290742240846, InvBCE: 0.8890712857246399\n",
      "Image fooled! Adding perturbation...\n",
      "Image 86...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 87...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 88...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 89...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 90...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 91...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 92...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 93...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 94...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 95...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 96...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 97...\n",
      "Loss: 1.4714313745498657, Norm: 0.0, InvBCE: 1.4528708457946777\n",
      "Loss: 1.4666575193405151, Norm: 0.00033336563501507044, InvBCE: 1.4480918645858765\n",
      "Loss: 1.4623016119003296, Norm: 0.0006630173302255571, InvBCE: 1.4437273740768433\n",
      "Image fooled! Adding perturbation...\n",
      "Image 98...\n",
      "Loss: 1.4519513845443726, Norm: 0.0, InvBCE: 1.433365821838379\n",
      "Loss: 1.4032552242279053, Norm: 0.0003742954577319324, InvBCE: 1.3846278190612793\n",
      "Loss: 1.358689546585083, Norm: 0.0007417931919917464, InvBCE: 1.3400160074234009\n",
      "Image fooled! Adding perturbation...\n",
      "Image 99...\n",
      "Image fooled! Adding perturbation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dba6a1fb8594475a4449436d103dfc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fooling rate: 0.62\n",
      "Starting epoch 2...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2338da2355e24294b8b96211f8972f04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 1...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 2...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 3...\n",
      "Loss: 4.759655475616455, Norm: 0.0, InvBCE: 4.740931510925293\n",
      "Loss: 3.9504644870758057, Norm: 0.0003836021642200649, InvBCE: 3.931675910949707\n",
      "Loss: 3.2929906845092773, Norm: 0.0007580589153803885, InvBCE: 3.2741329669952393\n",
      "Loss: 2.759991407394409, Norm: 0.0011237803846597672, InvBCE: 2.741061210632324\n",
      "Loss: 2.3276915550231934, Norm: 0.0014791719149798155, InvBCE: 2.3086860179901123\n",
      "Loss: 1.9772324562072754, Norm: 0.0018231574213132262, InvBCE: 1.958149790763855\n",
      "Loss: 1.6938133239746094, Norm: 0.0021549775265157223, InvBCE: 1.674652338027954\n",
      "Loss: 1.4652820825576782, Norm: 0.002474068896844983, InvBCE: 1.4460421800613403\n",
      "Loss: 1.281335711479187, Norm: 0.002780037233605981, InvBCE: 1.2620171308517456\n",
      "Loss: 1.1331526041030884, Norm: 0.0030726545955985785, InvBCE: 1.1137558221817017\n",
      "Loss: 1.0133806467056274, Norm: 0.0033518648706376553, InvBCE: 0.9939067959785461\n",
      "Loss: 0.9159759879112244, Norm: 0.003617773065343499, InvBCE: 0.8964265584945679\n",
      "Loss: 0.8361948132514954, Norm: 0.00387061876244843, InvBCE: 0.8165715932846069\n",
      "Loss: 0.7702734470367432, Norm: 0.00411076657474041, InvBCE: 0.7505784630775452\n",
      "Loss: 0.7153308391571045, Norm: 0.004338658414781094, InvBCE: 0.6955663561820984\n",
      "Loss: 0.6691633462905884, Norm: 0.004554781597107649, InvBCE: 0.6493316888809204\n",
      "Loss: 0.6300592422485352, Norm: 0.004759652074426413, InvBCE: 0.6101629137992859\n",
      "Loss: 0.5966888666152954, Norm: 0.004953803960233927, InvBCE: 0.5767303705215454\n",
      "Loss: 0.568004846572876, Norm: 0.005137782543897629, InvBCE: 0.5479867458343506\n",
      "Loss: 0.5431777834892273, Norm: 0.005312113557010889, InvBCE: 0.5231026411056519\n",
      "Image 4...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 5...\n",
      "Loss: 1.6259011030197144, Norm: 0.0, InvBCE: 1.6071771383285522\n",
      "Loss: 1.6096227169036865, Norm: 0.0003625042154453695, InvBCE: 1.5908371210098267\n",
      "Loss: 1.592695951461792, Norm: 0.0007229658076539636, InvBCE: 1.5738427639007568\n",
      "Loss: 1.575157642364502, Norm: 0.0010812419932335615, InvBCE: 1.5562313795089722\n",
      "Loss: 1.5570510625839233, Norm: 0.0014368739211931825, InvBCE: 1.5380467176437378\n",
      "Loss: 1.53841233253479, Norm: 0.0017895582132041454, InvBCE: 1.5193253755569458\n",
      "Loss: 1.5192795991897583, Norm: 0.0021391555201262236, InvBCE: 1.500105857849121\n",
      "Loss: 1.4997092485427856, Norm: 0.002485638251528144, InvBCE: 1.4804447889328003\n",
      "Loss: 1.4797879457473755, Norm: 0.002828952157869935, InvBCE: 1.4604291915893555\n",
      "Loss: 1.4596383571624756, Norm: 0.0031689596362411976, InvBCE: 1.440182089805603\n",
      "Loss: 1.439432144165039, Norm: 0.003505407366901636, InvBCE: 1.4198755025863647\n",
      "Image fooled! Adding perturbation...\n",
      "Image 6...\n",
      "Loss: 1.6618505716323853, Norm: 0.0, InvBCE: 1.6421911716461182\n",
      "Loss: 1.5914982557296753, Norm: 0.0003704335249494761, InvBCE: 1.571850299835205\n",
      "Loss: 1.5242164134979248, Norm: 0.0007373467669822276, InvBCE: 1.5045744180679321\n",
      "Loss: 1.4601439237594604, Norm: 0.0011010105954483151, InvBCE: 1.440502643585205\n",
      "Loss: 1.3993422985076904, Norm: 0.00146097328979522, InvBCE: 1.3796968460083008\n",
      "Loss: 1.341837763786316, Norm: 0.0018168637761846185, InvBCE: 1.3221834897994995\n",
      "Loss: 1.287631869316101, Norm: 0.0021683182567358017, InvBCE: 1.267964482307434\n",
      "Loss: 1.2367091178894043, Norm: 0.002514976542443037, InvBCE: 1.2170246839523315\n",
      "Loss: 1.1890538930892944, Norm: 0.002856456907466054, InvBCE: 1.1693487167358398\n",
      "Image fooled! Adding perturbation...\n",
      "Image 7...\n",
      "Loss: 1.1232680082321167, Norm: 0.0, InvBCE: 1.1035391092300415\n",
      "Loss: 1.0260162353515625, Norm: 0.00037838934804312885, InvBCE: 1.0062464475631714\n",
      "Loss: 0.9399312734603882, Norm: 0.0007514305179938674, InvBCE: 0.9201160669326782\n",
      "Loss: 0.8647330403327942, Norm: 0.0011181593872606754, InvBCE: 0.844869077205658\n",
      "Image fooled! Adding perturbation...\n",
      "Image 8...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 9...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 10...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 11...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 12...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 13...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 14...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 15...\n",
      "Loss: 0.9653044939041138, Norm: 0.0, InvBCE: 0.945389449596405\n",
      "Loss: 0.8262634873390198, Norm: 0.0003822350990958512, InvBCE: 0.8062961101531982\n",
      "Loss: 0.7242556810379028, Norm: 0.0007523022941313684, InvBCE: 0.7042307257652283\n",
      "Loss: 0.6484416723251343, Norm: 0.0011090411571785808, InvBCE: 0.6283552646636963\n",
      "Loss: 0.5911760330200195, Norm: 0.0014509025495499372, InvBCE: 0.5710256695747375\n",
      "Image fooled! Adding perturbation...\n",
      "Image 16...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 17...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 18...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 19...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 20...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 21...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 22...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 23...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 24...\n",
      "Loss: 0.8642411231994629, Norm: 0.0, InvBCE: 0.8440253138542175\n",
      "Loss: 0.7768306732177734, Norm: 0.0003790470655076206, InvBCE: 0.7565555572509766\n",
      "Loss: 0.7077995538711548, Norm: 0.0007480902131646872, InvBCE: 0.687461256980896\n",
      "Loss: 0.6531563997268677, Norm: 0.001106603303924203, InvBCE: 0.6327524781227112\n",
      "Image fooled! Adding perturbation...\n",
      "Image 25...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 26...\n",
      "Loss: 1.4790846109390259, Norm: 0.0, InvBCE: 1.458613395690918\n",
      "Loss: 1.4769924879074097, Norm: 0.0003154058940708637, InvBCE: 1.4566668272018433\n",
      "Loss: 1.4748029708862305, Norm: 0.000631237227935344, InvBCE: 1.4546188116073608\n",
      "Loss: 1.4725269079208374, Norm: 0.0009473906247876585, InvBCE: 1.4524800777435303\n",
      "Loss: 1.4701781272888184, Norm: 0.0012637393083423376, InvBCE: 1.450264811515808\n",
      "Loss: 1.4677720069885254, Norm: 0.0015801397385075688, InvBCE: 1.4479882717132568\n",
      "Loss: 1.4653260707855225, Norm: 0.0018964236369356513, InvBCE: 1.4456679821014404\n",
      "Loss: 1.462859034538269, Norm: 0.0022123903036117554, InvBCE: 1.4433228969573975\n",
      "Image fooled! Adding perturbation...\n",
      "Image 27...\n",
      "Loss: 1.2420958280563354, Norm: 0.0, InvBCE: 1.2226779460906982\n",
      "Loss: 1.131096601486206, Norm: 0.0003827851905953139, InvBCE: 1.1115976572036743\n",
      "Loss: 1.0335047245025635, Norm: 0.0007613380439579487, InvBCE: 1.0139179229736328\n",
      "Loss: 0.9480290412902832, Norm: 0.0011349190026521683, InvBCE: 0.928348183631897\n",
      "Loss: 0.8733881711959839, Norm: 0.001502378610894084, InvBCE: 0.8536078333854675\n",
      "Loss: 0.8083468675613403, Norm: 0.0018627361860126257, InvBCE: 0.788462221622467\n",
      "Loss: 0.7517445683479309, Norm: 0.002215155865997076, InvBCE: 0.731751561164856\n",
      "Loss: 0.7025165557861328, Norm: 0.0025589491706341505, InvBCE: 0.6824119091033936\n",
      "Loss: 0.659702479839325, Norm: 0.0028935715090483427, InvBCE: 0.6394835710525513\n",
      "Loss: 0.6224468946456909, Norm: 0.0032186140306293964, InvBCE: 0.6021118760108948\n",
      "Loss: 0.5899966955184937, Norm: 0.0035337882582098246, InvBCE: 0.5695443153381348\n",
      "Loss: 0.5616931319236755, Norm: 0.0038389116525650024, InvBCE: 0.5411227941513062\n",
      "Loss: 0.5369623899459839, Norm: 0.004133893176913261, InvBCE: 0.5162740349769592\n",
      "Loss: 0.515308678150177, Norm: 0.004418722819536924, InvBCE: 0.4945027530193329\n",
      "Image fooled! Adding perturbation...\n",
      "Image 28...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 29...\n",
      "Loss: 0.7349549531936646, Norm: 0.0, InvBCE: 0.7140323519706726\n",
      "Loss: 0.6908866763114929, Norm: 0.0003772213531192392, InvBCE: 0.6698693037033081\n",
      "Loss: 0.6517869830131531, Norm: 0.0007487494731321931, InvBCE: 0.6306696534156799\n",
      "Loss: 0.6173821687698364, Norm: 0.0011146353790536523, InvBCE: 0.5961602330207825\n",
      "Loss: 0.5873228311538696, Norm: 0.0014738977188244462, InvBCE: 0.5659924149513245\n",
      "Image fooled! Adding perturbation...\n",
      "Image 30...\n",
      "Loss: 1.4749023914337158, Norm: 0.0, InvBCE: 1.4534602165222168\n",
      "Loss: 1.310487151145935, Norm: 0.00038198489346541464, InvBCE: 1.2889587879180908\n",
      "Loss: 1.175821304321289, Norm: 0.0007544019026681781, InvBCE: 1.1542003154754639\n",
      "Loss: 1.0656815767288208, Norm: 0.0011198046850040555, InvBCE: 1.043962836265564\n",
      "Loss: 0.9757614135742188, Norm: 0.0014770312700420618, InvBCE: 0.9539408683776855\n",
      "Loss: 0.902101457118988, Norm: 0.001825159415602684, InvBCE: 0.8801760077476501\n",
      "Loss: 0.8413246273994446, Norm: 0.002163483528420329, InvBCE: 0.8192920684814453\n",
      "Loss: 0.7907869219779968, Norm: 0.002491520717740059, InvBCE: 0.7686459422111511\n",
      "Loss: 0.7483957409858704, Norm: 0.0028089911211282015, InvBCE: 0.72614586353302\n",
      "Loss: 0.7125185132026672, Norm: 0.0031157447956502438, InvBCE: 0.6901598572731018\n",
      "Image fooled! Adding perturbation...\n",
      "Image 31...\n",
      "Loss: 809.8460083007812, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8457641601562, Norm: 0.0002413323672953993, InvBCE: 809.8235473632812\n",
      "Loss: 809.8455810546875, Norm: 0.0004824252682738006, InvBCE: 809.8235473632812\n",
      "Loss: 809.8453369140625, Norm: 0.0007232595817185938, InvBCE: 809.8235473632812\n",
      "Loss: 809.8450927734375, Norm: 0.0009638159535825253, InvBCE: 809.8235473632812\n",
      "Loss: 809.8449096679688, Norm: 0.0012040743604302406, InvBCE: 809.8235473632812\n",
      "Loss: 809.8446655273438, Norm: 0.001444014604203403, InvBCE: 809.8235473632812\n",
      "Loss: 809.8444213867188, Norm: 0.0016836158465594053, InvBCE: 809.8235473632812\n",
      "Loss: 809.84423828125, Norm: 0.0019228568999096751, InvBCE: 809.8235473632812\n",
      "Loss: 809.843994140625, Norm: 0.00216171657666564, InvBCE: 809.8235473632812\n",
      "Loss: 809.8438110351562, Norm: 0.0024001728743314743, InvBCE: 809.8235473632812\n",
      "Loss: 809.8435668945312, Norm: 0.0026382040232419968, InvBCE: 809.8235473632812\n",
      "Loss: 809.8433227539062, Norm: 0.002875787205994129, InvBCE: 809.8235473632812\n",
      "Loss: 809.8431396484375, Norm: 0.0031129010021686554, InvBCE: 809.8235473632812\n",
      "Loss: 809.8428955078125, Norm: 0.0033495216630399227, InvBCE: 809.8235473632812\n",
      "Loss: 809.8427124023438, Norm: 0.0035856273025274277, InvBCE: 809.8235473632812\n",
      "Loss: 809.8424682617188, Norm: 0.003821194637566805, InvBCE: 809.8235473632812\n",
      "Loss: 809.84228515625, Norm: 0.004056200850754976, InvBCE: 809.8235473632812\n",
      "Loss: 809.842041015625, Norm: 0.0042906226590275764, InvBCE: 809.8235473632812\n",
      "Loss: 809.8418579101562, Norm: 0.004524437244981527, InvBCE: 809.8235473632812\n",
      "Image 32...\n",
      "Loss: 1.7597402334213257, Norm: 0.0, InvBCE: 1.7372735738754272\n",
      "Loss: 1.7503021955490112, Norm: 0.0003437178093008697, InvBCE: 1.727914810180664\n",
      "Loss: 1.7398675680160522, Norm: 0.0006867842748761177, InvBCE: 1.7175536155700684\n",
      "Loss: 1.728467345237732, Norm: 0.0010294460225850344, InvBCE: 1.706220269203186\n",
      "Loss: 1.7161104679107666, Norm: 0.0013715369859710336, InvBCE: 1.6939234733581543\n",
      "Loss: 1.7026877403259277, Norm: 0.0017130490159615874, InvBCE: 1.6805541515350342\n",
      "Loss: 1.688018560409546, Norm: 0.0020542594138532877, InvBCE: 1.6659318208694458\n",
      "Loss: 1.6718897819519043, Norm: 0.0023956450168043375, InvBCE: 1.6498433351516724\n",
      "Loss: 1.6541848182678223, Norm: 0.0027377065271139145, InvBCE: 1.6321721076965332\n",
      "Loss: 1.6349655389785767, Norm: 0.0030807876028120518, InvBCE: 1.6129802465438843\n",
      "Loss: 1.6143479347229004, Norm: 0.0034249776508659124, InvBCE: 1.5923837423324585\n",
      "Loss: 1.5925562381744385, Norm: 0.003770197741687298, InvBCE: 1.5706067085266113\n",
      "Loss: 1.5698915719985962, Norm: 0.004116110969334841, InvBCE: 1.5479508638381958\n",
      "Loss: 1.5466842651367188, Norm: 0.004462235141545534, InvBCE: 1.5247466564178467\n",
      "Loss: 1.5232750177383423, Norm: 0.0048080976121127605, InvBCE: 1.5013351440429688\n",
      "Loss: 1.5000001192092896, Norm: 0.005153121426701546, InvBCE: 1.478053092956543\n",
      "Loss: 1.477113127708435, Norm: 0.005496572237461805, InvBCE: 1.4551546573638916\n",
      "Loss: 1.4548711776733398, Norm: 0.005837608594447374, InvBCE: 1.4328973293304443\n",
      "Image fooled! Adding perturbation...\n",
      "Image 33...\n",
      "Loss: 1.048813819885254, Norm: 0.0, InvBCE: 1.026821494102478\n",
      "Loss: 0.969638466835022, Norm: 0.00037862357567064464, InvBCE: 0.9475997686386108\n",
      "Image fooled! Adding perturbation...\n",
      "Image 34...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 35...\n",
      "Loss: 1.384235143661499, Norm: 0.0, InvBCE: 1.362146019935608\n",
      "Loss: 1.3067065477371216, Norm: 0.0003789789916481823, InvBCE: 1.284629225730896\n",
      "Loss: 1.2387428283691406, Norm: 0.0007485427195206285, InvBCE: 1.216668963432312\n",
      "Loss: 1.1788698434829712, Norm: 0.0011081646662205458, InvBCE: 1.1567906141281128\n",
      "Loss: 1.12577486038208, Norm: 0.0014572861837223172, InvBCE: 1.1036818027496338\n",
      "Loss: 1.0783650875091553, Norm: 0.0017960825935006142, InvBCE: 1.0562503337860107\n",
      "Loss: 1.0357625484466553, Norm: 0.0021250522695481777, InvBCE: 1.0136191844940186\n",
      "Loss: 0.9972708225250244, Norm: 0.0024445143062621355, InvBCE: 0.9750926494598389\n",
      "Loss: 0.9623284339904785, Norm: 0.002754759043455124, InvBCE: 0.9401099681854248\n",
      "Loss: 0.9304825067520142, Norm: 0.0030560605227947235, InvBCE: 0.9082189202308655\n",
      "Image fooled! Adding perturbation...\n",
      "Image 36...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 37...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 38...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 39...\n",
      "Loss: 673.508056640625, Norm: 0.0, InvBCE: 673.4857177734375\n",
      "Loss: 673.5078125, Norm: 0.00024096931156236678, InvBCE: 673.4857177734375\n",
      "Loss: 673.507568359375, Norm: 0.0004816993896383792, InvBCE: 673.4857177734375\n",
      "Loss: 673.5073852539062, Norm: 0.0007221712148748338, InvBCE: 673.4857177734375\n",
      "Loss: 673.5071411132812, Norm: 0.0009623654186725616, InvBCE: 673.4857177734375\n",
      "Loss: 673.5068969726562, Norm: 0.001202262006700039, InvBCE: 673.4857177734375\n",
      "Loss: 673.5067138671875, Norm: 0.0014418406644836068, InvBCE: 673.4857177734375\n",
      "Loss: 673.5064697265625, Norm: 0.001681080786511302, InvBCE: 673.4857177734375\n",
      "Loss: 673.5062255859375, Norm: 0.0019199613016098738, InvBCE: 673.4857177734375\n",
      "Loss: 673.5060424804688, Norm: 0.002158460672944784, InvBCE: 673.4857177734375\n",
      "Loss: 673.5057983398438, Norm: 0.0023965570144355297, InvBCE: 673.4857177734375\n",
      "Loss: 673.505615234375, Norm: 0.002634228440001607, InvBCE: 673.4857177734375\n",
      "Loss: 673.50537109375, Norm: 0.0028714530635625124, InvBCE: 673.4857177734375\n",
      "Loss: 673.505126953125, Norm: 0.0031082078348845243, InvBCE: 673.4857177734375\n",
      "Loss: 673.5049438476562, Norm: 0.0033444706350564957, InvBCE: 673.4857177734375\n",
      "Loss: 673.5046997070312, Norm: 0.0035802186466753483, InvBCE: 673.4857177734375\n",
      "Loss: 673.5045166015625, Norm: 0.003815429052338004, InvBCE: 673.4857177734375\n",
      "Loss: 673.5042724609375, Norm: 0.004050078336149454, InvBCE: 673.4857177734375\n",
      "Loss: 673.5040893554688, Norm: 0.004284144379198551, InvBCE: 673.4857177734375\n",
      "Loss: 673.5038452148438, Norm: 0.004517603665590286, InvBCE: 673.4857177734375\n",
      "Image 40...\n",
      "Loss: 42.198974609375, Norm: 0.0, InvBCE: 42.17666244506836\n",
      "Loss: 42.19874954223633, Norm: 0.00024096931156236678, InvBCE: 42.17666244506836\n",
      "Loss: 42.19852828979492, Norm: 0.0004816993896383792, InvBCE: 42.17666244506836\n",
      "Loss: 42.19830322265625, Norm: 0.0007221712148748338, InvBCE: 42.17666244506836\n",
      "Loss: 42.19807815551758, Norm: 0.0009623654186725616, InvBCE: 42.17666244506836\n",
      "Loss: 42.19785690307617, Norm: 0.001202262006700039, InvBCE: 42.17666244506836\n",
      "Loss: 42.197635650634766, Norm: 0.0014418406644836068, InvBCE: 42.17666244506836\n",
      "Loss: 42.197410583496094, Norm: 0.001681080786511302, InvBCE: 42.17666244506836\n",
      "Loss: 42.19719314575195, Norm: 0.0019199613016098738, InvBCE: 42.17666244506836\n",
      "Loss: 42.19697189331055, Norm: 0.002158460672944784, InvBCE: 42.17666244506836\n",
      "Loss: 42.19675064086914, Norm: 0.0023965570144355297, InvBCE: 42.17666244506836\n",
      "Loss: 42.196529388427734, Norm: 0.002634228440001607, InvBCE: 42.17666244506836\n",
      "Loss: 42.196311950683594, Norm: 0.0028714530635625124, InvBCE: 42.17666244506836\n",
      "Loss: 42.19609451293945, Norm: 0.0031082078348845243, InvBCE: 42.17666244506836\n",
      "Loss: 42.19587707519531, Norm: 0.0033444706350564957, InvBCE: 42.17666244506836\n",
      "Loss: 42.19565963745117, Norm: 0.0035802186466753483, InvBCE: 42.17666244506836\n",
      "Loss: 42.19544219970703, Norm: 0.003815429052338004, InvBCE: 42.17666244506836\n",
      "Loss: 42.14360427856445, Norm: 0.004050078336149454, InvBCE: 42.125038146972656\n",
      "Loss: 41.8165397644043, Norm: 0.00407374557107687, InvBCE: 41.79799270629883\n",
      "Loss: 41.72224426269531, Norm: 0.00409278180450201, InvBCE: 41.703704833984375\n",
      "Image 41...\n",
      "Loss: 1.5868257284164429, Norm: 0.0, InvBCE: 1.5645127296447754\n",
      "Loss: 1.5574936866760254, Norm: 0.000362814636901021, InvBCE: 1.5351845026016235\n",
      "Loss: 1.5291579961776733, Norm: 0.0007228729082271457, InvBCE: 1.5068472623825073\n",
      "Loss: 1.5021177530288696, Norm: 0.0010800689924508333, InvBCE: 1.4798004627227783\n",
      "Loss: 1.4766303300857544, Norm: 0.001433847937732935, InvBCE: 1.454302191734314\n",
      "Loss: 1.4527736902236938, Norm: 0.0017836008919402957, InvBCE: 1.4304311275482178\n",
      "Loss: 1.4308826923370361, Norm: 0.0021286134142428637, InvBCE: 1.408522605895996\n",
      "Loss: 1.410851240158081, Norm: 0.002468066057190299, InvBCE: 1.3884711265563965\n",
      "Loss: 1.392635464668274, Norm: 0.002801173832267523, InvBCE: 1.3702336549758911\n",
      "Image fooled! Adding perturbation...\n",
      "Image 42...\n",
      "Loss: 1.6647803783416748, Norm: 0.0, InvBCE: 1.6423554420471191\n",
      "Loss: 1.6211017370224, Norm: 0.000364982319297269, InvBCE: 1.5986347198486328\n",
      "Loss: 1.5808749198913574, Norm: 0.0007154200575314462, InvBCE: 1.5583629608154297\n",
      "Loss: 1.5441752672195435, Norm: 0.001061899121850729, InvBCE: 1.5216155052185059\n",
      "Loss: 1.4869838953018188, Norm: 0.0014077541418373585, InvBCE: 1.4643727540969849\n",
      "Loss: 1.454331874847412, Norm: 0.0017490924801677465, InvBCE: 1.431666612625122\n",
      "Loss: 1.423134207725525, Norm: 0.0020841106306761503, InvBCE: 1.4004127979278564\n",
      "Loss: 1.3966012001037598, Norm: 0.0024113075342029333, InvBCE: 1.373822569847107\n",
      "Image fooled! Adding perturbation...\n",
      "Image 43...\n",
      "Loss: 1.8358395099639893, Norm: 0.0, InvBCE: 1.8130031824111938\n",
      "Loss: 1.2591725587844849, Norm: 0.0003749353636521846, InvBCE: 1.236224889755249\n",
      "Loss: 0.946308434009552, Norm: 0.0007309658685699105, InvBCE: 0.9232507348060608\n",
      "Loss: 0.7594683170318604, Norm: 0.0010668595787137747, InvBCE: 0.736303448677063\n",
      "Loss: 0.6506698727607727, Norm: 0.0013844750355929136, InvBCE: 0.6274012923240662\n",
      "Loss: 0.5615720152854919, Norm: 0.0016839782474562526, InvBCE: 0.5382035970687866\n",
      "Loss: 0.5029762983322144, Norm: 0.0019661851692944765, InvBCE: 0.4795125424861908\n",
      "Loss: 0.4597151577472687, Norm: 0.00223244889639318, InvBCE: 0.43616047501564026\n",
      "Loss: 0.4274579584598541, Norm: 0.002483781659975648, InvBCE: 0.403816819190979\n",
      "Loss: 0.40288037061691284, Norm: 0.002721486147493124, InvBCE: 0.3791572153568268\n",
      "Loss: 0.38328254222869873, Norm: 0.0029473132453858852, InvBCE: 0.3594813942909241\n",
      "Loss: 0.3677184581756592, Norm: 0.0031622995156794786, InvBCE: 0.34384316205978394\n",
      "Loss: 0.3546951413154602, Norm: 0.0033674933947622776, InvBCE: 0.3307493031024933\n",
      "Loss: 0.3443309962749481, Norm: 0.0035638322588056326, InvBCE: 0.3203180730342865\n",
      "Loss: 0.3351067900657654, Norm: 0.0037520602345466614, InvBCE: 0.31103000044822693\n",
      "Loss: 0.32712382078170776, Norm: 0.00393290538340807, InvBCE: 0.3029862344264984\n",
      "Loss: 0.32022345066070557, Norm: 0.004107045941054821, InvBCE: 0.29602789878845215\n",
      "Loss: 0.3142656087875366, Norm: 0.004275043960660696, InvBCE: 0.29001477360725403\n",
      "Loss: 0.3091711401939392, Norm: 0.0044374181888997555, InvBCE: 0.284867525100708\n",
      "Loss: 0.30442869663238525, Norm: 0.004594672936946154, InvBCE: 0.2800746262073517\n",
      "Image 44...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 45...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 46...\n",
      "Loss: 5.43310022354126, Norm: 0.0, InvBCE: 5.410264015197754\n",
      "Loss: 4.459409236907959, Norm: 0.0003817644319497049, InvBCE: 4.436529636383057\n",
      "Loss: 3.65803599357605, Norm: 0.0007543042302131653, InvBCE: 3.635108470916748\n",
      "Loss: 3.0121498107910156, Norm: 0.0011187251657247543, InvBCE: 2.9891700744628906\n",
      "Loss: 2.504844903945923, Norm: 0.0014729920076206326, InvBCE: 2.481809616088867\n",
      "Loss: 2.1074156761169434, Norm: 0.0018154529388993979, InvBCE: 2.084322690963745\n",
      "Loss: 1.7938992977142334, Norm: 0.0021452002692967653, InvBCE: 1.7707476615905762\n",
      "Loss: 1.5472983121871948, Norm: 0.00246175448410213, InvBCE: 1.5240874290466309\n",
      "Loss: 1.353968858718872, Norm: 0.002764853648841381, InvBCE: 1.330698847770691\n",
      "Loss: 1.2004915475845337, Norm: 0.0030544279143214226, InvBCE: 1.177163004875183\n",
      "Loss: 1.0560276508331299, Norm: 0.0033305431716144085, InvBCE: 1.0326414108276367\n",
      "Loss: 0.9295583963394165, Norm: 0.0035949184093624353, InvBCE: 0.9061148166656494\n",
      "Loss: 0.8488987684249878, Norm: 0.0038461184594780207, InvBCE: 0.8253992199897766\n",
      "Loss: 0.7908856272697449, Norm: 0.004083712585270405, InvBCE: 0.7673320770263672\n",
      "Loss: 0.7432810068130493, Norm: 0.004308383446186781, InvBCE: 0.7196755409240723\n",
      "Loss: 0.7032790184020996, Norm: 0.004520835820585489, InvBCE: 0.6796237826347351\n",
      "Loss: 0.6691584587097168, Norm: 0.004721782170236111, InvBCE: 0.6454556584358215\n",
      "Loss: 0.6399521827697754, Norm: 0.004911903757601976, InvBCE: 0.6162039637565613\n",
      "Loss: 0.6146811842918396, Norm: 0.005091832485049963, InvBCE: 0.5908897519111633\n",
      "Loss: 0.5925816893577576, Norm: 0.00526219280436635, InvBCE: 0.5687491297721863\n",
      "Image 47...\n",
      "Loss: 1.2457643747329712, Norm: 0.0, InvBCE: 1.2229280471801758\n",
      "Loss: 1.1532398462295532, Norm: 0.00037940547917969525, InvBCE: 1.1303471326828003\n",
      "Image fooled! Adding perturbation...\n",
      "Image 48...\n",
      "Loss: 1.4686522483825684, Norm: 0.0, InvBCE: 1.4456993341445923\n",
      "Loss: 1.4678322076797485, Norm: 0.0002775498142000288, InvBCE: 1.4450100660324097\n",
      "Loss: 1.466970443725586, Norm: 0.0005541666178032756, InvBCE: 1.4442760944366455\n",
      "Loss: 1.4660075902938843, Norm: 0.0008294631261378527, InvBCE: 1.4434386491775513\n",
      "Loss: 1.4661905765533447, Norm: 0.001103409449569881, InvBCE: 1.4437452554702759\n",
      "Loss: 1.4654371738433838, Norm: 0.0013745924225077033, InvBCE: 1.4431153535842896\n",
      "Image fooled! Adding perturbation...\n",
      "Image 49...\n",
      "Loss: 1.7026106119155884, Norm: 0.0, InvBCE: 1.6804115772247314\n",
      "Loss: 1.6083036661148071, Norm: 0.00037803364102728665, InvBCE: 1.5860555171966553\n",
      "Loss: 1.5173869132995605, Norm: 0.0007513817399740219, InvBCE: 1.4950833320617676\n",
      "Loss: 1.431554913520813, Norm: 0.001121004344895482, InvBCE: 1.4091906547546387\n",
      "Loss: 1.3522155284881592, Norm: 0.0014859952498227358, InvBCE: 1.3297860622406006\n",
      "Loss: 1.2803058624267578, Norm: 0.0018451707437634468, InvBCE: 1.2578080892562866\n",
      "Image fooled! Adding perturbation...\n",
      "Image 50...\n",
      "Loss: 809.8461303710938, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8458862304688, Norm: 0.00023979890102054924, InvBCE: 809.8235473632812\n",
      "Loss: 809.8456420898438, Norm: 0.0004793554835487157, InvBCE: 809.8235473632812\n",
      "Loss: 809.845458984375, Norm: 0.0007186506991274655, InvBCE: 809.8235473632812\n",
      "Loss: 809.84521484375, Norm: 0.0009576649172231555, InvBCE: 809.8235473632812\n",
      "Loss: 809.8450317382812, Norm: 0.0011963782599195838, InvBCE: 809.8235473632812\n",
      "Loss: 809.8447875976562, Norm: 0.001434770179912448, InvBCE: 809.8235473632812\n",
      "Loss: 809.8445434570312, Norm: 0.0016728199552744627, InvBCE: 809.8235473632812\n",
      "Loss: 809.8443603515625, Norm: 0.0019105062820017338, InvBCE: 809.8235473632812\n",
      "Loss: 809.8441162109375, Norm: 0.0021478079725056887, InvBCE: 809.8235473632812\n",
      "Loss: 809.8439331054688, Norm: 0.0023847029078751802, InvBCE: 809.8235473632812\n",
      "Loss: 809.8436889648438, Norm: 0.0026211696676909924, InvBCE: 809.8235473632812\n",
      "Loss: 809.8434448242188, Norm: 0.0028571856673806906, InvBCE: 809.8235473632812\n",
      "Loss: 809.84326171875, Norm: 0.003092728089541197, InvBCE: 809.8235473632812\n",
      "Loss: 809.843017578125, Norm: 0.003327775513753295, InvBCE: 809.8235473632812\n",
      "Loss: 809.8428344726562, Norm: 0.0035623039584606886, InvBCE: 809.8235473632812\n",
      "Loss: 809.8425903320312, Norm: 0.0037962920032441616, InvBCE: 809.8235473632812\n",
      "Loss: 809.8424072265625, Norm: 0.004029715899378061, InvBCE: 809.8235473632812\n",
      "Loss: 809.8421630859375, Norm: 0.004262553062289953, InvBCE: 809.8235473632812\n",
      "Loss: 809.8419799804688, Norm: 0.004494780674576759, InvBCE: 809.8235473632812\n",
      "Image 51...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 52...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 53...\n",
      "Loss: 1.5160636901855469, Norm: 0.0, InvBCE: 1.493495225906372\n",
      "Loss: 1.4810359477996826, Norm: 0.000369334127753973, InvBCE: 1.4584752321243286\n",
      "Loss: 1.4465761184692383, Norm: 0.000736625399440527, InvBCE: 1.4240174293518066\n",
      "Loss: 1.4131659269332886, Norm: 0.0011015842901542783, InvBCE: 1.3906036615371704\n",
      "Loss: 1.3812170028686523, Norm: 0.0014638834400102496, InvBCE: 1.3586459159851074\n",
      "Loss: 1.3510594367980957, Norm: 0.0018232649890705943, InvBCE: 1.328474521636963\n",
      "Image fooled! Adding perturbation...\n",
      "Image 54...\n",
      "Loss: 1.4727369546890259, Norm: 0.0, InvBCE: 1.4501339197158813\n",
      "Loss: 1.4696943759918213, Norm: 0.0003196989418938756, InvBCE: 1.4472087621688843\n",
      "Loss: 1.466692328453064, Norm: 0.0006388372858054936, InvBCE: 1.4443211555480957\n",
      "Image fooled! Adding perturbation...\n",
      "Image 55...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 56...\n",
      "Loss: 0.436888724565506, Norm: 0.0, InvBCE: 0.4146290719509125\n",
      "Image fooled! Adding perturbation...\n",
      "Image 57...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 58...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 59...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 60...\n",
      "Loss: 809.8458251953125, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8456420898438, Norm: 0.0002394039329374209, InvBCE: 809.8235473632812\n",
      "Loss: 809.8453979492188, Norm: 0.00047856158926151693, InvBCE: 809.8235473632812\n",
      "Loss: 809.84521484375, Norm: 0.0007174535421654582, InvBCE: 809.8235473632812\n",
      "Loss: 809.844970703125, Norm: 0.0009560598991811275, InvBCE: 809.8235473632812\n",
      "Loss: 809.8447265625, Norm: 0.0011943604331463575, InvBCE: 809.8235473632812\n",
      "Loss: 809.8445434570312, Norm: 0.001432334422133863, InvBCE: 809.8235473632812\n",
      "Loss: 809.8442993164062, Norm: 0.0016699605621397495, InvBCE: 809.8235473632812\n",
      "Loss: 809.8441162109375, Norm: 0.0019072175491601229, InvBCE: 809.8235473632812\n",
      "Loss: 809.8438720703125, Norm: 0.0021440833806991577, InvBCE: 809.8235473632812\n",
      "Loss: 809.8436279296875, Norm: 0.002380535937845707, InvBCE: 809.8235473632812\n",
      "Loss: 809.8434448242188, Norm: 0.002616553334519267, InvBCE: 809.8235473632812\n",
      "Loss: 809.8432006835938, Norm: 0.0028521122876554728, InvBCE: 809.8235473632812\n",
      "Loss: 809.843017578125, Norm: 0.003087190445512533, InvBCE: 809.8235473632812\n",
      "Loss: 809.8427734375, Norm: 0.0033217647578567266, InvBCE: 809.8235473632812\n",
      "Loss: 809.8425903320312, Norm: 0.0035558121744543314, InvBCE: 809.8235473632812\n",
      "Loss: 809.8423461914062, Norm: 0.0037893096450716257, InvBCE: 809.8235473632812\n",
      "Loss: 809.8421630859375, Norm: 0.004022234119474888, InvBCE: 809.8235473632812\n",
      "Loss: 809.8419189453125, Norm: 0.004254562314599752, InvBCE: 809.8235473632812\n",
      "Loss: 809.8417358398438, Norm: 0.00448627071455121, InvBCE: 809.8235473632812\n",
      "Image 61...\n",
      "Loss: 1.3307867050170898, Norm: 0.0, InvBCE: 1.3084791898727417\n",
      "Loss: 1.1898634433746338, Norm: 0.00038228786434046924, InvBCE: 1.1674903631210327\n",
      "Loss: 1.0731478929519653, Norm: 0.0007561147795058787, InvBCE: 1.0507047176361084\n",
      "Loss: 0.9761911034584045, Norm: 0.0011209659278392792, InvBCE: 0.95367431640625\n",
      "Loss: 0.8951047658920288, Norm: 0.0014755063457414508, InvBCE: 0.8725117444992065\n",
      "Loss: 0.8267577290534973, Norm: 0.0018187548266723752, InvBCE: 0.8040865659713745\n",
      "Loss: 0.7686858177185059, Norm: 0.0021502783056348562, InvBCE: 0.7459355592727661\n",
      "Image fooled! Adding perturbation...\n",
      "Image 62...\n",
      "Loss: 3.6553139686584473, Norm: 0.0, InvBCE: 3.6324844360351562\n",
      "Loss: 3.0093770027160645, Norm: 0.00038524859701283276, InvBCE: 2.9864766597747803\n",
      "Loss: 2.473784923553467, Norm: 0.0007631787448190153, InvBCE: 2.4508090019226074\n",
      "Loss: 2.0517523288726807, Norm: 0.0011329357512295246, InvBCE: 2.0286974906921387\n",
      "Loss: 1.7318514585494995, Norm: 0.0014918658416718245, InvBCE: 1.7087154388427734\n",
      "Loss: 1.4519951343536377, Norm: 0.0018375777872279286, InvBCE: 1.428776741027832\n",
      "Loss: 1.2315326929092407, Norm: 0.002149169333279133, InvBCE: 1.2082293033599854\n",
      "Loss: 1.1118049621582031, Norm: 0.0024457534309476614, InvBCE: 1.0884175300598145\n",
      "Loss: 1.0190892219543457, Norm: 0.00272700609639287, InvBCE: 0.9956192374229431\n",
      "Loss: 0.9457781910896301, Norm: 0.0029933140613138676, InvBCE: 0.9222275018692017\n",
      "Loss: 0.886362612247467, Norm: 0.003245375584810972, InvBCE: 0.8627331256866455\n",
      "Loss: 0.8374320864677429, Norm: 0.0034839750733226538, InvBCE: 0.8137259483337402\n",
      "Loss: 0.7963874340057373, Norm: 0.0037099160254001617, InvBCE: 0.7726068496704102\n",
      "Image fooled! Adding perturbation...\n",
      "Image 63...\n",
      "Loss: 1.7984493970870972, Norm: 0.0, InvBCE: 1.7745968103408813\n",
      "Loss: 1.7508183717727661, Norm: 0.0003696143685374409, InvBCE: 1.7269850969314575\n",
      "Loss: 1.702589750289917, Norm: 0.0007377253496088088, InvBCE: 1.6787713766098022\n",
      "Loss: 1.6540923118591309, Norm: 0.0011045250575989485, InvBCE: 1.6302844285964966\n",
      "Loss: 1.6056394577026367, Norm: 0.0014698333106935024, InvBCE: 1.5818378925323486\n",
      "Loss: 1.5576252937316895, Norm: 0.001833559712395072, InvBCE: 1.5338258743286133\n",
      "Loss: 1.5104196071624756, Norm: 0.002195573877543211, InvBCE: 1.4866183996200562\n",
      "Loss: 1.4643808603286743, Norm: 0.0025556653272360563, InvBCE: 1.4405741691589355\n",
      "Loss: 1.4198442697525024, Norm: 0.002913531381636858, InvBCE: 1.3960286378860474\n",
      "Loss: 1.377132534980774, Norm: 0.0032688146457076073, InvBCE: 1.3533046245574951\n",
      "Loss: 1.3365168571472168, Norm: 0.0036210876423865557, InvBCE: 1.312673568725586\n",
      "Image fooled! Adding perturbation...\n",
      "Image 64...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 65...\n",
      "Loss: 1.4892388582229614, Norm: 0.0, InvBCE: 1.4653774499893188\n",
      "Loss: 1.3736492395401, Norm: 0.0003772800846491009, InvBCE: 1.3497883081436157\n",
      "Loss: 1.2691760063171387, Norm: 0.0007511951844207942, InvBCE: 1.2453107833862305\n",
      "Loss: 1.1758092641830444, Norm: 0.0011215049307793379, InvBCE: 1.1519347429275513\n",
      "Loss: 1.093198537826538, Norm: 0.0014872108586132526, InvBCE: 1.0693104267120361\n",
      "Loss: 1.0207127332687378, Norm: 0.0018472692463546991, InvBCE: 0.9968070983886719\n",
      "Loss: 0.9575004577636719, Norm: 0.002200661925598979, InvBCE: 0.9335743188858032\n",
      "Image fooled! Adding perturbation...\n",
      "Image 66...\n",
      "Loss: 1.6486012935638428, Norm: 0.0, InvBCE: 1.6246519088745117\n",
      "Loss: 1.6100407838821411, Norm: 0.00037260318640619516, InvBCE: 1.5861408710479736\n",
      "Loss: 1.572055459022522, Norm: 0.0007427962264046073, InvBCE: 1.5482008457183838\n",
      "Loss: 1.5348902940750122, Norm: 0.0011107790051028132, InvBCE: 1.5110775232315063\n",
      "Loss: 1.498708724975586, Norm: 0.0014761205529794097, InvBCE: 1.4749343395233154\n",
      "Loss: 1.4636107683181763, Norm: 0.0018384282011538744, InvBCE: 1.4398716688156128\n",
      "Loss: 1.429619312286377, Norm: 0.0021973522379994392, InvBCE: 1.4059126377105713\n",
      "Loss: 1.3967456817626953, Norm: 0.0025526422541588545, InvBCE: 1.373068928718567\n",
      "Loss: 1.36500883102417, Norm: 0.0029040577355772257, InvBCE: 1.3413593769073486\n",
      "Loss: 1.3344359397888184, Norm: 0.0032513695769011974, InvBCE: 1.3108114004135132\n",
      "Image fooled! Adding perturbation...\n",
      "Image 67...\n",
      "Loss: 1.2709213495254517, Norm: 0.0, InvBCE: 1.2473193407058716\n",
      "Loss: 1.0832260847091675, Norm: 0.00038262957241386175, InvBCE: 1.059582233428955\n",
      "Loss: 0.9384099245071411, Norm: 0.000755461398512125, InvBCE: 0.914720892906189\n",
      "Loss: 0.8260778784751892, Norm: 0.0011180323781445622, InvBCE: 0.8023409843444824\n",
      "Loss: 0.7383033633232117, Norm: 0.0014687018701806664, InvBCE: 0.7145166397094727\n",
      "Loss: 0.6698508858680725, Norm: 0.0018064477480947971, InvBCE: 0.6460130214691162\n",
      "Loss: 0.6158580183982849, Norm: 0.0021305254194885492, InvBCE: 0.591968297958374\n",
      "Loss: 0.5729718804359436, Norm: 0.0024405517615377903, InvBCE: 0.5490302443504333\n",
      "Image fooled! Adding perturbation...\n",
      "Image 68...\n",
      "Loss: 1.3261756896972656, Norm: 0.0, InvBCE: 1.3021825551986694\n",
      "Image fooled! Adding perturbation...\n",
      "Image 69...\n",
      "Loss: 3.051412582397461, Norm: 0.0, InvBCE: 3.0274581909179688\n",
      "Loss: 2.648811101913452, Norm: 0.0003822316648438573, InvBCE: 2.624786376953125\n",
      "Loss: 2.3049471378326416, Norm: 0.0007596711511723697, InvBCE: 2.2808473110198975\n",
      "Loss: 2.014556884765625, Norm: 0.0011316777672618628, InvBCE: 1.9903781414031982\n",
      "Loss: 1.7715191841125488, Norm: 0.0014967630850151181, InvBCE: 1.7472584247589111\n",
      "Loss: 1.569367527961731, Norm: 0.001853557419963181, InvBCE: 1.5450221300125122\n",
      "Loss: 1.401745080947876, Norm: 0.0022009038366377354, InvBCE: 1.377313256263733\n",
      "Loss: 1.2628140449523926, Norm: 0.002537890337407589, InvBCE: 1.2382946014404297\n",
      "Loss: 1.147646188735962, Norm: 0.0028638378717005253, InvBCE: 1.123038649559021\n",
      "Loss: 1.0519291162490845, Norm: 0.003178264945745468, InvBCE: 1.0272332429885864\n",
      "Loss: 0.9718666076660156, Norm: 0.003480923594906926, InvBCE: 0.9470829367637634\n",
      "Loss: 0.9043973684310913, Norm: 0.0037717476952821016, InvBCE: 0.879526674747467\n",
      "Loss: 0.8471856713294983, Norm: 0.004050810355693102, InvBCE: 0.8222290277481079\n",
      "Loss: 0.7983825206756592, Norm: 0.004318295046687126, InvBCE: 0.7733414769172668\n",
      "Loss: 0.7564990520477295, Norm: 0.004574454389512539, InvBCE: 0.7313752770423889\n",
      "Loss: 0.7203255891799927, Norm: 0.0048195980489254, InvBCE: 0.6951209902763367\n",
      "Loss: 0.6889175772666931, Norm: 0.005054091103374958, InvBCE: 0.6636342406272888\n",
      "Loss: 0.6614935994148254, Norm: 0.005278324242681265, InvBCE: 0.6361337304115295\n",
      "Loss: 0.6374145150184631, Norm: 0.0054927123710513115, InvBCE: 0.6119803786277771\n",
      "Loss: 0.6161664128303528, Norm: 0.005697670858353376, InvBCE: 0.5906603336334229\n",
      "Image 70...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 71...\n",
      "Loss: 2.70701003074646, Norm: 0.0, InvBCE: 2.6830556392669678\n",
      "Loss: 2.4171814918518066, Norm: 0.000379439617972821, InvBCE: 2.3931667804718018\n",
      "Loss: 2.162721633911133, Norm: 0.0007536957273259759, InvBCE: 2.138641595840454\n",
      "Loss: 1.9403471946716309, Norm: 0.0011225499911233783, InvBCE: 1.9161975383758545\n",
      "Loss: 1.7466853857040405, Norm: 0.0014848288847133517, InvBCE: 1.72246253490448\n",
      "Loss: 1.5785448551177979, Norm: 0.001839531701989472, InvBCE: 1.5542458295822144\n",
      "Loss: 1.4328193664550781, Norm: 0.0021858273539692163, InvBCE: 1.4084419012069702\n",
      "Loss: 1.3065749406814575, Norm: 0.0025230266619473696, InvBCE: 1.282117247581482\n",
      "Loss: 1.197204828262329, Norm: 0.002850573742762208, InvBCE: 1.1726657152175903\n",
      "Loss: 1.102388858795166, Norm: 0.003168038558214903, InvBCE: 1.0777674913406372\n",
      "Loss: 1.020124077796936, Norm: 0.003475123317912221, InvBCE: 0.9954200983047485\n",
      "Loss: 0.9486218094825745, Norm: 0.0037716487422585487, InvBCE: 0.923835277557373\n",
      "Loss: 0.8863829374313354, Norm: 0.004057550337165594, InvBCE: 0.8615143299102783\n",
      "Loss: 0.8320609331130981, Norm: 0.004332839976996183, InvBCE: 0.8071109056472778\n",
      "Loss: 0.7845858335494995, Norm: 0.004597627557814121, InvBCE: 0.759555459022522\n",
      "Loss: 0.7429741621017456, Norm: 0.0048520732671022415, InvBCE: 0.7178646922111511\n",
      "Loss: 0.7063959240913391, Norm: 0.005096388980746269, InvBCE: 0.6812088489532471\n",
      "Loss: 0.6741827130317688, Norm: 0.0053308140486478806, InvBCE: 0.6489197015762329\n",
      "Loss: 0.6457191705703735, Norm: 0.005555627401918173, InvBCE: 0.6203820109367371\n",
      "Loss: 0.620449423789978, Norm: 0.005771128460764885, InvBCE: 0.5950400233268738\n",
      "Image 72...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 73...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 74...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 75...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 76...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 77...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 78...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 79...\n",
      "Loss: 809.8474731445312, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8472900390625, Norm: 0.00023900570522528142, InvBCE: 809.8235473632812\n",
      "Loss: 809.8470458984375, Norm: 0.0004777762806043029, InvBCE: 809.8235473632812\n",
      "Loss: 809.8468627929688, Norm: 0.0007162934052757919, InvBCE: 809.8235473632812\n",
      "Loss: 809.8466186523438, Norm: 0.0009545382927171886, InvBCE: 809.8235473632812\n",
      "Loss: 809.8463745117188, Norm: 0.001192492083646357, InvBCE: 809.8235473632812\n",
      "Loss: 809.84619140625, Norm: 0.0014301351038739085, InvBCE: 809.8235473632812\n",
      "Loss: 809.845947265625, Norm: 0.0016674479702487588, InvBCE: 809.8235473632812\n",
      "Loss: 809.8457641601562, Norm: 0.0019044103100895882, InvBCE: 809.8235473632812\n",
      "Loss: 809.8455200195312, Norm: 0.0021410020999610424, InvBCE: 809.8235473632812\n",
      "Loss: 809.8452758789062, Norm: 0.002377202268689871, InvBCE: 809.8235473632812\n",
      "Loss: 809.8450927734375, Norm: 0.0026129905600100756, InvBCE: 809.8235473632812\n",
      "Loss: 809.8448486328125, Norm: 0.0028483462519943714, InvBCE: 809.8235473632812\n",
      "Loss: 809.8446655273438, Norm: 0.003083247924223542, InvBCE: 809.8235473632812\n",
      "Loss: 809.8444213867188, Norm: 0.0033176748547703028, InvBCE: 809.8235473632812\n",
      "Loss: 809.84423828125, Norm: 0.0035516053903847933, InvBCE: 809.8235473632812\n",
      "Loss: 809.843994140625, Norm: 0.0037850188091397285, InvBCE: 809.8235473632812\n",
      "Loss: 809.8438110351562, Norm: 0.004017893690615892, InvBCE: 809.8235473632812\n",
      "Loss: 809.8435668945312, Norm: 0.004250208847224712, InvBCE: 809.8235473632812\n",
      "Loss: 809.8433837890625, Norm: 0.00448194332420826, InvBCE: 809.8235473632812\n",
      "Image 80...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 81...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 82...\n",
      "Loss: 1.0838581323623657, Norm: 0.0, InvBCE: 1.0599037408828735\n",
      "Loss: 0.9513313174247742, Norm: 0.000381895195459947, InvBCE: 0.9273244142532349\n",
      "Loss: 0.8458564281463623, Norm: 0.00075244513573125, InvBCE: 0.821794331073761\n",
      "Loss: 0.7654306888580322, Norm: 0.001111018005758524, InvBCE: 0.7413116097450256\n",
      "Image fooled! Adding perturbation...\n",
      "Image 83...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 84...\n",
      "Loss: 0.613192081451416, Norm: 0.0, InvBCE: 0.5890150666236877\n",
      "Loss: 0.5626757740974426, Norm: 0.000377676886273548, InvBCE: 0.5384312272071838\n",
      "Loss: 0.5212506055831909, Norm: 0.000749280967283994, InvBCE: 0.49693456292152405\n",
      "Image fooled! Adding perturbation...\n",
      "Image 85...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 86...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 87...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 88...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 89...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 90...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 91...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 92...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 93...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 94...\n",
      "Loss: 0.8800927400588989, Norm: 0.0, InvBCE: 0.8557021021842957\n",
      "Image fooled! Adding perturbation...\n",
      "Image 95...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 96...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 97...\n",
      "Loss: 1.476804256439209, Norm: 0.0, InvBCE: 1.4523777961730957\n",
      "Loss: 1.4718828201293945, Norm: 0.00033367975265718997, InvBCE: 1.4474552869796753\n",
      "Loss: 1.467250943183899, Norm: 0.0006651903386227787, InvBCE: 1.4428188800811768\n",
      "Image fooled! Adding perturbation...\n",
      "Image 98...\n",
      "Loss: 1.5290319919586182, Norm: 0.0, InvBCE: 1.504593014717102\n",
      "Loss: 1.4829131364822388, Norm: 0.00037461810279637575, InvBCE: 1.4584497213363647\n",
      "Loss: 1.4391318559646606, Norm: 0.0007444359362125397, InvBCE: 1.4146392345428467\n",
      "Loss: 1.3978344202041626, Norm: 0.001109588542021811, InvBCE: 1.3733080625534058\n",
      "Loss: 1.3590730428695679, Norm: 0.0014694604324176908, InvBCE: 1.3345091342926025\n",
      "Image fooled! Adding perturbation...\n",
      "Image 99...\n",
      "Image fooled! Adding perturbation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "591ffb415aae4506880150b7416c6868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fooling rate: 0.65\n",
      "Starting epoch 3...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27ffacd433d74b3a8ce3655a78c8da24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 1...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 2...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 3...\n",
      "Loss: 4.039544582366943, Norm: 0.0, InvBCE: 4.014939785003662\n",
      "Loss: 3.4015543460845947, Norm: 0.00038259863504208624, InvBCE: 3.3768887519836426\n",
      "Loss: 2.8748281002044678, Norm: 0.000757803616579622, InvBCE: 2.850097894668579\n",
      "Loss: 2.443341016769409, Norm: 0.0011251807445660233, InvBCE: 2.4185428619384766\n",
      "Loss: 2.091008186340332, Norm: 0.0014830369036644697, InvBCE: 2.0661401748657227\n",
      "Loss: 1.803304672241211, Norm: 0.0018301175441592932, InvBCE: 1.7783654928207397\n",
      "Loss: 1.5681415796279907, Norm: 0.0021655485033988953, InvBCE: 1.54313063621521\n",
      "Loss: 1.3754901885986328, Norm: 0.0024887509644031525, InvBCE: 1.350407600402832\n",
      "Loss: 1.2173312902450562, Norm: 0.002799357520416379, InvBCE: 1.1921775341033936\n",
      "Loss: 1.0869852304458618, Norm: 0.0030971786472946405, InvBCE: 1.0617612600326538\n",
      "Loss: 0.978964626789093, Norm: 0.003382213646546006, InvBCE: 0.9536718130111694\n",
      "Loss: 0.8889342546463013, Norm: 0.003654597792774439, InvBCE: 0.8635741472244263\n",
      "Loss: 0.8134828209877014, Norm: 0.003914578352123499, InvBCE: 0.7880573272705078\n",
      "Loss: 0.7499773502349854, Norm: 0.004162468947470188, InvBCE: 0.7244884967803955\n",
      "Loss: 0.6963732242584229, Norm: 0.004398636519908905, InvBCE: 0.6708231568336487\n",
      "Loss: 0.6510462760925293, Norm: 0.004623459652066231, InvBCE: 0.6254372596740723\n",
      "Loss: 0.6126581430435181, Norm: 0.004837347194552422, InvBCE: 0.5869924426078796\n",
      "Loss: 0.5800599455833435, Norm: 0.0050407168455421925, InvBCE: 0.5543398857116699\n",
      "Loss: 0.5522745251655579, Norm: 0.005233994219452143, InvBCE: 0.5265024900436401\n",
      "Loss: 0.5284664630889893, Norm: 0.005417622625827789, InvBCE: 0.5026447176933289\n",
      "Image 4...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 5...\n",
      "Loss: 1.5060265064239502, Norm: 0.0, InvBCE: 1.4814218282699585\n",
      "Loss: 1.4944490194320679, Norm: 0.000359704892616719, InvBCE: 1.4697524309158325\n",
      "Loss: 1.4830443859100342, Norm: 0.0007177350344136357, InvBCE: 1.458252191543579\n",
      "Loss: 1.4718178510665894, Norm: 0.0010737134143710136, InvBCE: 1.4469268321990967\n",
      "Loss: 1.4607635736465454, Norm: 0.0014271005056798458, InvBCE: 1.4357709884643555\n",
      "Loss: 1.449864149093628, Norm: 0.001777362427674234, InvBCE: 1.4247677326202393\n",
      "Loss: 1.4390920400619507, Norm: 0.0021239907946437597, InvBCE: 1.4138901233673096\n",
      "Image fooled! Adding perturbation...\n",
      "Image 6...\n",
      "Loss: 1.3305121660232544, Norm: 0.0, InvBCE: 1.3052033185958862\n",
      "Loss: 1.2872235774993896, Norm: 0.0003656491753645241, InvBCE: 1.261918306350708\n",
      "Loss: 1.2456337213516235, Norm: 0.000728251994587481, InvBCE: 1.2203283309936523\n",
      "Loss: 1.2059438228607178, Norm: 0.0010874996660277247, InvBCE: 1.1806355714797974\n",
      "Loss: 1.1683456897735596, Norm: 0.0014428053982555866, InvBCE: 1.1430323123931885\n",
      "Image fooled! Adding perturbation...\n",
      "Image 7...\n",
      "Loss: 1.0382676124572754, Norm: 0.0, InvBCE: 1.0129473209381104\n",
      "Loss: 0.9822816848754883, Norm: 0.0003736644284799695, InvBCE: 0.9569476842880249\n",
      "Loss: 0.9306462407112122, Norm: 0.0007441401248797774, InvBCE: 0.9052949547767639\n",
      "Loss: 0.8832533955574036, Norm: 0.0011109677143394947, InvBCE: 0.8578816056251526\n",
      "Loss: 0.8399685025215149, Norm: 0.0014733070274814963, InvBCE: 0.8145732283592224\n",
      "Image fooled! Adding perturbation...\n",
      "Image 8...\n",
      "Loss: 1.4706847667694092, Norm: 0.0, InvBCE: 1.4452635049819946\n",
      "Image fooled! Adding perturbation...\n",
      "Image 9...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 10...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 11...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 12...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 13...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 14...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 15...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 16...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 17...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 18...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 19...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 20...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 21...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 22...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 23...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 24...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 25...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 26...\n",
      "Loss: 1.4805277585983276, Norm: 0.0, InvBCE: 1.4551842212677002\n",
      "Loss: 1.4786969423294067, Norm: 0.0003117711457889527, InvBCE: 1.453493356704712\n",
      "Loss: 1.476812481880188, Norm: 0.0006238095229491591, InvBCE: 1.4517453908920288\n",
      "Loss: 1.474881887435913, Norm: 0.0009360709809698164, InvBCE: 1.4499481916427612\n",
      "Loss: 1.4729148149490356, Norm: 0.0012484537437558174, InvBCE: 1.4481110572814941\n",
      "Loss: 1.4709211587905884, Norm: 0.0015608306275680661, InvBCE: 1.446244239807129\n",
      "Loss: 1.4689122438430786, Norm: 0.0018730548908933997, InvBCE: 1.4443589448928833\n",
      "Loss: 1.4669010639190674, Norm: 0.0021849453914910555, InvBCE: 1.442468285560608\n",
      "Image fooled! Adding perturbation...\n",
      "Image 27...\n",
      "Loss: 0.9336060285568237, Norm: 0.0, InvBCE: 0.9092909097671509\n",
      "Loss: 0.856686532497406, Norm: 0.0003813841030932963, InvBCE: 0.8322768807411194\n",
      "Loss: 0.7891930937767029, Norm: 0.0007588232401758432, InvBCE: 0.7646844983100891\n",
      "Loss: 0.7301998734474182, Norm: 0.0011315830051898956, InvBCE: 0.7055884003639221\n",
      "Loss: 0.6787771582603455, Norm: 0.0014985253801569343, InvBCE: 0.6540594696998596\n",
      "Loss: 0.6340397000312805, Norm: 0.001858629984781146, InvBCE: 0.6092131733894348\n",
      "Loss: 0.5951735377311707, Norm: 0.0022109991405159235, InvBCE: 0.570236325263977\n",
      "Loss: 0.5614421367645264, Norm: 0.0025548632256686687, InvBCE: 0.5363929271697998\n",
      "Loss: 0.5321810841560364, Norm: 0.0028895880095660686, InvBCE: 0.5070193409919739\n",
      "Image fooled! Adding perturbation...\n",
      "Image 28...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 29...\n",
      "Loss: 0.6633109450340271, Norm: 0.0, InvBCE: 0.6380365490913391\n",
      "Loss: 0.627586305141449, Norm: 0.0003751314361579716, InvBCE: 0.6022345423698425\n",
      "Loss: 0.5961208939552307, Norm: 0.0007459800690412521, InvBCE: 0.5706872940063477\n",
      "Image fooled! Adding perturbation...\n",
      "Image 30...\n",
      "Loss: 0.8442138433456421, Norm: 0.0, InvBCE: 0.8186942934989929\n",
      "Loss: 0.7878716588020325, Norm: 0.0003770219045691192, InvBCE: 0.7622600197792053\n",
      "Loss: 0.7407405376434326, Norm: 0.000747453304938972, InvBCE: 0.7150323390960693\n",
      "Loss: 0.7010695338249207, Norm: 0.0011111523490399122, InvBCE: 0.6752611994743347\n",
      "Image fooled! Adding perturbation...\n",
      "Image 31...\n",
      "Loss: 809.8494873046875, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8492431640625, Norm: 0.00023879343643784523, InvBCE: 809.8235473632812\n",
      "Loss: 809.8489990234375, Norm: 0.00047736914712004364, InvBCE: 809.8235473632812\n",
      "Loss: 809.8488159179688, Norm: 0.0007157102809287608, InvBCE: 809.8235473632812\n",
      "Loss: 809.8485717773438, Norm: 0.0009538000449538231, InvBCE: 809.8235473632812\n",
      "Loss: 809.8483276367188, Norm: 0.0011916208313778043, InvBCE: 809.8235473632812\n",
      "Loss: 809.84814453125, Norm: 0.001429155352525413, InvBCE: 809.8235473632812\n",
      "Loss: 809.847900390625, Norm: 0.0016663854476064444, InvBCE: 809.8235473632812\n",
      "Loss: 809.8477172851562, Norm: 0.0019032933050766587, InvBCE: 809.8235473632812\n",
      "Loss: 809.8474731445312, Norm: 0.0021398605313152075, InvBCE: 809.8235473632812\n",
      "Loss: 809.8472900390625, Norm: 0.0023760683834552765, InvBCE: 809.8235473632812\n",
      "Loss: 809.8470458984375, Norm: 0.0026118988171219826, InvBCE: 809.8235473632812\n",
      "Loss: 809.8468017578125, Norm: 0.002847332740202546, InvBCE: 809.8235473632812\n",
      "Loss: 809.8466186523438, Norm: 0.003082351293414831, InvBCE: 809.8235473632812\n",
      "Loss: 809.8463745117188, Norm: 0.0033169358503073454, InvBCE: 809.8235473632812\n",
      "Loss: 809.84619140625, Norm: 0.003551068250089884, InvBCE: 809.8235473632812\n",
      "Loss: 809.845947265625, Norm: 0.003784728702157736, InvBCE: 809.8235473632812\n",
      "Loss: 809.8457641601562, Norm: 0.0040178983472287655, InvBCE: 809.8235473632812\n",
      "Loss: 809.8455200195312, Norm: 0.004250559955835342, InvBCE: 809.8235473632812\n",
      "Loss: 809.8453369140625, Norm: 0.004482693038880825, InvBCE: 809.8235473632812\n",
      "Image 32...\n",
      "Loss: 1.6760450601577759, Norm: 0.0, InvBCE: 1.6501338481903076\n",
      "Loss: 1.6574044227600098, Norm: 0.00035629101330414414, InvBCE: 1.6315083503723145\n",
      "Loss: 1.6375144720077515, Norm: 0.000711330387275666, InvBCE: 1.6116288900375366\n",
      "Loss: 1.6166681051254272, Norm: 0.0010652197524905205, InvBCE: 1.5907882452011108\n",
      "Loss: 1.5953025817871094, Norm: 0.0014174769166857004, InvBCE: 1.5694241523742676\n",
      "Loss: 1.573829174041748, Norm: 0.0017675475683063269, InvBCE: 1.5479483604431152\n",
      "Loss: 1.5524787902832031, Norm: 0.0021148885134607553, InvBCE: 1.5265921354293823\n",
      "Loss: 1.5313807725906372, Norm: 0.0024590862449258566, InvBCE: 1.5054851770401\n",
      "Loss: 1.5104949474334717, Norm: 0.0027996907010674477, InvBCE: 1.484587550163269\n",
      "Loss: 1.489915370941162, Norm: 0.0031365181785076857, InvBCE: 1.4639939069747925\n",
      "Loss: 1.469699501991272, Norm: 0.0034695982467383146, InvBCE: 1.4437618255615234\n",
      "Loss: 1.4498541355133057, Norm: 0.003798919962719083, InvBCE: 1.423898458480835\n",
      "Image fooled! Adding perturbation...\n",
      "Image 33...\n",
      "Loss: 1.057838797569275, Norm: 0.0, InvBCE: 1.0318639278411865\n",
      "Loss: 0.986849844455719, Norm: 0.00037813239032402635, InvBCE: 0.9608195424079895\n",
      "Loss: 0.9246878027915955, Norm: 0.0007519111968576908, InvBCE: 0.8985985517501831\n",
      "Image fooled! Adding perturbation...\n",
      "Image 34...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 35...\n",
      "Loss: 1.288356065750122, Norm: 0.0, InvBCE: 1.2622051239013672\n",
      "Loss: 1.2329702377319336, Norm: 0.0003710996243171394, InvBCE: 1.206756830215454\n",
      "Loss: 1.1841236352920532, Norm: 0.000726768805179745, InvBCE: 1.1578516960144043\n",
      "Loss: 1.1406047344207764, Norm: 0.00107285485137254, InvBCE: 1.1142786741256714\n",
      "Loss: 1.1013487577438354, Norm: 0.0014126359019428492, InvBCE: 1.0749709606170654\n",
      "Loss: 1.0655773878097534, Norm: 0.0017476098146289587, InvBCE: 1.0391489267349243\n",
      "Loss: 1.0327435731887817, Norm: 0.0020785548258572817, InvBCE: 1.006264567375183\n",
      "Loss: 1.002502202987671, Norm: 0.0024058129638433456, InvBCE: 0.9759718775749207\n",
      "Loss: 0.9746202230453491, Norm: 0.0027293406892567873, InvBCE: 0.9480372667312622\n",
      "Loss: 0.9489110112190247, Norm: 0.003048721933737397, InvBCE: 0.9222737550735474\n",
      "Image fooled! Adding perturbation...\n",
      "Image 36...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 37...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 38...\n",
      "Loss: 1.4788576364517212, Norm: 0.0, InvBCE: 1.4521640539169312\n",
      "Loss: 1.463362693786621, Norm: 0.00034551339922472835, InvBCE: 1.4367249011993408\n",
      "Loss: 1.448689579963684, Norm: 0.0006883771275170147, InvBCE: 1.4221042394638062\n",
      "Image fooled! Adding perturbation...\n",
      "Image 39...\n",
      "Loss: 673.5122680664062, Norm: 0.0, InvBCE: 673.4857177734375\n",
      "Loss: 673.5120239257812, Norm: 0.00023813608277123421, InvBCE: 673.4857177734375\n",
      "Loss: 673.5118408203125, Norm: 0.00047605944564566016, InvBCE: 673.4857177734375\n",
      "Loss: 673.5115966796875, Norm: 0.0007137539214454591, InvBCE: 673.4857177734375\n",
      "Loss: 673.5113525390625, Norm: 0.0009512031101621687, InvBCE: 673.4857177734375\n",
      "Loss: 673.5111694335938, Norm: 0.0011883900733664632, InvBCE: 673.4857177734375\n",
      "Loss: 673.5109252929688, Norm: 0.0014252978144213557, InvBCE: 673.4857177734375\n",
      "Loss: 673.5107421875, Norm: 0.0016619089292362332, InvBCE: 673.4857177734375\n",
      "Loss: 673.510498046875, Norm: 0.0018982059555128217, InvBCE: 673.4857177734375\n",
      "Loss: 673.51025390625, Norm: 0.002134171314537525, InvBCE: 673.4857177734375\n",
      "Loss: 673.5100708007812, Norm: 0.0023697870783507824, InvBCE: 673.4857177734375\n",
      "Loss: 673.5098266601562, Norm: 0.002605035435408354, InvBCE: 673.4857177734375\n",
      "Loss: 673.5096435546875, Norm: 0.0028398979920893908, InvBCE: 673.4857177734375\n",
      "Loss: 673.5093994140625, Norm: 0.003074357286095619, InvBCE: 673.4857177734375\n",
      "Loss: 673.5092163085938, Norm: 0.003308394458144903, InvBCE: 673.4857177734375\n",
      "Loss: 673.5089721679688, Norm: 0.003541991813108325, InvBCE: 673.4857177734375\n",
      "Loss: 673.5087890625, Norm: 0.0037751314230263233, InvBCE: 673.4857177734375\n",
      "Loss: 673.508544921875, Norm: 0.0040077948942780495, InvBCE: 673.4857177734375\n",
      "Loss: 673.5083618164062, Norm: 0.004239964298903942, InvBCE: 673.4857177734375\n",
      "Loss: 673.5081176757812, Norm: 0.004471622407436371, InvBCE: 673.4857177734375\n",
      "Image 40...\n",
      "Loss: 41.648765563964844, Norm: 0.0, InvBCE: 41.622230529785156\n",
      "Loss: 40.273189544677734, Norm: 0.00038002675864845514, InvBCE: 40.24660110473633\n",
      "Loss: 37.537620544433594, Norm: 0.0007452715071849525, InvBCE: 37.51097869873047\n",
      "Loss: 33.54937744140625, Norm: 0.001099988934583962, InvBCE: 33.522682189941406\n",
      "Loss: 28.13575553894043, Norm: 0.0014515295624732971, InvBCE: 28.108999252319336\n",
      "Loss: 22.451372146606445, Norm: 0.0018040378345176578, InvBCE: 22.424551010131836\n",
      "Loss: 17.46898078918457, Norm: 0.0021598448511213064, InvBCE: 17.442087173461914\n",
      "Loss: 13.617339134216309, Norm: 0.002514592604711652, InvBCE: 13.59036922454834\n",
      "Loss: 10.928569793701172, Norm: 0.002861668122932315, InvBCE: 10.901519775390625\n",
      "Loss: 9.0006103515625, Norm: 0.0031993312295526266, InvBCE: 8.973479270935059\n",
      "Loss: 7.563105583190918, Norm: 0.0035259907599538565, InvBCE: 7.535891532897949\n",
      "Loss: 5.902158737182617, Norm: 0.003840862540528178, InvBCE: 5.874862194061279\n",
      "Loss: 5.002652645111084, Norm: 0.004160863347351551, InvBCE: 4.9752678871154785\n",
      "Loss: 4.425028324127197, Norm: 0.0044640363194048405, InvBCE: 4.397556781768799\n",
      "Loss: 3.9814305305480957, Norm: 0.004751333501189947, InvBCE: 3.953874349594116\n",
      "Loss: 4.04893684387207, Norm: 0.005023154895752668, InvBCE: 4.021298408508301\n",
      "Loss: 3.574554920196533, Norm: 0.0051123593002557755, InvBCE: 3.5468878746032715\n",
      "Loss: 3.532149076461792, Norm: 0.005207717884331942, InvBCE: 3.5044524669647217\n",
      "Loss: 3.4927937984466553, Norm: 0.00530749186873436, InvBCE: 3.465066909790039\n",
      "Loss: 3.4563441276550293, Norm: 0.005410386249423027, InvBCE: 3.428586721420288\n",
      "Image 41...\n",
      "Loss: 1.5518152713775635, Norm: 0.0, InvBCE: 1.5252786874771118\n",
      "Loss: 1.5292655229568481, Norm: 0.00036085856845602393, InvBCE: 1.5027152299880981\n",
      "Loss: 1.5079344511032104, Norm: 0.0007194734062068164, InvBCE: 1.481366515159607\n",
      "Loss: 1.4879659414291382, Norm: 0.0010752220405265689, InvBCE: 1.4613771438598633\n",
      "Loss: 1.469407558441162, Norm: 0.0014272056287154555, InvBCE: 1.442789912223816\n",
      "Loss: 1.4525235891342163, Norm: 0.0017736409790813923, InvBCE: 1.425876259803772\n",
      "Loss: 1.437182903289795, Norm: 0.0021136258728802204, InvBCE: 1.4105051755905151\n",
      "Loss: 1.4233436584472656, Norm: 0.00244641094468534, InvBCE: 1.3966349363327026\n",
      "Loss: 1.4108829498291016, Norm: 0.002771362429484725, InvBCE: 1.3841431140899658\n",
      "Loss: 1.3996546268463135, Norm: 0.003087973454967141, InvBCE: 1.3728840351104736\n",
      "Image fooled! Adding perturbation...\n",
      "Image 42...\n",
      "Loss: 1.388442873954773, Norm: 0.0, InvBCE: 1.3616423606872559\n",
      "Image fooled! Adding perturbation...\n",
      "Image 43...\n",
      "Loss: 0.4013163149356842, Norm: 0.0, InvBCE: 0.37449297308921814\n",
      "Loss: 0.35733625292778015, Norm: 0.0003513084666337818, InvBCE: 0.33042770624160767\n",
      "Loss: 0.3251301646232605, Norm: 0.0006941776955500245, InvBCE: 0.2981373369693756\n",
      "Loss: 0.30122560262680054, Norm: 0.001027619349770248, InvBCE: 0.2741503119468689\n",
      "Loss: 0.2827686071395874, Norm: 0.0013509405544027686, InvBCE: 0.25561320781707764\n",
      "Loss: 0.26876044273376465, Norm: 0.0016640330431982875, InvBCE: 0.2415274828672409\n",
      "Loss: 0.2577223777770996, Norm: 0.001966858049854636, InvBCE: 0.2304145097732544\n",
      "Image fooled! Adding perturbation...\n",
      "Image 44...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 45...\n",
      "Loss: 1.4320043325424194, Norm: 0.0, InvBCE: 1.404624104499817\n",
      "Image fooled! Adding perturbation...\n",
      "Image 46...\n",
      "Loss: 2.1707534790039062, Norm: 0.0, InvBCE: 2.1433982849121094\n",
      "Loss: 1.9122674465179443, Norm: 0.0003795617667492479, InvBCE: 1.8848581314086914\n",
      "Loss: 1.6945158243179321, Norm: 0.0007506976253353059, InvBCE: 1.6670475006103516\n",
      "Loss: 1.5117552280426025, Norm: 0.0011142771691083908, InvBCE: 1.4842242002487183\n",
      "Loss: 1.356594204902649, Norm: 0.0014691947726532817, InvBCE: 1.3289978504180908\n",
      "Loss: 1.1800495386123657, Norm: 0.0018158151069656014, InvBCE: 1.1523860692977905\n",
      "Loss: 1.0544524192810059, Norm: 0.002151412656530738, InvBCE: 1.0267210006713867\n",
      "Loss: 0.9713369011878967, Norm: 0.0024742744863033295, InvBCE: 0.943537712097168\n",
      "Loss: 0.9024899005889893, Norm: 0.002784949028864503, InvBCE: 0.8746232986450195\n",
      "Loss: 0.8426877856254578, Norm: 0.0030840870458632708, InvBCE: 0.8147544860839844\n",
      "Loss: 0.790186882019043, Norm: 0.003372339066118002, InvBCE: 0.7621878981590271\n",
      "Loss: 0.7440291047096252, Norm: 0.00365012651309371, InvBCE: 0.7159655690193176\n",
      "Loss: 0.7030265927314758, Norm: 0.003917899914085865, InvBCE: 0.6748998761177063\n",
      "Loss: 0.6664463877677917, Norm: 0.00417604623362422, InvBCE: 0.6382578611373901\n",
      "Loss: 0.6337288618087769, Norm: 0.00442492077127099, InvBCE: 0.6054801940917969\n",
      "Loss: 0.6044051051139832, Norm: 0.004664833657443523, InvBCE: 0.5760980248451233\n",
      "Loss: 0.5780713558197021, Norm: 0.004896066151559353, InvBCE: 0.5497076511383057\n",
      "Loss: 0.5543767213821411, Norm: 0.005118861328810453, InvBCE: 0.5259583592414856\n",
      "Loss: 0.5330336689949036, Norm: 0.00533345015719533, InvBCE: 0.5045625567436218\n",
      "Loss: 0.5138136148452759, Norm: 0.005540068726986647, InvBCE: 0.48529183864593506\n",
      "Image 47...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 48...\n",
      "Loss: 1.470220685005188, Norm: 0.0, InvBCE: 1.4428656101226807\n",
      "Image fooled! Adding perturbation...\n",
      "Image 49...\n",
      "Loss: 1.7904616594314575, Norm: 0.0, InvBCE: 1.7632440328598022\n",
      "Loss: 1.703740119934082, Norm: 0.0003776365192607045, InvBCE: 1.6764870882034302\n",
      "Loss: 1.6192184686660767, Norm: 0.0007481029606424272, InvBCE: 1.5919268131256104\n",
      "Loss: 1.5384713411331177, Norm: 0.0011142920702695847, InvBCE: 1.5111382007598877\n",
      "Loss: 1.4626785516738892, Norm: 0.0014741903869435191, InvBCE: 1.4353011846542358\n",
      "Loss: 1.3931745290756226, Norm: 0.0018277958733960986, InvBCE: 1.3657500743865967\n",
      "Loss: 1.3301899433135986, Norm: 0.0021744908299297094, InvBCE: 1.3027156591415405\n",
      "Image fooled! Adding perturbation...\n",
      "Image 50...\n",
      "Loss: 809.85107421875, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.850830078125, Norm: 0.00023812911240383983, InvBCE: 809.8235473632812\n",
      "Loss: 809.8506469726562, Norm: 0.00047605246072635055, InvBCE: 809.8235473632812\n",
      "Loss: 809.8504028320312, Norm: 0.0007137545617297292, InvBCE: 809.8235473632812\n",
      "Loss: 809.8502197265625, Norm: 0.0009512194665148854, InvBCE: 809.8235473632812\n",
      "Loss: 809.8499755859375, Norm: 0.00118843128439039, InvBCE: 809.8235473632812\n",
      "Loss: 809.8497314453125, Norm: 0.0014253734843805432, InvBCE: 809.8235473632812\n",
      "Loss: 809.8495483398438, Norm: 0.0016620296519249678, InvBCE: 809.8235473632812\n",
      "Loss: 809.8493041992188, Norm: 0.001898383256047964, InvBCE: 809.8235473632812\n",
      "Loss: 809.84912109375, Norm: 0.0021344174165278673, InvBCE: 809.8235473632812\n",
      "Loss: 809.848876953125, Norm: 0.0023701146710664034, InvBCE: 809.8235473632812\n",
      "Loss: 809.8486938476562, Norm: 0.0026054582558572292, InvBCE: 809.8235473632812\n",
      "Loss: 809.8484497070312, Norm: 0.0028404316399246454, InvBCE: 809.8235473632812\n",
      "Loss: 809.8482666015625, Norm: 0.0030750171281397343, InvBCE: 809.8235473632812\n",
      "Loss: 809.8480224609375, Norm: 0.003309197025373578, InvBCE: 809.8235473632812\n",
      "Loss: 809.8477783203125, Norm: 0.003542955033481121, InvBCE: 809.8235473632812\n",
      "Loss: 809.8475952148438, Norm: 0.003776273922994733, InvBCE: 809.8235473632812\n",
      "Loss: 809.8473510742188, Norm: 0.004009136464446783, InvBCE: 809.8235473632812\n",
      "Loss: 809.84716796875, Norm: 0.004241525661200285, InvBCE: 809.8235473632812\n",
      "Loss: 809.8469848632812, Norm: 0.004473424516618252, InvBCE: 809.8235473632812\n",
      "Image 51...\n",
      "Loss: 1.106377124786377, Norm: 0.0, InvBCE: 1.0788506269454956\n",
      "Loss: 1.0291364192962646, Norm: 0.0003743655688595027, InvBCE: 1.001577377319336\n",
      "Image fooled! Adding perturbation...\n",
      "Image 52...\n",
      "Loss: 1.250353455543518, Norm: 0.0, InvBCE: 1.2227596044540405\n",
      "Loss: 1.2344424724578857, Norm: 0.0003612741711549461, InvBCE: 1.206907868385315\n",
      "Image fooled! Adding perturbation...\n",
      "Image 53...\n",
      "Loss: 1.4102212190628052, Norm: 0.0, InvBCE: 1.3827420473098755\n",
      "Loss: 1.3892024755477905, Norm: 0.0003656380285974592, InvBCE: 1.3617159128189087\n",
      "Loss: 1.3685194253921509, Norm: 0.0007299994467757642, InvBCE: 1.3410215377807617\n",
      "Loss: 1.3481889963150024, Norm: 0.0010930162388831377, InvBCE: 1.320676326751709\n",
      "Image fooled! Adding perturbation...\n",
      "Image 54...\n",
      "Loss: 1.480877161026001, Norm: 0.0, InvBCE: 1.4533463716506958\n",
      "Loss: 1.4775680303573608, Norm: 0.0003153661673422903, InvBCE: 1.4501655101776123\n",
      "Loss: 1.474318027496338, Norm: 0.0006301048560999334, InvBCE: 1.4470409154891968\n",
      "Loss: 1.4712026119232178, Norm: 0.0009435656247660518, InvBCE: 1.444048285484314\n",
      "Image fooled! Adding perturbation...\n",
      "Image 55...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 56...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 57...\n",
      "Loss: 1.3561511039733887, Norm: 0.0, InvBCE: 1.3291171789169312\n",
      "Image fooled! Adding perturbation...\n",
      "Image 58...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 59...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 60...\n",
      "Loss: 809.8506469726562, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8504028320312, Norm: 0.00023801303177606314, InvBCE: 809.8235473632812\n",
      "Loss: 809.8502197265625, Norm: 0.000475816719699651, InvBCE: 809.8235473632812\n",
      "Loss: 809.8499755859375, Norm: 0.0007133951876312494, InvBCE: 809.8235473632812\n",
      "Loss: 809.8497924804688, Norm: 0.0009507322683930397, InvBCE: 809.8235473632812\n",
      "Loss: 809.8495483398438, Norm: 0.0011878116056323051, InvBCE: 809.8235473632812\n",
      "Loss: 809.8493041992188, Norm: 0.0014246163191273808, InvBCE: 809.8235473632812\n",
      "Loss: 809.84912109375, Norm: 0.0016611299943178892, InvBCE: 809.8235473632812\n",
      "Loss: 809.848876953125, Norm: 0.0018973351689055562, InvBCE: 809.8235473632812\n",
      "Loss: 809.8486938476562, Norm: 0.0021332146134227514, InvBCE: 809.8235473632812\n",
      "Loss: 809.8484497070312, Norm: 0.0023687512148171663, InvBCE: 809.8235473632812\n",
      "Loss: 809.8482666015625, Norm: 0.0026039271615445614, InvBCE: 809.8235473632812\n",
      "Loss: 809.8480224609375, Norm: 0.002838725224137306, InvBCE: 809.8235473632812\n",
      "Loss: 809.8478393554688, Norm: 0.003073127707466483, InvBCE: 809.8235473632812\n",
      "Loss: 809.8475952148438, Norm: 0.0033071169164031744, InvBCE: 809.8235473632812\n",
      "Loss: 809.847412109375, Norm: 0.0035406751558184624, InvBCE: 809.8235473632812\n",
      "Loss: 809.84716796875, Norm: 0.003773785661906004, InvBCE: 809.8235473632812\n",
      "Loss: 809.8469848632812, Norm: 0.0040064300410449505, InvBCE: 809.8235473632812\n",
      "Loss: 809.8467407226562, Norm: 0.004238591063767672, InvBCE: 809.8235473632812\n",
      "Loss: 809.8465576171875, Norm: 0.0044702524319291115, InvBCE: 809.8235473632812\n",
      "Image 61...\n",
      "Loss: 1.0563355684280396, Norm: 0.0, InvBCE: 1.029231309890747\n",
      "Loss: 0.951667845249176, Norm: 0.0003796767850872129, InvBCE: 0.9244870543479919\n",
      "Loss: 0.8648198843002319, Norm: 0.0007500456995330751, InvBCE: 0.8375604152679443\n",
      "Loss: 0.7932981848716736, Norm: 0.0011098644463345408, InvBCE: 0.7659597992897034\n",
      "Image fooled! Adding perturbation...\n",
      "Image 62...\n",
      "Loss: 1.137853741645813, Norm: 0.0, InvBCE: 1.1104357242584229\n",
      "Loss: 0.9881795644760132, Norm: 0.00038078593206591904, InvBCE: 0.9606670141220093\n",
      "Loss: 0.876989483833313, Norm: 0.0007501967484131455, InvBCE: 0.849381148815155\n",
      "Image fooled! Adding perturbation...\n",
      "Image 63...\n",
      "Loss: 1.4433972835540771, Norm: 0.0, InvBCE: 1.4156934022903442\n",
      "Loss: 1.3994054794311523, Norm: 0.00036913249641656876, InvBCE: 1.3717031478881836\n",
      "Loss: 1.3578659296035767, Norm: 0.000735321082174778, InvBCE: 1.3301615715026855\n",
      "Image fooled! Adding perturbation...\n",
      "Image 64...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 65...\n",
      "Loss: 1.2504799365997314, Norm: 0.0, InvBCE: 1.2227704524993896\n",
      "Loss: 1.166125774383545, Norm: 0.00037515361327677965, InvBCE: 1.1384141445159912\n",
      "Loss: 1.0908820629119873, Norm: 0.0007472699508070946, InvBCE: 1.0631638765335083\n",
      "Loss: 1.0242524147033691, Norm: 0.0011153622763231397, InvBCE: 0.9965247511863708\n",
      "Loss: 0.965573787689209, Norm: 0.0014785779640078545, InvBCE: 0.9378336668014526\n",
      "Image fooled! Adding perturbation...\n",
      "Image 66...\n",
      "Loss: 1.4828622341156006, Norm: 0.0, InvBCE: 1.4551074504852295\n",
      "Loss: 1.4484087228775024, Norm: 0.0003708527365233749, InvBCE: 1.4207111597061157\n",
      "Loss: 1.4146500825881958, Norm: 0.0007386843208223581, InvBCE: 1.3870054483413696\n",
      "Loss: 1.3817188739776611, Norm: 0.0011036766227334738, InvBCE: 1.3541228771209717\n",
      "Loss: 1.349757194519043, Norm: 0.0014656191924586892, InvBCE: 1.3222057819366455\n",
      "Image fooled! Adding perturbation...\n",
      "Image 67...\n",
      "Loss: 0.8955006003379822, Norm: 0.0, InvBCE: 0.8679898381233215\n",
      "Loss: 0.8144681453704834, Norm: 0.0003783712745644152, InvBCE: 0.7868983149528503\n",
      "Loss: 0.7458127737045288, Norm: 0.0007507443078793585, InvBCE: 0.7181803584098816\n",
      "Loss: 0.6878446340560913, Norm: 0.0011160438880324364, InvBCE: 0.6601468920707703\n",
      "Loss: 0.638994574546814, Norm: 0.0014727974776178598, InvBCE: 0.6112295389175415\n",
      "Loss: 0.5979339480400085, Norm: 0.0018197562312707305, InvBCE: 0.5701005458831787\n",
      "Image fooled! Adding perturbation...\n",
      "Image 68...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 69...\n",
      "Loss: 2.5546326637268066, Norm: 0.0, InvBCE: 2.526730537414551\n",
      "Loss: 2.2661092281341553, Norm: 0.00038168628816492856, InvBCE: 2.2381365299224854\n",
      "Loss: 2.0154192447662354, Norm: 0.0007590614841319621, InvBCE: 1.9873722791671753\n",
      "Loss: 1.7987977266311646, Norm: 0.00113148451782763, InvBCE: 1.7706732749938965\n",
      "Loss: 1.6124261617660522, Norm: 0.001497843535616994, InvBCE: 1.5842214822769165\n",
      "Loss: 1.452857494354248, Norm: 0.0018569868989288807, InvBCE: 1.4245704412460327\n",
      "Loss: 1.3167364597320557, Norm: 0.002207888988777995, InvBCE: 1.2883654832839966\n",
      "Loss: 1.2008280754089355, Norm: 0.002549679484218359, InvBCE: 1.1723719835281372\n",
      "Loss: 1.1021353006362915, Norm: 0.0028816787526011467, InvBCE: 1.0735934972763062\n",
      "Loss: 1.0180162191390991, Norm: 0.003203371539711952, InvBCE: 0.9893884062767029\n",
      "Loss: 0.9461749196052551, Norm: 0.0035144160501658916, InvBCE: 0.9174614548683167\n",
      "Loss: 0.8846293091773987, Norm: 0.0038146167062222958, InvBCE: 0.855830729007721\n",
      "Loss: 0.8317139744758606, Norm: 0.004103890620172024, InvBCE: 0.8028311729431152\n",
      "Loss: 0.7860358357429504, Norm: 0.0043822601437568665, InvBCE: 0.7570699453353882\n",
      "Loss: 0.7464402914047241, Norm: 0.004649846814572811, InvBCE: 0.7173926830291748\n",
      "Loss: 0.7119593620300293, Norm: 0.004906839691102505, InvBCE: 0.6828315854072571\n",
      "Loss: 0.6817927360534668, Norm: 0.0051534888334572315, InvBCE: 0.6525864005088806\n",
      "Loss: 0.6552688479423523, Norm: 0.00539008853957057, InvBCE: 0.625985860824585\n",
      "Loss: 0.6318442821502686, Norm: 0.005616975016891956, InvBCE: 0.6024864912033081\n",
      "Loss: 0.6110681295394897, Norm: 0.00583450123667717, InvBCE: 0.5816375613212585\n",
      "Image 70...\n",
      "Loss: 1.2708685398101807, Norm: 0.0, InvBCE: 1.2429664134979248\n",
      "Image fooled! Adding perturbation...\n",
      "Image 71...\n",
      "Loss: 2.8441622257232666, Norm: 0.0, InvBCE: 2.8163270950317383\n",
      "Loss: 2.5295655727386475, Norm: 0.0003791119670495391, InvBCE: 2.501682758331299\n",
      "Loss: 2.2533931732177734, Norm: 0.0007524533430114388, InvBCE: 2.225459575653076\n",
      "Loss: 2.0124149322509766, Norm: 0.0011203396134078503, InvBCE: 1.9844270944595337\n",
      "Loss: 1.8031039237976074, Norm: 0.0014816004550084472, InvBCE: 1.7750588655471802\n",
      "Loss: 1.6217960119247437, Norm: 0.0018352317856624722, InvBCE: 1.593691349029541\n",
      "Loss: 1.4649990797042847, Norm: 0.002180407289415598, InvBCE: 1.4368327856063843\n",
      "Loss: 1.3295427560806274, Norm: 0.0025164654944092035, InvBCE: 1.3013131618499756\n",
      "Loss: 1.2126587629318237, Norm: 0.002842868212610483, InvBCE: 1.184364914894104\n",
      "Loss: 1.111878514289856, Norm: 0.003159214509651065, InvBCE: 1.083519697189331\n",
      "Loss: 1.02494215965271, Norm: 0.0034652091562747955, InvBCE: 0.9965180158615112\n",
      "Loss: 0.9498687386512756, Norm: 0.0037606582045555115, InvBCE: 0.9213794469833374\n",
      "Loss: 0.8849263787269592, Norm: 0.004045452922582626, InvBCE: 0.8563722372055054\n",
      "Loss: 0.8286439180374146, Norm: 0.004319553263485432, InvBCE: 0.800025463104248\n",
      "Loss: 0.779761552810669, Norm: 0.0045829699374735355, InvBCE: 0.7510795593261719\n",
      "Loss: 0.7372407913208008, Norm: 0.00483580632135272, InvBCE: 0.7084961533546448\n",
      "Loss: 0.7001804113388062, Norm: 0.005078216549009085, InvBCE: 0.6713742613792419\n",
      "Loss: 0.6677712202072144, Norm: 0.00531041668727994, InvBCE: 0.638904869556427\n",
      "Loss: 0.6393378376960754, Norm: 0.005532666575163603, InvBCE: 0.6104128360748291\n",
      "Loss: 0.614324152469635, Norm: 0.005745252128690481, InvBCE: 0.5853420495986938\n",
      "Image 72...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 73...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 74...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 75...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 76...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 77...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 78...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 79...\n",
      "Loss: 809.8513793945312, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8511352539062, Norm: 0.00023800297640264034, InvBCE: 809.8235473632812\n",
      "Loss: 809.8509521484375, Norm: 0.0004757996939588338, InvBCE: 809.8235473632812\n",
      "Loss: 809.8507080078125, Norm: 0.0007133745239116251, InvBCE: 809.8235473632812\n",
      "Loss: 809.8505249023438, Norm: 0.0009507116628810763, InvBCE: 809.8235473632812\n",
      "Loss: 809.8502807617188, Norm: 0.001187794841825962, InvBCE: 809.8235473632812\n",
      "Loss: 809.8500366210938, Norm: 0.0014246079372242093, InvBCE: 809.8235473632812\n",
      "Loss: 809.849853515625, Norm: 0.001661134185269475, InvBCE: 809.8235473632812\n",
      "Loss: 809.849609375, Norm: 0.0018973571714013815, InvBCE: 809.8235473632812\n",
      "Loss: 809.8494262695312, Norm: 0.0021332597825676203, InvBCE: 809.8235473632812\n",
      "Loss: 809.8491821289062, Norm: 0.002368824789300561, InvBCE: 809.8235473632812\n",
      "Loss: 809.8489990234375, Norm: 0.002604035660624504, InvBCE: 809.8235473632812\n",
      "Loss: 809.8487548828125, Norm: 0.002838874701410532, InvBCE: 809.8235473632812\n",
      "Loss: 809.8485717773438, Norm: 0.0030733251478523016, InvBCE: 809.8235473632812\n",
      "Loss: 809.8483276367188, Norm: 0.003307370003312826, InvBCE: 809.8235473632812\n",
      "Loss: 809.84814453125, Norm: 0.0035409913398325443, InvBCE: 809.8235473632812\n",
      "Loss: 809.847900390625, Norm: 0.0037741728592664003, InvBCE: 809.8235473632812\n",
      "Loss: 809.8477172851562, Norm: 0.00400689709931612, InvBCE: 809.8235473632812\n",
      "Loss: 809.8474731445312, Norm: 0.004239147529006004, InvBCE: 809.8235473632812\n",
      "Loss: 809.8472900390625, Norm: 0.004470906686037779, InvBCE: 809.8235473632812\n",
      "Image 80...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 81...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 82...\n",
      "Loss: 0.9082655906677246, Norm: 0.0, InvBCE: 0.8804303407669067\n",
      "Loss: 0.8204110264778137, Norm: 0.00037963848444633186, InvBCE: 0.792534589767456\n",
      "Image fooled! Adding perturbation...\n",
      "Image 83...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 84...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 85...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 86...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 87...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 88...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 89...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 90...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 91...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 92...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 93...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 94...\n",
      "Loss: 1.0135222673416138, Norm: 0.0, InvBCE: 0.9856002330780029\n",
      "Loss: 0.9274364113807678, Norm: 0.00037994058220647275, InvBCE: 0.8994766473770142\n",
      "Loss: 0.8548025488853455, Norm: 0.0007529471185989678, InvBCE: 0.826801598072052\n",
      "Image fooled! Adding perturbation...\n",
      "Image 95...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 96...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 97...\n",
      "Loss: 1.473073124885559, Norm: 0.0, InvBCE: 1.44502854347229\n",
      "Image fooled! Adding perturbation...\n",
      "Image 98...\n",
      "Loss: 1.420492172241211, Norm: 0.0, InvBCE: 1.3924367427825928\n",
      "Loss: 1.3814607858657837, Norm: 0.00037337865796871483, InvBCE: 1.3533636331558228\n",
      "Loss: 1.345295786857605, Norm: 0.000742242787964642, InvBCE: 1.3171533346176147\n",
      "Image fooled! Adding perturbation...\n",
      "Image 99...\n",
      "Image fooled! Adding perturbation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55eb9ca9b21b4e3ab54cfd9b7fd93c69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fooling rate: 0.68\n",
      "Starting epoch 4...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a161546436c24b9d9b6261c0a64514c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 1...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 2...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 3...\n",
      "Loss: 4.521964073181152, Norm: 0.0, InvBCE: 4.493773460388184\n",
      "Loss: 3.92197585105896, Norm: 0.00038219839916564524, InvBCE: 3.893730401992798\n",
      "Loss: 3.4093801975250244, Norm: 0.0007585235289297998, InvBCE: 3.3810768127441406\n",
      "Loss: 2.9748125076293945, Norm: 0.0011282799532637, InvBCE: 2.9464480876922607\n",
      "Loss: 2.607862949371338, Norm: 0.0014899001689627767, InvBCE: 2.5794355869293213\n",
      "Loss: 2.2982394695281982, Norm: 0.001842150348238647, InvBCE: 2.269747495651245\n",
      "Loss: 2.0365123748779297, Norm: 0.00218410836532712, InvBCE: 2.007955312728882\n",
      "Loss: 1.8144060373306274, Norm: 0.0025151455774903297, InvBCE: 1.785783290863037\n",
      "Loss: 1.6249430179595947, Norm: 0.002834911225363612, InvBCE: 1.596254825592041\n",
      "Loss: 1.4625099897384644, Norm: 0.0031432511750608683, InvBCE: 1.433756947517395\n",
      "Loss: 1.3226487636566162, Norm: 0.0034401582088321447, InvBCE: 1.293831706047058\n",
      "Loss: 1.2017878293991089, Norm: 0.0037257110234349966, InvBCE: 1.172908067703247\n",
      "Loss: 1.0971101522445679, Norm: 0.004000053275376558, InvBCE: 1.0681689977645874\n",
      "Loss: 1.0063726902008057, Norm: 0.004263364244252443, InvBCE: 0.9773717522621155\n",
      "Loss: 0.9279590249061584, Norm: 0.00451586302369833, InvBCE: 0.8988999724388123\n",
      "Loss: 0.8601787090301514, Norm: 0.004757770802825689, InvBCE: 0.831063449382782\n",
      "Loss: 0.8013376593589783, Norm: 0.004989366512745619, InvBCE: 0.7721681594848633\n",
      "Loss: 0.7502526640892029, Norm: 0.005210964009165764, InvBCE: 0.7210308909416199\n",
      "Loss: 0.7058829665184021, Norm: 0.005422884598374367, InvBCE: 0.6766109466552734\n",
      "Loss: 0.6673004031181335, Norm: 0.00562545470893383, InvBCE: 0.6379801630973816\n",
      "Image 4...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 5...\n",
      "Loss: 1.4490702152252197, Norm: 0.0, InvBCE: 1.4208793640136719\n",
      "Image fooled! Adding perturbation...\n",
      "Image 6...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 7...\n",
      "Loss: 1.0213929414749146, Norm: 0.0, InvBCE: 0.9931186437606812\n",
      "Loss: 0.9679398536682129, Norm: 0.00037259163218550384, InvBCE: 0.9396532773971558\n",
      "Loss: 0.918241024017334, Norm: 0.0007417419110424817, InvBCE: 0.8899394869804382\n",
      "Loss: 0.872315526008606, Norm: 0.001107280608266592, InvBCE: 0.8439965844154358\n",
      "Loss: 0.8301724195480347, Norm: 0.0014685187488794327, InvBCE: 0.8018338084220886\n",
      "Image fooled! Adding perturbation...\n",
      "Image 8...\n",
      "Loss: 1.462827205657959, Norm: 0.0, InvBCE: 1.434467077255249\n",
      "Image fooled! Adding perturbation...\n",
      "Image 9...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 10...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 11...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 12...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 13...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 14...\n",
      "Loss: 1.1696698665618896, Norm: 0.0, InvBCE: 1.1413869857788086\n",
      "Loss: 1.0733667612075806, Norm: 0.0003789226757362485, InvBCE: 1.0450416803359985\n",
      "Image fooled! Adding perturbation...\n",
      "Image 15...\n",
      "Loss: 0.6305263638496399, Norm: 0.0, InvBCE: 0.6021571755409241\n",
      "Image fooled! Adding perturbation...\n",
      "Image 16...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 17...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 18...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 19...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 20...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 21...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 22...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 23...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 24...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 25...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 26...\n",
      "Loss: 1.4818302392959595, Norm: 0.0, InvBCE: 1.4533894062042236\n",
      "Loss: 1.479952096939087, Norm: 0.0003105740179307759, InvBCE: 1.4516428709030151\n",
      "Loss: 1.4780421257019043, Norm: 0.0006212277221493423, InvBCE: 1.449861764907837\n",
      "Loss: 1.476110816001892, Norm: 0.0009318101219832897, InvBCE: 1.448056697845459\n",
      "Loss: 1.4741694927215576, Norm: 0.0012421682476997375, InvBCE: 1.4462392330169678\n",
      "Loss: 1.4722298383712769, Norm: 0.0015521508175879717, InvBCE: 1.4444209337234497\n",
      "Loss: 1.4703032970428467, Norm: 0.0018615981098264456, InvBCE: 1.4426134824752808\n",
      "Image fooled! Adding perturbation...\n",
      "Image 27...\n",
      "Loss: 0.7631449699401855, Norm: 0.0, InvBCE: 0.7355718612670898\n",
      "Loss: 0.7082626819610596, Norm: 0.00037852293462492526, InvBCE: 0.6805877685546875\n",
      "Loss: 0.6598846316337585, Norm: 0.0007529583526775241, InvBCE: 0.6321044564247131\n",
      "Loss: 0.617438793182373, Norm: 0.001122437883168459, InvBCE: 0.5895506739616394\n",
      "Loss: 0.5803452134132385, Norm: 0.001485832966864109, InvBCE: 0.55234694480896\n",
      "Loss: 0.5480200052261353, Norm: 0.0018421380082145333, InvBCE: 0.5199102163314819\n",
      "Loss: 0.5199019312858582, Norm: 0.00219049584120512, InvBCE: 0.49167966842651367\n",
      "Image fooled! Adding perturbation...\n",
      "Image 28...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 29...\n",
      "Loss: 0.6660443544387817, Norm: 0.0, InvBCE: 0.637709379196167\n",
      "Loss: 0.6305081248283386, Norm: 0.0003746221773326397, InvBCE: 0.6020860075950623\n",
      "Loss: 0.5989107489585876, Norm: 0.0007452658610418439, InvBCE: 0.5703977346420288\n",
      "Image fooled! Adding perturbation...\n",
      "Image 30...\n",
      "Loss: 0.8195754289627075, Norm: 0.0, InvBCE: 0.7909681797027588\n",
      "Loss: 0.7654977440834045, Norm: 0.0003758669481612742, InvBCE: 0.7367947697639465\n",
      "Loss: 0.7207804918289185, Norm: 0.0007450753473676741, InvBCE: 0.6919789910316467\n",
      "Image fooled! Adding perturbation...\n",
      "Image 31...\n",
      "Loss: 809.8524780273438, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8522338867188, Norm: 0.00023732060799375176, InvBCE: 809.8235473632812\n",
      "Loss: 809.8519897460938, Norm: 0.0004744393809232861, InvBCE: 809.8235473632812\n",
      "Loss: 809.851806640625, Norm: 0.000711341155692935, InvBCE: 809.8235473632812\n",
      "Loss: 809.8515625, Norm: 0.0009480105363763869, InvBCE: 809.8235473632812\n",
      "Loss: 809.8513793945312, Norm: 0.0011844319524243474, InvBCE: 809.8235473632812\n",
      "Loss: 809.8511352539062, Norm: 0.0014205893967300653, InvBCE: 809.8235473632812\n",
      "Loss: 809.8509521484375, Norm: 0.0016564669786021113, InvBCE: 809.8235473632812\n",
      "Loss: 809.8507080078125, Norm: 0.0018920482834801078, InvBCE: 809.8235473632812\n",
      "Loss: 809.8504638671875, Norm: 0.002127317013218999, InvBCE: 809.8235473632812\n",
      "Loss: 809.8502807617188, Norm: 0.0023622571025043726, InvBCE: 809.8235473632812\n",
      "Loss: 809.8500366210938, Norm: 0.002596851671114564, InvBCE: 809.8235473632812\n",
      "Loss: 809.849853515625, Norm: 0.0028310841880738735, InvBCE: 809.8235473632812\n",
      "Loss: 809.849609375, Norm: 0.003064938588067889, InvBCE: 809.8235473632812\n",
      "Loss: 809.8494262695312, Norm: 0.003298397408798337, InvBCE: 809.8235473632812\n",
      "Loss: 809.8491821289062, Norm: 0.0035314452834427357, InvBCE: 809.8235473632812\n",
      "Loss: 809.8489990234375, Norm: 0.0037640647497028112, InvBCE: 809.8235473632812\n",
      "Loss: 809.8487548828125, Norm: 0.0039962404407560825, InvBCE: 809.8235473632812\n",
      "Loss: 809.8485717773438, Norm: 0.004227955359965563, InvBCE: 809.8235473632812\n",
      "Loss: 809.848388671875, Norm: 0.004459193907678127, InvBCE: 809.8235473632812\n",
      "Image 32...\n",
      "Loss: 1.5547646284103394, Norm: 0.0, InvBCE: 1.525862693786621\n",
      "Loss: 1.53091561794281, Norm: 0.0003592446737457067, InvBCE: 1.502018928527832\n",
      "Loss: 1.5075894594192505, Norm: 0.0007152420002967119, InvBCE: 1.478696346282959\n",
      "Loss: 1.4849591255187988, Norm: 0.0010683572618290782, InvBCE: 1.4560678005218506\n",
      "Loss: 1.4632253646850586, Norm: 0.001418098108842969, InvBCE: 1.434334397315979\n",
      "Image fooled! Adding perturbation...\n",
      "Image 33...\n",
      "Loss: 0.949816882610321, Norm: 0.0, InvBCE: 0.9209247827529907\n",
      "Image fooled! Adding perturbation...\n",
      "Image 34...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 35...\n",
      "Loss: 1.106766700744629, Norm: 0.0, InvBCE: 1.0778080224990845\n",
      "Loss: 1.0337952375411987, Norm: 0.0003803202707786113, InvBCE: 1.0048185586929321\n",
      "Loss: 0.9974387884140015, Norm: 0.0007231407798826694, InvBCE: 0.9684361815452576\n",
      "Loss: 0.9711323380470276, Norm: 0.0010429981630295515, InvBCE: 0.9420971274375916\n",
      "Loss: 0.9488559365272522, Norm: 0.001344794174656272, InvBCE: 0.9197823405265808\n",
      "Image fooled! Adding perturbation...\n",
      "Image 36...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 37...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 38...\n",
      "Loss: 1.4932303428649902, Norm: 0.0, InvBCE: 1.464113473892212\n",
      "Loss: 1.4798424243927002, Norm: 0.00034617685014382005, InvBCE: 1.4507843255996704\n",
      "Loss: 1.466269612312317, Norm: 0.0006909455987624824, InvBCE: 1.4372671842575073\n",
      "Loss: 1.4525668621063232, Norm: 0.0010341680608689785, InvBCE: 1.4236170053482056\n",
      "Image fooled! Adding perturbation...\n",
      "Image 39...\n",
      "Loss: 673.5145874023438, Norm: 0.0, InvBCE: 673.4857177734375\n",
      "Loss: 673.514404296875, Norm: 0.0002370667934883386, InvBCE: 673.4857177734375\n",
      "Loss: 673.51416015625, Norm: 0.0004739305004477501, InvBCE: 673.4857177734375\n",
      "Loss: 673.5139770507812, Norm: 0.0007105758995749056, InvBCE: 673.4857177734375\n",
      "Loss: 673.5137329101562, Norm: 0.0009469875367358327, InvBCE: 673.4857177734375\n",
      "Loss: 673.5135498046875, Norm: 0.0011831496376544237, InvBCE: 673.4857177734375\n",
      "Loss: 673.5133056640625, Norm: 0.0014190463116392493, InvBCE: 673.4857177734375\n",
      "Loss: 673.5131225585938, Norm: 0.0016546614933758974, InvBCE: 673.4857177734375\n",
      "Loss: 673.5128784179688, Norm: 0.0018899785354733467, InvBCE: 673.4857177734375\n",
      "Loss: 673.5126342773438, Norm: 0.0021249819546937943, InvBCE: 673.4857177734375\n",
      "Loss: 673.512451171875, Norm: 0.002359654288738966, InvBCE: 673.4857177734375\n",
      "Loss: 673.51220703125, Norm: 0.0025939797051250935, InvBCE: 673.4857177734375\n",
      "Loss: 673.5120239257812, Norm: 0.00282794120721519, InvBCE: 673.4857177734375\n",
      "Loss: 673.5117797851562, Norm: 0.0030615224968641996, InvBCE: 673.4857177734375\n",
      "Loss: 673.5115966796875, Norm: 0.003294706577435136, InvBCE: 673.4857177734375\n",
      "Loss: 673.5113525390625, Norm: 0.0035274773836135864, InvBCE: 673.4857177734375\n",
      "Loss: 673.5111694335938, Norm: 0.003759818384423852, InvBCE: 673.4857177734375\n",
      "Loss: 673.510986328125, Norm: 0.003991712816059589, InvBCE: 673.4857177734375\n",
      "Loss: 673.5107421875, Norm: 0.0042231446132063866, InvBCE: 673.4857177734375\n",
      "Loss: 673.5105590820312, Norm: 0.004454098176211119, InvBCE: 673.4857177734375\n",
      "Image 40...\n",
      "Loss: 40.00899887084961, Norm: 0.0, InvBCE: 39.980098724365234\n",
      "Loss: 37.06084060668945, Norm: 0.000382194179110229, InvBCE: 37.031898498535156\n",
      "Loss: 32.83416748046875, Norm: 0.0007438497850671411, InvBCE: 32.805179595947266\n",
      "Loss: 27.24445343017578, Norm: 0.0011055016657337546, InvBCE: 27.215412139892578\n",
      "Loss: 21.545486450195312, Norm: 0.0014659978915005922, InvBCE: 21.516386032104492\n",
      "Loss: 16.75876808166504, Norm: 0.0018287089187651873, InvBCE: 16.729602813720703\n",
      "Loss: 13.096363067626953, Norm: 0.0021872154902666807, InvBCE: 13.067129135131836\n",
      "Loss: 10.500297546386719, Norm: 0.0025375995319336653, InvBCE: 10.470993041992188\n",
      "Loss: 8.619668960571289, Norm: 0.00287778303027153, InvBCE: 8.590291976928711\n",
      "Loss: 7.233814239501953, Norm: 0.003206240711733699, InvBCE: 7.20436429977417\n",
      "Loss: 5.878097057342529, Norm: 0.0035220312420278788, InvBCE: 5.848573684692383\n",
      "Loss: 4.770705699920654, Norm: 0.0038419163320213556, InvBCE: 4.74110221862793\n",
      "Loss: 4.222269058227539, Norm: 0.004143756814301014, InvBCE: 4.192586898803711\n",
      "Loss: 3.81095027923584, Norm: 0.004428307060152292, InvBCE: 3.781191825866699\n",
      "Loss: 3.4900028705596924, Norm: 0.004696290008723736, InvBCE: 3.4601707458496094\n",
      "Loss: 2.76711368560791, Norm: 0.004948765505105257, InvBCE: 2.737210273742676\n",
      "Loss: 2.504720449447632, Norm: 0.005185524933040142, InvBCE: 2.474748373031616\n",
      "Loss: 2.2862837314605713, Norm: 0.005407953169196844, InvBCE: 2.2562456130981445\n",
      "Loss: 2.1108405590057373, Norm: 0.005616975482553244, InvBCE: 2.0807387828826904\n",
      "Loss: 1.9584343433380127, Norm: 0.005813497584313154, InvBCE: 1.928271770477295\n",
      "Image 41...\n",
      "Loss: 1.4430608749389648, Norm: 0.0, InvBCE: 1.4141608476638794\n",
      "Loss: 1.4275842905044556, Norm: 0.0003552981361281127, InvBCE: 1.3986681699752808\n",
      "Loss: 1.41331148147583, Norm: 0.0007061933865770698, InvBCE: 1.3843772411346436\n",
      "Loss: 1.4002472162246704, Norm: 0.0010525197722017765, InvBCE: 1.371293067932129\n",
      "Image fooled! Adding perturbation...\n",
      "Image 42...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 43...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 44...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 45...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 46...\n",
      "Loss: 1.5758271217346191, Norm: 0.0, InvBCE: 1.5468518733978271\n",
      "Loss: 1.4090715646743774, Norm: 0.0003778482205234468, InvBCE: 1.380040168762207\n",
      "Loss: 1.2663578987121582, Norm: 0.0007483370136469603, InvBCE: 1.237267255783081\n",
      "Loss: 1.1446943283081055, Norm: 0.0011114608496427536, InvBCE: 1.1155421733856201\n",
      "Loss: 1.007269263267517, Norm: 0.001465678564272821, InvBCE: 0.9780539274215698\n",
      "Loss: 0.9040774703025818, Norm: 0.0017957482486963272, InvBCE: 0.8747970461845398\n",
      "Loss: 0.8386083841323853, Norm: 0.0021162317134439945, InvBCE: 0.8092632293701172\n",
      "Loss: 0.7844815254211426, Norm: 0.00242618378251791, InvBCE: 0.7550723552703857\n",
      "Loss: 0.7375293374061584, Norm: 0.0027256826870143414, InvBCE: 0.7080571055412292\n",
      "Loss: 0.696365475654602, Norm: 0.003015074646100402, InvBCE: 0.6668313145637512\n",
      "Loss: 0.6601994037628174, Norm: 0.0032946914434432983, InvBCE: 0.6306045651435852\n",
      "Loss: 0.6283904314041138, Norm: 0.0035648082848638296, InvBCE: 0.5987364053726196\n",
      "Loss: 0.6002591848373413, Norm: 0.0038256384432315826, InvBCE: 0.5705475807189941\n",
      "Loss: 0.5752366185188293, Norm: 0.0040774173103272915, InvBCE: 0.5454691052436829\n",
      "Loss: 0.5528741478919983, Norm: 0.004320365842431784, InvBCE: 0.523052453994751\n",
      "Loss: 0.5327974557876587, Norm: 0.00455474341288209, InvBCE: 0.5029233694076538\n",
      "Loss: 0.5147016644477844, Norm: 0.0047808014787733555, InvBCE: 0.4847770929336548\n",
      "Image fooled! Adding perturbation...\n",
      "Image 47...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 48...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 49...\n",
      "Loss: 1.361061930656433, Norm: 0.0, InvBCE: 1.3310887813568115\n",
      "Loss: 1.2929165363311768, Norm: 0.0003754406643565744, InvBCE: 1.2628780603408813\n",
      "Image fooled! Adding perturbation...\n",
      "Image 50...\n",
      "Loss: 809.8536376953125, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8534545898438, Norm: 0.0002367715205764398, InvBCE: 809.8235473632812\n",
      "Loss: 809.8532104492188, Norm: 0.0004733469686470926, InvBCE: 809.8235473632812\n",
      "Loss: 809.85302734375, Norm: 0.0007097117486409843, InvBCE: 809.8235473632812\n",
      "Loss: 809.852783203125, Norm: 0.0009458510321564972, InvBCE: 809.8235473632812\n",
      "Loss: 809.8525390625, Norm: 0.0011817497434094548, InvBCE: 809.8235473632812\n",
      "Loss: 809.8523559570312, Norm: 0.0014173927484080195, InvBCE: 809.8235473632812\n",
      "Loss: 809.8521118164062, Norm: 0.0016527645057067275, InvBCE: 809.8235473632812\n",
      "Loss: 809.8519287109375, Norm: 0.0018878496484830976, InvBCE: 809.8235473632812\n",
      "Loss: 809.8516845703125, Norm: 0.002122632460668683, InvBCE: 809.8235473632812\n",
      "Loss: 748.1043090820312, Norm: 0.002357097342610359, InvBCE: 748.0763549804688\n",
      "Loss: 442.9284973144531, Norm: 0.002355445409193635, InvBCE: 442.9005432128906\n",
      "Loss: 229.0943145751953, Norm: 0.002372194081544876, InvBCE: 229.06634521484375\n",
      "Loss: 119.84596252441406, Norm: 0.0024162442423403263, InvBCE: 119.8179702758789\n",
      "Loss: 68.2109603881836, Norm: 0.002485537203028798, InvBCE: 68.18294525146484\n",
      "Loss: 54.70393753051758, Norm: 0.002574395155534148, InvBCE: 54.675899505615234\n",
      "Loss: 35.63816452026367, Norm: 0.002677472773939371, InvBCE: 35.610103607177734\n",
      "Loss: 25.870853424072266, Norm: 0.0027891574427485466, InvBCE: 25.842771530151367\n",
      "Loss: 19.109073638916016, Norm: 0.00290534901432693, InvBCE: 19.08097267150879\n",
      "Loss: 14.898214340209961, Norm: 0.0030226942617446184, InvBCE: 14.870094299316406\n",
      "Image 51...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 52...\n",
      "Loss: 1.2544890642166138, Norm: 0.0, InvBCE: 1.2243822813034058\n",
      "Loss: 1.2401114702224731, Norm: 0.0003606118552852422, InvBCE: 1.2100542783737183\n",
      "Loss: 1.225783348083496, Norm: 0.0007199888932518661, InvBCE: 1.1957725286483765\n",
      "Image fooled! Adding perturbation...\n",
      "Image 53...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 54...\n",
      "Loss: 1.4789024591445923, Norm: 0.0, InvBCE: 1.4489349126815796\n",
      "Loss: 1.4765973091125488, Norm: 0.0003117219894193113, InvBCE: 1.4467653036117554\n",
      "Loss: 1.4743226766586304, Norm: 0.0006231304141692817, InvBCE: 1.4446234703063965\n",
      "Loss: 1.4720860719680786, Norm: 0.0009339347016066313, InvBCE: 1.4425172805786133\n",
      "Image fooled! Adding perturbation...\n",
      "Image 55...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 56...\n",
      "Loss: 0.506928026676178, Norm: 0.0, InvBCE: 0.47748714685440063\n",
      "Loss: 0.45763099193573, Norm: 0.00037398567656055093, InvBCE: 0.42814069986343384\n",
      "Loss: 0.41870009899139404, Norm: 0.0007390097016468644, InvBCE: 0.38915836811065674\n",
      "Image fooled! Adding perturbation...\n",
      "Image 57...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 58...\n",
      "Loss: 1.5063551664352417, Norm: 0.0, InvBCE: 1.476760745048523\n",
      "Loss: 1.4825315475463867, Norm: 0.0003677416534628719, InvBCE: 1.4530038833618164\n",
      "Loss: 1.4665776491165161, Norm: 0.0007087694248184562, InvBCE: 1.4371165037155151\n",
      "Loss: 1.4503755569458008, Norm: 0.0010511836735531688, InvBCE: 1.4209789037704468\n",
      "Loss: 1.4343360662460327, Norm: 0.0013936611358076334, InvBCE: 1.4050016403198242\n",
      "Image fooled! Adding perturbation...\n",
      "Image 59...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 60...\n",
      "Loss: 809.8528442382812, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8526000976562, Norm: 0.00023630252690054476, InvBCE: 809.8235473632812\n",
      "Loss: 809.8523559570312, Norm: 0.00047240222920663655, InvBCE: 809.8235473632812\n",
      "Loss: 809.8521728515625, Norm: 0.0007082839147187769, InvBCE: 809.8235473632812\n",
      "Loss: 809.8519287109375, Norm: 0.0009439322166144848, InvBCE: 809.8235473632812\n",
      "Loss: 809.8517456054688, Norm: 0.001179331447929144, InvBCE: 809.8235473632812\n",
      "Loss: 809.8515014648438, Norm: 0.0014144660672172904, InvBCE: 809.8235473632812\n",
      "Loss: 809.851318359375, Norm: 0.0016493197763338685, InvBCE: 809.8235473632812\n",
      "Loss: 809.85107421875, Norm: 0.0018838763935491443, InvBCE: 809.8235473632812\n",
      "Loss: 809.8508911132812, Norm: 0.002118120202794671, InvBCE: 809.8235473632812\n",
      "Loss: 809.8506469726562, Norm: 0.0023520339746028185, InvBCE: 809.8235473632812\n",
      "Loss: 809.8504638671875, Norm: 0.0025856024585664272, InvBCE: 809.8235473632812\n",
      "Loss: 809.8502197265625, Norm: 0.0028188081923872232, InvBCE: 809.8235473632812\n",
      "Loss: 809.8500366210938, Norm: 0.0030516351107507944, InvBCE: 809.8235473632812\n",
      "Loss: 809.8497924804688, Norm: 0.003284066915512085, InvBCE: 809.8235473632812\n",
      "Loss: 809.849609375, Norm: 0.0035160875413566828, InvBCE: 809.8235473632812\n",
      "Loss: 809.849365234375, Norm: 0.003747679991647601, InvBCE: 809.8235473632812\n",
      "Loss: 809.8491821289062, Norm: 0.003978828899562359, InvBCE: 809.8235473632812\n",
      "Loss: 809.8489379882812, Norm: 0.004209517501294613, InvBCE: 809.8235473632812\n",
      "Loss: 809.8487548828125, Norm: 0.004439730662852526, InvBCE: 809.8235473632812\n",
      "Image 61...\n",
      "Loss: 0.9074362516403198, Norm: 0.0, InvBCE: 0.8781619071960449\n",
      "Loss: 0.823721170425415, Norm: 0.00037836935371160507, InvBCE: 0.7943757772445679\n",
      "Image fooled! Adding perturbation...\n",
      "Image 62...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 63...\n",
      "Loss: 1.5064141750335693, Norm: 0.0, InvBCE: 1.4769948720932007\n",
      "Loss: 1.4631097316741943, Norm: 0.000369210698409006, InvBCE: 1.4336940050125122\n",
      "Loss: 1.4210889339447021, Norm: 0.0007368293008767068, InvBCE: 1.391672968864441\n",
      "Loss: 1.3806309700012207, Norm: 0.0011026441352441907, InvBCE: 1.3512108325958252\n",
      "Loss: 1.341977596282959, Norm: 0.0014661196619272232, InvBCE: 1.3125497102737427\n",
      "Image fooled! Adding perturbation...\n",
      "Image 64...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 65...\n",
      "Loss: 1.0410025119781494, Norm: 0.0, InvBCE: 1.0115634202957153\n",
      "Loss: 0.9810387492179871, Norm: 0.00037270659231580794, InvBCE: 0.951593279838562\n",
      "Loss: 0.9278072714805603, Norm: 0.0007416277076117694, InvBCE: 0.8983534574508667\n",
      "Image fooled! Adding perturbation...\n",
      "Image 66...\n",
      "Loss: 1.3813856840133667, Norm: 0.0, InvBCE: 1.3519207239151\n",
      "Loss: 1.3483234643936157, Norm: 0.0003695305495057255, InvBCE: 1.318910002708435\n",
      "Image fooled! Adding perturbation...\n",
      "Image 67...\n",
      "Loss: 0.6020355820655823, Norm: 0.0, InvBCE: 0.5726697444915771\n",
      "Image fooled! Adding perturbation...\n",
      "Image 68...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 69...\n",
      "Loss: 2.0680713653564453, Norm: 0.0, InvBCE: 2.0386526584625244\n",
      "Loss: 1.8358328342437744, Norm: 0.00038119012606330216, InvBCE: 1.8063453435897827\n",
      "Loss: 1.6383006572723389, Norm: 0.0007576646166853607, InvBCE: 1.6087404489517212\n",
      "Loss: 1.471097469329834, Norm: 0.001128473086282611, InvBCE: 1.4414608478546143\n",
      "Loss: 1.3299351930618286, Norm: 0.0014921737601980567, InvBCE: 1.300219178199768\n",
      "Loss: 1.2108430862426758, Norm: 0.0018475387478247285, InvBCE: 1.181045413017273\n",
      "Loss: 1.1102432012557983, Norm: 0.0021936073899269104, InvBCE: 1.0803619623184204\n",
      "Loss: 1.025052547454834, Norm: 0.0025296753738075495, InvBCE: 0.9950864911079407\n",
      "Loss: 0.9526457786560059, Norm: 0.002855277620255947, InvBCE: 0.9225941300392151\n",
      "Loss: 0.890814483165741, Norm: 0.0031701410189270973, InvBCE: 0.8606770038604736\n",
      "Loss: 0.8377460837364197, Norm: 0.003474163357168436, InvBCE: 0.8075228333473206\n",
      "Loss: 0.7919700145721436, Norm: 0.0037673674523830414, InvBCE: 0.7616615295410156\n",
      "Loss: 0.7522433400154114, Norm: 0.0040498520247638226, InvBCE: 0.7218504548072815\n",
      "Loss: 0.7175946831703186, Norm: 0.004321811255067587, InvBCE: 0.687118411064148\n",
      "Loss: 0.6872243881225586, Norm: 0.004583494272083044, InvBCE: 0.6566660404205322\n",
      "Loss: 0.6604557633399963, Norm: 0.004835168831050396, InvBCE: 0.6298168897628784\n",
      "Loss: 0.6367478370666504, Norm: 0.0050771660171449184, InvBCE: 0.6060301065444946\n",
      "Loss: 0.6156429648399353, Norm: 0.005309815984219313, InvBCE: 0.584848165512085\n",
      "Loss: 0.5967726707458496, Norm: 0.005533458665013313, InvBCE: 0.5659026503562927\n",
      "Image fooled! Adding perturbation...\n",
      "Image 70...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 71...\n",
      "Loss: 1.0683952569961548, Norm: 0.0, InvBCE: 1.0374521017074585\n",
      "Loss: 0.9713093638420105, Norm: 0.0003749100142158568, InvBCE: 0.9402846097946167\n",
      "Loss: 0.8877519369125366, Norm: 0.0007437989697791636, InvBCE: 0.8566421270370483\n",
      "Loss: 0.8161453604698181, Norm: 0.0011063282145187259, InvBCE: 0.7849476337432861\n",
      "Loss: 0.7549442648887634, Norm: 0.0014614107785746455, InvBCE: 0.7236565351486206\n",
      "Loss: 0.7026816606521606, Norm: 0.0018081603338941932, InvBCE: 0.6713026165962219\n",
      "Loss: 0.6580144762992859, Norm: 0.00214587664231658, InvBCE: 0.6265435218811035\n",
      "Loss: 0.619802713394165, Norm: 0.002474026056006551, InvBCE: 0.5882397890090942\n",
      "Loss: 0.5870040059089661, Norm: 0.002792239421978593, InvBCE: 0.5553497672080994\n",
      "Image fooled! Adding perturbation...\n",
      "Image 72...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 73...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 74...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 75...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 76...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 77...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 78...\n",
      "Loss: 1.7011688947677612, Norm: 0.0, InvBCE: 1.6694244146347046\n",
      "Loss: 1.6450088024139404, Norm: 0.0003712214238476008, InvBCE: 1.6133067607879639\n",
      "Loss: 1.590205430984497, Norm: 0.0007405516807921231, InvBCE: 1.558542251586914\n",
      "Loss: 1.5374199151992798, Norm: 0.0011077928356826305, InvBCE: 1.5057919025421143\n",
      "Loss: 1.4871251583099365, Norm: 0.0014723573112860322, InvBCE: 1.4555288553237915\n",
      "Loss: 1.4396401643753052, Norm: 0.0018336245557293296, InvBCE: 1.4080722332000732\n",
      "Loss: 1.3951154947280884, Norm: 0.0021910611540079117, InvBCE: 1.3635728359222412\n",
      "Loss: 1.353632926940918, Norm: 0.002544220769777894, InvBCE: 1.322112798690796\n",
      "Image fooled! Adding perturbation...\n",
      "Image 79...\n",
      "Loss: 809.8550415039062, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8548583984375, Norm: 0.00023701245663687587, InvBCE: 809.8235473632812\n",
      "Loss: 809.8546142578125, Norm: 0.0004738382704090327, InvBCE: 809.8235473632812\n",
      "Loss: 809.8543701171875, Norm: 0.0007104636169970036, InvBCE: 809.8235473632812\n",
      "Loss: 809.8541870117188, Norm: 0.0009468746720813215, InvBCE: 809.8235473632812\n",
      "Loss: 809.8539428710938, Norm: 0.0011830572038888931, InvBCE: 809.8235473632812\n",
      "Loss: 809.853759765625, Norm: 0.0014189968351274729, InvBCE: 809.8235473632812\n",
      "Loss: 809.853515625, Norm: 0.001654679188504815, InvBCE: 809.8235473632812\n",
      "Loss: 809.8533325195312, Norm: 0.001890089944936335, InvBCE: 809.8235473632812\n",
      "Loss: 809.8530883789062, Norm: 0.002125214086845517, InvBCE: 809.8235473632812\n",
      "Loss: 809.8529052734375, Norm: 0.002360037062317133, InvBCE: 809.8235473632812\n",
      "Loss: 809.8526611328125, Norm: 0.002594544319435954, InvBCE: 809.8235473632812\n",
      "Loss: 809.8524169921875, Norm: 0.0028287209570407867, InvBCE: 809.8235473632812\n",
      "Loss: 809.8522338867188, Norm: 0.0030625523068010807, InvBCE: 809.8235473632812\n",
      "Loss: 809.8519897460938, Norm: 0.0032960237003862858, InvBCE: 809.8235473632812\n",
      "Loss: 809.851806640625, Norm: 0.0035291207022964954, InvBCE: 809.8235473632812\n",
      "Loss: 809.8515625, Norm: 0.003761828877031803, InvBCE: 809.8235473632812\n",
      "Loss: 809.8513793945312, Norm: 0.003994133323431015, InvBCE: 809.8235473632812\n",
      "Loss: 809.8511962890625, Norm: 0.004226020537316799, InvBCE: 809.8235473632812\n",
      "Loss: 809.8509521484375, Norm: 0.004457475617527962, InvBCE: 809.8235473632812\n",
      "Image 80...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 81...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 82...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 83...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 84...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 85...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 86...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 87...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 88...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 89...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 90...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 91...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 92...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 93...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 94...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 95...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 96...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 97...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 98...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 99...\n",
      "Image fooled! Adding perturbation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e6167faa1924c43938a91aeaaf88131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fooling rate: 0.72\n",
      "Starting epoch 5...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a450cb92691746f09de9c275a5e80f6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 1...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 2...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 3...\n",
      "Loss: 2.516855001449585, Norm: 0.0, InvBCE: 2.4853549003601074\n",
      "Loss: 2.1774377822875977, Norm: 0.00038096774369478226, InvBCE: 2.1458780765533447\n",
      "Loss: 1.8924906253814697, Norm: 0.0007550481241196394, InvBCE: 1.860868215560913\n",
      "Loss: 1.6542720794677734, Norm: 0.001122245448641479, InvBCE: 1.6225841045379639\n",
      "Loss: 1.4558956623077393, Norm: 0.0014811630826443434, InvBCE: 1.4241400957107544\n",
      "Loss: 1.2909272909164429, Norm: 0.0018307205755263567, InvBCE: 1.259102463722229\n",
      "Loss: 1.1536098718643188, Norm: 0.002170068211853504, InvBCE: 1.12171471118927\n",
      "Loss: 1.0389769077301025, Norm: 0.0024985887575894594, InvBCE: 1.00701105594635\n",
      "Loss: 0.9428960680961609, Norm: 0.0028158773202449083, InvBCE: 0.9108595252037048\n",
      "Loss: 0.861985981464386, Norm: 0.00312171527184546, InvBCE: 0.8298793435096741\n",
      "Loss: 0.7935185432434082, Norm: 0.0034160292707383633, InvBCE: 0.7613427042961121\n",
      "Loss: 0.7353000640869141, Norm: 0.0036988675128668547, InvBCE: 0.703056275844574\n",
      "Loss: 0.685553252696991, Norm: 0.003970364574342966, InvBCE: 0.6532430052757263\n",
      "Loss: 0.64286869764328, Norm: 0.004230721853673458, InvBCE: 0.6104938387870789\n",
      "Loss: 0.6061379313468933, Norm: 0.004480187315493822, InvBCE: 0.5737003684043884\n",
      "Loss: 0.5744492411613464, Norm: 0.004719046410173178, InvBCE: 0.541951060295105\n",
      "Loss: 0.5470166802406311, Norm: 0.004947606474161148, InvBCE: 0.5144600868225098\n",
      "Loss: 0.5231717228889465, Norm: 0.005166190210729837, InvBCE: 0.4905589520931244\n",
      "Loss: 0.502361536026001, Norm: 0.0053751408122479916, InvBCE: 0.4696948826313019\n",
      "Loss: 0.4841196835041046, Norm: 0.005574820563197136, InvBCE: 0.4514015018939972\n",
      "Image 4...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 5...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 6...\n",
      "Loss: 1.2834769487380981, Norm: 0.0, InvBCE: 1.251976728439331\n",
      "Loss: 1.2476043701171875, Norm: 0.0003625254612416029, InvBCE: 1.216109037399292\n",
      "Loss: 1.2135848999023438, Norm: 0.000722255848813802, InvBCE: 1.1820919513702393\n",
      "Loss: 1.181496262550354, Norm: 0.001078881905414164, InvBCE: 1.1500035524368286\n",
      "Image fooled! Adding perturbation...\n",
      "Image 7...\n",
      "Loss: 0.9776963591575623, Norm: 0.0, InvBCE: 0.9462021589279175\n",
      "Loss: 0.9277796745300293, Norm: 0.0003720711392816156, InvBCE: 0.8962874412536621\n",
      "Loss: 0.8819950819015503, Norm: 0.0007414352730847895, InvBCE: 0.8505017161369324\n",
      "Loss: 0.8402838110923767, Norm: 0.0011073534842580557, InvBCE: 0.8087864518165588\n",
      "Image fooled! Adding perturbation...\n",
      "Image 8...\n",
      "Loss: 1.4987614154815674, Norm: 0.0, InvBCE: 1.4672576189041138\n",
      "Loss: 1.4836678504943848, Norm: 0.00035997756640426815, InvBCE: 1.4522336721420288\n",
      "Loss: 1.4669212102890015, Norm: 0.0007180704269558191, InvBCE: 1.435551404953003\n",
      "Image fooled! Adding perturbation...\n",
      "Image 9...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 10...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 11...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 12...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 13...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 14...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 15...\n",
      "Loss: 0.7357223033905029, Norm: 0.0, InvBCE: 0.7044116258621216\n",
      "Loss: 0.6556208729743958, Norm: 0.0003789947077166289, InvBCE: 0.6242404580116272\n",
      "Image fooled! Adding perturbation...\n",
      "Image 16...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 17...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 18...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 19...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 20...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 21...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 22...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 23...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 24...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 25...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 26...\n",
      "Loss: 1.4833650588989258, Norm: 0.0, InvBCE: 1.4519132375717163\n",
      "Loss: 1.4816025495529175, Norm: 0.00030570203671231866, InvBCE: 1.4502806663513184\n",
      "Loss: 1.4798126220703125, Norm: 0.0006115358555689454, InvBCE: 1.4486184120178223\n",
      "Loss: 1.478003978729248, Norm: 0.000917381199542433, InvBCE: 1.4469350576400757\n",
      "Loss: 1.4761853218078613, Norm: 0.0012231003493070602, InvBCE: 1.4452396631240845\n",
      "Loss: 1.4743674993515015, Norm: 0.0015285363188013434, InvBCE: 1.4435429573059082\n",
      "Image fooled! Adding perturbation...\n",
      "Image 27...\n",
      "Loss: 0.8633372783660889, Norm: 0.0, InvBCE: 0.8326320648193359\n",
      "Loss: 0.800722599029541, Norm: 0.0003794662479776889, InvBCE: 0.7699207067489624\n",
      "Loss: 0.744606614112854, Norm: 0.0007550932350568473, InvBCE: 0.7137050032615662\n",
      "Loss: 0.6944596171379089, Norm: 0.0011260334867984056, InvBCE: 0.6634559035301208\n",
      "Loss: 0.6497694253921509, Norm: 0.001491171889938414, InvBCE: 0.6186619997024536\n",
      "Loss: 0.6100528240203857, Norm: 0.0018495296826586127, InvBCE: 0.5788406729698181\n",
      "Loss: 0.5748547315597534, Norm: 0.0022002558689564466, InvBCE: 0.5435375571250916\n",
      "Loss: 0.543746829032898, Norm: 0.002542632631957531, InvBCE: 0.5123248100280762\n",
      "Image fooled! Adding perturbation...\n",
      "Image 28...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 29...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 30...\n",
      "Loss: 0.7599223852157593, Norm: 0.0, InvBCE: 0.7283962965011597\n",
      "Loss: 0.7080165147781372, Norm: 0.00037441158201545477, InvBCE: 0.6764003038406372\n",
      "Image fooled! Adding perturbation...\n",
      "Image 31...\n",
      "Loss: 809.8552856445312, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8550415039062, Norm: 0.00023651817173231393, InvBCE: 809.8235473632812\n",
      "Loss: 809.8547973632812, Norm: 0.00047284940956160426, InvBCE: 809.8235473632812\n",
      "Loss: 809.8546142578125, Norm: 0.000708980078343302, InvBCE: 809.8235473632812\n",
      "Loss: 809.8543701171875, Norm: 0.0009448961354792118, InvBCE: 809.8235473632812\n",
      "Loss: 809.8541870117188, Norm: 0.0011805836111307144, InvBCE: 809.8235473632812\n",
      "Loss: 809.8539428710938, Norm: 0.0014160281280055642, InvBCE: 809.8235473632812\n",
      "Loss: 809.853759765625, Norm: 0.0016512151341885328, InvBCE: 809.8235473632812\n",
      "Loss: 809.853515625, Norm: 0.001886130659841001, InvBCE: 809.8235473632812\n",
      "Loss: 809.8533325195312, Norm: 0.0021207595709711313, InvBCE: 809.8235473632812\n",
      "Loss: 809.8530883789062, Norm: 0.0023550873156636953, InvBCE: 809.8235473632812\n",
      "Loss: 809.8529052734375, Norm: 0.0025890993420034647, InvBCE: 809.8235473632812\n",
      "Loss: 809.8526611328125, Norm: 0.0028227809816598892, InvBCE: 809.8235473632812\n",
      "Loss: 809.8524780273438, Norm: 0.0030561177991330624, InvBCE: 809.8235473632812\n",
      "Loss: 809.8522338867188, Norm: 0.003289095126092434, InvBCE: 809.8235473632812\n",
      "Loss: 809.85205078125, Norm: 0.0035216982942074537, InvBCE: 809.8235473632812\n",
      "Loss: 809.851806640625, Norm: 0.0037539128679782152, InvBCE: 809.8235473632812\n",
      "Loss: 809.8516235351562, Norm: 0.003985724877566099, InvBCE: 809.8235473632812\n",
      "Loss: 809.8513793945312, Norm: 0.004217119887471199, InvBCE: 809.8235473632812\n",
      "Loss: 809.8511962890625, Norm: 0.004448084160685539, InvBCE: 809.8235473632812\n",
      "Image 32...\n",
      "Loss: 1.6211780309677124, Norm: 0.0, InvBCE: 1.5894696712493896\n",
      "Loss: 1.6039505004882812, Norm: 0.0003554832364898175, InvBCE: 1.5722578763961792\n",
      "Loss: 1.5865561962127686, Norm: 0.0007085348479449749, InvBCE: 1.5548763275146484\n",
      "Loss: 1.5690501928329468, Norm: 0.001059428439475596, InvBCE: 1.5373802185058594\n",
      "Loss: 1.5514557361602783, Norm: 0.0014080654364079237, InvBCE: 1.5197927951812744\n",
      "Loss: 1.5337930917739868, Norm: 0.001754429074935615, InvBCE: 1.5021343231201172\n",
      "Loss: 1.5161023139953613, Norm: 0.0020983985159546137, InvBCE: 1.484445333480835\n",
      "Loss: 1.4984462261199951, Norm: 0.0024399629328399897, InvBCE: 1.4667888879776\n",
      "Loss: 1.4809072017669678, Norm: 0.002779146656394005, InvBCE: 1.4492475986480713\n",
      "Loss: 1.4635722637176514, Norm: 0.003115985309705138, InvBCE: 1.4319087266921997\n",
      "Loss: 1.4465528726577759, Norm: 0.003450455144047737, InvBCE: 1.414884090423584\n",
      "Image fooled! Adding perturbation...\n",
      "Image 33...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 34...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 35...\n",
      "Loss: 1.075447916984558, Norm: 0.0, InvBCE: 1.0437726974487305\n",
      "Loss: 1.037635087966919, Norm: 0.0003689285658765584, InvBCE: 1.005900502204895\n",
      "Loss: 1.008575201034546, Norm: 0.0007292464142665267, InvBCE: 0.9767802357673645\n",
      "Loss: 0.9783403873443604, Norm: 0.0010757283307611942, InvBCE: 0.9464866518974304\n",
      "Loss: 0.953197181224823, Norm: 0.0014033025363460183, InvBCE: 0.9212896227836609\n",
      "Loss: 0.9395541548728943, Norm: 0.0017134094377979636, InvBCE: 0.9075987935066223\n",
      "Image fooled! Adding perturbation...\n",
      "Image 36...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 37...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 38...\n",
      "Loss: 1.4802992343902588, Norm: 0.0, InvBCE: 1.448299527168274\n",
      "Loss: 1.4677544832229614, Norm: 0.0003466120397206396, InvBCE: 1.4358100891113281\n",
      "Loss: 1.4543135166168213, Norm: 0.0006906294147484004, InvBCE: 1.422421932220459\n",
      "Image fooled! Adding perturbation...\n",
      "Image 39...\n",
      "Loss: 673.517578125, Norm: 0.0, InvBCE: 673.4857177734375\n",
      "Loss: 673.517333984375, Norm: 0.0002357327612116933, InvBCE: 673.4857177734375\n",
      "Loss: 673.5171508789062, Norm: 0.0004712759982794523, InvBCE: 673.4857177734375\n",
      "Loss: 673.5169067382812, Norm: 0.0007066157995723188, InvBCE: 673.4857177734375\n",
      "Loss: 673.5166625976562, Norm: 0.0009417380206286907, InvBCE: 673.4857177734375\n",
      "Loss: 673.5164794921875, Norm: 0.0011766284005716443, InvBCE: 673.4857177734375\n",
      "Loss: 673.5162353515625, Norm: 0.001411272562108934, InvBCE: 673.4857177734375\n",
      "Loss: 673.5160522460938, Norm: 0.0016456556040793657, InvBCE: 673.4857177734375\n",
      "Loss: 673.5158081054688, Norm: 0.0018797630909830332, InvBCE: 673.4857177734375\n",
      "Loss: 673.515625, Norm: 0.0021135802380740643, InvBCE: 673.4857177734375\n",
      "Loss: 673.515380859375, Norm: 0.002347092144191265, InvBCE: 673.4857177734375\n",
      "Loss: 673.5151977539062, Norm: 0.0025802841410040855, InvBCE: 673.4857177734375\n",
      "Loss: 673.5149536132812, Norm: 0.0028131408616900444, InvBCE: 673.4857177734375\n",
      "Loss: 673.5147705078125, Norm: 0.003045648103579879, InvBCE: 673.4857177734375\n",
      "Loss: 673.5145263671875, Norm: 0.003277790965512395, InvBCE: 673.4857177734375\n",
      "Loss: 673.5143432617188, Norm: 0.003509554546326399, InvBCE: 673.4857177734375\n",
      "Loss: 673.51416015625, Norm: 0.0037409248761832714, InvBCE: 673.4857177734375\n",
      "Loss: 673.513916015625, Norm: 0.003971886821091175, InvBCE: 673.4857177734375\n",
      "Loss: 673.5137329101562, Norm: 0.004202426411211491, InvBCE: 673.4857177734375\n",
      "Loss: 673.5134887695312, Norm: 0.0044325292110443115, InvBCE: 673.4857177734375\n",
      "Image 40...\n",
      "Loss: 21.641447067260742, Norm: 0.0, InvBCE: 21.60960578918457\n",
      "Loss: 17.319364547729492, Norm: 0.0003846830513793975, InvBCE: 17.287477493286133\n",
      "Loss: 13.766242027282715, Norm: 0.0007548514404334128, InvBCE: 13.734305381774902\n",
      "Loss: 11.213957786560059, Norm: 0.001109839417040348, InvBCE: 11.181970596313477\n",
      "Loss: 9.299294471740723, Norm: 0.0014530486660078168, InvBCE: 9.267253875732422\n",
      "Loss: 7.800427436828613, Norm: 0.001783896004781127, InvBCE: 7.768332004547119\n",
      "Loss: 5.934893608093262, Norm: 0.0021041766740381718, InvBCE: 5.902742862701416\n",
      "Loss: 5.066676139831543, Norm: 0.0024165071081370115, InvBCE: 5.034467697143555\n",
      "Loss: 4.432265758514404, Norm: 0.002715491456910968, InvBCE: 4.400000095367432\n",
      "Loss: 3.946920871734619, Norm: 0.0030012684874236584, InvBCE: 3.9145987033843994\n",
      "Loss: 3.5863494873046875, Norm: 0.0032738326117396355, InvBCE: 3.553971290588379\n",
      "Loss: 3.288940906524658, Norm: 0.0035335267893970013, InvBCE: 3.256507635116577\n",
      "Loss: 2.5729012489318848, Norm: 0.003780985949561, InvBCE: 2.5404140949249268\n",
      "Loss: 2.3538424968719482, Norm: 0.004015299957245588, InvBCE: 2.3213019371032715\n",
      "Loss: 2.1690874099731445, Norm: 0.004237174056470394, InvBCE: 2.1364946365356445\n",
      "Loss: 2.0101795196533203, Norm: 0.004447318613529205, InvBCE: 1.977535605430603\n",
      "Loss: 1.8734291791915894, Norm: 0.004646481014788151, InvBCE: 1.8407353162765503\n",
      "Loss: 1.7604172229766846, Norm: 0.0048353965394198895, InvBCE: 1.7276747226715088\n",
      "Loss: 1.6585134267807007, Norm: 0.005014840979129076, InvBCE: 1.6257234811782837\n",
      "Loss: 1.5574871301651, Norm: 0.00518572423607111, InvBCE: 1.5246509313583374\n",
      "Image 41...\n",
      "Loss: 1.4974029064178467, Norm: 0.0, InvBCE: 1.4655624628067017\n",
      "Loss: 1.4807891845703125, Norm: 0.0003565977676771581, InvBCE: 1.448932409286499\n",
      "Loss: 1.4648481607437134, Norm: 0.0007104124524630606, InvBCE: 1.4329725503921509\n",
      "Loss: 1.4495978355407715, Norm: 0.0010616577928885818, InvBCE: 1.4177008867263794\n",
      "Loss: 1.4350162744522095, Norm: 0.001409974996931851, InvBCE: 1.4030957221984863\n",
      "Loss: 1.4210901260375977, Norm: 0.0017550545744597912, InvBCE: 1.3891441822052002\n",
      "Loss: 1.4078056812286377, Norm: 0.0020965603180229664, InvBCE: 1.3758329153060913\n",
      "Image fooled! Adding perturbation...\n",
      "Image 42...\n",
      "Loss: 1.3950953483581543, Norm: 0.0, InvBCE: 1.363094687461853\n",
      "Image fooled! Adding perturbation...\n",
      "Image 43...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 44...\n",
      "Loss: 0.7529824376106262, Norm: 0.0, InvBCE: 0.7209742069244385\n",
      "Image fooled! Adding perturbation...\n",
      "Image 45...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 46...\n",
      "Loss: 0.5708118081092834, Norm: 0.0, InvBCE: 0.5387594699859619\n",
      "Loss: 0.5414780378341675, Norm: 0.00036662883940152824, InvBCE: 0.5093746185302734\n",
      "Loss: 0.5161443948745728, Norm: 0.0007251166389323771, InvBCE: 0.48398858308792114\n",
      "Image fooled! Adding perturbation...\n",
      "Image 47...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 48...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 49...\n",
      "Loss: 1.7476832866668701, Norm: 0.0, InvBCE: 1.715474247932434\n",
      "Loss: 1.6634774208068848, Norm: 0.0003787090827245265, InvBCE: 1.6312144994735718\n",
      "Loss: 1.5801414251327515, Norm: 0.000752478139474988, InvBCE: 1.54782235622406\n",
      "Loss: 1.4985072612762451, Norm: 0.0011228324146941304, InvBCE: 1.4661297798156738\n",
      "Loss: 1.4198330640792847, Norm: 0.0014892735052853823, InvBCE: 1.3873947858810425\n",
      "Loss: 1.3457493782043457, Norm: 0.00185094412881881, InvBCE: 1.3132485151290894\n",
      "Image fooled! Adding perturbation...\n",
      "Image 50...\n",
      "Loss: 208.01417541503906, Norm: 0.0, InvBCE: 207.9816131591797\n",
      "Loss: 82.2612533569336, Norm: 0.0003839890123344958, InvBCE: 82.22864532470703\n",
      "Loss: 54.215877532958984, Norm: 0.0007216667872853577, InvBCE: 54.18323516845703\n",
      "Loss: 31.23964500427246, Norm: 0.001028470927849412, InvBCE: 31.20697021484375\n",
      "Loss: 21.28636360168457, Norm: 0.0013045523082837462, InvBCE: 21.253660202026367\n",
      "Loss: 15.450106620788574, Norm: 0.0015541078755632043, InvBCE: 15.417378425598145\n",
      "Loss: 11.896042823791504, Norm: 0.0017807709518820047, InvBCE: 11.863292694091797\n",
      "Loss: 10.034564018249512, Norm: 0.0019876870792359114, InvBCE: 10.001794815063477\n",
      "Loss: 8.541342735290527, Norm: 0.0021777418442070484, InvBCE: 8.508557319641113\n",
      "Loss: 7.447998523712158, Norm: 0.002353046787902713, InvBCE: 7.41519832611084\n",
      "Loss: 6.636379241943359, Norm: 0.002515392377972603, InvBCE: 6.603566646575928\n",
      "Loss: 6.028899669647217, Norm: 0.0026663357857614756, InvBCE: 5.9960761070251465\n",
      "Loss: 5.546902179718018, Norm: 0.0028071932028979063, InvBCE: 5.514069557189941\n",
      "Loss: 5.171353340148926, Norm: 0.002939054276794195, InvBCE: 5.138513088226318\n",
      "Loss: 4.850350379943848, Norm: 0.0030629171524196863, InvBCE: 4.817503929138184\n",
      "Loss: 4.524486064910889, Norm: 0.0031795543618500233, InvBCE: 4.491634845733643\n",
      "Loss: 4.269275665283203, Norm: 0.0032897242344915867, InvBCE: 4.236420154571533\n",
      "Loss: 4.093834400177002, Norm: 0.003393937833607197, InvBCE: 4.060976028442383\n",
      "Loss: 3.9296469688415527, Norm: 0.0034927944652736187, InvBCE: 3.896786689758301\n",
      "Loss: 3.785813093185425, Norm: 0.003586819628253579, InvBCE: 3.7529516220092773\n",
      "Image 51...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 52...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 53...\n",
      "Loss: 1.3859103918075562, Norm: 0.0, InvBCE: 1.3533453941345215\n",
      "Loss: 1.3648910522460938, Norm: 0.0003647235862445086, InvBCE: 1.3323371410369873\n",
      "Image fooled! Adding perturbation...\n",
      "Image 54...\n",
      "Loss: 1.4849518537521362, Norm: 0.0, InvBCE: 1.4524056911468506\n",
      "Loss: 1.482787013053894, Norm: 0.00031004915945231915, InvBCE: 1.450381875038147\n",
      "Loss: 1.4805588722229004, Norm: 0.0006201923824846745, InvBCE: 1.4482920169830322\n",
      "Loss: 1.478284478187561, Norm: 0.0009303357219323516, InvBCE: 1.4461532831192017\n",
      "Loss: 1.475987434387207, Norm: 0.0012402643915265799, InvBCE: 1.4439892768859863\n",
      "Image fooled! Adding perturbation...\n",
      "Image 55...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 56...\n",
      "Loss: 0.48237118124961853, Norm: 0.0, InvBCE: 0.45050352811813354\n",
      "Loss: 0.4375673234462738, Norm: 0.00037348715704865754, InvBCE: 0.4056542217731476\n",
      "Image fooled! Adding perturbation...\n",
      "Image 57...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 58...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 59...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 60...\n",
      "Loss: 809.8555297851562, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8552856445312, Norm: 0.0002355863543925807, InvBCE: 809.8235473632812\n",
      "Loss: 809.8551025390625, Norm: 0.00047098370851017535, InvBCE: 809.8235473632812\n",
      "Loss: 809.8548583984375, Norm: 0.0007061782525852323, InvBCE: 809.8235473632812\n",
      "Loss: 809.8546142578125, Norm: 0.0009411558858118951, InvBCE: 809.8235473632812\n",
      "Loss: 809.8544311523438, Norm: 0.0011759023182094097, InvBCE: 809.8235473632812\n",
      "Loss: 809.8541870117188, Norm: 0.0014104032889008522, InvBCE: 809.8235473632812\n",
      "Loss: 809.85400390625, Norm: 0.0016446438385173678, InvBCE: 809.8235473632812\n",
      "Loss: 809.853759765625, Norm: 0.00187860953155905, InvBCE: 809.8235473632812\n",
      "Loss: 809.8535766601562, Norm: 0.0021122859325259924, InvBCE: 809.8235473632812\n",
      "Loss: 809.8533325195312, Norm: 0.0023456576745957136, InvBCE: 809.8235473632812\n",
      "Loss: 809.8531494140625, Norm: 0.0025787106715142727, InvBCE: 809.8235473632812\n",
      "Loss: 809.8529052734375, Norm: 0.002811429323628545, InvBCE: 809.8235473632812\n",
      "Loss: 809.8527221679688, Norm: 0.0030437996610999107, InvBCE: 809.8235473632812\n",
      "Loss: 809.8524780273438, Norm: 0.003275806549936533, InvBCE: 809.8235473632812\n",
      "Loss: 809.852294921875, Norm: 0.0035074353218078613, InvBCE: 809.8235473632812\n",
      "Loss: 809.8521118164062, Norm: 0.0037386715412139893, InvBCE: 809.8235473632812\n",
      "Loss: 809.8518676757812, Norm: 0.00396950077265501, InvBCE: 809.8235473632812\n",
      "Loss: 809.8516845703125, Norm: 0.004199909046292305, InvBCE: 809.8235473632812\n",
      "Loss: 809.8514404296875, Norm: 0.004429881926625967, InvBCE: 809.8235473632812\n",
      "Image 61...\n",
      "Loss: 0.84979647397995, Norm: 0.0, InvBCE: 0.8178365230560303\n",
      "Loss: 0.7731221318244934, Norm: 0.00037783393054269254, InvBCE: 0.741096019744873\n",
      "Image fooled! Adding perturbation...\n",
      "Image 62...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 63...\n",
      "Loss: 1.4963388442993164, Norm: 0.0, InvBCE: 1.4642442464828491\n",
      "Loss: 1.4566419124603271, Norm: 0.00036864925641566515, InvBCE: 1.4245339632034302\n",
      "Loss: 1.4180397987365723, Norm: 0.0007356781861744821, InvBCE: 1.3859152793884277\n",
      "Loss: 1.3807258605957031, Norm: 0.0011009708978235722, InvBCE: 1.3485815525054932\n",
      "Loss: 1.3448656797409058, Norm: 0.001464154338464141, InvBCE: 1.3126986026763916\n",
      "Image fooled! Adding perturbation...\n",
      "Image 64...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 65...\n",
      "Loss: 0.9851231575012207, Norm: 0.0, InvBCE: 0.9529305696487427\n",
      "Loss: 0.9313622713088989, Norm: 0.0003716822830028832, InvBCE: 0.8991445899009705\n",
      "Image fooled! Adding perturbation...\n",
      "Image 66...\n",
      "Loss: 1.3652218580245972, Norm: 0.0, InvBCE: 1.3329768180847168\n",
      "Loss: 1.3335198163986206, Norm: 0.00036938488483428955, InvBCE: 1.301323413848877\n",
      "Image fooled! Adding perturbation...\n",
      "Image 67...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 68...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 69...\n",
      "Loss: 0.7722626328468323, Norm: 0.0, InvBCE: 0.740111768245697\n",
      "Loss: 0.7198463678359985, Norm: 0.00037425424670800567, InvBCE: 0.6875907778739929\n",
      "Loss: 0.6752433776855469, Norm: 0.0007432062411680818, InvBCE: 0.6428806781768799\n",
      "Loss: 0.6372199058532715, Norm: 0.0011057781521230936, InvBCE: 0.6047486662864685\n",
      "Loss: 0.6047253012657166, Norm: 0.001460845465771854, InvBCE: 0.5721447467803955\n",
      "Image fooled! Adding perturbation...\n",
      "Image 70...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 71...\n",
      "Loss: 0.7665605545043945, Norm: 0.0, InvBCE: 0.7338705658912659\n",
      "Loss: 0.7092945575714111, Norm: 0.0003703392285387963, InvBCE: 0.6765240430831909\n",
      "Loss: 0.6598435044288635, Norm: 0.0007355255074799061, InvBCE: 0.6269904375076294\n",
      "Loss: 0.6173558831214905, Norm: 0.0010948439594358206, InvBCE: 0.5844186544418335\n",
      "Loss: 0.5810015201568604, Norm: 0.0014470783062279224, InvBCE: 0.5479791760444641\n",
      "Image fooled! Adding perturbation...\n",
      "Image 72...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 73...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 74...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 75...\n",
      "Loss: 4.308247089385986, Norm: 0.0, InvBCE: 4.275139331817627\n",
      "Loss: 2.4781558513641357, Norm: 0.0003782721469178796, InvBCE: 2.4451262950897217\n",
      "Image fooled! Adding perturbation...\n",
      "Image 76...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 77...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 78...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 79...\n",
      "Loss: 809.8565063476562, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8563232421875, Norm: 0.0002354431344429031, InvBCE: 809.8235473632812\n",
      "Loss: 809.8560791015625, Norm: 0.00047070361324585974, InvBCE: 809.8235473632812\n",
      "Loss: 809.8558959960938, Norm: 0.0007057681796140969, InvBCE: 809.8235473632812\n",
      "Loss: 809.8556518554688, Norm: 0.0009406234603375196, InvBCE: 809.8235473632812\n",
      "Loss: 809.85546875, Norm: 0.0011752555146813393, InvBCE: 809.8235473632812\n",
      "Loss: 809.855224609375, Norm: 0.0014096508966758847, InvBCE: 809.8235473632812\n",
      "Loss: 809.8550415039062, Norm: 0.0016437952872365713, InvBCE: 809.8235473632812\n",
      "Loss: 809.8547973632812, Norm: 0.0018776749493554235, InvBCE: 809.8235473632812\n",
      "Loss: 809.8546142578125, Norm: 0.002111275913193822, InvBCE: 809.8235473632812\n",
      "Loss: 809.8543701171875, Norm: 0.002344583859667182, InvBCE: 809.8235473632812\n",
      "Loss: 809.8541870117188, Norm: 0.0025775847025215626, InvBCE: 809.8235473632812\n",
      "Loss: 809.8539428710938, Norm: 0.002810264937579632, InvBCE: 809.8235473632812\n",
      "Loss: 809.853759765625, Norm: 0.003042609430849552, InvBCE: 809.8235473632812\n",
      "Loss: 809.853515625, Norm: 0.0032746053766459227, InvBCE: 809.8235473632812\n",
      "Loss: 809.8533325195312, Norm: 0.003506238106638193, InvBCE: 809.8235473632812\n",
      "Loss: 809.8530883789062, Norm: 0.0037374943494796753, InvBCE: 809.8235473632812\n",
      "Loss: 809.8529052734375, Norm: 0.003968359902501106, InvBCE: 809.8235473632812\n",
      "Loss: 809.8526611328125, Norm: 0.004198821727186441, InvBCE: 809.8235473632812\n",
      "Loss: 809.8524780273438, Norm: 0.004428866319358349, InvBCE: 809.8235473632812\n",
      "Image 80...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 81...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 82...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 83...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 84...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 85...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 86...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 87...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 88...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 89...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 90...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 91...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 92...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 93...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 94...\n",
      "Loss: 0.8681633472442627, Norm: 0.0, InvBCE: 0.8351871371269226\n",
      "Image fooled! Adding perturbation...\n",
      "Image 95...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 96...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 97...\n",
      "Loss: 1.4802026748657227, Norm: 0.0, InvBCE: 1.447181224822998\n",
      "Loss: 1.4761674404144287, Norm: 0.00033064623130485415, InvBCE: 1.443131685256958\n",
      "Image fooled! Adding perturbation...\n",
      "Image 98...\n",
      "Loss: 1.3596316576004028, Norm: 0.0, InvBCE: 1.3265796899795532\n",
      "Image fooled! Adding perturbation...\n",
      "Image 99...\n",
      "Image fooled! Adding perturbation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0943902d6a7c4e90b1a29759870e3e54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fooling rate: 0.76\n",
      "Starting epoch 6...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34fb8b1f4adf40bfb66a9af5afbc1bd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 1...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 2...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 3...\n",
      "Loss: 3.2484021186828613, Norm: 0.0, InvBCE: 3.2153127193450928\n",
      "Loss: 2.8542098999023438, Norm: 0.00038148820749484, InvBCE: 2.8210625648498535\n",
      "Loss: 2.51200008392334, Norm: 0.0007578976219519973, InvBCE: 2.4787914752960205\n",
      "Loss: 2.2183234691619873, Norm: 0.0011287975357845426, InvBCE: 2.1850507259368896\n",
      "Loss: 1.965120553970337, Norm: 0.0014930906472727656, InvBCE: 1.9317811727523804\n",
      "Loss: 1.7471972703933716, Norm: 0.0018497674027457833, InvBCE: 1.7137893438339233\n",
      "Loss: 1.559989333152771, Norm: 0.002197863766923547, InvBCE: 1.5265116691589355\n",
      "Loss: 1.3993430137634277, Norm: 0.0025365599431097507, InvBCE: 1.3657948970794678\n",
      "Loss: 1.2615548372268677, Norm: 0.0028651857282966375, InvBCE: 1.227936029434204\n",
      "Loss: 1.1433361768722534, Norm: 0.00318323471583426, InvBCE: 1.1096469163894653\n",
      "Loss: 1.0418199300765991, Norm: 0.0034903609193861485, InvBCE: 1.0080608129501343\n",
      "Loss: 0.9545385837554932, Norm: 0.003786347573623061, InvBCE: 0.920710563659668\n",
      "Loss: 0.8794081211090088, Norm: 0.004071111790835857, InvBCE: 0.8455126285552979\n",
      "Loss: 0.8146775960922241, Norm: 0.004344654269516468, InvBCE: 0.7807161211967468\n",
      "Loss: 0.7588754892349243, Norm: 0.004607060924172401, InvBCE: 0.7248498201370239\n",
      "Loss: 0.7107218503952026, Norm: 0.00485848356038332, InvBCE: 0.6766339540481567\n",
      "Loss: 0.66910719871521, Norm: 0.005099122412502766, InvBCE: 0.6349591016769409\n",
      "Loss: 0.6330623626708984, Norm: 0.005329223349690437, InvBCE: 0.5988563299179077\n",
      "Loss: 0.6017519235610962, Norm: 0.005549072753638029, InvBCE: 0.5674901008605957\n",
      "Loss: 0.5744631886482239, Norm: 0.00575899938121438, InvBCE: 0.5401479005813599\n",
      "Image 4...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 5...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 6...\n",
      "Loss: 1.1648904085159302, Norm: 0.0, InvBCE: 1.131800889968872\n",
      "Image fooled! Adding perturbation...\n",
      "Image 7...\n",
      "Loss: 0.9599563479423523, Norm: 0.0, InvBCE: 0.9268676042556763\n",
      "Loss: 0.9090747237205505, Norm: 0.0003719569358509034, InvBCE: 0.8759957551956177\n",
      "Loss: 0.862350344657898, Norm: 0.000741007796023041, InvBCE: 0.8292781710624695\n",
      "Loss: 0.8197636008262634, Norm: 0.0011064328718930483, InvBCE: 0.786695659160614\n",
      "Image fooled! Adding perturbation...\n",
      "Image 8...\n",
      "Loss: 1.477207899093628, Norm: 0.0, InvBCE: 1.4441418647766113\n",
      "Image fooled! Adding perturbation...\n",
      "Image 9...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 10...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 11...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 12...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 13...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 14...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 15...\n",
      "Loss: 0.6407895088195801, Norm: 0.0, InvBCE: 0.6077849864959717\n",
      "Image fooled! Adding perturbation...\n",
      "Image 16...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 17...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 18...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 19...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 20...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 21...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 22...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 23...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 24...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 25...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 26...\n",
      "Loss: 1.4849604368209839, Norm: 0.0, InvBCE: 1.4518846273422241\n",
      "Loss: 1.4831795692443848, Norm: 0.0003048460348509252, InvBCE: 1.4502263069152832\n",
      "Loss: 1.4813730716705322, Norm: 0.0006097903242334723, InvBCE: 1.4485400915145874\n",
      "Loss: 1.47955322265625, Norm: 0.0009146792581304908, InvBCE: 1.446838140487671\n",
      "Loss: 1.477724313735962, Norm: 0.0012193744769319892, InvBCE: 1.4451251029968262\n",
      "Loss: 1.475899577140808, Norm: 0.0015237235929816961, InvBCE: 1.4434140920639038\n",
      "Image fooled! Adding perturbation...\n",
      "Image 27...\n",
      "Loss: 0.6762261390686035, Norm: 0.0, InvBCE: 0.6438527703285217\n",
      "Loss: 0.6322661638259888, Norm: 0.0003762470150832087, InvBCE: 0.5997877717018127\n",
      "Loss: 0.5930749773979187, Norm: 0.0007484075031243265, InvBCE: 0.5604896545410156\n",
      "Loss: 0.5582910776138306, Norm: 0.0011154452804476023, InvBCE: 0.5255975127220154\n",
      "Loss: 0.5275567173957825, Norm: 0.0014762372011318803, InvBCE: 0.49475449323654175\n",
      "Image fooled! Adding perturbation...\n",
      "Image 28...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 29...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 30...\n",
      "Loss: 0.776292085647583, Norm: 0.0, InvBCE: 0.7433813214302063\n",
      "Loss: 0.7225158214569092, Norm: 0.00037481283652596176, InvBCE: 0.6895135045051575\n",
      "Image fooled! Adding perturbation...\n",
      "Image 31...\n",
      "Loss: 809.8566284179688, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8564453125, Norm: 0.00023494950437452644, InvBCE: 809.8235473632812\n",
      "Loss: 809.856201171875, Norm: 0.00046971585834398866, InvBCE: 809.8235473632812\n",
      "Loss: 809.8560180664062, Norm: 0.0007042858051136136, InvBCE: 809.8235473632812\n",
      "Loss: 809.8557739257812, Norm: 0.0009386456804350019, InvBCE: 809.8235473632812\n",
      "Loss: 809.8555908203125, Norm: 0.0011727819219231606, InvBCE: 809.8235473632812\n",
      "Loss: 809.8553466796875, Norm: 0.0014066806761547923, InvBCE: 809.8235473632812\n",
      "Loss: 809.8551635742188, Norm: 0.0016403279732912779, InvBCE: 809.8235473632812\n",
      "Loss: 809.8549194335938, Norm: 0.0018737099599093199, InvBCE: 809.8235473632812\n",
      "Loss: 809.854736328125, Norm: 0.0021068123169243336, InvBCE: 809.8235473632812\n",
      "Loss: 809.8544921875, Norm: 0.0023396210744976997, InvBCE: 809.8235473632812\n",
      "Loss: 809.8543090820312, Norm: 0.0025721220299601555, InvBCE: 809.8235473632812\n",
      "Loss: 809.8540649414062, Norm: 0.0028043014463037252, InvBCE: 809.8235473632812\n",
      "Loss: 809.8538818359375, Norm: 0.003036144655197859, InvBCE: 809.8235473632812\n",
      "Loss: 809.8536376953125, Norm: 0.0032676381524652243, InvBCE: 809.8235473632812\n",
      "Loss: 809.8534545898438, Norm: 0.0034987679682672024, InvBCE: 809.8235473632812\n",
      "Loss: 809.8532104492188, Norm: 0.003729520132765174, InvBCE: 809.8235473632812\n",
      "Loss: 809.85302734375, Norm: 0.003959881607443094, InvBCE: 809.8235473632812\n",
      "Loss: 809.852783203125, Norm: 0.0041898381896317005, InvBCE: 809.8235473632812\n",
      "Loss: 809.8526000976562, Norm: 0.004419376607984304, InvBCE: 809.8235473632812\n",
      "Image 32...\n",
      "Loss: 1.532102346420288, Norm: 0.0, InvBCE: 1.4990060329437256\n",
      "Loss: 1.5143364667892456, Norm: 0.0003579894546419382, InvBCE: 1.4812449216842651\n",
      "Loss: 1.4966909885406494, Norm: 0.0007126962882466614, InvBCE: 1.463602066040039\n",
      "Loss: 1.4791889190673828, Norm: 0.0010646680602803826, InvBCE: 1.4461007118225098\n",
      "Loss: 1.4618929624557495, Norm: 0.0014141531428322196, InvBCE: 1.4288041591644287\n",
      "Image fooled! Adding perturbation...\n",
      "Image 33...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 34...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 35...\n",
      "Loss: 1.0333809852600098, Norm: 0.0, InvBCE: 1.0002903938293457\n",
      "Loss: 1.0010502338409424, Norm: 0.0003746797447092831, InvBCE: 0.9679635167121887\n",
      "Loss: 0.9802758097648621, Norm: 0.0007004195358604193, InvBCE: 0.9471833109855652\n",
      "Loss: 0.961556613445282, Norm: 0.0010113565949723125, InvBCE: 0.928449809551239\n",
      "Loss: 0.9457013010978699, Norm: 0.0013165912823751569, InvBCE: 0.9125769138336182\n",
      "Image fooled! Adding perturbation...\n",
      "Image 36...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 37...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 38...\n",
      "Loss: 1.4871464967727661, Norm: 0.0, InvBCE: 1.454000473022461\n",
      "Loss: 1.4756460189819336, Norm: 0.0003451171505730599, InvBCE: 1.4425538778305054\n",
      "Loss: 1.464123010635376, Norm: 0.0006886934279464185, InvBCE: 1.4310821294784546\n",
      "Image fooled! Adding perturbation...\n",
      "Image 39...\n",
      "Loss: 673.5187377929688, Norm: 0.0, InvBCE: 673.4857177734375\n",
      "Loss: 673.5184936523438, Norm: 0.0002346827823203057, InvBCE: 673.4857177734375\n",
      "Loss: 673.5182495117188, Norm: 0.00046918055159039795, InvBCE: 673.4857177734375\n",
      "Loss: 673.51806640625, Norm: 0.0007034798036329448, InvBCE: 673.4857177734375\n",
      "Loss: 673.517822265625, Norm: 0.0009375668596476316, InvBCE: 673.4857177734375\n",
      "Loss: 673.5176391601562, Norm: 0.0011714280117303133, InvBCE: 673.4857177734375\n",
      "Loss: 673.5173950195312, Norm: 0.0014050491154193878, InvBCE: 673.4857177734375\n",
      "Loss: 673.5172119140625, Norm: 0.0016384159680455923, InvBCE: 673.4857177734375\n",
      "Loss: 673.5169677734375, Norm: 0.0018715147161856294, InvBCE: 673.4857177734375\n",
      "Loss: 673.5167846679688, Norm: 0.0021043308079242706, InvBCE: 673.4857177734375\n",
      "Loss: 673.5165405273438, Norm: 0.002336850157007575, InvBCE: 673.4857177734375\n",
      "Loss: 673.516357421875, Norm: 0.002569058444350958, InvBCE: 673.4857177734375\n",
      "Loss: 673.5161743164062, Norm: 0.0028009414672851562, InvBCE: 673.4857177734375\n",
      "Loss: 673.5159301757812, Norm: 0.0030324850231409073, InvBCE: 673.4857177734375\n",
      "Loss: 673.5157470703125, Norm: 0.003263674909248948, InvBCE: 673.4857177734375\n",
      "Loss: 673.5155029296875, Norm: 0.003494496922940016, InvBCE: 673.4857177734375\n",
      "Loss: 673.5153198242188, Norm: 0.0037249375600367785, InvBCE: 673.4857177734375\n",
      "Loss: 673.5150756835938, Norm: 0.003954982850700617, InvBCE: 673.4857177734375\n",
      "Loss: 673.514892578125, Norm: 0.004184618592262268, InvBCE: 673.4857177734375\n",
      "Loss: 673.5147094726562, Norm: 0.0044138324446976185, InvBCE: 673.4857177734375\n",
      "Image 40...\n",
      "Loss: 16.218435287475586, Norm: 0.0, InvBCE: 16.185443878173828\n",
      "Loss: 12.973325729370117, Norm: 0.00038452845183201134, InvBCE: 12.940290451049805\n",
      "Loss: 10.465180397033691, Norm: 0.0007586475694552064, InvBCE: 10.432098388671875\n",
      "Loss: 8.621658325195312, Norm: 0.0011226104106754065, InvBCE: 8.58852767944336\n",
      "Loss: 7.1658525466918945, Norm: 0.001476755365729332, InvBCE: 7.132671356201172\n",
      "Loss: 5.393100261688232, Norm: 0.0018210691632702947, InvBCE: 5.359865665435791\n",
      "Loss: 4.631354808807373, Norm: 0.002151874825358391, InvBCE: 4.598066329956055\n",
      "Loss: 4.075389385223389, Norm: 0.002468283986672759, InvBCE: 4.042047023773193\n",
      "Loss: 3.6659095287323, Norm: 0.0027700222562998533, InvBCE: 3.6325130462646484\n",
      "Loss: 3.402949333190918, Norm: 0.003057439113035798, InvBCE: 3.3694984912872314\n",
      "Loss: 3.214210033416748, Norm: 0.003226573346182704, InvBCE: 3.1807334423065186\n",
      "Loss: 3.1115164756774902, Norm: 0.003399340435862541, InvBCE: 3.078012704849243\n",
      "Loss: 3.0198147296905518, Norm: 0.003573436988517642, InvBCE: 2.9862825870513916\n",
      "Loss: 2.937208414077759, Norm: 0.003747234819456935, InvBCE: 2.90364670753479\n",
      "Loss: 2.862506151199341, Norm: 0.003919598180800676, InvBCE: 2.8289144039154053\n",
      "Loss: 2.794527769088745, Norm: 0.004089741501957178, InvBCE: 2.7609055042266846\n",
      "Loss: 2.7322640419006348, Norm: 0.004257130436599255, InvBCE: 2.698610782623291\n",
      "Loss: 2.674762487411499, Norm: 0.0044214120134711266, InvBCE: 2.641077756881714\n",
      "Loss: 2.621051788330078, Norm: 0.004582386463880539, InvBCE: 2.5873355865478516\n",
      "Loss: 2.570317506790161, Norm: 0.004739914555102587, InvBCE: 2.536569833755493\n",
      "Image 41...\n",
      "Loss: 1.4872759580612183, Norm: 0.0, InvBCE: 1.4542838335037231\n",
      "Loss: 1.4709582328796387, Norm: 0.0003563809732440859, InvBCE: 1.4379429817199707\n",
      "Loss: 1.455212950706482, Norm: 0.0007103533716872334, InvBCE: 1.4221727848052979\n",
      "Loss: 1.4400479793548584, Norm: 0.0010616111103445292, InvBCE: 1.4069814682006836\n",
      "Loss: 1.4254823923110962, Norm: 0.0014096813974902034, InvBCE: 1.3923887014389038\n",
      "Loss: 1.4115201234817505, Norm: 0.0017540015978738666, InvBCE: 1.3783988952636719\n",
      "Image fooled! Adding perturbation...\n",
      "Image 42...\n",
      "Loss: 1.4186216592788696, Norm: 0.0, InvBCE: 1.3854732513427734\n",
      "Loss: 1.3926630020141602, Norm: 0.0003578151226975024, InvBCE: 1.3595242500305176\n",
      "Image fooled! Adding perturbation...\n",
      "Image 43...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 44...\n",
      "Loss: 0.7695989012718201, Norm: 0.0, InvBCE: 0.7364649772644043\n",
      "Image fooled! Adding perturbation...\n",
      "Image 45...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 46...\n",
      "Loss: 0.5430452823638916, Norm: 0.0, InvBCE: 0.5098633170127869\n",
      "Loss: 0.5151222944259644, Norm: 0.0003657336055766791, InvBCE: 0.4818865656852722\n",
      "Image fooled! Adding perturbation...\n",
      "Image 47...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 48...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 49...\n",
      "Loss: 1.5726062059402466, Norm: 0.0, InvBCE: 1.5393162965774536\n",
      "Loss: 1.4942809343338013, Norm: 0.00037828576751053333, InvBCE: 1.4609346389770508\n",
      "Loss: 1.418165683746338, Norm: 0.0007523484528064728, InvBCE: 1.3847600221633911\n",
      "Loss: 1.3456907272338867, Norm: 0.001122498419135809, InvBCE: 1.312222957611084\n",
      "Image fooled! Adding perturbation...\n",
      "Image 50...\n",
      "Loss: 115.6240005493164, Norm: 0.0, InvBCE: 115.59046936035156\n",
      "Loss: 66.33937072753906, Norm: 0.0003838925913441926, InvBCE: 66.3058090209961\n",
      "Loss: 35.51897048950195, Norm: 0.0007299334392882884, InvBCE: 35.485374450683594\n",
      "Loss: 22.26332664489746, Norm: 0.0010473524453118443, InvBCE: 22.22970199584961\n",
      "Loss: 15.132102966308594, Norm: 0.0013356995768845081, InvBCE: 15.098451614379883\n",
      "Loss: 11.17329216003418, Norm: 0.0015978397568687797, InvBCE: 11.139616966247559\n",
      "Loss: 9.105695724487305, Norm: 0.0018369528697803617, InvBCE: 9.071999549865723\n",
      "Loss: 7.565581321716309, Norm: 0.002056174911558628, InvBCE: 7.531866550445557\n",
      "Loss: 6.52394962310791, Norm: 0.002258178312331438, InvBCE: 6.490218162536621\n",
      "Loss: 5.7855329513549805, Norm: 0.002444970654323697, InvBCE: 5.751786708831787\n",
      "Loss: 5.187473773956299, Norm: 0.0026183598674833775, InvBCE: 5.153714179992676\n",
      "Loss: 4.7094502449035645, Norm: 0.002779922680929303, InvBCE: 4.6756792068481445\n",
      "Loss: 4.3946075439453125, Norm: 0.0029308979865163565, InvBCE: 4.36082649230957\n",
      "Loss: 4.144157886505127, Norm: 0.003072173334658146, InvBCE: 4.110368251800537\n",
      "Loss: 3.929036855697632, Norm: 0.00320504535920918, InvBCE: 3.8952395915985107\n",
      "Loss: 3.7524144649505615, Norm: 0.0033304302487522364, InvBCE: 3.718611001968384\n",
      "Loss: 3.5983524322509766, Norm: 0.0034490565303713083, InvBCE: 3.5645437240600586\n",
      "Loss: 3.4649386405944824, Norm: 0.0035616334062069654, InvBCE: 3.4311258792877197\n",
      "Loss: 3.3490452766418457, Norm: 0.0036687771789729595, InvBCE: 3.3152291774749756\n",
      "Loss: 3.2458689212799072, Norm: 0.003771003568544984, InvBCE: 3.212050437927246\n",
      "Image 51...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 52...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 53...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 54...\n",
      "Loss: 1.4834959506988525, Norm: 0.0, InvBCE: 1.4499640464782715\n",
      "Loss: 1.4813345670700073, Norm: 0.00031221582321450114, InvBCE: 1.4479345083236694\n",
      "Loss: 1.4791096448898315, Norm: 0.0006243702373467386, InvBCE: 1.445839285850525\n",
      "Loss: 1.4768308401107788, Norm: 0.000936458702199161, InvBCE: 1.443687915802002\n",
      "Image fooled! Adding perturbation...\n",
      "Image 55...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 56...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 57...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 58...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 59...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 60...\n",
      "Loss: 809.8565673828125, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8563232421875, Norm: 0.00023461715318262577, InvBCE: 809.8235473632812\n",
      "Loss: 809.8561401367188, Norm: 0.00046904952614568174, InvBCE: 809.8235473632812\n",
      "Loss: 809.8558959960938, Norm: 0.0007032835274003446, InvBCE: 809.8235473632812\n",
      "Loss: 809.855712890625, Norm: 0.0009373056818731129, InvBCE: 809.8235473632812\n",
      "Loss: 809.85546875, Norm: 0.001171101932413876, InvBCE: 809.8235473632812\n",
      "Loss: 809.8552856445312, Norm: 0.0014046586584299803, InvBCE: 809.8235473632812\n",
      "Loss: 809.8550415039062, Norm: 0.0016379613662138581, InvBCE: 809.8235473632812\n",
      "Loss: 809.8548583984375, Norm: 0.0018709960859268904, InvBCE: 809.8235473632812\n",
      "Loss: 809.8546142578125, Norm: 0.0021037484984844923, InvBCE: 809.8235473632812\n",
      "Loss: 809.8544311523438, Norm: 0.0023362047504633665, InvBCE: 809.8235473632812\n",
      "Loss: 809.8541870117188, Norm: 0.002568350173532963, InvBCE: 809.8235473632812\n",
      "Loss: 809.85400390625, Norm: 0.0028001705650240183, InvBCE: 809.8235473632812\n",
      "Loss: 809.8538208007812, Norm: 0.0030316519550979137, InvBCE: 809.8235473632812\n",
      "Loss: 809.8535766601562, Norm: 0.0032627794425934553, InvBCE: 809.8235473632812\n",
      "Loss: 809.8533935546875, Norm: 0.003493540221825242, InvBCE: 809.8235473632812\n",
      "Loss: 809.8531494140625, Norm: 0.0037239196244627237, InvBCE: 809.8235473632812\n",
      "Loss: 809.8529663085938, Norm: 0.003953903913497925, InvBCE: 809.8235473632812\n",
      "Loss: 809.8527221679688, Norm: 0.004183479584753513, InvBCE: 809.8235473632812\n",
      "Loss: 809.8525390625, Norm: 0.004412633366882801, InvBCE: 809.8235473632812\n",
      "Image 61...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 62...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 63...\n",
      "Loss: 1.3778421878814697, Norm: 0.0, InvBCE: 1.3448243141174316\n",
      "Image fooled! Adding perturbation...\n",
      "Image 64...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 65...\n",
      "Loss: 0.9908304810523987, Norm: 0.0, InvBCE: 0.9577896595001221\n",
      "Loss: 0.9369606971740723, Norm: 0.00037158012855798006, InvBCE: 0.9038974642753601\n",
      "Image fooled! Adding perturbation...\n",
      "Image 66...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 67...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 68...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 69...\n",
      "Loss: 0.6162557005882263, Norm: 0.0, InvBCE: 0.5831673741340637\n",
      "Image fooled! Adding perturbation...\n",
      "Image 70...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 71...\n",
      "Loss: 0.7229207754135132, Norm: 0.0, InvBCE: 0.6897192001342773\n",
      "Loss: 0.6705234050750732, Norm: 0.0003693272592499852, InvBCE: 0.637241542339325\n",
      "Loss: 0.6257628798484802, Norm: 0.0007325124461203814, InvBCE: 0.5923978686332703\n",
      "Loss: 0.5876356959342957, Norm: 0.0010889038676396012, InvBCE: 0.5541852712631226\n",
      "Image fooled! Adding perturbation...\n",
      "Image 72...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 73...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 74...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 75...\n",
      "Loss: 1.696058988571167, Norm: 0.0, InvBCE: 1.6625218391418457\n",
      "Image fooled! Adding perturbation...\n",
      "Image 76...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 77...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 78...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 79...\n",
      "Loss: 809.8569946289062, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8568115234375, Norm: 0.00023449903528671712, InvBCE: 809.8235473632812\n",
      "Loss: 809.8565673828125, Norm: 0.00046881590969860554, InvBCE: 809.8235473632812\n",
      "Loss: 809.8563842773438, Norm: 0.0007029374246485531, InvBCE: 809.8235473632812\n",
      "Loss: 809.8561401367188, Norm: 0.000936850265134126, InvBCE: 809.8235473632812\n",
      "Loss: 809.85595703125, Norm: 0.0011705405777320266, InvBCE: 809.8235473632812\n",
      "Loss: 809.855712890625, Norm: 0.001403994974680245, InvBCE: 809.8235473632812\n",
      "Loss: 809.8555297851562, Norm: 0.0016371995443478227, InvBCE: 809.8235473632812\n",
      "Loss: 809.8552856445312, Norm: 0.0018701402004808187, InvBCE: 809.8235473632812\n",
      "Loss: 809.8551025390625, Norm: 0.0021028032060712576, InvBCE: 809.8235473632812\n",
      "Loss: 809.8548583984375, Norm: 0.002335174474865198, InvBCE: 809.8235473632812\n",
      "Loss: 809.8546752929688, Norm: 0.002567240037024021, InvBCE: 809.8235473632812\n",
      "Loss: 809.8544311523438, Norm: 0.0027989863883703947, InvBCE: 809.8235473632812\n",
      "Loss: 809.854248046875, Norm: 0.0030303990934044123, InvBCE: 809.8235473632812\n",
      "Loss: 809.8540649414062, Norm: 0.0032614644151180983, InvBCE: 809.8235473632812\n",
      "Loss: 809.8538208007812, Norm: 0.0034921688493341208, InvBCE: 809.8235473632812\n",
      "Loss: 809.8536376953125, Norm: 0.0037224984262138605, InvBCE: 809.8235473632812\n",
      "Loss: 809.8533935546875, Norm: 0.003952439874410629, InvBCE: 809.8235473632812\n",
      "Loss: 809.8532104492188, Norm: 0.004181980155408382, InvBCE: 809.8235473632812\n",
      "Loss: 809.8529663085938, Norm: 0.004411105997860432, InvBCE: 809.8235473632812\n",
      "Image 80...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 81...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 82...\n",
      "Loss: 0.7717108726501465, Norm: 0.0, InvBCE: 0.7382369041442871\n",
      "Image fooled! Adding perturbation...\n",
      "Image 83...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 84...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 85...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 86...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 87...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 88...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 89...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 90...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 91...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 92...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 93...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 94...\n",
      "Loss: 0.8654561638832092, Norm: 0.0, InvBCE: 0.8319426774978638\n",
      "Image fooled! Adding perturbation...\n",
      "Image 95...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 96...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 97...\n",
      "Loss: 1.4761452674865723, Norm: 0.0, InvBCE: 1.4425817728042603\n",
      "Image fooled! Adding perturbation...\n",
      "Image 98...\n",
      "Loss: 1.3749605417251587, Norm: 0.0, InvBCE: 1.3413805961608887\n",
      "Image fooled! Adding perturbation...\n",
      "Image 99...\n",
      "Image fooled! Adding perturbation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a7a2ac60edc4890948b739856f5de33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fooling rate: 0.78\n",
      "Starting epoch 7...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c5aa50a653b41e592c81d946615e5d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 1...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 2...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 3...\n",
      "Loss: 3.4470794200897217, Norm: 0.0, InvBCE: 3.4134628772735596\n",
      "Loss: 3.038621425628662, Norm: 0.0003815780219156295, InvBCE: 3.004950761795044\n",
      "Loss: 2.6819262504577637, Norm: 0.0007582416292279959, InvBCE: 2.648198366165161\n",
      "Loss: 2.374680757522583, Norm: 0.0011295194271951914, InvBCE: 2.340893030166626\n",
      "Loss: 2.109168767929077, Norm: 0.001494231983087957, InvBCE: 2.0753188133239746\n",
      "Loss: 1.880286693572998, Norm: 0.001851419685408473, InvBCE: 1.8463728427886963\n",
      "Loss: 1.6834964752197266, Norm: 0.002200173446908593, InvBCE: 1.64951753616333\n",
      "Loss: 1.5145138502120972, Norm: 0.0025397210847586393, InvBCE: 1.4804691076278687\n",
      "Loss: 1.3694539070129395, Norm: 0.002869431162253022, InvBCE: 1.3353430032730103\n",
      "Loss: 1.2448382377624512, Norm: 0.0031888424418866634, InvBCE: 1.2106611728668213\n",
      "Loss: 1.1375770568847656, Norm: 0.0034976231399923563, InvBCE: 1.1033343076705933\n",
      "Loss: 1.0450141429901123, Norm: 0.0037955897860229015, InvBCE: 1.0107065439224243\n",
      "Loss: 0.9649093747138977, Norm: 0.004082674626260996, InvBCE: 0.9305379390716553\n",
      "Loss: 0.8954126238822937, Norm: 0.004358906764537096, InvBCE: 0.8609786629676819\n",
      "Loss: 0.8349746465682983, Norm: 0.004624385852366686, InvBCE: 0.8004797101020813\n",
      "Loss: 0.7823065519332886, Norm: 0.004879258573055267, InvBCE: 0.7477522492408752\n",
      "Loss: 0.7363126873970032, Norm: 0.00512372050434351, InvBCE: 0.7017008662223816\n",
      "Loss: 0.6960477232933044, Norm: 0.005358005873858929, InvBCE: 0.6613802909851074\n",
      "Loss: 0.6606972217559814, Norm: 0.0055823796428740025, InvBCE: 0.6259761452674866\n",
      "Loss: 0.6295729279518127, Norm: 0.005797133781015873, InvBCE: 0.5948002338409424\n",
      "Image 4...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 5...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 6...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 7...\n",
      "Loss: 0.9610970616340637, Norm: 0.0, InvBCE: 0.9274804592132568\n",
      "Loss: 0.911245584487915, Norm: 0.0003720007371157408, InvBCE: 0.8776378035545349\n",
      "Loss: 0.8651934862136841, Norm: 0.0007411871920339763, InvBCE: 0.8315916657447815\n",
      "Loss: 0.8229585289955139, Norm: 0.0011071861954405904, InvBCE: 0.7893601059913635\n",
      "Image fooled! Adding perturbation...\n",
      "Image 8...\n",
      "Loss: 1.4799054861068726, Norm: 0.0, InvBCE: 1.4463080167770386\n",
      "Image fooled! Adding perturbation...\n",
      "Image 9...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 10...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 11...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 12...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 13...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 14...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 15...\n",
      "Loss: 0.638839840888977, Norm: 0.0, InvBCE: 0.6053023338317871\n",
      "Image fooled! Adding perturbation...\n",
      "Image 16...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 17...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 18...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 19...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 20...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 21...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 22...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 23...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 24...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 25...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 26...\n",
      "Loss: 1.4822553396224976, Norm: 0.0, InvBCE: 1.4486465454101562\n",
      "Loss: 1.4804635047912598, Norm: 0.00030491757206618786, InvBCE: 1.4469703435897827\n",
      "Loss: 1.4786678552627563, Norm: 0.000609649287071079, InvBCE: 1.4452881813049316\n",
      "Loss: 1.476873517036438, Norm: 0.0009139478206634521, InvBCE: 1.4436050653457642\n",
      "Image fooled! Adding perturbation...\n",
      "Image 27...\n",
      "Loss: 0.5973964929580688, Norm: 0.0, InvBCE: 0.5642375946044922\n",
      "Loss: 0.5615467429161072, Norm: 0.00037388282362371683, InvBCE: 0.5282809138298035\n",
      "Loss: 0.5297889113426208, Norm: 0.0007435939041897655, InvBCE: 0.49641475081443787\n",
      "Image fooled! Adding perturbation...\n",
      "Image 28...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 29...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 30...\n",
      "Loss: 0.7554047703742981, Norm: 0.0, InvBCE: 0.7219216227531433\n",
      "Loss: 0.7062045335769653, Norm: 0.0003743530542124063, InvBCE: 0.6726254820823669\n",
      "Image fooled! Adding perturbation...\n",
      "Image 31...\n",
      "Loss: 809.8572387695312, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8569946289062, Norm: 0.00023415236501023173, InvBCE: 809.8235473632812\n",
      "Loss: 809.8568115234375, Norm: 0.00046812286018393934, InvBCE: 809.8235473632812\n",
      "Loss: 809.8565673828125, Norm: 0.000701898243278265, InvBCE: 809.8235473632812\n",
      "Loss: 809.8563842773438, Norm: 0.0009354652720503509, InvBCE: 809.8235473632812\n",
      "Loss: 809.8561401367188, Norm: 0.0011688102968037128, InvBCE: 809.8235473632812\n",
      "Loss: 809.85595703125, Norm: 0.0014019198715686798, InvBCE: 809.8235473632812\n",
      "Loss: 809.855712890625, Norm: 0.001634779735468328, InvBCE: 809.8235473632812\n",
      "Loss: 809.8555297851562, Norm: 0.0018673765007406473, InvBCE: 809.8235473632812\n",
      "Loss: 809.8552856445312, Norm: 0.0020996960811316967, InvBCE: 809.8235473632812\n",
      "Loss: 809.8551025390625, Norm: 0.0023317246232181787, InvBCE: 809.8235473632812\n",
      "Loss: 809.8548583984375, Norm: 0.0025634481571614742, InvBCE: 809.8235473632812\n",
      "Loss: 809.8546752929688, Norm: 0.0027948529459536076, InvBCE: 809.8235473632812\n",
      "Loss: 809.8544311523438, Norm: 0.003025924554094672, InvBCE: 809.8235473632812\n",
      "Loss: 809.854248046875, Norm: 0.003256650408729911, InvBCE: 809.8235473632812\n",
      "Loss: 809.8540649414062, Norm: 0.0034870156086981297, InvBCE: 809.8235473632812\n",
      "Loss: 809.8538208007812, Norm: 0.0037170073483139277, InvBCE: 809.8235473632812\n",
      "Loss: 809.8536376953125, Norm: 0.003946612123399973, InvBCE: 809.8235473632812\n",
      "Loss: 809.8533935546875, Norm: 0.004175816662609577, InvBCE: 809.8235473632812\n",
      "Loss: 809.8532104492188, Norm: 0.004404607228934765, InvBCE: 809.8235473632812\n",
      "Image 32...\n",
      "Loss: 1.509800672531128, Norm: 0.0, InvBCE: 1.4761254787445068\n",
      "Loss: 1.4913908243179321, Norm: 0.0003586022066883743, InvBCE: 1.4577147960662842\n",
      "Loss: 1.4733637571334839, Norm: 0.0007141655078157783, InvBCE: 1.4396851062774658\n",
      "Loss: 1.4557284116744995, Norm: 0.0010671268682926893, InvBCE: 1.4220457077026367\n",
      "Image fooled! Adding perturbation...\n",
      "Image 33...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 34...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 35...\n",
      "Loss: 1.0202031135559082, Norm: 0.0, InvBCE: 0.9865151643753052\n",
      "Loss: 0.9870044589042664, Norm: 0.0003716768987942487, InvBCE: 0.9533098340034485\n",
      "Loss: 0.9760904908180237, Norm: 0.0006690691807307303, InvBCE: 0.9423794746398926\n",
      "Loss: 0.9625253677368164, Norm: 0.0009739407105371356, InvBCE: 0.9287935495376587\n",
      "Loss: 0.9475288987159729, Norm: 0.0012709097936749458, InvBCE: 0.9137716293334961\n",
      "Image fooled! Adding perturbation...\n",
      "Image 36...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 37...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 38...\n",
      "Loss: 1.481911540031433, Norm: 0.0, InvBCE: 1.4481245279312134\n",
      "Loss: 1.470611810684204, Norm: 0.0003445200272835791, InvBCE: 1.4368765354156494\n",
      "Loss: 1.459293246269226, Norm: 0.0006876433617435396, InvBCE: 1.4256073236465454\n",
      "Image fooled! Adding perturbation...\n",
      "Image 39...\n",
      "Loss: 673.5193481445312, Norm: 0.0, InvBCE: 673.4857177734375\n",
      "Loss: 673.5191650390625, Norm: 0.00023397247423417866, InvBCE: 673.4857177734375\n",
      "Loss: 673.5189208984375, Norm: 0.0004677621473092586, InvBCE: 673.4857177734375\n",
      "Loss: 673.5187377929688, Norm: 0.0007013555732555687, InvBCE: 673.4857177734375\n",
      "Loss: 673.5184936523438, Norm: 0.0009347394807264209, InvBCE: 673.4857177734375\n",
      "Loss: 673.518310546875, Norm: 0.0011679001618176699, InvBCE: 673.4857177734375\n",
      "Loss: 673.51806640625, Norm: 0.0014008238213136792, InvBCE: 673.4857177734375\n",
      "Loss: 673.5178833007812, Norm: 0.0016334964893758297, InvBCE: 673.4857177734375\n",
      "Loss: 673.5176391601562, Norm: 0.0018659045454114676, InvBCE: 673.4857177734375\n",
      "Loss: 673.5174560546875, Norm: 0.0020980339031666517, InvBCE: 673.4857177734375\n",
      "Loss: 673.5172119140625, Norm: 0.0023298701271414757, InvBCE: 673.4857177734375\n",
      "Loss: 673.5170288085938, Norm: 0.0025613997131586075, InvBCE: 673.4857177734375\n",
      "Loss: 673.5167846679688, Norm: 0.0027926089242100716, InvBCE: 673.4857177734375\n",
      "Loss: 673.5166015625, Norm: 0.003023482859134674, InvBCE: 673.4857177734375\n",
      "Loss: 673.516357421875, Norm: 0.0032540084794163704, InvBCE: 673.4857177734375\n",
      "Loss: 673.5161743164062, Norm: 0.0034841715823858976, InvBCE: 673.4857177734375\n",
      "Loss: 673.5159912109375, Norm: 0.0037139588966965675, InvBCE: 673.4857177734375\n",
      "Loss: 673.5157470703125, Norm: 0.0039433566853404045, InvBCE: 673.4857177734375\n",
      "Loss: 673.5155639648438, Norm: 0.00417235167697072, InvBCE: 673.4857177734375\n",
      "Loss: 673.5153198242188, Norm: 0.00440093083307147, InvBCE: 673.4857177734375\n",
      "Image 40...\n",
      "Loss: 12.644308090209961, Norm: 0.0, InvBCE: 12.61067008972168\n",
      "Loss: 10.256889343261719, Norm: 0.0003844682942144573, InvBCE: 10.2232084274292\n",
      "Loss: 8.44698715209961, Norm: 0.0007582624675706029, InvBCE: 8.413259506225586\n",
      "Loss: 6.304807662963867, Norm: 0.0011234148405492306, InvBCE: 6.271031379699707\n",
      "Loss: 5.306944847106934, Norm: 0.0014804935781285167, InvBCE: 5.273116588592529\n",
      "Loss: 4.579031467437744, Norm: 0.001822474179789424, InvBCE: 4.5451507568359375\n",
      "Loss: 4.040151596069336, Norm: 0.0021498422138392925, InvBCE: 4.0062174797058105\n",
      "Loss: 4.772172451019287, Norm: 0.002462289994582534, InvBCE: 4.738184928894043\n",
      "Loss: 2.66416335105896, Norm: 0.0027676138561218977, InvBCE: 2.6301207542419434\n",
      "Loss: 2.3530588150024414, Norm: 0.0030569962691515684, InvBCE: 2.318960428237915\n",
      "Loss: 2.096982002258301, Norm: 0.003331561107188463, InvBCE: 2.0628273487091064\n",
      "Loss: 1.8996421098709106, Norm: 0.0035901018418371677, InvBCE: 1.865432620048523\n",
      "Loss: 1.7097904682159424, Norm: 0.0038365561049431562, InvBCE: 1.6755263805389404\n",
      "Loss: 1.4998606443405151, Norm: 0.004071648232638836, InvBCE: 1.4655425548553467\n",
      "Loss: 1.3641210794448853, Norm: 0.004295808728784323, InvBCE: 1.3297500610351562\n",
      "Loss: 1.2351362705230713, Norm: 0.004509841091930866, InvBCE: 1.2007132768630981\n",
      "Loss: 1.1275416612625122, Norm: 0.00471431715413928, InvBCE: 1.0930678844451904\n",
      "Loss: 1.0320007801055908, Norm: 0.00490989163517952, InvBCE: 0.9974774718284607\n",
      "Loss: 0.8468626141548157, Norm: 0.005097026936709881, InvBCE: 0.8122910261154175\n",
      "Loss: 0.7901449799537659, Norm: 0.0052749235183000565, InvBCE: 0.7555269598960876\n",
      "Image 41...\n",
      "Loss: 1.4636694192886353, Norm: 0.0, InvBCE: 1.430031180381775\n",
      "Loss: 1.4486795663833618, Norm: 0.0003549664979800582, InvBCE: 1.4150151014328003\n",
      "Loss: 1.4342164993286133, Norm: 0.0007068554987199605, InvBCE: 1.4005248546600342\n",
      "Loss: 1.4202805757522583, Norm: 0.0010558848734945059, InvBCE: 1.3865611553192139\n",
      "Loss: 1.4068808555603027, Norm: 0.001401648041792214, InvBCE: 1.373133897781372\n",
      "Image fooled! Adding perturbation...\n",
      "Image 42...\n",
      "Loss: 1.4018088579177856, Norm: 0.0, InvBCE: 1.368034839630127\n",
      "Image fooled! Adding perturbation...\n",
      "Image 43...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 44...\n",
      "Loss: 0.7703648209571838, Norm: 0.0, InvBCE: 0.7365953326225281\n",
      "Image fooled! Adding perturbation...\n",
      "Image 45...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 46...\n",
      "Loss: 0.5335500240325928, Norm: 0.0, InvBCE: 0.49973008036613464\n",
      "Loss: 0.5069043636322021, Norm: 0.0003658068017102778, InvBCE: 0.47302961349487305\n",
      "Image fooled! Adding perturbation...\n",
      "Image 47...\n",
      "Loss: 1.1095426082611084, Norm: 0.0, InvBCE: 1.0756129026412964\n",
      "Image fooled! Adding perturbation...\n",
      "Image 48...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 49...\n",
      "Loss: 1.4373382329940796, Norm: 0.0, InvBCE: 1.4033598899841309\n",
      "Loss: 1.3667638301849365, Norm: 0.0003776169032789767, InvBCE: 1.3327229022979736\n",
      "Loss: 1.3000997304916382, Norm: 0.0007501012878492475, InvBCE: 1.2659937143325806\n",
      "Image fooled! Adding perturbation...\n",
      "Image 50...\n",
      "Loss: 90.94490051269531, Norm: 0.0, InvBCE: 90.91072845458984\n",
      "Loss: 54.32632827758789, Norm: 0.00038384090294130147, InvBCE: 54.29212188720703\n",
      "Loss: 28.622791290283203, Norm: 0.0007407987723127007, InvBCE: 28.58855628967285\n",
      "Loss: 18.742204666137695, Norm: 0.0010521868243813515, InvBCE: 18.707942962646484\n",
      "Loss: 13.13758659362793, Norm: 0.001336206798441708, InvBCE: 13.103301048278809\n",
      "Loss: 10.065488815307617, Norm: 0.0015952677931636572, InvBCE: 10.031181335449219\n",
      "Loss: 8.372904777526855, Norm: 0.0018322300165891647, InvBCE: 8.338578224182129\n",
      "Loss: 7.036920547485352, Norm: 0.002050451235845685, InvBCE: 7.002577304840088\n",
      "Loss: 6.144063949584961, Norm: 0.0022523074876517057, InvBCE: 6.109705924987793\n",
      "Loss: 5.480156421661377, Norm: 0.002439718460664153, InvBCE: 5.445785045623779\n",
      "Loss: 4.940901756286621, Norm: 0.0026145419105887413, InvBCE: 4.906518459320068\n",
      "Loss: 4.500341892242432, Norm: 0.0027779564261436462, InvBCE: 4.465948581695557\n",
      "Loss: 4.222885608673096, Norm: 0.0029311326798051596, InvBCE: 4.188483238220215\n",
      "Loss: 3.9775960445404053, Norm: 0.00307525135576725, InvBCE: 3.943186044692993\n",
      "Loss: 3.775167942047119, Norm: 0.0032112605404108763, InvBCE: 3.7407515048980713\n",
      "Loss: 3.6062798500061035, Norm: 0.0033399611711502075, InvBCE: 3.5718581676483154\n",
      "Loss: 3.4568209648132324, Norm: 0.003462155582383275, InvBCE: 3.4223952293395996\n",
      "Loss: 3.3264966011047363, Norm: 0.0035785124637186527, InvBCE: 3.292067527770996\n",
      "Loss: 3.211695671081543, Norm: 0.0036895843222737312, InvBCE: 3.1772642135620117\n",
      "Loss: 3.1217005252838135, Norm: 0.003795881289988756, InvBCE: 3.0872673988342285\n",
      "Image 51...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 52...\n",
      "Loss: 1.2341957092285156, Norm: 0.0, InvBCE: 1.2000224590301514\n",
      "Image fooled! Adding perturbation...\n",
      "Image 53...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 54...\n",
      "Loss: 1.480783462524414, Norm: 0.0, InvBCE: 1.446663498878479\n",
      "Loss: 1.4784939289093018, Norm: 0.00031473374110646546, InvBCE: 1.4444985389709473\n",
      "Loss: 1.4761552810668945, Norm: 0.0006294023478403687, InvBCE: 1.4422814846038818\n",
      "Image fooled! Adding perturbation...\n",
      "Image 55...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 56...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 57...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 58...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 59...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 60...\n",
      "Loss: 809.8572998046875, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8571166992188, Norm: 0.00023402515216730535, InvBCE: 809.8235473632812\n",
      "Loss: 809.8568725585938, Norm: 0.0004678679397329688, InvBCE: 809.8235473632812\n",
      "Loss: 809.856689453125, Norm: 0.0007015151786617935, InvBCE: 809.8235473632812\n",
      "Loss: 809.8564453125, Norm: 0.000934953335672617, InvBCE: 809.8235473632812\n",
      "Loss: 809.8562622070312, Norm: 0.0011681689647957683, InvBCE: 809.8235473632812\n",
      "Loss: 809.8560180664062, Norm: 0.001401148154400289, InvBCE: 809.8235473632812\n",
      "Loss: 809.8558349609375, Norm: 0.0016338771674782038, InvBCE: 809.8235473632812\n",
      "Loss: 809.8555908203125, Norm: 0.0018663422670215368, InvBCE: 809.8235473632812\n",
      "Loss: 809.8554077148438, Norm: 0.002098529366776347, InvBCE: 809.8235473632812\n",
      "Loss: 809.8551635742188, Norm: 0.0023304244969040155, InvBCE: 809.8235473632812\n",
      "Loss: 809.85498046875, Norm: 0.0025620136875659227, InvBCE: 809.8235473632812\n",
      "Loss: 809.854736328125, Norm: 0.002793283201754093, InvBCE: 809.8235473632812\n",
      "Loss: 809.8545532226562, Norm: 0.0030242190696299076, InvBCE: 809.8235473632812\n",
      "Loss: 809.8543090820312, Norm: 0.003254807088524103, InvBCE: 809.8235473632812\n",
      "Loss: 809.8541259765625, Norm: 0.0034850339870899916, InvBCE: 809.8235473632812\n",
      "Loss: 809.8538818359375, Norm: 0.0037148864939808846, InvBCE: 809.8235473632812\n",
      "Loss: 809.8536987304688, Norm: 0.003944350406527519, InvBCE: 809.8235473632812\n",
      "Loss: 809.853515625, Norm: 0.004173412453383207, InvBCE: 809.8235473632812\n",
      "Loss: 809.853271484375, Norm: 0.004402060527354479, InvBCE: 809.8235473632812\n",
      "Image 61...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 62...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 63...\n",
      "Loss: 1.3963866233825684, Norm: 0.0, InvBCE: 1.362631916999817\n",
      "Loss: 1.3598734140396118, Norm: 0.0003681904054246843, InvBCE: 1.3260972499847412\n",
      "Image fooled! Adding perturbation...\n",
      "Image 64...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 65...\n",
      "Loss: 0.930415153503418, Norm: 0.0, InvBCE: 0.8966146111488342\n",
      "Image fooled! Adding perturbation...\n",
      "Image 66...\n",
      "Loss: 1.340503454208374, Norm: 0.0, InvBCE: 1.3066810369491577\n",
      "Image fooled! Adding perturbation...\n",
      "Image 67...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 68...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 69...\n",
      "Loss: 0.6026084423065186, Norm: 0.0, InvBCE: 0.5688343644142151\n",
      "Image fooled! Adding perturbation...\n",
      "Image 70...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 71...\n",
      "Loss: 0.6860344409942627, Norm: 0.0, InvBCE: 0.6521500945091248\n",
      "Loss: 0.6392256021499634, Norm: 0.0003680285590235144, InvBCE: 0.6052572131156921\n",
      "Loss: 0.5993387699127197, Norm: 0.0007293499656952918, InvBCE: 0.5652845501899719\n",
      "Image fooled! Adding perturbation...\n",
      "Image 72...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 73...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 74...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 75...\n",
      "Loss: 1.1666674613952637, Norm: 0.0, InvBCE: 1.1325260400772095\n",
      "Image fooled! Adding perturbation...\n",
      "Image 76...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 77...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 78...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 79...\n",
      "Loss: 809.8576049804688, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.857421875, Norm: 0.00023402761144097894, InvBCE: 809.8235473632812\n",
      "Loss: 809.857177734375, Norm: 0.000467875215690583, InvBCE: 809.8235473632812\n",
      "Loss: 809.8569946289062, Norm: 0.0007015296723693609, InvBCE: 809.8235473632812\n",
      "Loss: 809.8567504882812, Norm: 0.0009349778993055224, InvBCE: 809.8235473632812\n",
      "Loss: 809.8565673828125, Norm: 0.0011682064505293965, InvBCE: 809.8235473632812\n",
      "Loss: 809.8563232421875, Norm: 0.0014012017054483294, InvBCE: 809.8235473632812\n",
      "Loss: 809.8561401367188, Norm: 0.0016339505091309547, InvBCE: 809.8235473632812\n",
      "Loss: 809.8558959960938, Norm: 0.0018664385424926877, InvBCE: 809.8235473632812\n",
      "Loss: 809.855712890625, Norm: 0.00209865253418684, InvBCE: 809.8235473632812\n",
      "Loss: 809.85546875, Norm: 0.0023305783979594707, InvBCE: 809.8235473632812\n",
      "Loss: 809.8552856445312, Norm: 0.0025622027460485697, InvBCE: 809.8235473632812\n",
      "Loss: 809.8551025390625, Norm: 0.0027935118414461613, InvBCE: 809.8235473632812\n",
      "Loss: 809.8548583984375, Norm: 0.0030244917143136263, InvBCE: 809.8235473632812\n",
      "Loss: 809.8546752929688, Norm: 0.00325512932613492, InvBCE: 809.8235473632812\n",
      "Loss: 809.8544311523438, Norm: 0.0034854107070714235, InvBCE: 809.8235473632812\n",
      "Loss: 809.854248046875, Norm: 0.003715322818607092, InvBCE: 809.8235473632812\n",
      "Loss: 809.85400390625, Norm: 0.003944852389395237, InvBCE: 809.8235473632812\n",
      "Loss: 809.8538208007812, Norm: 0.004173985682427883, InvBCE: 809.8235473632812\n",
      "Loss: 809.8536376953125, Norm: 0.004402711056172848, InvBCE: 809.8235473632812\n",
      "Image 80...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 81...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 82...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 83...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 84...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 85...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 86...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 87...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 88...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 89...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 90...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 91...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 92...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 93...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 94...\n",
      "Loss: 0.8779433369636536, Norm: 0.0, InvBCE: 0.8438624739646912\n",
      "Image fooled! Adding perturbation...\n",
      "Image 95...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 96...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 97...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 98...\n",
      "Loss: 1.3881632089614868, Norm: 0.0, InvBCE: 1.3540308475494385\n",
      "Loss: 1.3551253080368042, Norm: 0.00037378203705884516, InvBCE: 1.320960283279419\n",
      "Image fooled! Adding perturbation...\n",
      "Image 99...\n",
      "Image fooled! Adding perturbation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "288104e8269e497cbdabbcafa52707bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fooling rate: 0.79\n",
      "Starting epoch 8...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "337576077490407eaae5dea950fa1515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 1...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 2...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 3...\n",
      "Loss: 3.683434009552002, Norm: 0.0, InvBCE: 3.64923357963562\n",
      "Loss: 3.255052089691162, Norm: 0.0003817024116870016, InvBCE: 3.220799207687378\n",
      "Loss: 2.877197027206421, Norm: 0.0007578618242405355, InvBCE: 2.8428895473480225\n",
      "Loss: 2.5467934608459473, Norm: 0.0011291990522295237, InvBCE: 2.5124289989471436\n",
      "Loss: 2.2611231803894043, Norm: 0.0014943263959139585, InvBCE: 2.2267000675201416\n",
      "Loss: 2.0132954120635986, Norm: 0.001852339832112193, InvBCE: 1.9788116216659546\n",
      "Loss: 1.7991737127304077, Norm: 0.0022023371420800686, InvBCE: 1.7646281719207764\n",
      "Loss: 1.6146221160888672, Norm: 0.0025434810668230057, InvBCE: 1.5800139904022217\n",
      "Loss: 1.4558082818984985, Norm: 0.0028750698547810316, InvBCE: 1.4211372137069702\n",
      "Loss: 1.3192477226257324, Norm: 0.0031965498346835375, InvBCE: 1.2845137119293213\n",
      "Loss: 1.2017898559570312, Norm: 0.003507523098960519, InvBCE: 1.1669931411743164\n",
      "Loss: 1.1006519794464111, Norm: 0.0038077428471297026, InvBCE: 1.0657933950424194\n",
      "Loss: 1.0134027004241943, Norm: 0.0040970779955387115, InvBCE: 0.9784832000732422\n",
      "Loss: 0.9379834532737732, Norm: 0.004375506658107042, InvBCE: 0.9030042886734009\n",
      "Loss: 0.8726339340209961, Norm: 0.004643081221729517, InvBCE: 0.8375964760780334\n",
      "Loss: 0.815886378288269, Norm: 0.004899935331195593, InvBCE: 0.780792236328125\n",
      "Loss: 0.766497015953064, Norm: 0.005146251060068607, InvBCE: 0.7313478589057922\n",
      "Loss: 0.7234179973602295, Norm: 0.00538224820047617, InvBCE: 0.6882156133651733\n",
      "Loss: 0.6857421398162842, Norm: 0.005608188454061747, InvBCE: 0.6504884362220764\n",
      "Loss: 0.6526932716369629, Norm: 0.005824365187436342, InvBCE: 0.6173902153968811\n",
      "Image 4...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 5...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 6...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 7...\n",
      "Loss: 0.8905386328697205, Norm: 0.0, InvBCE: 0.8563380837440491\n",
      "Loss: 0.8456650376319885, Norm: 0.00037107948446646333, InvBCE: 0.811468780040741\n",
      "Image fooled! Adding perturbation...\n",
      "Image 8...\n",
      "Loss: 1.4675830602645874, Norm: 0.0, InvBCE: 1.433388113975525\n",
      "Image fooled! Adding perturbation...\n",
      "Image 9...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 10...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 11...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 12...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 13...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 14...\n",
      "Loss: 1.073934555053711, Norm: 0.0, InvBCE: 1.0397993326187134\n",
      "Image fooled! Adding perturbation...\n",
      "Image 15...\n",
      "Loss: 0.6431000232696533, Norm: 0.0, InvBCE: 0.6088953614234924\n",
      "Image fooled! Adding perturbation...\n",
      "Image 16...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 17...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 18...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 19...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 20...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 21...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 22...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 23...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 24...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 25...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 26...\n",
      "Loss: 1.4810172319412231, Norm: 0.0, InvBCE: 1.446747064590454\n",
      "Loss: 1.4792133569717407, Norm: 0.0003053543041460216, InvBCE: 1.4450546503067017\n",
      "Loss: 1.477413296699524, Norm: 0.000610449758823961, InvBCE: 1.443364143371582\n",
      "Image fooled! Adding perturbation...\n",
      "Image 27...\n",
      "Loss: 0.594495952129364, Norm: 0.0, InvBCE: 0.5605543255805969\n",
      "Loss: 0.5586757659912109, Norm: 0.0003736623330041766, InvBCE: 0.5246276259422302\n",
      "Loss: 0.5269992351531982, Norm: 0.0007432053098455071, InvBCE: 0.49284324049949646\n",
      "Image fooled! Adding perturbation...\n",
      "Image 28...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 29...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 30...\n",
      "Loss: 0.737887978553772, Norm: 0.0, InvBCE: 0.7036236524581909\n",
      "Image fooled! Adding perturbation...\n",
      "Image 31...\n",
      "Loss: 809.85791015625, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.857666015625, Norm: 0.0002339079655939713, InvBCE: 809.8235473632812\n",
      "Loss: 809.8574829101562, Norm: 0.0004676370008382946, InvBCE: 809.8235473632812\n",
      "Loss: 809.8572387695312, Norm: 0.0007011741399765015, InvBCE: 809.8235473632812\n",
      "Loss: 809.8570556640625, Norm: 0.0009345063008368015, InvBCE: 809.8235473632812\n",
      "Loss: 809.8568115234375, Norm: 0.0011676200665533543, InvBCE: 809.8235473632812\n",
      "Loss: 809.8566284179688, Norm: 0.0014005022821947932, InvBCE: 809.8235473632812\n",
      "Loss: 809.8563842773438, Norm: 0.0016331393271684647, InvBCE: 809.8235473632812\n",
      "Loss: 809.856201171875, Norm: 0.0018655175808817148, InvBCE: 809.8235473632812\n",
      "Loss: 809.8560180664062, Norm: 0.0020976236555725336, InvBCE: 809.8235473632812\n",
      "Loss: 809.8557739257812, Norm: 0.002329443348571658, InvBCE: 809.8235473632812\n",
      "Loss: 809.8555908203125, Norm: 0.002560964087024331, InvBCE: 809.8235473632812\n",
      "Loss: 809.8553466796875, Norm: 0.0027921716682612896, InvBCE: 809.8235473632812\n",
      "Loss: 809.8551635742188, Norm: 0.0030230518896132708, InvBCE: 809.8235473632812\n",
      "Loss: 809.8549194335938, Norm: 0.0032535926438868046, InvBCE: 809.8235473632812\n",
      "Loss: 809.854736328125, Norm: 0.0034837801940739155, InvBCE: 809.8235473632812\n",
      "Loss: 809.8544921875, Norm: 0.0037136005703359842, InvBCE: 809.8235473632812\n",
      "Loss: 809.8543090820312, Norm: 0.0039430418983101845, InvBCE: 809.8235473632812\n",
      "Loss: 809.8541259765625, Norm: 0.004172090440988541, InvBCE: 809.8235473632812\n",
      "Loss: 809.8538818359375, Norm: 0.004400733392685652, InvBCE: 809.8235473632812\n",
      "Image 32...\n",
      "Loss: 1.492826223373413, Norm: 0.0, InvBCE: 1.4584661722183228\n",
      "Loss: 1.4750460386276245, Norm: 0.00035796983866021037, InvBCE: 1.4406838417053223\n",
      "Loss: 1.4576255083084106, Norm: 0.0007129455916583538, InvBCE: 1.4232597351074219\n",
      "Image fooled! Adding perturbation...\n",
      "Image 33...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 34...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 35...\n",
      "Loss: 0.9984956979751587, Norm: 0.0, InvBCE: 0.9641252756118774\n",
      "Loss: 0.9646943807601929, Norm: 0.0003687021671794355, InvBCE: 0.9303076267242432\n",
      "Image fooled! Adding perturbation...\n",
      "Image 36...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 37...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 38...\n",
      "Loss: 1.4698518514633179, Norm: 0.0, InvBCE: 1.4354439973831177\n",
      "Loss: 1.458729863166809, Norm: 0.00034410785883665085, InvBCE: 1.4243711233139038\n",
      "Image fooled! Adding perturbation...\n",
      "Image 39...\n",
      "Loss: 673.52001953125, Norm: 0.0, InvBCE: 673.4857177734375\n",
      "Loss: 673.5198364257812, Norm: 0.00023371596762444824, InvBCE: 673.4857177734375\n",
      "Loss: 673.5195922851562, Norm: 0.0004672520444728434, InvBCE: 673.4857177734375\n",
      "Loss: 673.5194091796875, Norm: 0.0007005951483733952, InvBCE: 673.4857177734375\n",
      "Loss: 673.5191650390625, Norm: 0.0009337321389466524, InvBCE: 673.4857177734375\n",
      "Loss: 673.5189819335938, Norm: 0.001166649628430605, InvBCE: 673.4857177734375\n",
      "Loss: 673.5187377929688, Norm: 0.00139933405444026, InvBCE: 673.4857177734375\n",
      "Loss: 673.5185546875, Norm: 0.0016317719127982855, InvBCE: 673.4857177734375\n",
      "Loss: 673.518310546875, Norm: 0.0018639496993273497, InvBCE: 673.4857177734375\n",
      "Loss: 673.5181274414062, Norm: 0.0020958534441888332, InvBCE: 673.4857177734375\n",
      "Loss: 673.5178833007812, Norm: 0.0023274696432054043, InvBCE: 673.4857177734375\n",
      "Loss: 673.5177001953125, Norm: 0.0025587845593690872, InvBCE: 673.4857177734375\n",
      "Loss: 673.5174560546875, Norm: 0.0027897844556719065, InvBCE: 673.4857177734375\n",
      "Loss: 673.5172729492188, Norm: 0.00302045582793653, InvBCE: 673.4857177734375\n",
      "Loss: 673.51708984375, Norm: 0.0032507851719856262, InvBCE: 673.4857177734375\n",
      "Loss: 673.516845703125, Norm: 0.003480758983641863, InvBCE: 673.4857177734375\n",
      "Loss: 673.5166625976562, Norm: 0.003710363991558552, InvBCE: 673.4857177734375\n",
      "Loss: 673.5164184570312, Norm: 0.003939587157219648, InvBCE: 673.4857177734375\n",
      "Loss: 673.5162353515625, Norm: 0.004168414976447821, InvBCE: 673.4857177734375\n",
      "Loss: 673.5160522460938, Norm: 0.004396834876388311, InvBCE: 673.4857177734375\n",
      "Image 40...\n",
      "Loss: 10.000945091247559, Norm: 0.0, InvBCE: 9.966632843017578\n",
      "Loss: 7.539349555969238, Norm: 0.000383990874979645, InvBCE: 7.504995822906494\n",
      "Loss: 6.34807825088501, Norm: 0.0007612740155309439, InvBCE: 6.31367826461792\n",
      "Loss: 5.439412593841553, Norm: 0.0011226726928725839, InvBCE: 5.404965400695801\n",
      "Loss: 4.73393440246582, Norm: 0.0014726363588124514, InvBCE: 4.699438571929932\n",
      "Loss: 3.454326629638672, Norm: 0.001809805864468217, InvBCE: 3.419780969619751\n",
      "Loss: 2.9652137756347656, Norm: 0.0021316215861588717, InvBCE: 2.9306154251098633\n",
      "Loss: 2.567667007446289, Norm: 0.0024400916881859303, InvBCE: 2.5330142974853516\n",
      "Loss: 2.263009548187256, Norm: 0.0027360660023987293, InvBCE: 2.2283012866973877\n",
      "Loss: 1.9212840795516968, Norm: 0.0030204777140170336, InvBCE: 1.8865196704864502\n",
      "Loss: 1.7000634670257568, Norm: 0.00329262251034379, InvBCE: 1.6652425527572632\n",
      "Loss: 1.499167561531067, Norm: 0.003553563728928566, InvBCE: 1.4642902612686157\n",
      "Loss: 1.3326400518417358, Norm: 0.0038037945050746202, InvBCE: 1.2977068424224854\n",
      "Loss: 1.0552728176116943, Norm: 0.004043920896947384, InvBCE: 1.0202844142913818\n",
      "Loss: 0.9595650434494019, Norm: 0.0042722937650978565, InvBCE: 0.924523115158081\n",
      "Loss: 0.8669878244400024, Norm: 0.004490196704864502, InvBCE: 0.831893801689148\n",
      "Loss: 0.7861146926879883, Norm: 0.00469833193346858, InvBCE: 0.7509700655937195\n",
      "Loss: 0.7186011672019958, Norm: 0.00489707151427865, InvBCE: 0.6834074854850769\n",
      "Loss: 0.6608778238296509, Norm: 0.005086682271212339, InvBCE: 0.6256366968154907\n",
      "Loss: 0.6137633919715881, Norm: 0.005267182365059853, InvBCE: 0.5784766674041748\n",
      "Image 41...\n",
      "Loss: 1.4409719705581665, Norm: 0.0, InvBCE: 1.4066598415374756\n",
      "Loss: 1.4265094995498657, Norm: 0.00035334634594619274, InvBCE: 1.3921747207641602\n",
      "Loss: 1.4125628471374512, Norm: 0.0007043688092380762, InvBCE: 1.3782049417495728\n",
      "Image fooled! Adding perturbation...\n",
      "Image 42...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 43...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 44...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 45...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 46...\n",
      "Loss: 0.5110492706298828, Norm: 0.0, InvBCE: 0.4766683578491211\n",
      "Image fooled! Adding perturbation...\n",
      "Image 47...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 48...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 49...\n",
      "Loss: 1.4381901025772095, Norm: 0.0, InvBCE: 1.403757095336914\n",
      "Loss: 1.3672873973846436, Norm: 0.00037766870809718966, InvBCE: 1.3327914476394653\n",
      "Loss: 1.302096962928772, Norm: 0.0007410866091959178, InvBCE: 1.2675330638885498\n",
      "Image fooled! Adding perturbation...\n",
      "Image 50...\n",
      "Loss: 92.6297378540039, Norm: 0.0, InvBCE: 92.59510803222656\n",
      "Loss: 55.1356086730957, Norm: 0.0003836826654151082, InvBCE: 55.100948333740234\n",
      "Loss: 29.535343170166016, Norm: 0.0007411334663629532, InvBCE: 29.500654220581055\n",
      "Loss: 19.696306228637695, Norm: 0.00102866196539253, InvBCE: 19.661596298217773\n",
      "Loss: 14.164306640625, Norm: 0.0012949011288583279, InvBCE: 14.129576683044434\n",
      "Loss: 10.952155113220215, Norm: 0.0015403112629428506, InvBCE: 10.917407989501953\n",
      "Loss: 8.953330993652344, Norm: 0.0017668113578110933, InvBCE: 8.918567657470703\n",
      "Loss: 7.761962890625, Norm: 0.0019764434546232224, InvBCE: 7.72718620300293\n",
      "Loss: 6.746174335479736, Norm: 0.002171457977965474, InvBCE: 6.711385250091553\n",
      "Loss: 6.018749237060547, Norm: 0.002353074960410595, InvBCE: 5.983949661254883\n",
      "Loss: 5.433437347412109, Norm: 0.0025230608880519867, InvBCE: 5.398628234863281\n",
      "Loss: 4.966909408569336, Norm: 0.002682857681065798, InvBCE: 4.932092189788818\n",
      "Loss: 4.555269241333008, Norm: 0.0028332110960036516, InvBCE: 4.520444869995117\n",
      "Loss: 4.28333854675293, Norm: 0.0029748757369816303, InvBCE: 4.248508453369141\n",
      "Loss: 4.067905902862549, Norm: 0.003108882112428546, InvBCE: 4.033071041107178\n",
      "Loss: 3.8716397285461426, Norm: 0.0032360032200813293, InvBCE: 3.836801290512085\n",
      "Loss: 3.7030203342437744, Norm: 0.003357002977281809, InvBCE: 3.6681790351867676\n",
      "Loss: 3.560587167739868, Norm: 0.0034723891876637936, InvBCE: 3.5257437229156494\n",
      "Loss: 3.43212890625, Norm: 0.003582689445465803, InvBCE: 3.3972842693328857\n",
      "Loss: 3.317272663116455, Norm: 0.0036883694119751453, InvBCE: 3.2824275493621826\n",
      "Image 51...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 52...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 53...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 54...\n",
      "Loss: 1.4791274070739746, Norm: 0.0, InvBCE: 1.4444942474365234\n",
      "Image fooled! Adding perturbation...\n",
      "Image 55...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 56...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 57...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 58...\n",
      "Loss: 1.4322798252105713, Norm: 0.0, InvBCE: 1.3977662324905396\n",
      "Image fooled! Adding perturbation...\n",
      "Image 59...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 60...\n",
      "Loss: 809.8579711914062, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8577880859375, Norm: 0.0002337873593205586, InvBCE: 809.8235473632812\n",
      "Loss: 809.8575439453125, Norm: 0.0004673954681493342, InvBCE: 809.8235473632812\n",
      "Loss: 809.8573608398438, Norm: 0.0007008113898336887, InvBCE: 809.8235473632812\n",
      "Loss: 809.8571166992188, Norm: 0.0009340219548903406, InvBCE: 809.8235473632812\n",
      "Loss: 809.85693359375, Norm: 0.0011670137755572796, InvBCE: 809.8235473632812\n",
      "Loss: 809.856689453125, Norm: 0.0013997736386954784, InvBCE: 809.8235473632812\n",
      "Loss: 809.8565063476562, Norm: 0.0016322879819199443, InvBCE: 809.8235473632812\n",
      "Loss: 809.8562622070312, Norm: 0.0018645429518073797, InvBCE: 809.8235473632812\n",
      "Loss: 809.8560791015625, Norm: 0.0020965251605957747, InvBCE: 809.8235473632812\n",
      "Loss: 809.8558349609375, Norm: 0.0023282209876924753, InvBCE: 809.8235473632812\n",
      "Loss: 809.8556518554688, Norm: 0.00255961692892015, InvBCE: 809.8235473632812\n",
      "Loss: 809.8554077148438, Norm: 0.002790699014440179, InvBCE: 809.8235473632812\n",
      "Loss: 809.855224609375, Norm: 0.0030214539729058743, InvBCE: 809.8235473632812\n",
      "Loss: 809.8550415039062, Norm: 0.003251868300139904, InvBCE: 809.8235473632812\n",
      "Loss: 809.8547973632812, Norm: 0.00348192872479558, InvBCE: 809.8235473632812\n",
      "Loss: 809.8546142578125, Norm: 0.0037116215098649263, InvBCE: 809.8235473632812\n",
      "Loss: 809.8543701171875, Norm: 0.003940934780985117, InvBCE: 809.8235473632812\n",
      "Loss: 809.8541870117188, Norm: 0.004169853869825602, InvBCE: 809.8235473632812\n",
      "Loss: 809.85400390625, Norm: 0.004398367367684841, InvBCE: 809.8235473632812\n",
      "Image 61...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 62...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 63...\n",
      "Loss: 1.384645700454712, Norm: 0.0, InvBCE: 1.3502076864242554\n",
      "Loss: 1.3495553731918335, Norm: 0.00036787206772714853, InvBCE: 1.315093994140625\n",
      "Image fooled! Adding perturbation...\n",
      "Image 64...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 65...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 66...\n",
      "Loss: 1.3400907516479492, Norm: 0.0, InvBCE: 1.3056031465530396\n",
      "Image fooled! Adding perturbation...\n",
      "Image 67...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 68...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 69...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 70...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 71...\n",
      "Loss: 0.6584222316741943, Norm: 0.0, InvBCE: 0.6239800453186035\n",
      "Loss: 0.615786075592041, Norm: 0.00036724944948218763, InvBCE: 0.5812602639198303\n",
      "Loss: 0.5794205069541931, Norm: 0.0007275703246705234, InvBCE: 0.5448094606399536\n",
      "Image fooled! Adding perturbation...\n",
      "Image 72...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 73...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 74...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 75...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 76...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 77...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 78...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 79...\n",
      "Loss: 809.8582153320312, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8580322265625, Norm: 0.000233859071158804, InvBCE: 809.8235473632812\n",
      "Loss: 809.8577880859375, Norm: 0.00046754087088629603, InvBCE: 809.8235473632812\n",
      "Loss: 809.8576049804688, Norm: 0.000701032520737499, InvBCE: 809.8235473632812\n",
      "Loss: 809.8573608398438, Norm: 0.0009343210840597749, InvBCE: 809.8235473632812\n",
      "Loss: 809.857177734375, Norm: 0.001167393522337079, InvBCE: 809.8235473632812\n",
      "Loss: 809.85693359375, Norm: 0.0014002365060150623, InvBCE: 809.8235473632812\n",
      "Loss: 809.8567504882812, Norm: 0.001632836414501071, InvBCE: 809.8235473632812\n",
      "Loss: 809.8565673828125, Norm: 0.0018651802092790604, InvBCE: 809.8235473632812\n",
      "Loss: 809.8563232421875, Norm: 0.0020972543861716986, InvBCE: 809.8235473632812\n",
      "Loss: 809.8561401367188, Norm: 0.0023290454410016537, InvBCE: 809.8235473632812\n",
      "Loss: 809.8558959960938, Norm: 0.0025605398695915937, InvBCE: 809.8235473632812\n",
      "Loss: 809.855712890625, Norm: 0.002791724167764187, InvBCE: 809.8235473632812\n",
      "Loss: 809.85546875, Norm: 0.0030225850641727448, InvBCE: 809.8235473632812\n",
      "Loss: 809.8552856445312, Norm: 0.0032531097531318665, InvBCE: 809.8235473632812\n",
      "Loss: 809.8550415039062, Norm: 0.0034832844976335764, InvBCE: 809.8235473632812\n",
      "Loss: 809.8548583984375, Norm: 0.00371309625916183, InvBCE: 809.8235473632812\n",
      "Loss: 809.8546752929688, Norm: 0.00394253246486187, InvBCE: 809.8235473632812\n",
      "Loss: 809.8544311523438, Norm: 0.004171579610556364, InvBCE: 809.8235473632812\n",
      "Loss: 809.854248046875, Norm: 0.004400225821882486, InvBCE: 809.8235473632812\n",
      "Image 80...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 81...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 82...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 83...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 84...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 85...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 86...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 87...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 88...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 89...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 90...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 91...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 92...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 93...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 94...\n",
      "Loss: 0.850938618183136, Norm: 0.0, InvBCE: 0.8162412643432617\n",
      "Image fooled! Adding perturbation...\n",
      "Image 95...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 96...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 97...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 98...\n",
      "Loss: 1.3513256311416626, Norm: 0.0, InvBCE: 1.3165762424468994\n",
      "Image fooled! Adding perturbation...\n",
      "Image 99...\n",
      "Image fooled! Adding perturbation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "059b0b1edffe401492dc9bdf7bd77268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fooling rate: 0.8\n",
      "Starting epoch 9...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "206c4d7baff042b7a2870f21ff018680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 1...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 2...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 3...\n",
      "Loss: 3.671405553817749, Norm: 0.0, InvBCE: 3.636624574661255\n",
      "Loss: 3.2485673427581787, Norm: 0.0003816524113062769, InvBCE: 3.213733673095703\n",
      "Loss: 2.8737246990203857, Norm: 0.0007578202057629824, InvBCE: 2.8388359546661377\n",
      "Loss: 2.5461111068725586, Norm: 0.0011289017274975777, InvBCE: 2.511165142059326\n",
      "Loss: 2.259817600250244, Norm: 0.0014936656225472689, InvBCE: 2.2248127460479736\n",
      "Loss: 2.010681629180908, Norm: 0.0018513824325054884, InvBCE: 1.9756165742874146\n",
      "Loss: 1.7952145338058472, Norm: 0.0022011909168213606, InvBCE: 1.760088324546814\n",
      "Loss: 1.6095980405807495, Norm: 0.0025422610342502594, InvBCE: 1.5744099617004395\n",
      "Loss: 1.4501053094863892, Norm: 0.002873883582651615, InvBCE: 1.4148552417755127\n",
      "Loss: 1.3132551908493042, Norm: 0.0031954722944647074, InvBCE: 1.2779432535171509\n",
      "Loss: 1.195876955986023, Norm: 0.003506592009216547, InvBCE: 1.160503625869751\n",
      "Loss: 1.0951330661773682, Norm: 0.003806946100667119, InvBCE: 1.0596990585327148\n",
      "Loss: 1.0085312128067017, Norm: 0.004096364602446556, InvBCE: 0.9730377197265625\n",
      "Loss: 0.9339107275009155, Norm: 0.0043747881427407265, InvBCE: 0.8983590006828308\n",
      "Loss: 0.8694417476654053, Norm: 0.00464225560426712, InvBCE: 0.8338332176208496\n",
      "Loss: 0.8135859966278076, Norm: 0.0048988875932991505, InvBCE: 0.7779223322868347\n",
      "Loss: 0.7650644779205322, Norm: 0.005144869443029165, InvBCE: 0.7293474674224854\n",
      "Loss: 0.7227952480316162, Norm: 0.005380426533520222, InvBCE: 0.6870266795158386\n",
      "Loss: 0.6858639121055603, Norm: 0.00560582522302866, InvBCE: 0.6500456929206848\n",
      "Loss: 0.6534843444824219, Norm: 0.005821365863084793, InvBCE: 0.6176183819770813\n",
      "Image 4...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 5...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 6...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 7...\n",
      "Loss: 0.8782021403312683, Norm: 0.0, InvBCE: 0.8434211015701294\n",
      "Loss: 0.8351711630821228, Norm: 0.00037087968667037785, InvBCE: 0.8003939986228943\n",
      "Image fooled! Adding perturbation...\n",
      "Image 8...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 9...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 10...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 11...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 12...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 13...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 14...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 15...\n",
      "Loss: 0.619777500629425, Norm: 0.0, InvBCE: 0.5850016474723816\n",
      "Image fooled! Adding perturbation...\n",
      "Image 16...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 17...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 18...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 19...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 20...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 21...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 22...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 23...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 24...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 25...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 26...\n",
      "Loss: 1.4806169271469116, Norm: 0.0, InvBCE: 1.4457764625549316\n",
      "Loss: 1.4788247346878052, Norm: 0.0003050140803679824, InvBCE: 1.4440937042236328\n",
      "Loss: 1.4770402908325195, Norm: 0.000609627109952271, InvBCE: 1.442416787147522\n",
      "Image fooled! Adding perturbation...\n",
      "Image 27...\n",
      "Loss: 0.5750287771224976, Norm: 0.0, InvBCE: 0.5405111908912659\n",
      "Loss: 0.5408690571784973, Norm: 0.0003727491421159357, InvBCE: 0.506243884563446\n",
      "Image fooled! Adding perturbation...\n",
      "Image 28...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 29...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 30...\n",
      "Loss: 0.714475154876709, Norm: 0.0, InvBCE: 0.679741382598877\n",
      "Image fooled! Adding perturbation...\n",
      "Image 31...\n",
      "Loss: 809.8583984375, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.858154296875, Norm: 0.00023365883680526167, InvBCE: 809.8235473632812\n",
      "Loss: 809.8579711914062, Norm: 0.0004671406059060246, InvBCE: 809.8235473632812\n",
      "Loss: 809.8577270507812, Norm: 0.000700432516168803, InvBCE: 809.8235473632812\n",
      "Loss: 809.8575439453125, Norm: 0.0009335214854218066, InvBCE: 809.8235473632812\n",
      "Loss: 809.8572998046875, Norm: 0.0011663944460451603, InvBCE: 809.8235473632812\n",
      "Loss: 809.8571166992188, Norm: 0.0013990383595228195, InvBCE: 809.8235473632812\n",
      "Loss: 809.8568725585938, Norm: 0.0016314397798851132, InvBCE: 809.8235473632812\n",
      "Loss: 809.856689453125, Norm: 0.0018635852029547095, InvBCE: 809.8235473632812\n",
      "Loss: 809.8564453125, Norm: 0.00209546135738492, InvBCE: 809.8235473632812\n",
      "Loss: 809.8562622070312, Norm: 0.0023270549718290567, InvBCE: 809.8235473632812\n",
      "Loss: 809.8560180664062, Norm: 0.0025583524256944656, InvBCE: 809.8235473632812\n",
      "Loss: 809.8558349609375, Norm: 0.0027893404476344585, InvBCE: 809.8235473632812\n",
      "Loss: 809.8555908203125, Norm: 0.00302000530064106, InvBCE: 809.8235473632812\n",
      "Loss: 809.8554077148438, Norm: 0.003250334644690156, InvBCE: 809.8235473632812\n",
      "Loss: 809.855224609375, Norm: 0.0034803145099431276, InvBCE: 809.8235473632812\n",
      "Loss: 809.85498046875, Norm: 0.003709932090714574, InvBCE: 809.8235473632812\n",
      "Loss: 809.8547973632812, Norm: 0.003939175046980381, InvBCE: 809.8235473632812\n",
      "Loss: 809.8545532226562, Norm: 0.0041680303402245045, InvBCE: 809.8235473632812\n",
      "Loss: 809.8543701171875, Norm: 0.004396484699100256, InvBCE: 809.8235473632812\n",
      "Image 32...\n",
      "Loss: 1.4813792705535889, Norm: 0.0, InvBCE: 1.4465538263320923\n",
      "Loss: 1.4641940593719482, Norm: 0.00035758299054577947, InvBCE: 1.429368257522583\n",
      "Image fooled! Adding perturbation...\n",
      "Image 33...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 34...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 35...\n",
      "Loss: 1.0140992403030396, Norm: 0.0, InvBCE: 0.9792709350585938\n",
      "Loss: 0.9779806733131409, Norm: 0.00037206962588243186, InvBCE: 0.9431391954421997\n",
      "Loss: 0.9522314667701721, Norm: 0.0007184412679634988, InvBCE: 0.9173750877380371\n",
      "Image fooled! Adding perturbation...\n",
      "Image 36...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 37...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 38...\n",
      "Loss: 1.465580940246582, Norm: 0.0, InvBCE: 1.4307048320770264\n",
      "Image fooled! Adding perturbation...\n",
      "Image 39...\n",
      "Loss: 673.5205688476562, Norm: 0.0, InvBCE: 673.4857177734375\n",
      "Loss: 673.5203247070312, Norm: 0.00023358612088486552, InvBCE: 673.4857177734375\n",
      "Loss: 673.5201416015625, Norm: 0.00046699499944224954, InvBCE: 673.4857177734375\n",
      "Loss: 673.5198974609375, Norm: 0.0007002137717790902, InvBCE: 673.4857177734375\n",
      "Loss: 673.5197143554688, Norm: 0.0009332295157946646, InvBCE: 673.4857177734375\n",
      "Loss: 673.5194702148438, Norm: 0.0011660290183499455, InvBCE: 673.4857177734375\n",
      "Loss: 673.519287109375, Norm: 0.0013985992409288883, InvBCE: 673.4857177734375\n",
      "Loss: 673.51904296875, Norm: 0.0016309265047311783, InvBCE: 673.4857177734375\n",
      "Loss: 673.5188598632812, Norm: 0.0018629975384101272, InvBCE: 673.4857177734375\n",
      "Loss: 673.5186157226562, Norm: 0.002094798954203725, InvBCE: 673.4857177734375\n",
      "Loss: 673.5184326171875, Norm: 0.002326317597180605, InvBCE: 673.4857177734375\n",
      "Loss: 673.5181884765625, Norm: 0.0025575393810868263, InvBCE: 673.4857177734375\n",
      "Loss: 673.5180053710938, Norm: 0.002788451500236988, InvBCE: 673.4857177734375\n",
      "Loss: 673.5177612304688, Norm: 0.0030190402176231146, InvBCE: 673.4857177734375\n",
      "Loss: 673.517578125, Norm: 0.0032492924947291613, InvBCE: 673.4857177734375\n",
      "Loss: 673.5173950195312, Norm: 0.003479195525869727, InvBCE: 673.4857177734375\n",
      "Loss: 673.5171508789062, Norm: 0.003708735341206193, InvBCE: 673.4857177734375\n",
      "Loss: 673.5169677734375, Norm: 0.003937899600714445, InvBCE: 673.4857177734375\n",
      "Loss: 673.5167236328125, Norm: 0.004166675731539726, InvBCE: 673.4857177734375\n",
      "Loss: 673.5165405273438, Norm: 0.0043950509279966354, InvBCE: 673.4857177734375\n",
      "Image 40...\n",
      "Loss: 9.448622703552246, Norm: 0.0, InvBCE: 9.413793563842773\n",
      "Loss: 7.10784387588501, Norm: 0.0003838029515463859, InvBCE: 7.072975158691406\n",
      "Loss: 6.034251689910889, Norm: 0.0007554828189313412, InvBCE: 5.999341011047363\n",
      "Loss: 5.203423023223877, Norm: 0.001115302206017077, InvBCE: 5.168467998504639\n",
      "Loss: 4.549018859863281, Norm: 0.0014642938040196896, InvBCE: 4.514017581939697\n",
      "Loss: 3.3202483654022217, Norm: 0.0018008612096309662, InvBCE: 3.2851996421813965\n",
      "Loss: 2.8508567810058594, Norm: 0.002122130710631609, InvBCE: 2.8157570362091064\n",
      "Loss: 2.4820985794067383, Norm: 0.0024303700774908066, InvBCE: 2.446945905685425\n",
      "Loss: 2.169755697250366, Norm: 0.0027265690732747316, InvBCE: 2.1345489025115967\n",
      "Loss: 1.83903169631958, Norm: 0.003011709777638316, InvBCE: 1.8037697076797485\n",
      "Loss: 1.6054847240447998, Norm: 0.003285595215857029, InvBCE: 1.5701671838760376\n",
      "Loss: 1.4150854349136353, Norm: 0.0035487045533955097, InvBCE: 1.3797123432159424\n",
      "Loss: 1.101744532585144, Norm: 0.003801519051194191, InvBCE: 1.0663161277770996\n",
      "Loss: 0.995238184928894, Norm: 0.004041900858283043, InvBCE: 0.959756076335907\n",
      "Loss: 0.8936334252357483, Norm: 0.004271048586815596, InvBCE: 0.858099102973938\n",
      "Loss: 0.8046579957008362, Norm: 0.004489990882575512, InvBCE: 0.7690728306770325\n",
      "Loss: 0.7306306958198547, Norm: 0.004699111450463533, InvBCE: 0.694996178150177\n",
      "Loss: 0.6676461100578308, Norm: 0.004898678045719862, InvBCE: 0.6319637894630432\n",
      "Loss: 0.6162819862365723, Norm: 0.00508876284584403, InvBCE: 0.5805535316467285\n",
      "Loss: 0.5752368569374084, Norm: 0.00526956282556057, InvBCE: 0.5394641160964966\n",
      "Image 41...\n",
      "Loss: 1.4311869144439697, Norm: 0.0, InvBCE: 1.3963582515716553\n",
      "Loss: 1.41695237159729, Norm: 0.00035239645512774587, InvBCE: 1.3821029663085938\n",
      "Loss: 1.4032795429229736, Norm: 0.0007018749020062387, InvBCE: 1.3684098720550537\n",
      "Image fooled! Adding perturbation...\n",
      "Image 42...\n",
      "Loss: 1.3992778062820435, Norm: 0.0, InvBCE: 1.3643888235092163\n",
      "Image fooled! Adding perturbation...\n",
      "Image 43...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 44...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 45...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 46...\n",
      "Loss: 0.512614905834198, Norm: 0.0, InvBCE: 0.4777345061302185\n",
      "Image fooled! Adding perturbation...\n",
      "Image 47...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 48...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 49...\n",
      "Loss: 1.3573799133300781, Norm: 0.0, InvBCE: 1.3224488496780396\n",
      "Image fooled! Adding perturbation...\n",
      "Image 50...\n",
      "Loss: 70.40311431884766, Norm: 0.0, InvBCE: 70.36811828613281\n",
      "Loss: 127.34880065917969, Norm: 0.0003836671239696443, InvBCE: 127.31383514404297\n",
      "Loss: 123.9714584350586, Norm: 0.0005419576191343367, InvBCE: 123.93648529052734\n",
      "Loss: 89.73828125, Norm: 0.0006999669712968171, InvBCE: 89.70330047607422\n",
      "Loss: 59.59537124633789, Norm: 0.0008873010519891977, InvBCE: 59.56037521362305\n",
      "Loss: 54.033042907714844, Norm: 0.0010925264796242118, InvBCE: 53.99802780151367\n",
      "Loss: 36.931453704833984, Norm: 0.0013066346291452646, InvBCE: 36.896419525146484\n",
      "Loss: 26.315753936767578, Norm: 0.0015199288027361035, InvBCE: 26.280704498291016\n",
      "Loss: 20.487266540527344, Norm: 0.0017265675123780966, InvBCE: 20.452199935913086\n",
      "Loss: 16.036209106445312, Norm: 0.0019239960238337517, InvBCE: 16.001127243041992\n",
      "Loss: 13.069588661193848, Norm: 0.0021110018715262413, InvBCE: 13.034493446350098\n",
      "Loss: 10.895081520080566, Norm: 0.002287329640239477, InvBCE: 10.859973907470703\n",
      "Loss: 9.401209831237793, Norm: 0.0024531155358999968, InvBCE: 9.36609172821045\n",
      "Loss: 8.310627937316895, Norm: 0.0026088349986821413, InvBCE: 8.275500297546387\n",
      "Loss: 7.63693904876709, Norm: 0.0027550712693482637, InvBCE: 7.601803302764893\n",
      "Loss: 6.955057144165039, Norm: 0.0028925552032887936, InvBCE: 6.919914245605469\n",
      "Loss: 6.378498077392578, Norm: 0.0030220241751521826, InvBCE: 6.343349933624268\n",
      "Loss: 5.922138690948486, Norm: 0.003144012065604329, InvBCE: 5.886985778808594\n",
      "Loss: 5.549650192260742, Norm: 0.003259112359955907, InvBCE: 5.514493942260742\n",
      "Loss: 5.236630916595459, Norm: 0.003367871278896928, InvBCE: 5.20147180557251\n",
      "Image 51...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 52...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 53...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 54...\n",
      "Loss: 1.4790657758712769, Norm: 0.0, InvBCE: 1.4440690279006958\n",
      "Image fooled! Adding perturbation...\n",
      "Image 55...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 56...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 57...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 58...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 59...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 60...\n",
      "Loss: 809.8583984375, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8582153320312, Norm: 0.00023363696527667344, InvBCE: 809.8235473632812\n",
      "Loss: 809.8579711914062, Norm: 0.000467096921056509, InvBCE: 809.8235473632812\n",
      "Loss: 809.8577880859375, Norm: 0.0007003670325502753, InvBCE: 809.8235473632812\n",
      "Loss: 809.8575439453125, Norm: 0.00093343440676108, InvBCE: 809.8235473632812\n",
      "Loss: 809.8573608398438, Norm: 0.0011662858305498958, InvBCE: 809.8235473632812\n",
      "Loss: 809.8571166992188, Norm: 0.0013989080907776952, InvBCE: 809.8235473632812\n",
      "Loss: 809.85693359375, Norm: 0.0016312880907207727, InvBCE: 809.8235473632812\n",
      "Loss: 809.8567504882812, Norm: 0.0018634120933711529, InvBCE: 809.8235473632812\n",
      "Loss: 809.8565063476562, Norm: 0.0020952667109668255, InvBCE: 809.8235473632812\n",
      "Loss: 809.8563232421875, Norm: 0.0023268391378223896, InvBCE: 809.8235473632812\n",
      "Loss: 809.8560791015625, Norm: 0.0025581151712685823, InvBCE: 809.8235473632812\n",
      "Loss: 809.8558959960938, Norm: 0.0027890820056200027, InvBCE: 809.8235473632812\n",
      "Loss: 809.8556518554688, Norm: 0.0030197259038686752, InvBCE: 809.8235473632812\n",
      "Loss: 809.85546875, Norm: 0.003250033827498555, InvBCE: 809.8235473632812\n",
      "Loss: 809.855224609375, Norm: 0.0034799925051629543, InvBCE: 809.8235473632812\n",
      "Loss: 809.8550415039062, Norm: 0.0037095891311764717, InvBCE: 809.8235473632812\n",
      "Loss: 809.8548583984375, Norm: 0.003938810899853706, InvBCE: 809.8235473632812\n",
      "Loss: 809.8546142578125, Norm: 0.004167644772678614, InvBCE: 809.8235473632812\n",
      "Loss: 809.8544311523438, Norm: 0.004396078642457724, InvBCE: 809.8235473632812\n",
      "Image 61...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 62...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 63...\n",
      "Loss: 1.3856689929962158, Norm: 0.0, InvBCE: 1.3507908582687378\n",
      "Loss: 1.3511532545089722, Norm: 0.0003676665364764631, InvBCE: 1.316249132156372\n",
      "Image fooled! Adding perturbation...\n",
      "Image 64...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 65...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 66...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 67...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 68...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 69...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 70...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 71...\n",
      "Loss: 0.6178401112556458, Norm: 0.0, InvBCE: 0.5829070806503296\n",
      "Loss: 0.5807399153709412, Norm: 0.00036530077341012657, InvBCE: 0.5457227230072021\n",
      "Image fooled! Adding perturbation...\n",
      "Image 72...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 73...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 74...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 75...\n",
      "Loss: 1.4462780952453613, Norm: 0.0, InvBCE: 1.4111759662628174\n",
      "Image fooled! Adding perturbation...\n",
      "Image 76...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 77...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 78...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 79...\n",
      "Loss: 809.8585815429688, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8583984375, Norm: 0.00023363978834822774, InvBCE: 809.8235473632812\n",
      "Loss: 809.858154296875, Norm: 0.00046710399328731, InvBCE: 809.8235473632812\n",
      "Loss: 809.8579711914062, Norm: 0.0007003798382356763, InvBCE: 809.8235473632812\n",
      "Loss: 809.8577270507812, Norm: 0.0009334546630270779, InvBCE: 809.8235473632812\n",
      "Loss: 809.8575439453125, Norm: 0.001166315283626318, InvBCE: 809.8235473632812\n",
      "Loss: 809.8572998046875, Norm: 0.0013989488361403346, InvBCE: 809.8235473632812\n",
      "Loss: 809.8571166992188, Norm: 0.0016313416417688131, InvBCE: 809.8235473632812\n",
      "Loss: 809.8568725585938, Norm: 0.0018634811276569963, InvBCE: 809.8235473632812\n",
      "Loss: 809.856689453125, Norm: 0.0020953535567969084, InvBCE: 809.8235473632812\n",
      "Loss: 809.8564453125, Norm: 0.0023269455414265394, InvBCE: 809.8235473632812\n",
      "Loss: 809.8562622070312, Norm: 0.0025582441594451666, InvBCE: 809.8235473632812\n",
      "Loss: 809.8560180664062, Norm: 0.0027892361395061016, InvBCE: 809.8235473632812\n",
      "Loss: 809.8558349609375, Norm: 0.003019907744601369, InvBCE: 809.8235473632812\n",
      "Loss: 809.8555908203125, Norm: 0.003250246401876211, InvBCE: 809.8235473632812\n",
      "Loss: 809.8554077148438, Norm: 0.00348023883998394, InvBCE: 809.8235473632812\n",
      "Loss: 809.855224609375, Norm: 0.003709872718900442, InvBCE: 809.8235473632812\n",
      "Loss: 809.85498046875, Norm: 0.003939134534448385, InvBCE: 809.8235473632812\n",
      "Loss: 809.8547973632812, Norm: 0.0041680121794342995, InvBCE: 809.8235473632812\n",
      "Loss: 809.8545532226562, Norm: 0.0043964930810034275, InvBCE: 809.8235473632812\n",
      "Image 80...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 81...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 82...\n",
      "Loss: 0.7677204012870789, Norm: 0.0, InvBCE: 0.7326794862747192\n",
      "Image fooled! Adding perturbation...\n",
      "Image 83...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 84...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 85...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 86...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 87...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 88...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 89...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 90...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 91...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 92...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 93...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 94...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 95...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 96...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 97...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 98...\n",
      "Loss: 1.3495879173278809, Norm: 0.0, InvBCE: 1.3145074844360352\n",
      "Image fooled! Adding perturbation...\n",
      "Image 99...\n",
      "Image fooled! Adding perturbation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c25c6b99418413180712b40697229bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fooling rate: 0.81\n",
      "Starting epoch 10...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41dc47a2505540bfa2d1d5f029a18904",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 1...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 2...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 3...\n",
      "Loss: 3.7237863540649414, Norm: 0.0, InvBCE: 3.688673973083496\n",
      "Loss: 3.298203945159912, Norm: 0.0003816353273577988, InvBCE: 3.2630386352539062\n",
      "Loss: 2.9201161861419678, Norm: 0.000757322646677494, InvBCE: 2.8848958015441895\n",
      "Loss: 2.588223457336426, Norm: 0.0011274064891040325, InvBCE: 2.552946090698242\n",
      "Loss: 2.2979793548583984, Norm: 0.0014906381256878376, InvBCE: 2.262643575668335\n",
      "Loss: 2.0446181297302246, Norm: 0.0018466025358065963, InvBCE: 2.0092225074768066\n",
      "Loss: 1.8249073028564453, Norm: 0.0021946444176137447, InvBCE: 1.7894511222839355\n",
      "Loss: 1.6353554725646973, Norm: 0.0025340579450130463, InvBCE: 1.5998382568359375\n",
      "Loss: 1.4723200798034668, Norm: 0.002864191308617592, InvBCE: 1.436741828918457\n",
      "Loss: 1.3323097229003906, Norm: 0.003184504574164748, InvBCE: 1.2966705560684204\n",
      "Loss: 1.2121297121047974, Norm: 0.003494562581181526, InvBCE: 1.1764302253723145\n",
      "Loss: 1.1089249849319458, Norm: 0.0037940614856779575, InvBCE: 1.0731658935546875\n",
      "Loss: 1.0201729536056519, Norm: 0.004082805011421442, InvBCE: 0.9843554496765137\n",
      "Loss: 0.9436904191970825, Norm: 0.004360716324299574, InvBCE: 0.9078157544136047\n",
      "Loss: 0.8776199221611023, Norm: 0.004627811722457409, InvBCE: 0.8416895270347595\n",
      "Loss: 0.8203729391098022, Norm: 0.004884191323071718, InvBCE: 0.7843884825706482\n",
      "Loss: 0.7706316709518433, Norm: 0.0051300302147865295, InvBCE: 0.7345948815345764\n",
      "Loss: 0.727277398109436, Norm: 0.005365549121052027, InvBCE: 0.6911900639533997\n",
      "Loss: 0.6893740296363831, Norm: 0.005591011606156826, InvBCE: 0.65323805809021\n",
      "Loss: 0.6561336517333984, Norm: 0.005806711968034506, InvBCE: 0.6199509501457214\n",
      "Image 4...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 5...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 6...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 7...\n",
      "Loss: 0.8784466981887817, Norm: 0.0, InvBCE: 0.8433342576026917\n",
      "Loss: 0.8355775475502014, Norm: 0.0003708537551574409, InvBCE: 0.8004677891731262\n",
      "Image fooled! Adding perturbation...\n",
      "Image 8...\n",
      "Loss: 1.4720940589904785, Norm: 0.0, InvBCE: 1.4369843006134033\n",
      "Image fooled! Adding perturbation...\n",
      "Image 9...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 10...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 11...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 12...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 13...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 14...\n",
      "Loss: 1.0650678873062134, Norm: 0.0, InvBCE: 1.0300207138061523\n",
      "Image fooled! Adding perturbation...\n",
      "Image 15...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 16...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 17...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 18...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 19...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 20...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 21...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 22...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 23...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 24...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 25...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 26...\n",
      "Loss: 1.4791275262832642, Norm: 0.0, InvBCE: 1.4440149068832397\n",
      "Loss: 1.4773463010787964, Norm: 0.0003049626830033958, InvBCE: 1.4423408508300781\n",
      "Image fooled! Adding perturbation...\n",
      "Image 27...\n",
      "Loss: 0.5696266293525696, Norm: 0.0, InvBCE: 0.5347266793251038\n",
      "Loss: 0.5360562205314636, Norm: 0.0003725107235368341, InvBCE: 0.5010489821434021\n",
      "Image fooled! Adding perturbation...\n",
      "Image 28...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 29...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 30...\n",
      "Loss: 0.7053692936897278, Norm: 0.0, InvBCE: 0.6702535152435303\n",
      "Image fooled! Adding perturbation...\n",
      "Image 31...\n",
      "Loss: 809.8587646484375, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8585205078125, Norm: 0.00023352917924057692, InvBCE: 809.8235473632812\n",
      "Loss: 809.8583374023438, Norm: 0.0004668830370064825, InvBCE: 809.8235473632812\n",
      "Loss: 809.8580932617188, Norm: 0.000700049044098705, InvBCE: 809.8235473632812\n",
      "Loss: 809.85791015625, Norm: 0.0009330142638646066, InvBCE: 809.8235473632812\n",
      "Loss: 809.857666015625, Norm: 0.0011657659197226167, InvBCE: 809.8235473632812\n",
      "Loss: 809.8574829101562, Norm: 0.0013982908567413688, InvBCE: 809.8235473632812\n",
      "Loss: 809.8572387695312, Norm: 0.001630575628951192, InvBCE: 809.8235473632812\n",
      "Loss: 809.8570556640625, Norm: 0.001862607547082007, InvBCE: 809.8235473632812\n",
      "Loss: 809.8568115234375, Norm: 0.002094373106956482, InvBCE: 809.8235473632812\n",
      "Loss: 809.8566284179688, Norm: 0.002325858920812607, InvBCE: 809.8235473632812\n",
      "Loss: 809.8564453125, Norm: 0.0025570520665496588, InvBCE: 809.8235473632812\n",
      "Loss: 809.856201171875, Norm: 0.0027879392728209496, InvBCE: 809.8235473632812\n",
      "Loss: 809.8560180664062, Norm: 0.003018507268279791, InvBCE: 809.8235473632812\n",
      "Loss: 809.8557739257812, Norm: 0.003248743014410138, InvBCE: 809.8235473632812\n",
      "Loss: 809.8555908203125, Norm: 0.0034786337055265903, InvBCE: 809.8235473632812\n",
      "Loss: 809.8553466796875, Norm: 0.0037081660702824593, InvBCE: 809.8235473632812\n",
      "Loss: 809.8551635742188, Norm: 0.0039373282343149185, InvBCE: 809.8235473632812\n",
      "Loss: 809.85498046875, Norm: 0.0041661071591079235, InvBCE: 809.8235473632812\n",
      "Loss: 809.854736328125, Norm: 0.004394490271806717, InvBCE: 809.8235473632812\n",
      "Image 32...\n",
      "Loss: 1.477462649345398, Norm: 0.0, InvBCE: 1.4422545433044434\n",
      "Loss: 1.4600714445114136, Norm: 0.0003578868054319173, InvBCE: 1.4248628616333008\n",
      "Image fooled! Adding perturbation...\n",
      "Image 33...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 34...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 35...\n",
      "Loss: 0.9749330878257751, Norm: 0.0, InvBCE: 0.9397218227386475\n",
      "Loss: 0.9458847641944885, Norm: 0.0003713249461725354, InvBCE: 0.910654604434967\n",
      "Image fooled! Adding perturbation...\n",
      "Image 36...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 37...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 38...\n",
      "Loss: 1.4628843069076538, Norm: 0.0, InvBCE: 1.4276316165924072\n",
      "Image fooled! Adding perturbation...\n",
      "Image 39...\n",
      "Loss: 673.5209350585938, Norm: 0.0, InvBCE: 673.4857177734375\n",
      "Loss: 673.5206909179688, Norm: 0.0002334445744054392, InvBCE: 673.4857177734375\n",
      "Loss: 673.5205078125, Norm: 0.00046671347809024155, InvBCE: 673.4857177734375\n",
      "Loss: 673.520263671875, Norm: 0.0006997939781285822, InvBCE: 673.4857177734375\n",
      "Loss: 673.5200805664062, Norm: 0.0009326731669716537, InvBCE: 673.4857177734375\n",
      "Loss: 673.5198364257812, Norm: 0.0011653382098302245, InvBCE: 673.4857177734375\n",
      "Loss: 673.5196533203125, Norm: 0.0013977758353576064, InvBCE: 673.4857177734375\n",
      "Loss: 673.5194091796875, Norm: 0.0016299729468300939, InvBCE: 673.4857177734375\n",
      "Loss: 673.5192260742188, Norm: 0.0018619165057316422, InvBCE: 673.4857177734375\n",
      "Loss: 673.5189819335938, Norm: 0.002093592658638954, InvBCE: 673.4857177734375\n",
      "Loss: 673.518798828125, Norm: 0.0023249885998666286, InvBCE: 673.4857177734375\n",
      "Loss: 673.5186157226562, Norm: 0.002556090708822012, InvBCE: 673.4857177734375\n",
      "Loss: 673.5183715820312, Norm: 0.002786886179819703, InvBCE: 673.4857177734375\n",
      "Loss: 673.5181884765625, Norm: 0.0030173612758517265, InvBCE: 673.4857177734375\n",
      "Loss: 673.5179443359375, Norm: 0.0032475038897246122, InvBCE: 673.4857177734375\n",
      "Loss: 673.5177612304688, Norm: 0.0034772998187690973, InvBCE: 673.4857177734375\n",
      "Loss: 673.5175170898438, Norm: 0.003706736955791712, InvBCE: 673.4857177734375\n",
      "Loss: 673.517333984375, Norm: 0.003935802262276411, InvBCE: 673.4857177734375\n",
      "Loss: 673.5171508789062, Norm: 0.004164483398199081, InvBCE: 673.4857177734375\n",
      "Loss: 673.5169067382812, Norm: 0.004392767325043678, InvBCE: 673.4857177734375\n",
      "Image 40...\n",
      "Loss: 7.548370361328125, Norm: 0.0, InvBCE: 7.513164043426514\n",
      "Loss: 6.419585704803467, Norm: 0.00038349180249497294, InvBCE: 6.384340286254883\n",
      "Loss: 5.509702205657959, Norm: 0.0007548064459115267, InvBCE: 5.474415302276611\n",
      "Loss: 6.282273769378662, Norm: 0.0011179529828950763, InvBCE: 6.24694299697876\n",
      "Loss: 3.553368091583252, Norm: 0.0014261866454035044, InvBCE: 3.5180020332336426\n",
      "Loss: 3.1359074115753174, Norm: 0.0017261550528928638, InvBCE: 3.1005020141601562\n",
      "Loss: 2.760798931121826, Norm: 0.0020208926871418953, InvBCE: 2.7253499031066895\n",
      "Loss: 2.4489033222198486, Norm: 0.0023086215369403362, InvBCE: 2.413408041000366\n",
      "Loss: 2.1725361347198486, Norm: 0.002588513307273388, InvBCE: 2.1369926929473877\n",
      "Loss: 1.8600177764892578, Norm: 0.002861236222088337, InvBCE: 1.8244242668151855\n",
      "Loss: 1.6484735012054443, Norm: 0.0031255907379090786, InvBCE: 1.6128289699554443\n",
      "Loss: 1.452073574066162, Norm: 0.0033815810456871986, InvBCE: 1.4163775444030762\n",
      "Loss: 1.2881771326065063, Norm: 0.0036291249562054873, InvBCE: 1.2524293661117554\n",
      "Loss: 1.0141059160232544, Norm: 0.0038683637976646423, InvBCE: 0.9783066511154175\n",
      "Loss: 0.9189832210540771, Norm: 0.004097104538232088, InvBCE: 0.8831337094306946\n",
      "Loss: 0.8287345170974731, Norm: 0.00431623961776495, InvBCE: 0.7928360104560852\n",
      "Loss: 0.7503088712692261, Norm: 0.004526149481534958, InvBCE: 0.7143625617027283\n",
      "Loss: 0.6850486397743225, Norm: 0.00472693145275116, InvBCE: 0.6490559577941895\n",
      "Loss: 0.6298178434371948, Norm: 0.00491873174905777, InvBCE: 0.5937802791595459\n",
      "Loss: 0.5846924185752869, Norm: 0.005101563408970833, InvBCE: 0.5486116409301758\n",
      "Image 41...\n",
      "Loss: 1.4179134368896484, Norm: 0.0, InvBCE: 1.3827073574066162\n",
      "Loss: 1.404195785522461, Norm: 0.0003511854447424412, InvBCE: 1.3689696788787842\n",
      "Image fooled! Adding perturbation...\n",
      "Image 42...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 43...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 44...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 45...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 46...\n",
      "Loss: 0.5052054524421692, Norm: 0.0, InvBCE: 0.4699603021144867\n",
      "Image fooled! Adding perturbation...\n",
      "Image 47...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 48...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 49...\n",
      "Loss: 1.351161241531372, Norm: 0.0, InvBCE: 1.3158669471740723\n",
      "Image fooled! Adding perturbation...\n",
      "Image 50...\n",
      "Loss: 59.300331115722656, Norm: 0.0, InvBCE: 59.26497268676758\n",
      "Loss: 30.694700241088867, Norm: 0.0003834828967228532, InvBCE: 30.659318923950195\n",
      "Loss: 18.136953353881836, Norm: 0.0007305553299374878, InvBCE: 18.10154914855957\n",
      "Loss: 12.330560684204102, Norm: 0.0010429839603602886, InvBCE: 12.295136451721191\n",
      "Loss: 9.294855117797852, Norm: 0.0013275330420583487, InvBCE: 9.259413719177246\n",
      "Loss: 7.627601146697998, Norm: 0.001588128157891333, InvBCE: 7.592143535614014\n",
      "Loss: 6.428290367126465, Norm: 0.001828412408940494, InvBCE: 6.392818927764893\n",
      "Loss: 5.545233726501465, Norm: 0.002051141345873475, InvBCE: 5.5097503662109375\n",
      "Loss: 4.929439544677734, Norm: 0.0022585669066756964, InvBCE: 4.893945693969727\n",
      "Loss: 4.454353332519531, Norm: 0.0024578857701271772, InvBCE: 4.418849945068359\n",
      "Loss: 4.119137287139893, Norm: 0.002643936313688755, InvBCE: 4.083625316619873\n",
      "Loss: 3.8460144996643066, Norm: 0.002818870358169079, InvBCE: 3.810495615005493\n",
      "Loss: 3.6216137409210205, Norm: 0.0029838706832379103, InvBCE: 3.5860888957977295\n",
      "Loss: 3.433575391769409, Norm: 0.0031401042360812426, InvBCE: 3.398045778274536\n",
      "Loss: 3.2832536697387695, Norm: 0.0032884571701288223, InvBCE: 3.247720241546631\n",
      "Loss: 3.1481399536132812, Norm: 0.0034294193610548973, InvBCE: 3.1126036643981934\n",
      "Loss: 3.026581048965454, Norm: 0.003564032493159175, InvBCE: 2.9910426139831543\n",
      "Loss: 2.919534921646118, Norm: 0.0036929305642843246, InvBCE: 2.8839950561523438\n",
      "Loss: 2.824342966079712, Norm: 0.0038166558369994164, InvBCE: 2.7888023853302\n",
      "Loss: 2.745724678039551, Norm: 0.003935659769922495, InvBCE: 2.710184097290039\n",
      "Image 51...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 52...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 53...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 54...\n",
      "Loss: 1.478592872619629, Norm: 0.0, InvBCE: 1.4432348012924194\n",
      "Image fooled! Adding perturbation...\n",
      "Image 55...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 56...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 57...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 58...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 59...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 60...\n",
      "Loss: 809.8587646484375, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8585815429688, Norm: 0.00023349601542577147, InvBCE: 809.8235473632812\n",
      "Loss: 809.8583374023438, Norm: 0.00046681647654622793, InvBCE: 809.8235473632812\n",
      "Loss: 809.858154296875, Norm: 0.0006999486358836293, InvBCE: 809.8235473632812\n",
      "Loss: 809.85791015625, Norm: 0.0009328797459602356, InvBCE: 809.8235473632812\n",
      "Loss: 809.8577270507812, Norm: 0.0011655967682600021, InvBCE: 809.8235473632812\n",
      "Loss: 809.8574829101562, Norm: 0.0013980865478515625, InvBCE: 809.8235473632812\n",
      "Loss: 809.8572998046875, Norm: 0.001630336162634194, InvBCE: 809.8235473632812\n",
      "Loss: 809.8570556640625, Norm: 0.0018623321084305644, InvBCE: 809.8235473632812\n",
      "Loss: 809.8568725585938, Norm: 0.0020940611138939857, InvBCE: 809.8235473632812\n",
      "Loss: 809.856689453125, Norm: 0.0023255101405084133, InvBCE: 809.8235473632812\n",
      "Loss: 809.8564453125, Norm: 0.0025566655676811934, InvBCE: 809.8235473632812\n",
      "Loss: 809.8562622070312, Norm: 0.002787514589726925, InvBCE: 809.8235473632812\n",
      "Loss: 809.8560180664062, Norm: 0.003018043702468276, InvBCE: 809.8235473632812\n",
      "Loss: 809.8558349609375, Norm: 0.003248239867389202, InvBCE: 809.8235473632812\n",
      "Loss: 809.8555908203125, Norm: 0.0034780900459736586, InvBCE: 809.8235473632812\n",
      "Loss: 809.8554077148438, Norm: 0.0037075818981975317, InvBCE: 809.8235473632812\n",
      "Loss: 809.855224609375, Norm: 0.003936702385544777, InvBCE: 809.8235473632812\n",
      "Loss: 809.85498046875, Norm: 0.004165438935160637, InvBCE: 809.8235473632812\n",
      "Loss: 809.8547973632812, Norm: 0.004393778741359711, InvBCE: 809.8235473632812\n",
      "Image 61...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 62...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 63...\n",
      "Loss: 1.3831665515899658, Norm: 0.0, InvBCE: 1.3479266166687012\n",
      "Loss: 1.348819375038147, Norm: 0.00036753120366483927, InvBCE: 1.3135508298873901\n",
      "Image fooled! Adding perturbation...\n",
      "Image 64...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 65...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 66...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 67...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 68...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 69...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 70...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 71...\n",
      "Loss: 0.6123586297035217, Norm: 0.0, InvBCE: 0.5770585536956787\n",
      "Image fooled! Adding perturbation...\n",
      "Image 72...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 73...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 74...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 75...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 76...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 77...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 78...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 79...\n",
      "Loss: 809.8589477539062, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8587036132812, Norm: 0.00023352274729404598, InvBCE: 809.8235473632812\n",
      "Loss: 809.8585205078125, Norm: 0.0004668710462283343, InvBCE: 809.8235473632812\n",
      "Loss: 809.8582763671875, Norm: 0.000700032280292362, InvBCE: 809.8235473632812\n",
      "Loss: 809.8580932617188, Norm: 0.0009329936001449823, InvBCE: 809.8235473632812\n",
      "Loss: 809.8578491210938, Norm: 0.0011657422874122858, InvBCE: 809.8235473632812\n",
      "Loss: 809.857666015625, Norm: 0.0013982652453705668, InvBCE: 809.8235473632812\n",
      "Loss: 809.857421875, Norm: 0.0016305494355037808, InvBCE: 809.8235473632812\n",
      "Loss: 809.8572387695312, Norm: 0.0018625815864652395, InvBCE: 809.8235473632812\n",
      "Loss: 809.8569946289062, Norm: 0.0020943486597388983, InvBCE: 809.8235473632812\n",
      "Loss: 809.8568115234375, Norm: 0.0023258377332240343, InvBCE: 809.8235473632812\n",
      "Loss: 809.8565673828125, Norm: 0.002557035069912672, InvBCE: 809.8235473632812\n",
      "Loss: 809.8563842773438, Norm: 0.0027879278641194105, InvBCE: 809.8235473632812\n",
      "Loss: 809.8561401367188, Norm: 0.003018503077328205, InvBCE: 809.8235473632812\n",
      "Loss: 809.85595703125, Norm: 0.0032487474381923676, InvBCE: 809.8235473632812\n",
      "Loss: 809.8557739257812, Norm: 0.0034786483738571405, InvBCE: 809.8235473632812\n",
      "Loss: 809.8555297851562, Norm: 0.0037081933114677668, InvBCE: 809.8235473632812\n",
      "Loss: 809.8553466796875, Norm: 0.003937369212508202, InvBCE: 809.8235473632812\n",
      "Loss: 809.8551025390625, Norm: 0.004166163504123688, InvBCE: 809.8235473632812\n",
      "Loss: 809.8549194335938, Norm: 0.004394564777612686, InvBCE: 809.8235473632812\n",
      "Image 80...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 81...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 82...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 83...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 84...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 85...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 86...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 87...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 88...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 89...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 90...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 91...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 92...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 93...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 94...\n",
      "Loss: 0.8577955365180969, Norm: 0.0, InvBCE: 0.8224203586578369\n",
      "Image fooled! Adding perturbation...\n",
      "Image 95...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 96...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 97...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 98...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 99...\n",
      "Image fooled! Adding perturbation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e5e4ed22eb74f4eacf277f0dc0a26d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fooling rate: 0.85\n",
      "Starting epoch 11...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb890f39618f4b0487c11668233129b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 1...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 2...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 3...\n",
      "Loss: 3.802299737930298, Norm: 0.0, InvBCE: 3.7668724060058594\n",
      "Loss: 3.373356342315674, Norm: 0.0003814786032307893, InvBCE: 3.3378779888153076\n",
      "Loss: 2.991258382797241, Norm: 0.0007567964494228363, InvBCE: 2.955726385116577\n",
      "Loss: 2.655221462249756, Norm: 0.001126853283494711, InvBCE: 2.619633674621582\n",
      "Loss: 2.3592963218688965, Norm: 0.0014905583811923862, InvBCE: 2.3236513137817383\n",
      "Loss: 2.100038528442383, Norm: 0.0018472240772098303, InvBCE: 2.0643351078033447\n",
      "Loss: 1.8743462562561035, Norm: 0.002196092391386628, InvBCE: 1.8385834693908691\n",
      "Loss: 1.6788724660873413, Norm: 0.0025364349130541086, InvBCE: 1.643049955368042\n",
      "Loss: 1.5102685689926147, Norm: 0.0028675966896116734, InvBCE: 1.474386215209961\n",
      "Loss: 1.3653230667114258, Norm: 0.003189012873917818, InvBCE: 1.3293811082839966\n",
      "Loss: 1.2409322261810303, Norm: 0.0035002243239432573, InvBCE: 1.2049312591552734\n",
      "Loss: 1.1341893672943115, Norm: 0.003800890175625682, InvBCE: 1.0981301069259644\n",
      "Loss: 1.0424835681915283, Norm: 0.0040907952934503555, InvBCE: 1.0063670873641968\n",
      "Loss: 0.963544487953186, Norm: 0.004369837697595358, InvBCE: 0.9273719787597656\n",
      "Loss: 0.895419716835022, Norm: 0.004638014826923609, InvBCE: 0.8591926693916321\n",
      "Loss: 0.8364729285240173, Norm: 0.004895422141999006, InvBCE: 0.8001928329467773\n",
      "Loss: 0.7853159308433533, Norm: 0.005142228212207556, InvBCE: 0.7489845156669617\n",
      "Loss: 0.7407823204994202, Norm: 0.005378649570047855, InvBCE: 0.7044013142585754\n",
      "Loss: 0.7018885612487793, Norm: 0.005604932550340891, InvBCE: 0.6654597520828247\n",
      "Loss: 0.6678118705749512, Norm: 0.005821377504616976, InvBCE: 0.6313371062278748\n",
      "Image 4...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 5...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 6...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 7...\n",
      "Loss: 0.8696991801261902, Norm: 0.0, InvBCE: 0.8342719078063965\n",
      "Loss: 0.8275300860404968, Norm: 0.0003706426068674773, InvBCE: 0.7921030521392822\n",
      "Image fooled! Adding perturbation...\n",
      "Image 8...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 9...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 10...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 11...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 12...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 13...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 14...\n",
      "Loss: 1.0764074325561523, Norm: 0.0, InvBCE: 1.0409780740737915\n",
      "Image fooled! Adding perturbation...\n",
      "Image 15...\n",
      "Loss: 0.606955885887146, Norm: 0.0, InvBCE: 0.5714612007141113\n",
      "Image fooled! Adding perturbation...\n",
      "Image 16...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 17...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 18...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 19...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 20...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 21...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 22...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 23...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 24...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 25...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 26...\n",
      "Loss: 1.4788987636566162, Norm: 0.0, InvBCE: 1.4433387517929077\n",
      "Image fooled! Adding perturbation...\n",
      "Image 27...\n",
      "Loss: 0.5460025668144226, Norm: 0.0, InvBCE: 0.5105475187301636\n",
      "Image fooled! Adding perturbation...\n",
      "Image 28...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 29...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 30...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 31...\n",
      "Loss: 809.859130859375, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.85888671875, Norm: 0.00023343514476437122, InvBCE: 809.8235473632812\n",
      "Loss: 809.8587036132812, Norm: 0.00046669653966091573, InvBCE: 809.8235473632812\n",
      "Loss: 809.8584594726562, Norm: 0.0006997716263867915, InvBCE: 809.8235473632812\n",
      "Loss: 809.8582763671875, Norm: 0.0009326477302238345, InvBCE: 809.8235473632812\n",
      "Loss: 809.8580322265625, Norm: 0.0011653121327981353, InvBCE: 809.8235473632812\n",
      "Loss: 809.8578491210938, Norm: 0.0013977517373859882, InvBCE: 809.8235473632812\n",
      "Loss: 809.8576049804688, Norm: 0.0016299536218866706, InvBCE: 809.8235473632812\n",
      "Loss: 809.857421875, Norm: 0.0018619047477841377, InvBCE: 809.8235473632812\n",
      "Loss: 809.857177734375, Norm: 0.002093591960147023, InvBCE: 809.8235473632812\n",
      "Loss: 809.8569946289062, Norm: 0.0023250021040439606, InvBCE: 809.8235473632812\n",
      "Loss: 809.8567504882812, Norm: 0.0025561221409589052, InvBCE: 809.8235473632812\n",
      "Loss: 809.8565673828125, Norm: 0.0027869390323758125, InvBCE: 809.8235473632812\n",
      "Loss: 809.8563842773438, Norm: 0.003017440205439925, InvBCE: 809.8235473632812\n",
      "Loss: 809.8561401367188, Norm: 0.0032476119231432676, InvBCE: 809.8235473632812\n",
      "Loss: 809.85595703125, Norm: 0.003477441845461726, InvBCE: 809.8235473632812\n",
      "Loss: 809.855712890625, Norm: 0.0037069173995405436, InvBCE: 809.8235473632812\n",
      "Loss: 809.8555297851562, Norm: 0.003936025779694319, InvBCE: 809.8235473632812\n",
      "Loss: 809.8552856445312, Norm: 0.004164755344390869, InvBCE: 809.8235473632812\n",
      "Loss: 809.8551025390625, Norm: 0.004393092822283506, InvBCE: 809.8235473632812\n",
      "Image 32...\n",
      "Loss: 1.4605244398117065, Norm: 0.0, InvBCE: 1.4249626398086548\n",
      "Image fooled! Adding perturbation...\n",
      "Image 33...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 34...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 35...\n",
      "Loss: 0.954011857509613, Norm: 0.0, InvBCE: 0.9184476733207703\n",
      "Image fooled! Adding perturbation...\n",
      "Image 36...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 37...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 38...\n",
      "Loss: 1.461769461631775, Norm: 0.0, InvBCE: 1.4261837005615234\n",
      "Image fooled! Adding perturbation...\n",
      "Image 39...\n",
      "Loss: 673.521240234375, Norm: 0.0, InvBCE: 673.4857177734375\n",
      "Loss: 673.5210571289062, Norm: 0.00023337094171438366, InvBCE: 673.4857177734375\n",
      "Loss: 673.5208129882812, Norm: 0.00046656784252263606, InvBCE: 673.4857177734375\n",
      "Loss: 673.5206298828125, Norm: 0.0006995780859142542, InvBCE: 673.4857177734375\n",
      "Loss: 673.5203857421875, Norm: 0.0009323889971710742, InvBCE: 673.4857177734375\n",
      "Loss: 673.5202026367188, Norm: 0.0011649875668808818, InvBCE: 673.4857177734375\n",
      "Loss: 673.5199584960938, Norm: 0.0013973611639812589, InvBCE: 673.4857177734375\n",
      "Loss: 673.519775390625, Norm: 0.0016294964589178562, InvBCE: 673.4857177734375\n",
      "Loss: 673.51953125, Norm: 0.0018613804131746292, InvBCE: 673.4857177734375\n",
      "Loss: 673.5193481445312, Norm: 0.0020929998718202114, InvBCE: 673.4857177734375\n",
      "Loss: 673.5191040039062, Norm: 0.002324342029169202, InvBCE: 673.4857177734375\n",
      "Loss: 673.5189208984375, Norm: 0.002555393148213625, InvBCE: 673.4857177734375\n",
      "Loss: 673.5187377929688, Norm: 0.002786140888929367, InvBCE: 673.4857177734375\n",
      "Loss: 673.5184936523438, Norm: 0.0030165715143084526, InvBCE: 673.4857177734375\n",
      "Loss: 673.518310546875, Norm: 0.003246672684326768, InvBCE: 673.4857177734375\n",
      "Loss: 673.51806640625, Norm: 0.003476430894806981, InvBCE: 673.4857177734375\n",
      "Loss: 673.5178833007812, Norm: 0.003705834038555622, InvBCE: 673.4857177734375\n",
      "Loss: 673.5177001953125, Norm: 0.003934869077056646, InvBCE: 673.4857177734375\n",
      "Loss: 673.5174560546875, Norm: 0.004163524601608515, InvBCE: 673.4857177734375\n",
      "Loss: 673.5172729492188, Norm: 0.0043917871080338955, InvBCE: 673.4857177734375\n",
      "Image 40...\n",
      "Loss: 6.838769912719727, Norm: 0.0, InvBCE: 6.8032307624816895\n",
      "Loss: 5.872256278991699, Norm: 0.00038318164297379553, InvBCE: 5.836678504943848\n",
      "Loss: 4.237344264984131, Norm: 0.0007560254307463765, InvBCE: 4.201725482940674\n",
      "Loss: 3.5227065086364746, Norm: 0.0011047860607504845, InvBCE: 3.487039804458618\n",
      "Loss: 2.965521812438965, Norm: 0.0014444927219301462, InvBCE: 2.9298031330108643\n",
      "Loss: 2.5097265243530273, Norm: 0.0017760880291461945, InvBCE: 2.4739532470703125\n",
      "Loss: 2.0702731609344482, Norm: 0.0020988397300243378, InvBCE: 2.0344433784484863\n",
      "Loss: 1.7596515417099, Norm: 0.002411422785371542, InvBCE: 1.7237638235092163\n",
      "Loss: 1.3388653993606567, Norm: 0.0027132027316838503, InvBCE: 1.3029191493988037\n",
      "Loss: 1.1795157194137573, Norm: 0.002999804215505719, InvBCE: 1.1435126066207886\n",
      "Loss: 1.0285983085632324, Norm: 0.0032740794122219086, InvBCE: 0.9925392270088196\n",
      "Loss: 0.9001334309577942, Norm: 0.003536846023052931, InvBCE: 0.8640195727348328\n",
      "Loss: 0.7912341356277466, Norm: 0.0037885152269154787, InvBCE: 0.7550666928291321\n",
      "Loss: 0.7050467729568481, Norm: 0.004029011819511652, InvBCE: 0.6688271164894104\n",
      "Loss: 0.6380259394645691, Norm: 0.004258058499544859, InvBCE: 0.6017558574676514\n",
      "Loss: 0.5872785449028015, Norm: 0.004475605208426714, InvBCE: 0.5509599447250366\n",
      "Image fooled! Adding perturbation...\n",
      "Image 41...\n",
      "Loss: 1.411470651626587, Norm: 0.0, InvBCE: 1.375105619430542\n",
      "Image fooled! Adding perturbation...\n",
      "Image 42...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 43...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 44...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 45...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 46...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 47...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 48...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 49...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 50...\n",
      "Loss: 5.514017105102539, Norm: 0.0, InvBCE: 5.477661609649658\n",
      "Loss: 4.668966770172119, Norm: 0.00038183736614882946, InvBCE: 4.632593154907227\n",
      "Loss: 4.017433166503906, Norm: 0.0007530677830800414, InvBCE: 3.98103928565979\n",
      "Loss: 3.511931896209717, Norm: 0.0011141995200887322, InvBCE: 3.475515604019165\n",
      "Loss: 3.1053149700164795, Norm: 0.0014640239533036947, InvBCE: 3.068873643875122\n",
      "Loss: 2.7661421298980713, Norm: 0.0018024067394435406, InvBCE: 2.7296738624572754\n",
      "Loss: 2.4743778705596924, Norm: 0.00212850421667099, InvBCE: 2.4378809928894043\n",
      "Loss: 2.220165729522705, Norm: 0.0024437373504042625, InvBCE: 2.18363881111145\n",
      "Loss: 1.987120509147644, Norm: 0.002749738749116659, InvBCE: 1.9505623579025269\n",
      "Loss: 1.7701369524002075, Norm: 0.003047157544642687, InvBCE: 1.733546257019043\n",
      "Loss: 1.5730692148208618, Norm: 0.0033363259863108397, InvBCE: 1.5364450216293335\n",
      "Loss: 1.399797797203064, Norm: 0.0036169749218970537, InvBCE: 1.363139271736145\n",
      "Loss: 1.2485923767089844, Norm: 0.0038888307753950357, InvBCE: 1.2118993997573853\n",
      "Loss: 1.1146347522735596, Norm: 0.004151618108153343, InvBCE: 1.0779072046279907\n",
      "Loss: 0.9953498244285583, Norm: 0.004405407700687647, InvBCE: 0.9585880637168884\n",
      "Loss: 0.8894134759902954, Norm: 0.004650188609957695, InvBCE: 0.8526178598403931\n",
      "Loss: 0.7979303598403931, Norm: 0.004885798320174217, InvBCE: 0.761101484298706\n",
      "Loss: 0.7210566401481628, Norm: 0.0051120370626449585, InvBCE: 0.6841952800750732\n",
      "Loss: 0.6575029492378235, Norm: 0.005328718572854996, InvBCE: 0.620610237121582\n",
      "Loss: 0.6053990721702576, Norm: 0.005535740405321121, InvBCE: 0.5684763193130493\n",
      "Image 51...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 52...\n",
      "Loss: 1.2406219244003296, Norm: 0.0, InvBCE: 1.2042661905288696\n",
      "Image fooled! Adding perturbation...\n",
      "Image 53...\n",
      "Loss: 1.356977939605713, Norm: 0.0, InvBCE: 1.3206772804260254\n",
      "Image fooled! Adding perturbation...\n",
      "Image 54...\n",
      "Loss: 1.4881188869476318, Norm: 0.0, InvBCE: 1.4518401622772217\n",
      "Loss: 1.4858806133270264, Norm: 0.00031147897243499756, InvBCE: 1.4497110843658447\n",
      "Loss: 1.483643889427185, Norm: 0.0006227035773918033, InvBCE: 1.4475815296173096\n",
      "Loss: 1.4814255237579346, Norm: 0.0009333672933280468, InvBCE: 1.445468544960022\n",
      "Loss: 1.479246735572815, Norm: 0.0012429686030372977, InvBCE: 1.4433934688568115\n",
      "Image fooled! Adding perturbation...\n",
      "Image 55...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 56...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 57...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 58...\n",
      "Loss: 1.4694355726242065, Norm: 0.0, InvBCE: 1.433685064315796\n",
      "Loss: 1.4536542892456055, Norm: 0.00036467169411480427, InvBCE: 1.4179754257202148\n",
      "Loss: 1.4381022453308105, Norm: 0.0007275490206666291, InvBCE: 1.4024924039840698\n",
      "Image fooled! Adding perturbation...\n",
      "Image 59...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 60...\n",
      "Loss: 809.8590698242188, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.85888671875, Norm: 0.00023332163982558995, InvBCE: 809.8235473632812\n",
      "Loss: 809.858642578125, Norm: 0.00046646781265735626, InvBCE: 809.8235473632812\n",
      "Loss: 809.8584594726562, Norm: 0.0006994258146733046, InvBCE: 809.8235473632812\n",
      "Loss: 809.8582153320312, Norm: 0.0009321828256361187, InvBCE: 809.8235473632812\n",
      "Loss: 809.8580322265625, Norm: 0.0011647259816527367, InvBCE: 809.8235473632812\n",
      "Loss: 809.8577880859375, Norm: 0.001397042302414775, InvBCE: 809.8235473632812\n",
      "Loss: 809.8576049804688, Norm: 0.001629118574783206, InvBCE: 809.8235473632812\n",
      "Loss: 809.8573608398438, Norm: 0.0018609414109960198, InvBCE: 809.8235473632812\n",
      "Loss: 809.857177734375, Norm: 0.0020924981217831373, InvBCE: 809.8235473632812\n",
      "Loss: 809.8569946289062, Norm: 0.002323774853721261, InvBCE: 809.8235473632812\n",
      "Loss: 809.8567504882812, Norm: 0.002554758917540312, InvBCE: 809.8235473632812\n",
      "Loss: 809.8565673828125, Norm: 0.002785437274724245, InvBCE: 809.8235473632812\n",
      "Loss: 809.8563232421875, Norm: 0.0030157961882650852, InvBCE: 809.8235473632812\n",
      "Loss: 809.8561401367188, Norm: 0.003245823085308075, InvBCE: 809.8235473632812\n",
      "Loss: 809.8558959960938, Norm: 0.0034755049273371696, InvBCE: 809.8235473632812\n",
      "Loss: 809.855712890625, Norm: 0.0037048289086669683, InvBCE: 809.8235473632812\n",
      "Loss: 809.8555297851562, Norm: 0.003933782689273357, InvBCE: 809.8235473632812\n",
      "Loss: 809.8552856445312, Norm: 0.004162353929132223, InvBCE: 809.8235473632812\n",
      "Loss: 809.8551025390625, Norm: 0.004390529356896877, InvBCE: 809.8235473632812\n",
      "Image 61...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 62...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 63...\n",
      "Loss: 1.395258903503418, Norm: 0.0, InvBCE: 1.3597158193588257\n",
      "Loss: 1.3563966751098633, Norm: 0.0003686081327032298, InvBCE: 1.3208256959915161\n",
      "Image fooled! Adding perturbation...\n",
      "Image 64...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 65...\n",
      "Loss: 0.9447003602981567, Norm: 0.0, InvBCE: 0.909098744392395\n",
      "Image fooled! Adding perturbation...\n",
      "Image 66...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 67...\n",
      "Loss: 0.5903975963592529, Norm: 0.0, InvBCE: 0.5547787547111511\n",
      "Image fooled! Adding perturbation...\n",
      "Image 68...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 69...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 70...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 71...\n",
      "Loss: 0.5918543338775635, Norm: 0.0, InvBCE: 0.5561986565589905\n",
      "Image fooled! Adding perturbation...\n",
      "Image 72...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 73...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 74...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 75...\n",
      "Loss: 3.925337076187134, Norm: 0.0, InvBCE: 3.88960862159729\n",
      "Loss: 1.437972068786621, Norm: 0.0003850753419101238, InvBCE: 1.402320146560669\n",
      "Image fooled! Adding perturbation...\n",
      "Image 76...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 77...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 78...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 79...\n",
      "Loss: 809.859130859375, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8589477539062, Norm: 0.00023312729899771512, InvBCE: 809.8235473632812\n",
      "Loss: 809.8587036132812, Norm: 0.0004660793929360807, InvBCE: 809.8235473632812\n",
      "Loss: 809.8585205078125, Norm: 0.0006988437380641699, InvBCE: 809.8235473632812\n",
      "Loss: 809.8582763671875, Norm: 0.0009314074413850904, InvBCE: 809.8235473632812\n",
      "Loss: 809.8580932617188, Norm: 0.0011637578718364239, InvBCE: 809.8235473632812\n",
      "Loss: 809.8578491210938, Norm: 0.0013958816416561604, InvBCE: 809.8235473632812\n",
      "Loss: 809.857666015625, Norm: 0.0016277657123282552, InvBCE: 809.8235473632812\n",
      "Loss: 809.857421875, Norm: 0.0018593973945826292, InvBCE: 809.8235473632812\n",
      "Loss: 809.8572387695312, Norm: 0.002090762834995985, InvBCE: 809.8235473632812\n",
      "Loss: 809.8569946289062, Norm: 0.0023218493442982435, InvBCE: 809.8235473632812\n",
      "Loss: 809.8568115234375, Norm: 0.0025526436511427164, InvBCE: 809.8235473632812\n",
      "Loss: 809.8565673828125, Norm: 0.0027831324841827154, InvBCE: 809.8235473632812\n",
      "Loss: 809.8563842773438, Norm: 0.003013302804902196, InvBCE: 809.8235473632812\n",
      "Loss: 809.856201171875, Norm: 0.0032431420404464006, InvBCE: 809.8235473632812\n",
      "Loss: 809.85595703125, Norm: 0.0034726366866379976, InvBCE: 809.8235473632812\n",
      "Loss: 809.8557739257812, Norm: 0.0037017744034528732, InvBCE: 809.8235473632812\n",
      "Loss: 809.8555297851562, Norm: 0.00393054261803627, InvBCE: 809.8235473632812\n",
      "Loss: 809.8553466796875, Norm: 0.004158928524702787, InvBCE: 809.8235473632812\n",
      "Loss: 809.8551635742188, Norm: 0.004386920481920242, InvBCE: 809.8235473632812\n",
      "Image 80...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 81...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 82...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 83...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 84...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 85...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 86...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 87...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 88...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 89...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 90...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 91...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 92...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 93...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 94...\n",
      "Loss: 0.9066352844238281, Norm: 0.0, InvBCE: 0.8710513114929199\n",
      "Image fooled! Adding perturbation...\n",
      "Image 95...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 96...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 97...\n",
      "Loss: 1.4781726598739624, Norm: 0.0, InvBCE: 1.4425486326217651\n",
      "Image fooled! Adding perturbation...\n",
      "Image 98...\n",
      "Loss: 1.416886329650879, Norm: 0.0, InvBCE: 1.3812421560287476\n",
      "Loss: 1.383164644241333, Norm: 0.0003732931800186634, InvBCE: 1.3474847078323364\n",
      "Loss: 1.3520481586456299, Norm: 0.0007434705039486289, InvBCE: 1.3163294792175293\n",
      "Image fooled! Adding perturbation...\n",
      "Image 99...\n",
      "Image fooled! Adding perturbation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ada29c0274d8498d868d7d7fdbad5591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fooling rate: 0.82\n",
      "Starting epoch 12...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "005254e4cd154e12bd20fc2166f0f322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 1...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 2...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 3...\n",
      "Loss: 3.327279806137085, Norm: 0.0, InvBCE: 3.2915198802948\n",
      "Loss: 2.941934108734131, Norm: 0.00038193483487702906, InvBCE: 2.9061286449432373\n",
      "Loss: 2.6014015674591064, Norm: 0.000757944246288389, InvBCE: 2.5655477046966553\n",
      "Loss: 2.3018851280212402, Norm: 0.0011281362967565656, InvBCE: 2.2659802436828613\n",
      "Loss: 2.0394091606140137, Norm: 0.0014913345221430063, InvBCE: 2.0034515857696533\n",
      "Loss: 1.8103288412094116, Norm: 0.0018465330358594656, InvBCE: 1.7743170261383057\n",
      "Loss: 1.611060380935669, Norm: 0.0021928385831415653, InvBCE: 1.5749934911727905\n",
      "Loss: 1.4383835792541504, Norm: 0.0025295058730989695, InvBCE: 1.4022610187530518\n",
      "Loss: 1.289231777191162, Norm: 0.0028559172060340643, InvBCE: 1.2530533075332642\n",
      "Loss: 1.1607234477996826, Norm: 0.0031716274097561836, InvBCE: 1.1244893074035645\n",
      "Loss: 1.050349235534668, Norm: 0.0034763209987431765, InvBCE: 1.0140597820281982\n",
      "Loss: 0.9558342099189758, Norm: 0.0037697728257626295, InvBCE: 0.9194902777671814\n",
      "Loss: 0.8750069737434387, Norm: 0.004051872994750738, InvBCE: 0.8386095762252808\n",
      "Loss: 0.805836021900177, Norm: 0.004322607070207596, InvBCE: 0.7693864107131958\n",
      "Loss: 0.7464920282363892, Norm: 0.004582064226269722, InvBCE: 0.7099916338920593\n",
      "Loss: 0.6954077482223511, Norm: 0.0048304065130651, InvBCE: 0.6588582396507263\n",
      "Loss: 0.6512899994850159, Norm: 0.005067878868430853, InvBCE: 0.6146930456161499\n",
      "Loss: 0.6130873560905457, Norm: 0.0052947732619941235, InvBCE: 0.5764448642730713\n",
      "Loss: 0.5799352526664734, Norm: 0.0055114091373980045, InvBCE: 0.5432490706443787\n",
      "Loss: 0.5511124134063721, Norm: 0.005718124099075794, InvBCE: 0.5143845081329346\n",
      "Image 4...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 5...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 6...\n",
      "Loss: 1.21845281124115, Norm: 0.0, InvBCE: 1.1826928853988647\n",
      "Loss: 1.182134747505188, Norm: 0.0003627044497989118, InvBCE: 1.1463662385940552\n",
      "Image fooled! Adding perturbation...\n",
      "Image 7...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 8...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 9...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 10...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 11...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 12...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 13...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 14...\n",
      "Loss: 1.0652759075164795, Norm: 0.0, InvBCE: 1.029496669769287\n",
      "Image fooled! Adding perturbation...\n",
      "Image 15...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 16...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 17...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 18...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 19...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 20...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 21...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 22...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 23...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 24...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 25...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 26...\n",
      "Loss: 1.4781545400619507, Norm: 0.0, InvBCE: 1.4423067569732666\n",
      "Image fooled! Adding perturbation...\n",
      "Image 27...\n",
      "Loss: 0.5858402252197266, Norm: 0.0, InvBCE: 0.5501039028167725\n",
      "Loss: 0.5519442558288574, Norm: 0.0003732455661520362, InvBCE: 0.5161008834838867\n",
      "Image fooled! Adding perturbation...\n",
      "Image 28...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 29...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 30...\n",
      "Loss: 0.7241235971450806, Norm: 0.0, InvBCE: 0.688171923160553\n",
      "Image fooled! Adding perturbation...\n",
      "Image 31...\n",
      "Loss: 809.8595581054688, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.859375, Norm: 0.0002331954165128991, InvBCE: 809.8235473632812\n",
      "Loss: 809.859130859375, Norm: 0.0004662174906115979, InvBCE: 809.8235473632812\n",
      "Loss: 809.8589477539062, Norm: 0.0006990538095124066, InvBCE: 809.8235473632812\n",
      "Loss: 809.8587036132812, Norm: 0.000931691552978009, InvBCE: 809.8235473632812\n",
      "Loss: 809.8585205078125, Norm: 0.0011641182936728, InvBCE: 809.8235473632812\n",
      "Loss: 809.8582763671875, Norm: 0.0013963208766654134, InvBCE: 809.8235473632812\n",
      "Loss: 809.8580932617188, Norm: 0.0016282865544781089, InvBCE: 809.8235473632812\n",
      "Loss: 809.85791015625, Norm: 0.0018600024050101638, InvBCE: 809.8235473632812\n",
      "Loss: 809.857666015625, Norm: 0.0020914552733302116, InvBCE: 809.8235473632812\n",
      "Loss: 809.8574829101562, Norm: 0.002322632120922208, InvBCE: 809.8235473632812\n",
      "Loss: 809.8572387695312, Norm: 0.0025535200256854296, InvBCE: 809.8235473632812\n",
      "Loss: 809.8570556640625, Norm: 0.002784106181934476, InvBCE: 809.8235473632812\n",
      "Loss: 809.8568115234375, Norm: 0.003014377783983946, InvBCE: 809.8235473632812\n",
      "Loss: 809.8566284179688, Norm: 0.003244321560487151, InvBCE: 809.8235473632812\n",
      "Loss: 809.8563842773438, Norm: 0.003473924705758691, InvBCE: 809.8235473632812\n",
      "Loss: 809.856201171875, Norm: 0.0037031755782663822, InvBCE: 809.8235473632812\n",
      "Loss: 809.8560180664062, Norm: 0.003932061139494181, InvBCE: 809.8235473632812\n",
      "Loss: 809.8557739257812, Norm: 0.00416056951507926, InvBCE: 809.8235473632812\n",
      "Loss: 809.8555908203125, Norm: 0.0043886881321668625, InvBCE: 809.8235473632812\n",
      "Image 32...\n",
      "Loss: 1.4801726341247559, Norm: 0.0, InvBCE: 1.4441406726837158\n",
      "Loss: 1.462675929069519, Norm: 0.0003588327672332525, InvBCE: 1.4266471862792969\n",
      "Image fooled! Adding perturbation...\n",
      "Image 33...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 34...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 35...\n",
      "Loss: 1.054936170578003, Norm: 0.0, InvBCE: 1.0189085006713867\n",
      "Loss: 1.0209728479385376, Norm: 0.00036349010770209134, InvBCE: 0.9849039316177368\n",
      "Loss: 0.985707700252533, Norm: 0.0007078793714754283, InvBCE: 0.9495987296104431\n",
      "Loss: 0.9568050503730774, Norm: 0.0010401959298178554, InvBCE: 0.9206587672233582\n",
      "Image fooled! Adding perturbation...\n",
      "Image 36...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 37...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 38...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 39...\n",
      "Loss: 581.2808837890625, Norm: 0.0, InvBCE: 581.2446899414062\n",
      "Loss: 320.4610595703125, Norm: 0.00038477263296954334, InvBCE: 320.4248352050781\n",
      "Loss: 182.59681701660156, Norm: 0.0007471239077858627, InvBCE: 182.56053161621094\n",
      "Loss: 107.94143676757812, Norm: 0.0010765517363324761, InvBCE: 107.90509796142578\n",
      "Loss: 70.9959716796875, Norm: 0.0013796496205031872, InvBCE: 70.95958709716797\n",
      "Loss: 49.99439239501953, Norm: 0.001656756387092173, InvBCE: 49.95795822143555\n",
      "Loss: 38.382774353027344, Norm: 0.0019101679790765047, InvBCE: 38.34629821777344\n",
      "Loss: 31.41892433166504, Norm: 0.002142414217814803, InvBCE: 31.382408142089844\n",
      "Loss: 25.90997314453125, Norm: 0.0023562300484627485, InvBCE: 25.87342071533203\n",
      "Loss: 22.363887786865234, Norm: 0.0025535414461046457, InvBCE: 22.327301025390625\n",
      "Loss: 19.669748306274414, Norm: 0.002736462280154228, InvBCE: 19.633129119873047\n",
      "Loss: 17.680078506469727, Norm: 0.00290664448402822, InvBCE: 17.643430709838867\n",
      "Loss: 16.134729385375977, Norm: 0.0030654463917016983, InvBCE: 16.098054885864258\n",
      "Loss: 14.890884399414062, Norm: 0.003214034717530012, InvBCE: 14.854186058044434\n",
      "Loss: 13.907586097717285, Norm: 0.0033534877002239227, InvBCE: 13.870865821838379\n",
      "Loss: 13.117400169372559, Norm: 0.0034847164060920477, InvBCE: 13.080658912658691\n",
      "Loss: 12.422449111938477, Norm: 0.00360853667370975, InvBCE: 12.385688781738281\n",
      "Loss: 11.842602729797363, Norm: 0.003725707298144698, InvBCE: 11.805825233459473\n",
      "Loss: 11.347526550292969, Norm: 0.003836866468191147, InvBCE: 11.3107328414917\n",
      "Loss: 10.889147758483887, Norm: 0.00394259812310338, InvBCE: 10.852339744567871\n",
      "Image 40...\n",
      "Loss: 0.8515860438346863, Norm: 0.0, InvBCE: 0.8154022693634033\n",
      "Loss: 0.7186300754547119, Norm: 0.0003762498090509325, InvBCE: 0.6823832988739014\n",
      "Loss: 0.6266052722930908, Norm: 0.0007406967924907804, InvBCE: 0.5902954936027527\n",
      "Image fooled! Adding perturbation...\n",
      "Image 41...\n",
      "Loss: 1.4280909299850464, Norm: 0.0, InvBCE: 1.391719102859497\n",
      "Loss: 1.4134876728057861, Norm: 0.00035119609674438834, InvBCE: 1.3771085739135742\n",
      "Image fooled! Adding perturbation...\n",
      "Image 42...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 43...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 44...\n",
      "Loss: 0.7830934524536133, Norm: 0.0, InvBCE: 0.7467078566551208\n",
      "Loss: 0.7502821683883667, Norm: 0.00036781124072149396, InvBCE: 0.7138444185256958\n",
      "Image fooled! Adding perturbation...\n",
      "Image 45...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 46...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 47...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 48...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 49...\n",
      "Loss: 1.374559760093689, Norm: 0.0, InvBCE: 1.3380674123764038\n",
      "Loss: 1.3164626359939575, Norm: 0.00037576135946437716, InvBCE: 1.2799144983291626\n",
      "Image fooled! Adding perturbation...\n",
      "Image 50...\n",
      "Loss: 6.241963863372803, Norm: 0.0, InvBCE: 6.205357074737549\n",
      "Loss: 5.186511516571045, Norm: 0.0003819074190687388, InvBCE: 5.149884223937988\n",
      "Loss: 4.4417877197265625, Norm: 0.000754822394810617, InvBCE: 4.405138969421387\n",
      "Loss: 3.8683159351348877, Norm: 0.00111884786747396, InvBCE: 3.8316433429718018\n",
      "Loss: 3.396388053894043, Norm: 0.001469305483624339, InvBCE: 3.359689474105835\n",
      "Loss: 3.0072977542877197, Norm: 0.0018088457873091102, InvBCE: 2.970571279525757\n",
      "Loss: 2.6774837970733643, Norm: 0.002137652598321438, InvBCE: 2.6407277584075928\n",
      "Loss: 2.393813371658325, Norm: 0.0024562086910009384, InvBCE: 2.3570268154144287\n",
      "Loss: 2.1385443210601807, Norm: 0.002762971678748727, InvBCE: 2.1017262935638428\n",
      "Loss: 1.9108020067214966, Norm: 0.0030610375106334686, InvBCE: 1.8739516735076904\n",
      "Loss: 1.7019782066345215, Norm: 0.0033506646286696196, InvBCE: 1.6650947332382202\n",
      "Loss: 1.5118262767791748, Norm: 0.0036320495419204235, InvBCE: 1.474908709526062\n",
      "Loss: 1.3450955152511597, Norm: 0.003904947079718113, InvBCE: 1.3081433773040771\n",
      "Loss: 1.2004274129867554, Norm: 0.004168914631009102, InvBCE: 1.1634405851364136\n",
      "Loss: 1.073657751083374, Norm: 0.004423763137310743, InvBCE: 1.0366361141204834\n",
      "Loss: 0.9629319310188293, Norm: 0.004669372923672199, InvBCE: 0.9258760213851929\n",
      "Loss: 0.8663005232810974, Norm: 0.00490564713254571, InvBCE: 0.8292109370231628\n",
      "Loss: 0.7838089466094971, Norm: 0.005132514052093029, InvBCE: 0.7466865181922913\n",
      "Loss: 0.7146211862564087, Norm: 0.0053498586639761925, InvBCE: 0.6774670481681824\n",
      "Loss: 0.6560128331184387, Norm: 0.005557614378631115, InvBCE: 0.6188281774520874\n",
      "Image 51...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 52...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 53...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 54...\n",
      "Loss: 1.4816445112228394, Norm: 0.0, InvBCE: 1.445037841796875\n",
      "Loss: 1.4795784950256348, Norm: 0.00031018524896353483, InvBCE: 1.443084716796875\n",
      "Image fooled! Adding perturbation...\n",
      "Image 55...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 56...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 57...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 58...\n",
      "Loss: 1.456155776977539, Norm: 0.0, InvBCE: 1.4197731018066406\n",
      "Loss: 1.4405368566513062, Norm: 0.000364145846106112, InvBCE: 1.404221773147583\n",
      "Image fooled! Adding perturbation...\n",
      "Image 59...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 60...\n",
      "Loss: 809.8598022460938, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8595581054688, Norm: 0.00023318521562032402, InvBCE: 809.8235473632812\n",
      "Loss: 809.859375, Norm: 0.00046619740896858275, InvBCE: 809.8235473632812\n",
      "Loss: 809.859130859375, Norm: 0.0006990242400206625, InvBCE: 809.8235473632812\n",
      "Loss: 809.8589477539062, Norm: 0.0009316531359218061, InvBCE: 809.8235473632812\n",
      "Loss: 809.8587036132812, Norm: 0.001164071261882782, InvBCE: 809.8235473632812\n",
      "Loss: 809.8585205078125, Norm: 0.001396265928633511, InvBCE: 809.8235473632812\n",
      "Loss: 809.8583374023438, Norm: 0.0016282240394502878, InvBCE: 809.8235473632812\n",
      "Loss: 809.8580932617188, Norm: 0.0018599327886477113, InvBCE: 809.8235473632812\n",
      "Loss: 809.85791015625, Norm: 0.002091379137709737, InvBCE: 809.8235473632812\n",
      "Loss: 809.857666015625, Norm: 0.0023225503973662853, InvBCE: 809.8235473632812\n",
      "Loss: 809.8574829101562, Norm: 0.0025534331798553467, InvBCE: 809.8235473632812\n",
      "Loss: 809.8572387695312, Norm: 0.0027840149123221636, InvBCE: 809.8235473632812\n",
      "Loss: 809.8570556640625, Norm: 0.0030142825562506914, InvBCE: 809.8235473632812\n",
      "Loss: 809.8568725585938, Norm: 0.003244223305955529, InvBCE: 809.8235473632812\n",
      "Loss: 809.8566284179688, Norm: 0.003473825054243207, InvBCE: 809.8235473632812\n",
      "Loss: 809.8564453125, Norm: 0.003703074296936393, InvBCE: 809.8235473632812\n",
      "Loss: 809.856201171875, Norm: 0.003931959625333548, InvBCE: 809.8235473632812\n",
      "Loss: 809.8560180664062, Norm: 0.004160468466579914, InvBCE: 809.8235473632812\n",
      "Loss: 809.8558349609375, Norm: 0.004388588946312666, InvBCE: 809.8235473632812\n",
      "Image 61...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 62...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 63...\n",
      "Loss: 1.3788635730743408, Norm: 0.0, InvBCE: 1.3426138162612915\n",
      "Image fooled! Adding perturbation...\n",
      "Image 64...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 65...\n",
      "Loss: 0.9556289315223694, Norm: 0.0, InvBCE: 0.9193488955497742\n",
      "Image fooled! Adding perturbation...\n",
      "Image 66...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 67...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 68...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 69...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 70...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 71...\n",
      "Loss: 0.5809934735298157, Norm: 0.0, InvBCE: 0.5447005033493042\n",
      "Image fooled! Adding perturbation...\n",
      "Image 72...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 73...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 74...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 75...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 76...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 77...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 78...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 79...\n",
      "Loss: 809.8599243164062, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8596801757812, Norm: 0.00023313330893870443, InvBCE: 809.8235473632812\n",
      "Loss: 809.8594970703125, Norm: 0.0004660944687202573, InvBCE: 809.8235473632812\n",
      "Loss: 809.8592529296875, Norm: 0.0006988709210418165, InvBCE: 809.8235473632812\n",
      "Loss: 809.8590698242188, Norm: 0.0009314502240158617, InvBCE: 809.8235473632812\n",
      "Loss: 809.8588256835938, Norm: 0.0011638198047876358, InvBCE: 809.8235473632812\n",
      "Loss: 809.858642578125, Norm: 0.0013959667412564158, InvBCE: 809.8235473632812\n",
      "Loss: 809.8583984375, Norm: 0.0016278784023597836, InvBCE: 809.8235473632812\n",
      "Loss: 809.8582153320312, Norm: 0.0018595416331663728, InvBCE: 809.8235473632812\n",
      "Loss: 809.8580322265625, Norm: 0.0020909439772367477, InvBCE: 809.8235473632812\n",
      "Loss: 809.8577880859375, Norm: 0.0023220719303935766, InvBCE: 809.8235473632812\n",
      "Loss: 809.8576049804688, Norm: 0.002552913036197424, InvBCE: 809.8235473632812\n",
      "Loss: 809.8573608398438, Norm: 0.0027834544889628887, InvBCE: 809.8235473632812\n",
      "Loss: 809.857177734375, Norm: 0.0030136830173432827, InvBCE: 809.8235473632812\n",
      "Loss: 809.85693359375, Norm: 0.0032435867469757795, InvBCE: 809.8235473632812\n",
      "Loss: 809.8567504882812, Norm: 0.003473152406513691, InvBCE: 809.8235473632812\n",
      "Loss: 809.8565673828125, Norm: 0.0037023676559329033, InvBCE: 809.8235473632812\n",
      "Loss: 809.8563232421875, Norm: 0.00393122062087059, InvBCE: 809.8235473632812\n",
      "Loss: 809.8561401367188, Norm: 0.004159699194133282, InvBCE: 809.8235473632812\n",
      "Loss: 809.8558959960938, Norm: 0.004387790337204933, InvBCE: 809.8235473632812\n",
      "Image 80...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 81...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 82...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 83...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 84...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 85...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 86...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 87...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 88...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 89...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 90...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 91...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 92...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 93...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 94...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 95...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 96...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 97...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 98...\n",
      "Loss: 1.3587701320648193, Norm: 0.0, InvBCE: 1.3224033117294312\n",
      "Image fooled! Adding perturbation...\n",
      "Image 99...\n",
      "Image fooled! Adding perturbation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a056cfe739254c9fa8c4fa8dc79491d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fooling rate: 0.84\n",
      "Starting epoch 13...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e59bf294c10849adb4438659cf0011a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 1...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 2...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 3...\n",
      "Loss: 3.057088851928711, Norm: 0.0, InvBCE: 3.020681142807007\n",
      "Loss: 2.7122318744659424, Norm: 0.00038154382491484284, InvBCE: 2.6757771968841553\n",
      "Loss: 2.407482862472534, Norm: 0.0007579089724458754, InvBCE: 2.370978355407715\n",
      "Loss: 2.1396212577819824, Norm: 0.001128939911723137, InvBCE: 2.10306453704834\n",
      "Loss: 1.9049911499023438, Norm: 0.001493369578383863, InvBCE: 1.8683803081512451\n",
      "Loss: 1.7001254558563232, Norm: 0.0018500604201108217, InvBCE: 1.663459300994873\n",
      "Loss: 1.5219285488128662, Norm: 0.002197996946051717, InvBCE: 1.4852062463760376\n",
      "Loss: 1.3674155473709106, Norm: 0.002536336425691843, InvBCE: 1.330636739730835\n",
      "Loss: 1.2337841987609863, Norm: 0.002864440204575658, InvBCE: 1.1969490051269531\n",
      "Loss: 1.118455171585083, Norm: 0.0031818458810448647, InvBCE: 1.081563949584961\n",
      "Loss: 1.019110083580017, Norm: 0.0034882337786257267, InvBCE: 0.9821634292602539\n",
      "Loss: 0.9336361289024353, Norm: 0.0037834111135452986, InvBCE: 0.8966350555419922\n",
      "Loss: 0.8600801229476929, Norm: 0.004067295230925083, InvBCE: 0.8230257630348206\n",
      "Loss: 0.7966175079345703, Norm: 0.0043398975394666195, InvBCE: 0.7595112323760986\n",
      "Loss: 0.7416127920150757, Norm: 0.004601335618644953, InvBCE: 0.704456090927124\n",
      "Loss: 0.6936367750167847, Norm: 0.004851825535297394, InvBCE: 0.6564313173294067\n",
      "Loss: 0.6515072584152222, Norm: 0.005091654136776924, InvBCE: 0.6142547726631165\n",
      "Loss: 0.6142966747283936, Norm: 0.005321157164871693, InvBCE: 0.5769990086555481\n",
      "Loss: 0.5813129544258118, Norm: 0.005540704820305109, InvBCE: 0.5439720153808594\n",
      "Loss: 0.5520501732826233, Norm: 0.005750672891736031, InvBCE: 0.5146678686141968\n",
      "Image 4...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 5...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 6...\n",
      "Loss: 1.1910964250564575, Norm: 0.0, InvBCE: 1.154688835144043\n",
      "Image fooled! Adding perturbation...\n",
      "Image 7...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 8...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 9...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 10...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 11...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 12...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 13...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 14...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 15...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 16...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 17...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 18...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 19...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 20...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 21...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 22...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 23...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 24...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 25...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 26...\n",
      "Loss: 1.4803558588027954, Norm: 0.0, InvBCE: 1.4439350366592407\n",
      "Image fooled! Adding perturbation...\n",
      "Image 27...\n",
      "Loss: 0.567510187625885, Norm: 0.0, InvBCE: 0.5312028527259827\n",
      "Loss: 0.5360120534896851, Norm: 0.00037215318297967315, InvBCE: 0.49959829449653625\n",
      "Image fooled! Adding perturbation...\n",
      "Image 28...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 29...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 30...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 31...\n",
      "Loss: 809.8600463867188, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.85986328125, Norm: 0.00023313742713071406, InvBCE: 809.8235473632812\n",
      "Loss: 809.859619140625, Norm: 0.00046610331628471613, InvBCE: 809.8235473632812\n",
      "Loss: 809.8594360351562, Norm: 0.0006988852401264012, InvBCE: 809.8235473632812\n",
      "Loss: 809.8591918945312, Norm: 0.0009314707713201642, InvBCE: 809.8235473632812\n",
      "Loss: 809.8590087890625, Norm: 0.001163847278803587, InvBCE: 809.8235473632812\n",
      "Loss: 809.8587646484375, Norm: 0.0013960021315142512, InvBCE: 809.8235473632812\n",
      "Loss: 809.8585815429688, Norm: 0.0016279226401820779, InvBCE: 809.8235473632812\n",
      "Loss: 809.8583984375, Norm: 0.0018595958827063441, InvBCE: 809.8235473632812\n",
      "Loss: 809.858154296875, Norm: 0.002091008936986327, InvBCE: 809.8235473632812\n",
      "Loss: 809.8579711914062, Norm: 0.0023221487645059824, InvBCE: 809.8235473632812\n",
      "Loss: 809.8577270507812, Norm: 0.0025530029088258743, InvBCE: 809.8235473632812\n",
      "Loss: 809.8575439453125, Norm: 0.0027835587970912457, InvBCE: 809.8235473632812\n",
      "Loss: 809.8572998046875, Norm: 0.0030138033907860518, InvBCE: 809.8235473632812\n",
      "Loss: 809.8571166992188, Norm: 0.003243723651394248, InvBCE: 809.8235473632812\n",
      "Loss: 809.85693359375, Norm: 0.0034733079373836517, InvBCE: 809.8235473632812\n",
      "Loss: 809.856689453125, Norm: 0.0037025432102382183, InvBCE: 809.8235473632812\n",
      "Loss: 809.8565063476562, Norm: 0.003931417595595121, InvBCE: 809.8235473632812\n",
      "Loss: 809.8562622070312, Norm: 0.004159919451922178, InvBCE: 809.8235473632812\n",
      "Loss: 809.8560791015625, Norm: 0.004388035740703344, InvBCE: 809.8235473632812\n",
      "Image 32...\n",
      "Loss: 1.459119439125061, Norm: 0.0, InvBCE: 1.4225982427597046\n",
      "Image fooled! Adding perturbation...\n",
      "Image 33...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 34...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 35...\n",
      "Loss: 1.0077751874923706, Norm: 0.0, InvBCE: 0.9712576866149902\n",
      "Loss: 0.9710713624954224, Norm: 0.0003665236581582576, InvBCE: 0.9345209002494812\n",
      "Loss: 0.9418317079544067, Norm: 0.0007290749927051365, InvBCE: 0.905245840549469\n",
      "Image fooled! Adding perturbation...\n",
      "Image 36...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 37...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 38...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 39...\n",
      "Loss: 306.35687255859375, Norm: 0.0, InvBCE: 306.32025146484375\n",
      "Loss: 169.1243438720703, Norm: 0.00038471637526527047, InvBCE: 169.08766174316406\n",
      "Loss: 96.45491790771484, Norm: 0.0007417855667881668, InvBCE: 96.41818237304688\n",
      "Loss: 62.08371353149414, Norm: 0.0010682364227250218, InvBCE: 62.04692840576172\n",
      "Loss: 43.71391677856445, Norm: 0.0013665725709870458, InvBCE: 43.67708206176758\n",
      "Loss: 33.64820861816406, Norm: 0.0016385691706091166, InvBCE: 33.611328125\n",
      "Loss: 27.28360366821289, Norm: 0.0018684255192056298, InvBCE: 27.246686935424805\n",
      "Loss: 23.189208984375, Norm: 0.002082348568364978, InvBCE: 23.15225601196289\n",
      "Loss: 20.07819938659668, Norm: 0.002281401539221406, InvBCE: 20.041213989257812\n",
      "Loss: 17.870712280273438, Norm: 0.00246720714494586, InvBCE: 17.833698272705078\n",
      "Loss: 16.160581588745117, Norm: 0.002641332568600774, InvBCE: 16.123538970947266\n",
      "Loss: 14.815234184265137, Norm: 0.0028048891108483076, InvBCE: 14.778165817260742\n",
      "Loss: 13.765949249267578, Norm: 0.0029589668847620487, InvBCE: 13.728857040405273\n",
      "Loss: 12.92413330078125, Norm: 0.003104542149230838, InvBCE: 12.887019157409668\n",
      "Loss: 12.208745002746582, Norm: 0.0032424908131361008, InvBCE: 12.171610832214355\n",
      "Loss: 11.595972061157227, Norm: 0.0033735830802470446, InvBCE: 11.558818817138672\n",
      "Loss: 11.066534042358398, Norm: 0.0034985782112926245, InvBCE: 11.029362678527832\n",
      "Loss: 10.591322898864746, Norm: 0.0036180459428578615, InvBCE: 10.5541353225708\n",
      "Loss: 10.171844482421875, Norm: 0.003732506651431322, InvBCE: 10.134642601013184\n",
      "Loss: 9.79386043548584, Norm: 0.0038424700032919645, InvBCE: 9.756644248962402\n",
      "Image 40...\n",
      "Loss: 0.6859228610992432, Norm: 0.0, InvBCE: 0.6492992639541626\n",
      "Loss: 0.6014089584350586, Norm: 0.0003728920128196478, InvBCE: 0.5647236108779907\n",
      "Image fooled! Adding perturbation...\n",
      "Image 41...\n",
      "Loss: 1.4178273677825928, Norm: 0.0, InvBCE: 1.3810795545578003\n",
      "Loss: 1.4034491777420044, Norm: 0.0003509081434458494, InvBCE: 1.366692304611206\n",
      "Image fooled! Adding perturbation...\n",
      "Image 42...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 43...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 44...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 45...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 46...\n",
      "Loss: 0.5310156941413879, Norm: 0.0, InvBCE: 0.4942505955696106\n",
      "Image fooled! Adding perturbation...\n",
      "Image 47...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 48...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 49...\n",
      "Loss: 1.3789204359054565, Norm: 0.0, InvBCE: 1.342123031616211\n",
      "Loss: 1.3206992149353027, Norm: 0.00037583900848403573, InvBCE: 1.2838438749313354\n",
      "Image fooled! Adding perturbation...\n",
      "Image 50...\n",
      "Loss: 6.168426513671875, Norm: 0.0, InvBCE: 6.131510257720947\n",
      "Loss: 5.21067476272583, Norm: 0.00038189388578757644, InvBCE: 5.173739433288574\n",
      "Loss: 4.495749473571777, Norm: 0.0007508164271712303, InvBCE: 4.458791732788086\n",
      "Loss: 3.946223258972168, Norm: 0.0011077412636950612, InvBCE: 3.90924072265625\n",
      "Loss: 3.4854507446289062, Norm: 0.0014538350515067577, InvBCE: 3.448441505432129\n",
      "Loss: 3.0948312282562256, Norm: 0.0017897447105497122, InvBCE: 3.057793617248535\n",
      "Loss: 2.75807523727417, Norm: 0.0021159218158572912, InvBCE: 2.721008062362671\n",
      "Loss: 2.4621217250823975, Norm: 0.0024330406449735165, InvBCE: 2.4250237941741943\n",
      "Loss: 2.1946282386779785, Norm: 0.0027404269203543663, InvBCE: 2.157498836517334\n",
      "Loss: 1.9568703174591064, Norm: 0.0030396352522075176, InvBCE: 1.9197083711624146\n",
      "Loss: 1.742297649383545, Norm: 0.0033306428231298923, InvBCE: 1.7051024436950684\n",
      "Loss: 1.5463247299194336, Norm: 0.0036134880501776934, InvBCE: 1.509095549583435\n",
      "Loss: 1.3742769956588745, Norm: 0.0038879134226590395, InvBCE: 1.3370133638381958\n",
      "Loss: 1.2235690355300903, Norm: 0.004153440240770578, InvBCE: 1.1862709522247314\n",
      "Loss: 1.09292471408844, Norm: 0.004409806337207556, InvBCE: 1.0555921792984009\n",
      "Loss: 0.9789879322052002, Norm: 0.004656759090721607, InvBCE: 0.9416212439537048\n",
      "Loss: 0.8802794218063354, Norm: 0.0048941317945718765, InvBCE: 0.8428792357444763\n",
      "Loss: 0.795742928981781, Norm: 0.005121913738548756, InvBCE: 0.758310079574585\n",
      "Loss: 0.7240121364593506, Norm: 0.005339934956282377, InvBCE: 0.6865478157997131\n",
      "Loss: 0.6657077074050903, Norm: 0.005548109766095877, InvBCE: 0.6282131671905518\n",
      "Image 51...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 52...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 53...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 54...\n",
      "Loss: 1.480391025543213, Norm: 0.0, InvBCE: 1.4434748888015747\n",
      "Image fooled! Adding perturbation...\n",
      "Image 55...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 56...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 57...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 58...\n",
      "Loss: 1.4441205263137817, Norm: 0.0, InvBCE: 1.4073163270950317\n",
      "Image fooled! Adding perturbation...\n",
      "Image 59...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 60...\n",
      "Loss: 651.3974609375, Norm: 0.0, InvBCE: 651.3607177734375\n",
      "Loss: 309.3882141113281, Norm: 0.000375433883164078, InvBCE: 309.3514404296875\n",
      "Loss: 224.57801818847656, Norm: 0.0006905869813635945, InvBCE: 224.54122924804688\n",
      "Loss: 155.4070587158203, Norm: 0.0009320713579654694, InvBCE: 155.37026977539062\n",
      "Loss: 111.67454528808594, Norm: 0.0011701235780492425, InvBCE: 111.63774871826172\n",
      "Loss: 83.94963073730469, Norm: 0.0013975142501294613, InvBCE: 83.91283416748047\n",
      "Loss: 66.09588623046875, Norm: 0.001612462685443461, InvBCE: 66.05908966064453\n",
      "Loss: 54.308372497558594, Norm: 0.001814871677197516, InvBCE: 54.271575927734375\n",
      "Loss: 45.66447448730469, Norm: 0.0020055726636201143, InvBCE: 45.62767791748047\n",
      "Loss: 40.17887878417969, Norm: 0.002185099059715867, InvBCE: 40.142086029052734\n",
      "Loss: 35.7314453125, Norm: 0.0023545671720057726, InvBCE: 35.69465637207031\n",
      "Loss: 32.29017639160156, Norm: 0.0025148061104118824, InvBCE: 32.253395080566406\n",
      "Loss: 29.621238708496094, Norm: 0.002666665241122246, InvBCE: 29.584463119506836\n",
      "Loss: 27.13739585876465, Norm: 0.002811094280332327, InvBCE: 27.100627899169922\n",
      "Loss: 25.513273239135742, Norm: 0.002948608947917819, InvBCE: 25.47651481628418\n",
      "Loss: 24.115026473999023, Norm: 0.0030799303203821182, InvBCE: 24.078277587890625\n",
      "Loss: 23.35480308532715, Norm: 0.0032056295312941074, InvBCE: 23.318065643310547\n",
      "Loss: 22.37029457092285, Norm: 0.003325535450130701, InvBCE: 22.333568572998047\n",
      "Loss: 21.5374755859375, Norm: 0.0034409132786095142, InvBCE: 21.500761032104492\n",
      "Loss: 20.779293060302734, Norm: 0.0035522764082998037, InvBCE: 20.742591857910156\n",
      "Image 61...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 62...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 63...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 64...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 65...\n",
      "Loss: 0.9507429599761963, Norm: 0.0, InvBCE: 0.9140039086341858\n",
      "Image fooled! Adding perturbation...\n",
      "Image 66...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 67...\n",
      "Loss: 0.5871177911758423, Norm: 0.0, InvBCE: 0.5503681302070618\n",
      "Image fooled! Adding perturbation...\n",
      "Image 68...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 69...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 70...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 71...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 72...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 73...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 74...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 75...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 76...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 77...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 78...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 79...\n",
      "Loss: 809.8603515625, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.860107421875, Norm: 0.00023315112048294395, InvBCE: 809.8235473632812\n",
      "Loss: 809.8599243164062, Norm: 0.0004661314596887678, InvBCE: 809.8235473632812\n",
      "Loss: 809.8596801757812, Norm: 0.0006989288376644254, InvBCE: 809.8235473632812\n",
      "Loss: 809.8594970703125, Norm: 0.0009315306087955832, InvBCE: 809.8235473632812\n",
      "Loss: 809.8592529296875, Norm: 0.0011639244621619582, InvBCE: 809.8235473632812\n",
      "Loss: 809.8590698242188, Norm: 0.0013960977084934711, InvBCE: 809.8235473632812\n",
      "Loss: 809.8588256835938, Norm: 0.001628037542104721, InvBCE: 809.8235473632812\n",
      "Loss: 809.858642578125, Norm: 0.0018597310408949852, InvBCE: 809.8235473632812\n",
      "Loss: 809.8584594726562, Norm: 0.0020911660976707935, InvBCE: 809.8235473632812\n",
      "Loss: 809.8582153320312, Norm: 0.002322329441085458, InvBCE: 809.8235473632812\n",
      "Loss: 809.8580322265625, Norm: 0.0025532084982842207, InvBCE: 809.8235473632812\n",
      "Loss: 809.8577880859375, Norm: 0.0027837902307510376, InvBCE: 809.8235473632812\n",
      "Loss: 809.8576049804688, Norm: 0.0030140625312924385, InvBCE: 809.8235473632812\n",
      "Loss: 809.8573608398438, Norm: 0.003244012361392379, InvBCE: 809.8235473632812\n",
      "Loss: 809.857177734375, Norm: 0.0034736276138573885, InvBCE: 809.8235473632812\n",
      "Loss: 809.8569946289062, Norm: 0.003702895948663354, InvBCE: 809.8235473632812\n",
      "Loss: 809.8567504882812, Norm: 0.003931805025786161, InvBCE: 809.8235473632812\n",
      "Loss: 809.8565673828125, Norm: 0.004160343203693628, InvBCE: 809.8235473632812\n",
      "Loss: 809.8563232421875, Norm: 0.004388498608022928, InvBCE: 809.8235473632812\n",
      "Image 80...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 81...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 82...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 83...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 84...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 85...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 86...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 87...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 88...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 89...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 90...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 91...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 92...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 93...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 94...\n",
      "Loss: 0.8612646460533142, Norm: 0.0, InvBCE: 0.824474573135376\n",
      "Image fooled! Adding perturbation...\n",
      "Image 95...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 96...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 97...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 98...\n",
      "Loss: 1.352278470993042, Norm: 0.0, InvBCE: 1.3154491186141968\n",
      "Image fooled! Adding perturbation...\n",
      "Image 99...\n",
      "Image fooled! Adding perturbation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b45782f5e54c494b932ffd69e8f203a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fooling rate: 0.85\n",
      "Starting epoch 14...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6327f296364d4b5eb36a4fbc9a64e864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 1...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 2...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 3...\n",
      "Loss: 2.890559434890747, Norm: 0.0, InvBCE: 2.8536884784698486\n",
      "Loss: 2.556708574295044, Norm: 0.00038147822488099337, InvBCE: 2.5197930335998535\n",
      "Loss: 2.262239933013916, Norm: 0.0007576048374176025, InvBCE: 2.2252771854400635\n",
      "Loss: 2.0039877891540527, Norm: 0.0011280147591605783, InvBCE: 1.9669755697250366\n",
      "Loss: 1.7787675857543945, Norm: 0.0014913101913407445, InvBCE: 1.7417043447494507\n",
      "Loss: 1.5832196474075317, Norm: 0.0018463433953002095, InvBCE: 1.5461041927337646\n",
      "Loss: 1.4141396284103394, Norm: 0.0021922276355326176, InvBCE: 1.3769713640213013\n",
      "Loss: 1.268527626991272, Norm: 0.002528260461986065, InvBCE: 1.2313060760498047\n",
      "Loss: 1.1434869766235352, Norm: 0.002853883896023035, InvBCE: 1.1062122583389282\n",
      "Loss: 1.0363119840621948, Norm: 0.0031686807051301003, InvBCE: 0.998984158039093\n",
      "Loss: 0.9444902539253235, Norm: 0.003472356591373682, InvBCE: 0.9071100354194641\n",
      "Loss: 0.8656923174858093, Norm: 0.003764755092561245, InvBCE: 0.8282604217529297\n",
      "Loss: 0.7978062033653259, Norm: 0.0040458510629832745, InvBCE: 0.760323703289032\n",
      "Loss: 0.7390090823173523, Norm: 0.004315732512623072, InvBCE: 0.7014772295951843\n",
      "Loss: 0.6878281235694885, Norm: 0.004574574064463377, InvBCE: 0.6502484083175659\n",
      "Loss: 0.6431235074996948, Norm: 0.004822611343115568, InvBCE: 0.6054974794387817\n",
      "Loss: 0.6040218472480774, Norm: 0.005060102790594101, InvBCE: 0.5663512349128723\n",
      "Loss: 0.5698420405387878, Norm: 0.005287341307848692, InvBCE: 0.532128632068634\n",
      "Loss: 0.5400152802467346, Norm: 0.005504624918103218, InvBCE: 0.5022608637809753\n",
      "Loss: 0.5140386819839478, Norm: 0.005712262354791164, InvBCE: 0.47624510526657104\n",
      "Image 4...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 5...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 6...\n",
      "Loss: 1.1729388236999512, Norm: 0.0, InvBCE: 1.1360677480697632\n",
      "Image fooled! Adding perturbation...\n",
      "Image 7...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 8...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 9...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 10...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 11...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 12...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 13...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 14...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 15...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 16...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 17...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 18...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 19...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 20...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 21...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 22...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 23...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 24...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 25...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 26...\n",
      "Loss: 1.4809701442718506, Norm: 0.0, InvBCE: 1.4440855979919434\n",
      "Loss: 1.4792191982269287, Norm: 0.00030457432148978114, InvBCE: 1.4424495697021484\n",
      "Image fooled! Adding perturbation...\n",
      "Image 27...\n",
      "Loss: 0.5576447248458862, Norm: 0.0, InvBCE: 0.5209882855415344\n",
      "Image fooled! Adding perturbation...\n",
      "Image 28...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 29...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 30...\n",
      "Loss: 0.7302525043487549, Norm: 0.0, InvBCE: 0.6934881806373596\n",
      "Image fooled! Adding perturbation...\n",
      "Image 31...\n",
      "Loss: 809.8604125976562, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8601684570312, Norm: 0.0002330743009224534, InvBCE: 809.8235473632812\n",
      "Loss: 809.8599853515625, Norm: 0.0004659779369831085, InvBCE: 809.8235473632812\n",
      "Loss: 809.8597412109375, Norm: 0.0006986986263655126, InvBCE: 809.8235473632812\n",
      "Loss: 809.8595581054688, Norm: 0.000931224029045552, InvBCE: 809.8235473632812\n",
      "Loss: 809.8593139648438, Norm: 0.0011635415721684694, InvBCE: 809.8235473632812\n",
      "Loss: 809.859130859375, Norm: 0.0013956386828795075, InvBCE: 809.8235473632812\n",
      "Loss: 809.85888671875, Norm: 0.0016275027301162481, InvBCE: 809.8235473632812\n",
      "Loss: 809.8587036132812, Norm: 0.0018591205589473248, InvBCE: 809.8235473632812\n",
      "Loss: 809.8584594726562, Norm: 0.0020904801785945892, InvBCE: 809.8235473632812\n",
      "Loss: 809.8582763671875, Norm: 0.0023215683177113533, InvBCE: 809.8235473632812\n",
      "Loss: 809.8580932617188, Norm: 0.0025523724034428596, InvBCE: 809.8235473632812\n",
      "Loss: 809.8578491210938, Norm: 0.0027828796301037073, InvBCE: 809.8235473632812\n",
      "Loss: 809.857666015625, Norm: 0.003013077424839139, InvBCE: 809.8235473632812\n",
      "Loss: 809.857421875, Norm: 0.0032429532147943974, InvBCE: 809.8235473632812\n",
      "Loss: 809.8572387695312, Norm: 0.0034724946599453688, InvBCE: 809.8235473632812\n",
      "Loss: 809.8569946289062, Norm: 0.0037016896530985832, InvBCE: 809.8235473632812\n",
      "Loss: 809.8568115234375, Norm: 0.003930525854229927, InvBCE: 809.8235473632812\n",
      "Loss: 809.8566284179688, Norm: 0.004158991388976574, InvBCE: 809.8235473632812\n",
      "Loss: 809.8563842773438, Norm: 0.004387074615806341, InvBCE: 809.8235473632812\n",
      "Image 32...\n",
      "Loss: 1.4594781398773193, Norm: 0.0, InvBCE: 1.4226365089416504\n",
      "Image fooled! Adding perturbation...\n",
      "Image 33...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 34...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 35...\n",
      "Loss: 1.0050203800201416, Norm: 0.0, InvBCE: 0.9681805968284607\n",
      "Loss: 0.9739957451820374, Norm: 0.0003625229583121836, InvBCE: 0.9371109008789062\n",
      "Loss: 0.9402188062667847, Norm: 0.0007067019469104707, InvBCE: 0.9032931327819824\n",
      "Image fooled! Adding perturbation...\n",
      "Image 36...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 37...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 38...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 39...\n",
      "Loss: 168.1604766845703, Norm: 0.0, InvBCE: 168.12350463867188\n",
      "Loss: 93.31648254394531, Norm: 0.00038461643271148205, InvBCE: 93.27945709228516\n",
      "Loss: 58.40700912475586, Norm: 0.0007384582422673702, InvBCE: 58.369930267333984\n",
      "Loss: 40.39891815185547, Norm: 0.0010646660812199116, InvBCE: 40.36178970336914\n",
      "Loss: 30.924287796020508, Norm: 0.0013644438004121184, InvBCE: 30.887109756469727\n",
      "Loss: 24.443267822265625, Norm: 0.0016400143504142761, InvBCE: 24.406044006347656\n",
      "Loss: 20.317731857299805, Norm: 0.0018954664701595902, InvBCE: 20.28046417236328\n",
      "Loss: 17.502378463745117, Norm: 0.0021335668861865997, InvBCE: 17.465070724487305\n",
      "Loss: 15.44968318939209, Norm: 0.0023563061840832233, InvBCE: 15.412338256835938\n",
      "Loss: 13.939139366149902, Norm: 0.002565520815551281, InvBCE: 13.901759147644043\n",
      "Loss: 12.78441047668457, Norm: 0.0027627190575003624, InvBCE: 12.746997833251953\n",
      "Loss: 11.856283187866211, Norm: 0.0029491528403013945, InvBCE: 11.818840026855469\n",
      "Loss: 11.075636863708496, Norm: 0.0031261155381798744, InvBCE: 11.038164138793945\n",
      "Loss: 10.407206535339355, Norm: 0.0032946309074759483, InvBCE: 10.369707107543945\n",
      "Loss: 9.830669403076172, Norm: 0.0034555455204099417, InvBCE: 9.793144226074219\n",
      "Loss: 9.260265350341797, Norm: 0.003609644714742899, InvBCE: 9.222716331481934\n",
      "Loss: 7.796336650848389, Norm: 0.0037586605176329613, InvBCE: 7.758764266967773\n",
      "Loss: 7.467719554901123, Norm: 0.0039011312182992697, InvBCE: 7.430125713348389\n",
      "Loss: 7.186345100402832, Norm: 0.0040376512333750725, InvBCE: 7.148731231689453\n",
      "Loss: 6.937106132507324, Norm: 0.004168796353042126, InvBCE: 6.899473667144775\n",
      "Image 40...\n",
      "Loss: 0.6127563714981079, Norm: 0.0, InvBCE: 0.5757889151573181\n",
      "Image fooled! Adding perturbation...\n",
      "Image 41...\n",
      "Loss: 1.4077720642089844, Norm: 0.0, InvBCE: 1.370742678642273\n",
      "Image fooled! Adding perturbation...\n",
      "Image 42...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 43...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 44...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 45...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 46...\n",
      "Loss: 0.5153813362121582, Norm: 0.0, InvBCE: 0.47835007309913635\n",
      "Image fooled! Adding perturbation...\n",
      "Image 47...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 48...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 49...\n",
      "Loss: 1.3139557838439941, Norm: 0.0, InvBCE: 1.2768895626068115\n",
      "Image fooled! Adding perturbation...\n",
      "Image 50...\n",
      "Loss: 6.502898693084717, Norm: 0.0, InvBCE: 6.465771198272705\n",
      "Loss: 5.443198204040527, Norm: 0.0003817985125351697, InvBCE: 5.406049728393555\n",
      "Loss: 4.638068675994873, Norm: 0.0007523155654780567, InvBCE: 4.600898265838623\n",
      "Loss: 4.0229997634887695, Norm: 0.0011153677478432655, InvBCE: 3.9858059883117676\n",
      "Loss: 3.548412799835205, Norm: 0.0014687362127006054, InvBCE: 3.5111935138702393\n",
      "Loss: 3.1480636596679688, Norm: 0.0018103626789525151, InvBCE: 3.1108171939849854\n",
      "Loss: 2.808461904525757, Norm: 0.002140530850738287, InvBCE: 2.771186590194702\n",
      "Loss: 2.5091392993927, Norm: 0.0024600031320005655, InvBCE: 2.4718337059020996\n",
      "Loss: 2.2428579330444336, Norm: 0.0027662981301546097, InvBCE: 2.205521583557129\n",
      "Loss: 2.0012965202331543, Norm: 0.003064347431063652, InvBCE: 1.96392822265625\n",
      "Loss: 1.7864561080932617, Norm: 0.0033543184399604797, InvBCE: 1.74905526638031\n",
      "Loss: 1.5903598070144653, Norm: 0.0036361950915306807, InvBCE: 1.552925705909729\n",
      "Loss: 1.4155006408691406, Norm: 0.003909772727638483, InvBCE: 1.378032922744751\n",
      "Loss: 1.2623745203018188, Norm: 0.0041747018694877625, InvBCE: 1.2248730659484863\n",
      "Loss: 1.1280202865600586, Norm: 0.004430809058248997, InvBCE: 1.0904850959777832\n",
      "Loss: 1.0108964443206787, Norm: 0.004677732940763235, InvBCE: 0.9733277559280396\n",
      "Loss: 0.9079196453094482, Norm: 0.004915387835353613, InvBCE: 0.8703181147575378\n",
      "Loss: 0.8187940120697021, Norm: 0.005143731366842985, InvBCE: 0.781160295009613\n",
      "Loss: 0.7438310384750366, Norm: 0.005362650845199823, InvBCE: 0.70616614818573\n",
      "Loss: 0.6811390519142151, Norm: 0.00557194696739316, InvBCE: 0.6434442400932312\n",
      "Image 51...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 52...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 53...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 54...\n",
      "Loss: 1.4799197912216187, Norm: 0.0, InvBCE: 1.4427924156188965\n",
      "Image fooled! Adding perturbation...\n",
      "Image 55...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 56...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 57...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 58...\n",
      "Loss: 1.4423385858535767, Norm: 0.0, InvBCE: 1.4053219556808472\n",
      "Image fooled! Adding perturbation...\n",
      "Image 59...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 60...\n",
      "Loss: 693.0479125976562, Norm: 0.0, InvBCE: 693.010986328125\n",
      "Loss: 325.3692321777344, Norm: 0.0003753587952814996, InvBCE: 325.3322448730469\n",
      "Loss: 220.64537048339844, Norm: 0.0007144416449591517, InvBCE: 220.60836791992188\n",
      "Loss: 149.3945770263672, Norm: 0.0009692950407043099, InvBCE: 149.35757446289062\n",
      "Loss: 105.88111114501953, Norm: 0.00121406395919621, InvBCE: 105.84410095214844\n",
      "Loss: 79.30068969726562, Norm: 0.0014447699068114161, InvBCE: 79.26367950439453\n",
      "Loss: 62.66707229614258, Norm: 0.001660751411691308, InvBCE: 62.630062103271484\n",
      "Loss: 51.693267822265625, Norm: 0.0018624450312927365, InvBCE: 51.6562614440918\n",
      "Loss: 44.22614669799805, Norm: 0.0020518205128610134, InvBCE: 44.18914031982422\n",
      "Loss: 38.711647033691406, Norm: 0.0022291215136647224, InvBCE: 38.67464828491211\n",
      "Loss: 34.6435661315918, Norm: 0.002396036870777607, InvBCE: 34.606571197509766\n",
      "Loss: 31.464406967163086, Norm: 0.0025535656604915857, InvBCE: 31.427419662475586\n",
      "Loss: 28.54203987121582, Norm: 0.002702688332647085, InvBCE: 28.50506019592285\n",
      "Loss: 26.674440383911133, Norm: 0.0028441965114325285, InvBCE: 26.637470245361328\n",
      "Loss: 25.188636779785156, Norm: 0.0029788189567625523, InvBCE: 25.151676177978516\n",
      "Loss: 23.88207244873047, Norm: 0.00310729444026947, InvBCE: 23.845123291015625\n",
      "Loss: 23.220443725585938, Norm: 0.003230195725336671, InvBCE: 23.18350601196289\n",
      "Loss: 22.29290199279785, Norm: 0.0033481933642178774, InvBCE: 22.255977630615234\n",
      "Loss: 21.45836067199707, Norm: 0.0034617125056684017, InvBCE: 21.421449661254883\n",
      "Loss: 20.735036849975586, Norm: 0.0035712039098143578, InvBCE: 20.698139190673828\n",
      "Image 61...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 62...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 63...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 64...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 65...\n",
      "Loss: 0.9329597353935242, Norm: 0.0, InvBCE: 0.8960064649581909\n",
      "Image fooled! Adding perturbation...\n",
      "Image 66...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 67...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 68...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 69...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 70...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 71...\n",
      "Loss: 0.6102395057678223, Norm: 0.0, InvBCE: 0.5732741355895996\n",
      "Image fooled! Adding perturbation...\n",
      "Image 72...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 73...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 74...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 75...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 76...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 77...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 78...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 79...\n",
      "Loss: 809.860595703125, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8603515625, Norm: 0.0002330495772184804, InvBCE: 809.8235473632812\n",
      "Loss: 809.8601684570312, Norm: 0.0004659292462747544, InvBCE: 809.8235473632812\n",
      "Loss: 809.8599243164062, Norm: 0.0006986268563196063, InvBCE: 809.8235473632812\n",
      "Loss: 809.8597412109375, Norm: 0.0009311299654655159, InvBCE: 809.8235473632812\n",
      "Loss: 809.8594970703125, Norm: 0.0011634263209998608, InvBCE: 809.8235473632812\n",
      "Loss: 809.8593139648438, Norm: 0.001395503175444901, InvBCE: 809.8235473632812\n",
      "Loss: 809.8590698242188, Norm: 0.0016273480141535401, InvBCE: 809.8235473632812\n",
      "Loss: 809.85888671875, Norm: 0.001858948147855699, InvBCE: 809.8235473632812\n",
      "Loss: 809.8587036132812, Norm: 0.0020902908872812986, InvBCE: 809.8235473632812\n",
      "Loss: 809.8584594726562, Norm: 0.002321363426744938, InvBCE: 809.8235473632812\n",
      "Loss: 809.8582763671875, Norm: 0.0025521533098071814, InvBCE: 809.8235473632812\n",
      "Loss: 809.8580322265625, Norm: 0.002782647730782628, InvBCE: 809.8235473632812\n",
      "Loss: 809.8578491210938, Norm: 0.0030128343496471643, InvBCE: 809.8235473632812\n",
      "Loss: 809.8576049804688, Norm: 0.0032427008263766766, InvBCE: 809.8235473632812\n",
      "Loss: 809.857421875, Norm: 0.00347223412245512, InvBCE: 809.8235473632812\n",
      "Loss: 809.8572387695312, Norm: 0.003701422829180956, InvBCE: 809.8235473632812\n",
      "Loss: 809.8569946289062, Norm: 0.003930254839360714, InvBCE: 809.8235473632812\n",
      "Loss: 809.8568115234375, Norm: 0.004158718045800924, InvBCE: 809.8235473632812\n",
      "Loss: 809.8565673828125, Norm: 0.004386800341308117, InvBCE: 809.8235473632812\n",
      "Image 80...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 81...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 82...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 83...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 84...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 85...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 86...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 87...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 88...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 89...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 90...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 91...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 92...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 93...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 94...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 95...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 96...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 97...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 98...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 99...\n",
      "Image fooled! Adding perturbation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "456d5cb69adb47fca22c724a30058cff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fooling rate: 0.88\n",
      "Starting epoch 15...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64976b5388e143148def429762142f57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 1...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 2...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 3...\n",
      "Loss: 2.915243148803711, Norm: 0.0, InvBCE: 2.8782060146331787\n",
      "Loss: 2.585829019546509, Norm: 0.00038140779361128807, InvBCE: 2.5487492084503174\n",
      "Loss: 2.2949845790863037, Norm: 0.0007572274771519005, InvBCE: 2.257858991622925\n",
      "Loss: 2.039776086807251, Norm: 0.001127373892813921, InvBCE: 2.0026025772094727\n",
      "Loss: 1.817287802696228, Norm: 0.0014905326534062624, InvBCE: 1.780064582824707\n",
      "Loss: 1.624184012413025, Norm: 0.00184555200394243, InvBCE: 1.5869098901748657\n",
      "Loss: 1.4569268226623535, Norm: 0.002191539155319333, InvBCE: 1.4196010828018188\n",
      "Loss: 1.3121553659439087, Norm: 0.0025278418324887753, InvBCE: 1.2747776508331299\n",
      "Loss: 1.1868685483932495, Norm: 0.0028539858758449554, InvBCE: 1.1494386196136475\n",
      "Loss: 1.0784145593643188, Norm: 0.0031696315854787827, InvBCE: 1.0409324169158936\n",
      "Loss: 0.9844552874565125, Norm: 0.003474536584690213, InvBCE: 0.9469214081764221\n",
      "Loss: 0.9029131531715393, Norm: 0.0037685621064156294, InvBCE: 0.8653281331062317\n",
      "Loss: 0.8319433927536011, Norm: 0.004051670432090759, InvBCE: 0.7943080067634583\n",
      "Loss: 0.7699480056762695, Norm: 0.004323921632021666, InvBCE: 0.7322633862495422\n",
      "Loss: 0.7156004905700684, Norm: 0.004585445858538151, InvBCE: 0.6778678894042969\n",
      "Loss: 0.6678587794303894, Norm: 0.0048364270478487015, InvBCE: 0.6300796866416931\n",
      "Loss: 0.6259154677391052, Norm: 0.005077081266790628, InvBCE: 0.5880913734436035\n",
      "Loss: 0.5891391038894653, Norm: 0.0053076534532010555, InvBCE: 0.5512717366218567\n",
      "Loss: 0.5569865107536316, Norm: 0.005528402514755726, InvBCE: 0.5190775394439697\n",
      "Loss: 0.528962254524231, Norm: 0.005739582236856222, InvBCE: 0.49101343750953674\n",
      "Image 4...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 5...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 6...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 7...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 8...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 9...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 10...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 11...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 12...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 13...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 14...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 15...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 16...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 17...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 18...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 19...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 20...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 21...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 22...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 23...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 24...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 25...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 26...\n",
      "Loss: 1.4804332256317139, Norm: 0.0, InvBCE: 1.4433962106704712\n",
      "Image fooled! Adding perturbation...\n",
      "Image 27...\n",
      "Loss: 0.5514072775840759, Norm: 0.0, InvBCE: 0.5144832730293274\n",
      "Image fooled! Adding perturbation...\n",
      "Image 28...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 29...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 30...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 31...\n",
      "Loss: 809.860595703125, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8603515625, Norm: 0.00023298787709791213, InvBCE: 809.8235473632812\n",
      "Loss: 809.8601684570312, Norm: 0.00046580570051446557, InvBCE: 809.8235473632812\n",
      "Loss: 809.8599243164062, Norm: 0.0006984412902966142, InvBCE: 809.8235473632812\n",
      "Loss: 809.8597412109375, Norm: 0.000930882291868329, InvBCE: 809.8235473632812\n",
      "Loss: 809.8594970703125, Norm: 0.0011631163069978356, InvBCE: 809.8235473632812\n",
      "Loss: 809.8593139648438, Norm: 0.0013951307628303766, InvBCE: 809.8235473632812\n",
      "Loss: 809.8590698242188, Norm: 0.001626912853680551, InvBCE: 809.8235473632812\n",
      "Loss: 809.85888671875, Norm: 0.0018584500066936016, InvBCE: 809.8235473632812\n",
      "Loss: 809.8587036132812, Norm: 0.002089729765430093, InvBCE: 809.8235473632812\n",
      "Loss: 809.8584594726562, Norm: 0.0023207389749586582, InvBCE: 809.8235473632812\n",
      "Loss: 809.8582763671875, Norm: 0.002551465528085828, InvBCE: 809.8235473632812\n",
      "Loss: 809.8580322265625, Norm: 0.002781896386295557, InvBCE: 809.8235473632812\n",
      "Loss: 809.8578491210938, Norm: 0.0030120189767330885, InvBCE: 809.8235473632812\n",
      "Loss: 809.8576049804688, Norm: 0.0032418211922049522, InvBCE: 809.8235473632812\n",
      "Loss: 809.857421875, Norm: 0.003471290459856391, InvBCE: 809.8235473632812\n",
      "Loss: 809.8572387695312, Norm: 0.0037004146724939346, InvBCE: 809.8235473632812\n",
      "Loss: 809.8569946289062, Norm: 0.003929181955754757, InvBCE: 809.8235473632812\n",
      "Loss: 809.8568115234375, Norm: 0.004157579503953457, InvBCE: 809.8235473632812\n",
      "Loss: 809.8565673828125, Norm: 0.004385596606880426, InvBCE: 809.8235473632812\n",
      "Image 32...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 33...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 34...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 35...\n",
      "Loss: 0.9556825160980225, Norm: 0.0, InvBCE: 0.9186510443687439\n",
      "Image fooled! Adding perturbation...\n",
      "Image 36...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 37...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 38...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 39...\n",
      "Loss: 125.70333099365234, Norm: 0.0, InvBCE: 125.66625213623047\n",
      "Loss: 73.09036254882812, Norm: 0.00038452778244391084, InvBCE: 73.05322265625\n",
      "Loss: 46.97796630859375, Norm: 0.000740187184419483, InvBCE: 46.94077682495117\n",
      "Loss: 33.96357345581055, Norm: 0.0010665390873327851, InvBCE: 33.92633056640625\n",
      "Loss: 26.34263038635254, Norm: 0.0013669354375451803, InvBCE: 26.30533790588379\n",
      "Loss: 21.482969284057617, Norm: 0.0016455750446766615, InvBCE: 21.44563102722168\n",
      "Loss: 18.12925148010254, Norm: 0.0019055932061746716, InvBCE: 18.091869354248047\n",
      "Loss: 15.797840118408203, Norm: 0.0021491835359483957, InvBCE: 15.760416984558105\n",
      "Loss: 14.112467765808105, Norm: 0.0023782779462635517, InvBCE: 14.075006484985352\n",
      "Loss: 12.854710578918457, Norm: 0.0025945052038878202, InvBCE: 12.81721305847168\n",
      "Loss: 11.849331855773926, Norm: 0.0027992473915219307, InvBCE: 11.811800003051758\n",
      "Loss: 10.997014045715332, Norm: 0.0029939915984869003, InvBCE: 10.959450721740723\n",
      "Loss: 10.280455589294434, Norm: 0.003179770428687334, InvBCE: 10.2428617477417\n",
      "Loss: 9.647235870361328, Norm: 0.0033574984408915043, InvBCE: 9.609612464904785\n",
      "Loss: 8.025906562805176, Norm: 0.0035283672623336315, InvBCE: 7.988256454467773\n",
      "Loss: 7.640903472900391, Norm: 0.003691752441227436, InvBCE: 7.603227138519287\n",
      "Loss: 7.313068866729736, Norm: 0.003848315915092826, InvBCE: 7.2753682136535645\n",
      "Loss: 7.023820877075195, Norm: 0.003998674917966127, InvBCE: 6.98609733581543\n",
      "Loss: 6.767571926116943, Norm: 0.004143392201513052, InvBCE: 6.729827404022217\n",
      "Loss: 6.537724018096924, Norm: 0.004282954148948193, InvBCE: 6.499959468841553\n",
      "Image 40...\n",
      "Loss: 0.5812875032424927, Norm: 0.0, InvBCE: 0.5442065000534058\n",
      "Image fooled! Adding perturbation...\n",
      "Image 41...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 42...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 43...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 44...\n",
      "Loss: 0.7514727115631104, Norm: 0.0, InvBCE: 0.7143293619155884\n",
      "Image fooled! Adding perturbation...\n",
      "Image 45...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 46...\n",
      "Loss: 0.5064243674278259, Norm: 0.0, InvBCE: 0.4692288041114807\n",
      "Image fooled! Adding perturbation...\n",
      "Image 47...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 48...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 49...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 50...\n",
      "Loss: 6.881157398223877, Norm: 0.0, InvBCE: 6.843925476074219\n",
      "Loss: 5.7115302085876465, Norm: 0.00038201166898943484, InvBCE: 5.674278736114502\n",
      "Loss: 4.860934734344482, Norm: 0.000752254098188132, InvBCE: 4.823661804199219\n",
      "Loss: 4.229990005493164, Norm: 0.001110450248233974, InvBCE: 4.192694187164307\n",
      "Loss: 3.744225263595581, Norm: 0.001455881749279797, InvBCE: 3.7069053649902344\n",
      "Loss: 3.331618070602417, Norm: 0.0017893366748467088, InvBCE: 3.2942724227905273\n",
      "Loss: 2.975867509841919, Norm: 0.002111947163939476, InvBCE: 2.938494920730591\n",
      "Loss: 2.6676692962646484, Norm: 0.0024240599013864994, InvBCE: 2.6302688121795654\n",
      "Loss: 2.396307945251465, Norm: 0.002727061975747347, InvBCE: 2.3588788509368896\n",
      "Loss: 2.1448323726654053, Norm: 0.003021670738235116, InvBCE: 2.1073739528656006\n",
      "Loss: 1.920336365699768, Norm: 0.0033082833979278803, InvBCE: 1.8828476667404175\n",
      "Loss: 1.7205430269241333, Norm: 0.0035867930855602026, InvBCE: 1.6830235719680786\n",
      "Loss: 1.5391566753387451, Norm: 0.00385712506249547, InvBCE: 1.5016062259674072\n",
      "Loss: 1.3780224323272705, Norm: 0.004119130317121744, InvBCE: 1.3404407501220703\n",
      "Loss: 1.2359750270843506, Norm: 0.004372561816126108, InvBCE: 1.198362112045288\n",
      "Loss: 1.1096917390823364, Norm: 0.004617335274815559, InvBCE: 1.0720478296279907\n",
      "Loss: 0.9998888969421387, Norm: 0.004853302612900734, InvBCE: 0.9622143507003784\n",
      "Loss: 0.9026088714599609, Norm: 0.005080326925963163, InvBCE: 0.8649042844772339\n",
      "Loss: 0.8182607293128967, Norm: 0.005298460368067026, InvBCE: 0.7805268168449402\n",
      "Loss: 0.746924638748169, Norm: 0.005507551599293947, InvBCE: 0.7091623544692993\n",
      "Image 51...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 52...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 53...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 54...\n",
      "Loss: 1.479529857635498, Norm: 0.0, InvBCE: 1.4422979354858398\n",
      "Image fooled! Adding perturbation...\n",
      "Image 55...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 56...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 57...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 58...\n",
      "Loss: 1.438977599143982, Norm: 0.0, InvBCE: 1.401855230331421\n",
      "Image fooled! Adding perturbation...\n",
      "Image 59...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 60...\n",
      "Loss: 802.8850708007812, Norm: 0.0, InvBCE: 802.8480224609375\n",
      "Loss: 376.25506591796875, Norm: 0.00037533952854573727, InvBCE: 376.2179870605469\n",
      "Loss: 249.28759765625, Norm: 0.0007144560222513974, InvBCE: 249.25048828125\n",
      "Loss: 149.58642578125, Norm: 0.0010278299450874329, InvBCE: 149.54930114746094\n",
      "Loss: 97.45680236816406, Norm: 0.001313585671596229, InvBCE: 97.41966247558594\n",
      "Loss: 70.27271270751953, Norm: 0.0015733845066279173, InvBCE: 70.23556518554688\n",
      "Loss: 54.6826057434082, Norm: 0.0018104084301739931, InvBCE: 54.64544677734375\n",
      "Loss: 44.96218490600586, Norm: 0.0020277067087590694, InvBCE: 44.92502212524414\n",
      "Loss: 38.24334716796875, Norm: 0.002227776451036334, InvBCE: 38.20618438720703\n",
      "Loss: 33.63999938964844, Norm: 0.002413119189441204, InvBCE: 33.60283660888672\n",
      "Loss: 29.774059295654297, Norm: 0.002585682086646557, InvBCE: 29.73689842224121\n",
      "Loss: 27.42526626586914, Norm: 0.0027469811029732227, InvBCE: 27.38810920715332\n",
      "Loss: 25.498703002929688, Norm: 0.0028982677031308413, InvBCE: 25.461551666259766\n",
      "Loss: 24.414236068725586, Norm: 0.003040747717022896, InvBCE: 24.377092361450195\n",
      "Loss: 23.159677505493164, Norm: 0.00317543838173151, InvBCE: 23.122543334960938\n",
      "Loss: 22.09192657470703, Norm: 0.0033032414503395557, InvBCE: 22.05480194091797\n",
      "Loss: 21.216882705688477, Norm: 0.0034249136224389076, InvBCE: 21.179767608642578\n",
      "Loss: 20.448545455932617, Norm: 0.0035411345306783915, InvBCE: 20.41144371032715\n",
      "Loss: 19.784706115722656, Norm: 0.003652446437627077, InvBCE: 19.747615814208984\n",
      "Loss: 19.216800689697266, Norm: 0.0037593855522572994, InvBCE: 19.179723739624023\n",
      "Image 61...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 62...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 63...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 64...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 65...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 66...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 67...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 68...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 69...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 70...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 71...\n",
      "Loss: 0.5874456763267517, Norm: 0.0, InvBCE: 0.5503858923912048\n",
      "Image fooled! Adding perturbation...\n",
      "Image 72...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 73...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 74...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 75...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 76...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 77...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 78...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 79...\n",
      "Loss: 809.8606567382812, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8604736328125, Norm: 0.00023296837753150612, InvBCE: 809.8235473632812\n",
      "Loss: 809.8602294921875, Norm: 0.00046576716704294086, InvBCE: 809.8235473632812\n",
      "Loss: 809.8600463867188, Norm: 0.0006983841303735971, InvBCE: 809.8235473632812\n",
      "Loss: 809.8598022460938, Norm: 0.0009308069129474461, InvBCE: 809.8235473632812\n",
      "Loss: 809.859619140625, Norm: 0.001163023291155696, InvBCE: 809.8235473632812\n",
      "Loss: 809.8594360351562, Norm: 0.0013950205175206065, InvBCE: 809.8235473632812\n",
      "Loss: 809.8591918945312, Norm: 0.0016267863102257252, InvBCE: 809.8235473632812\n",
      "Loss: 809.8590087890625, Norm: 0.001858307747170329, InvBCE: 809.8235473632812\n",
      "Loss: 809.8587646484375, Norm: 0.002089572139084339, InvBCE: 809.8235473632812\n",
      "Loss: 809.8585815429688, Norm: 0.002320566913112998, InvBCE: 809.8235473632812\n",
      "Loss: 809.8583374023438, Norm: 0.0025512794964015484, InvBCE: 809.8235473632812\n",
      "Loss: 809.858154296875, Norm: 0.002781697316095233, InvBCE: 809.8235473632812\n",
      "Loss: 809.85791015625, Norm: 0.003011808032169938, InvBCE: 809.8235473632812\n",
      "Loss: 809.8577270507812, Norm: 0.0032415990717709064, InvBCE: 809.8235473632812\n",
      "Loss: 809.8575439453125, Norm: 0.0034710578620433807, InvBCE: 809.8235473632812\n",
      "Loss: 809.8572998046875, Norm: 0.0037001725286245346, InvBCE: 809.8235473632812\n",
      "Loss: 809.8571166992188, Norm: 0.003928930964320898, InvBCE: 809.8235473632812\n",
      "Loss: 809.8568725585938, Norm: 0.004157321527600288, InvBCE: 809.8235473632812\n",
      "Loss: 809.856689453125, Norm: 0.00438533304259181, InvBCE: 809.8235473632812\n",
      "Image 80...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 81...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 82...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 83...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 84...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 85...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 86...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 87...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 88...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 89...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 90...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 91...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 92...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 93...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 94...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 95...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 96...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 97...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 98...\n",
      "Loss: 1.3514626026153564, Norm: 0.0, InvBCE: 1.3143303394317627\n",
      "Image fooled! Adding perturbation...\n",
      "Image 99...\n",
      "Image fooled! Adding perturbation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ffd8ebdc8b644fe90a1df7bb13a8642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fooling rate: 0.85\n",
      "Starting epoch 16...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87876d4f2bc549b19e4ef064de1af663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 1...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 2...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 3...\n",
      "Loss: 2.737297773361206, Norm: 0.0, InvBCE: 2.7001237869262695\n",
      "Loss: 2.4238932132720947, Norm: 0.00038133299676701427, InvBCE: 2.3866772651672363\n",
      "Loss: 2.1474080085754395, Norm: 0.0007565947016701102, InvBCE: 2.110147476196289\n",
      "Loss: 1.905051589012146, Norm: 0.001125786337070167, InvBCE: 1.8677446842193604\n",
      "Loss: 1.6938438415527344, Norm: 0.0014877183130010962, InvBCE: 1.6564888954162598\n",
      "Loss: 1.5106295347213745, Norm: 0.001841532182879746, InvBCE: 1.4732253551483154\n",
      "Loss: 1.352137565612793, Norm: 0.0021864918526262045, InvBCE: 1.3146833181381226\n",
      "Loss: 1.2152618169784546, Norm: 0.0025219398085027933, InvBCE: 1.1777567863464355\n",
      "Loss: 1.097119927406311, Norm: 0.0028473089914768934, InvBCE: 1.0595638751983643\n",
      "Loss: 0.9951093196868896, Norm: 0.0031621584203094244, InvBCE: 0.9575022459030151\n",
      "Loss: 0.906897246837616, Norm: 0.0034661891404539347, InvBCE: 0.8692395091056824\n",
      "Loss: 0.8304735422134399, Norm: 0.0037592430599033833, InvBCE: 0.792765736579895\n",
      "Loss: 0.764151394367218, Norm: 0.004041265696287155, InvBCE: 0.726394534111023\n",
      "Loss: 0.7065768837928772, Norm: 0.004312280565500259, InvBCE: 0.6687720417976379\n",
      "Loss: 0.6566680073738098, Norm: 0.004572378005832434, InvBCE: 0.6188165545463562\n",
      "Loss: 0.6135203838348389, Norm: 0.004821698646992445, InvBCE: 0.5756238102912903\n",
      "Loss: 0.5763209462165833, Norm: 0.005060413386672735, InvBCE: 0.5383808016777039\n",
      "Loss: 0.544317901134491, Norm: 0.005288729909807444, InvBCE: 0.5063359141349792\n",
      "Loss: 0.5168218016624451, Norm: 0.005506881978362799, InvBCE: 0.47879964113235474\n",
      "Loss: 0.493205189704895, Norm: 0.005715135484933853, InvBCE: 0.45514458417892456\n",
      "Image 4...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 5...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 6...\n",
      "Loss: 1.1756619215011597, Norm: 0.0, InvBCE: 1.1384879350662231\n",
      "Image fooled! Adding perturbation...\n",
      "Image 7...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 8...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 9...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 10...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 11...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 12...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 13...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 14...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 15...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 16...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 17...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 18...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 19...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 20...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 21...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 22...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 23...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 24...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 25...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 26...\n",
      "Loss: 1.4811806678771973, Norm: 0.0, InvBCE: 1.4439924955368042\n",
      "Image fooled! Adding perturbation...\n",
      "Image 27...\n",
      "Loss: 0.5368048548698425, Norm: 0.0, InvBCE: 0.49973049759864807\n",
      "Image fooled! Adding perturbation...\n",
      "Image 28...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 29...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 30...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 31...\n",
      "Loss: 809.8607177734375, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8605346679688, Norm: 0.00023294701531995088, InvBCE: 809.8235473632812\n",
      "Loss: 809.8602905273438, Norm: 0.0004657246172428131, InvBCE: 809.8235473632812\n",
      "Loss: 809.860107421875, Norm: 0.0006983206840232015, InvBCE: 809.8235473632812\n",
      "Loss: 809.85986328125, Norm: 0.0009307228610850871, InvBCE: 809.8235473632812\n",
      "Loss: 809.8596801757812, Norm: 0.0011629188666120172, InvBCE: 809.8235473632812\n",
      "Loss: 809.8594360351562, Norm: 0.0013948960695415735, InvBCE: 809.8235473632812\n",
      "Loss: 809.8592529296875, Norm: 0.0016266419552266598, InvBCE: 809.8235473632812\n",
      "Loss: 809.8590087890625, Norm: 0.0018581440672278404, InvBCE: 809.8235473632812\n",
      "Loss: 809.8588256835938, Norm: 0.002089389367029071, InvBCE: 809.8235473632812\n",
      "Loss: 809.858642578125, Norm: 0.0023203652817755938, InvBCE: 809.8235473632812\n",
      "Loss: 809.8583984375, Norm: 0.002551059704273939, InvBCE: 809.8235473632812\n",
      "Loss: 809.8582153320312, Norm: 0.002781459828838706, InvBCE: 809.8235473632812\n",
      "Loss: 809.8579711914062, Norm: 0.0030115528497844934, InvBCE: 809.8235473632812\n",
      "Loss: 809.8577880859375, Norm: 0.003241326892748475, InvBCE: 809.8235473632812\n",
      "Loss: 809.8575439453125, Norm: 0.00347076915204525, InvBCE: 809.8235473632812\n",
      "Loss: 809.8573608398438, Norm: 0.0036998679861426353, InvBCE: 809.8235473632812\n",
      "Loss: 809.857177734375, Norm: 0.003928611520677805, InvBCE: 809.8235473632812\n",
      "Loss: 809.85693359375, Norm: 0.004156986717134714, InvBCE: 809.8235473632812\n",
      "Loss: 809.8567504882812, Norm: 0.004384983796626329, InvBCE: 809.8235473632812\n",
      "Image 32...\n",
      "Loss: 1.454637885093689, Norm: 0.0, InvBCE: 1.4174561500549316\n",
      "Image fooled! Adding perturbation...\n",
      "Image 33...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 34...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 35...\n",
      "Loss: 0.9586209654808044, Norm: 0.0, InvBCE: 0.9214420914649963\n",
      "Image fooled! Adding perturbation...\n",
      "Image 36...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 37...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 38...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 39...\n",
      "Loss: 116.90153503417969, Norm: 0.0, InvBCE: 116.86430358886719\n",
      "Loss: 68.6712646484375, Norm: 0.0003845246392302215, InvBCE: 68.63397979736328\n",
      "Loss: 44.95866012573242, Norm: 0.000739687355235219, InvBCE: 44.92131805419922\n",
      "Loss: 33.1085090637207, Norm: 0.0010672961361706257, InvBCE: 33.07111740112305\n",
      "Loss: 25.472095489501953, Norm: 0.0013702519936487079, InvBCE: 25.434654235839844\n",
      "Loss: 20.788414001464844, Norm: 0.0016515274764969945, InvBCE: 20.750926971435547\n",
      "Loss: 17.68096160888672, Norm: 0.0019140024669468403, InvBCE: 17.643430709838867\n",
      "Loss: 15.472840309143066, Norm: 0.0021599926985800266, InvBCE: 15.435269355773926\n",
      "Loss: 13.899038314819336, Norm: 0.00239130319096148, InvBCE: 13.861428260803223\n",
      "Loss: 12.678433418273926, Norm: 0.002609861083328724, InvBCE: 12.640787124633789\n",
      "Loss: 11.69699764251709, Norm: 0.0028169790748506784, InvBCE: 11.659317970275879\n",
      "Loss: 10.878921508789062, Norm: 0.0030140734743326902, InvBCE: 10.841208457946777\n",
      "Loss: 10.186524391174316, Norm: 0.0032022332306951284, InvBCE: 10.148780822753906\n",
      "Loss: 8.477519989013672, Norm: 0.003382451366633177, InvBCE: 8.439746856689453\n",
      "Loss: 7.978640079498291, Norm: 0.003556287381798029, InvBCE: 7.940838813781738\n",
      "Loss: 7.60740852355957, Norm: 0.0037224809639155865, InvBCE: 7.569580554962158\n",
      "Loss: 7.282618999481201, Norm: 0.0038817510940134525, InvBCE: 7.2447662353515625\n",
      "Loss: 6.9956440925598145, Norm: 0.004034802317619324, InvBCE: 6.957767486572266\n",
      "Loss: 6.738646030426025, Norm: 0.004182173404842615, InvBCE: 6.700747013092041\n",
      "Loss: 6.507197380065918, Norm: 0.004324405919760466, InvBCE: 6.4692769050598145\n",
      "Image 40...\n",
      "Loss: 0.5797030925750732, Norm: 0.0, InvBCE: 0.5424693822860718\n",
      "Image fooled! Adding perturbation...\n",
      "Image 41...\n",
      "Loss: 1.409013271331787, Norm: 0.0, InvBCE: 1.3717172145843506\n",
      "Image fooled! Adding perturbation...\n",
      "Image 42...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 43...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 44...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 45...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 46...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 47...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 48...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 49...\n",
      "Loss: 1.337422251701355, Norm: 0.0, InvBCE: 1.3001245260238647\n",
      "Image fooled! Adding perturbation...\n",
      "Image 50...\n",
      "Loss: 6.694908142089844, Norm: 0.0, InvBCE: 6.657550811767578\n",
      "Loss: 5.599688529968262, Norm: 0.0003819351550191641, InvBCE: 5.562310695648193\n",
      "Loss: 4.804637432098389, Norm: 0.0007509105489589274, InvBCE: 4.767237663269043\n",
      "Loss: 4.216582775115967, Norm: 0.0011080673430114985, InvBCE: 4.179159164428711\n",
      "Loss: 3.7323262691497803, Norm: 0.001452424912713468, InvBCE: 3.6948771476745605\n",
      "Loss: 3.323195219039917, Norm: 0.0017859147628769279, InvBCE: 3.285719633102417\n",
      "Loss: 2.969043493270874, Norm: 0.0021097627468407154, InvBCE: 2.9315402507781982\n",
      "Loss: 2.6574714183807373, Norm: 0.0024240948259830475, InvBCE: 2.6199398040771484\n",
      "Loss: 2.3806397914886475, Norm: 0.0027307996060699224, InvBCE: 2.34307861328125\n",
      "Loss: 2.1221492290496826, Norm: 0.0030293383169919252, InvBCE: 2.08455753326416\n",
      "Loss: 1.8926705121994019, Norm: 0.0033199938479810953, InvBCE: 1.8550478219985962\n",
      "Loss: 1.6852532625198364, Norm: 0.0036026188172399998, InvBCE: 1.6475989818572998\n",
      "Loss: 1.4985970258712769, Norm: 0.0038771419785916805, InvBCE: 1.4609107971191406\n",
      "Loss: 1.3354994058609009, Norm: 0.0041431705467402935, InvBCE: 1.2977811098098755\n",
      "Loss: 1.1920928955078125, Norm: 0.004400405567139387, InvBCE: 1.1543426513671875\n",
      "Loss: 1.0650370121002197, Norm: 0.004648699890822172, InvBCE: 1.0272550582885742\n",
      "Loss: 0.9547910094261169, Norm: 0.0048879883252084255, InvBCE: 0.9169778823852539\n",
      "Loss: 0.8590197563171387, Norm: 0.005117878783494234, InvBCE: 0.8211761713027954\n",
      "Loss: 0.7768089175224304, Norm: 0.0053383056074380875, InvBCE: 0.7389355897903442\n",
      "Loss: 0.7108203768730164, Norm: 0.00554907089099288, InvBCE: 0.6729184985160828\n",
      "Image 51...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 52...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 53...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 54...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 55...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 56...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 57...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 58...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 59...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 60...\n",
      "Loss: 653.2239379882812, Norm: 0.0, InvBCE: 653.1865844726562\n",
      "Loss: 306.74212646484375, Norm: 0.00037526580854319036, InvBCE: 306.7047424316406\n",
      "Loss: 215.94430541992188, Norm: 0.0007102568633854389, InvBCE: 215.9069061279297\n",
      "Loss: 129.3651123046875, Norm: 0.0010083607630804181, InvBCE: 129.32769775390625\n",
      "Loss: 87.41960144042969, Norm: 0.0012835920788347721, InvBCE: 87.3821792602539\n",
      "Loss: 64.41292572021484, Norm: 0.0015359855024144053, InvBCE: 64.37549591064453\n",
      "Loss: 50.65159225463867, Norm: 0.0017679667798802257, InvBCE: 50.614158630371094\n",
      "Loss: 42.287574768066406, Norm: 0.001982436515390873, InvBCE: 42.25014114379883\n",
      "Loss: 36.23318862915039, Norm: 0.0021812564227730036, InvBCE: 36.19575500488281\n",
      "Loss: 31.963809967041016, Norm: 0.0023662406019866467, InvBCE: 31.92637825012207\n",
      "Loss: 28.427873611450195, Norm: 0.0025390679948031902, InvBCE: 28.39044761657715\n",
      "Loss: 26.220670700073242, Norm: 0.002701032441109419, InvBCE: 26.183250427246094\n",
      "Loss: 24.413230895996094, Norm: 0.002853481564670801, InvBCE: 24.375818252563477\n",
      "Loss: 23.383211135864258, Norm: 0.0029973448254168034, InvBCE: 23.345808029174805\n",
      "Loss: 22.20049285888672, Norm: 0.0031337908003479242, InvBCE: 22.16309928894043\n",
      "Loss: 21.23183822631836, Norm: 0.0032636080868542194, InvBCE: 21.194456100463867\n",
      "Loss: 20.352497100830078, Norm: 0.0033867289312183857, InvBCE: 20.315126419067383\n",
      "Loss: 19.62169647216797, Norm: 0.003504666965454817, InvBCE: 19.584339141845703\n",
      "Loss: 18.986421585083008, Norm: 0.0036179746966809034, InvBCE: 18.949079513549805\n",
      "Loss: 18.439985275268555, Norm: 0.003727145027369261, InvBCE: 18.40265655517578\n",
      "Image 61...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 62...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 63...\n",
      "Loss: 1.3513195514678955, Norm: 0.0, InvBCE: 1.3139622211456299\n",
      "Image fooled! Adding perturbation...\n",
      "Image 64...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 65...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 66...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 67...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 68...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 69...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 70...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 71...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 72...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 73...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 74...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 75...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 76...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 77...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 78...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 79...\n",
      "Loss: 809.8609619140625, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8607177734375, Norm: 0.00023296810104511678, InvBCE: 809.8235473632812\n",
      "Loss: 809.8605346679688, Norm: 0.0004657675453927368, InvBCE: 809.8235473632812\n",
      "Loss: 809.8602905273438, Norm: 0.0006983861094340682, InvBCE: 809.8235473632812\n",
      "Loss: 809.860107421875, Norm: 0.0009308118023909628, InvBCE: 809.8235473632812\n",
      "Loss: 809.85986328125, Norm: 0.0011630321387201548, InvBCE: 809.8235473632812\n",
      "Loss: 809.8596801757812, Norm: 0.0013950347201898694, InvBCE: 809.8235473632812\n",
      "Loss: 809.8594360351562, Norm: 0.0016268069157376885, InvBCE: 809.8235473632812\n",
      "Loss: 809.8592529296875, Norm: 0.0018583362689241767, InvBCE: 809.8235473632812\n",
      "Loss: 809.8590087890625, Norm: 0.0020896103233098984, InvBCE: 809.8235473632812\n",
      "Loss: 809.8588256835938, Norm: 0.0023206165060400963, InvBCE: 809.8235473632812\n",
      "Loss: 809.8585815429688, Norm: 0.0025513418950140476, InvBCE: 809.8235473632812\n",
      "Loss: 809.8583984375, Norm: 0.002781774615868926, InvBCE: 809.8235473632812\n",
      "Loss: 809.8582153320312, Norm: 0.0030119018629193306, InvBCE: 809.8235473632812\n",
      "Loss: 809.8579711914062, Norm: 0.003241711063310504, InvBCE: 809.8235473632812\n",
      "Loss: 809.8577880859375, Norm: 0.003471190808340907, InvBCE: 809.8235473632812\n",
      "Loss: 809.8575439453125, Norm: 0.0037003285251557827, InvBCE: 809.8235473632812\n",
      "Loss: 809.8573608398438, Norm: 0.003929112106561661, InvBCE: 809.8235473632812\n",
      "Loss: 809.857177734375, Norm: 0.0041575306095182896, InvBCE: 809.8235473632812\n",
      "Loss: 809.85693359375, Norm: 0.0043855709955096245, InvBCE: 809.8235473632812\n",
      "Image 80...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 81...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 82...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 83...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 84...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 85...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 86...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 87...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 88...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 89...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 90...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 91...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 92...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 93...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 94...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 95...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 96...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 97...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 98...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 99...\n",
      "Image fooled! Adding perturbation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7aa0b61469c41ccbdfd7667fd5e0482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fooling rate: 0.91\n",
      "Starting epoch 17...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5583f6787320413ba7d779487f78a991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 1...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 2...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 3...\n",
      "Loss: 2.7794058322906494, Norm: 0.0, InvBCE: 2.742020606994629\n",
      "Loss: 2.4657645225524902, Norm: 0.0003813198709394783, InvBCE: 2.4283363819122314\n",
      "Loss: 2.189441204071045, Norm: 0.0007569206645712256, InvBCE: 2.151967763900757\n",
      "Loss: 1.947590708732605, Norm: 0.0011264538625255227, InvBCE: 1.9100697040557861\n",
      "Loss: 1.736924409866333, Norm: 0.001488697831518948, InvBCE: 1.6993544101715088\n",
      "Loss: 1.5540188550949097, Norm: 0.0018426751485094428, InvBCE: 1.5163986682891846\n",
      "Loss: 1.3954544067382812, Norm: 0.0021876422688364983, InvBCE: 1.3577831983566284\n",
      "Loss: 1.258043646812439, Norm: 0.0025230152532458305, InvBCE: 1.2203209400177002\n",
      "Loss: 1.1389521360397339, Norm: 0.002848326927050948, InvBCE: 1.1011775732040405\n",
      "Loss: 1.035683274269104, Norm: 0.0031632280442863703, InvBCE: 0.9978569149971008\n",
      "Loss: 0.9460315704345703, Norm: 0.0034674950875341892, InvBCE: 0.9081536531448364\n",
      "Loss: 0.8680235743522644, Norm: 0.0037610032595694065, InvBCE: 0.8300947546958923\n",
      "Loss: 0.7999442219734192, Norm: 0.004043729975819588, InvBCE: 0.7619653344154358\n",
      "Loss: 0.74034583568573, Norm: 0.0043157292529940605, InvBCE: 0.7023179531097412\n",
      "Loss: 0.6880906820297241, Norm: 0.004577117972075939, InvBCE: 0.6500151753425598\n",
      "Loss: 0.6423081755638123, Norm: 0.004828053992241621, InvBCE: 0.6041865348815918\n",
      "Loss: 0.6023074388504028, Norm: 0.005068715661764145, InvBCE: 0.5641412138938904\n",
      "Loss: 0.5674871802330017, Norm: 0.005299300886690617, InvBCE: 0.529278039932251\n",
      "Loss: 0.5372840166091919, Norm: 0.005520027130842209, InvBCE: 0.499033659696579\n",
      "Loss: 0.5111653804779053, Norm: 0.0057311286218464375, InvBCE: 0.47287559509277344\n",
      "Image 4...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 5...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 6...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 7...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 8...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 9...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 10...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 11...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 12...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 13...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 14...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 15...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 16...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 17...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 18...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 19...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 20...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 21...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 22...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 23...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 24...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 25...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 26...\n",
      "Loss: 1.4799044132232666, Norm: 0.0, InvBCE: 1.442519187927246\n",
      "Image fooled! Adding perturbation...\n",
      "Image 27...\n",
      "Loss: 0.5369917154312134, Norm: 0.0, InvBCE: 0.49972012639045715\n",
      "Image fooled! Adding perturbation...\n",
      "Image 28...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 29...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 30...\n",
      "Loss: 0.7188177704811096, Norm: 0.0, InvBCE: 0.681438684463501\n",
      "Image fooled! Adding perturbation...\n",
      "Image 31...\n",
      "Loss: 809.8610229492188, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8607788085938, Norm: 0.00023293208505492657, InvBCE: 809.8235473632812\n",
      "Loss: 809.860595703125, Norm: 0.0004656957753468305, InvBCE: 809.8235473632812\n",
      "Loss: 809.8603515625, Norm: 0.0006982791237533092, InvBCE: 809.8235473632812\n",
      "Loss: 809.8601684570312, Norm: 0.0009306696592830122, InvBCE: 809.8235473632812\n",
      "Loss: 809.8599243164062, Norm: 0.0011628554202616215, InvBCE: 809.8235473632812\n",
      "Loss: 809.8597412109375, Norm: 0.0013948238920420408, InvBCE: 809.8235473632812\n",
      "Loss: 809.8594970703125, Norm: 0.0016265623271465302, InvBCE: 809.8235473632812\n",
      "Loss: 809.8593139648438, Norm: 0.0018580583855509758, InvBCE: 809.8235473632812\n",
      "Loss: 809.8590698242188, Norm: 0.002089299727231264, InvBCE: 809.8235473632812\n",
      "Loss: 809.85888671875, Norm: 0.002320273546501994, InvBCE: 809.8235473632812\n",
      "Loss: 809.8587036132812, Norm: 0.002550967503339052, InvBCE: 809.8235473632812\n",
      "Loss: 809.8584594726562, Norm: 0.002781369024887681, InvBCE: 809.8235473632812\n",
      "Loss: 809.8582763671875, Norm: 0.0030114660039544106, InvBCE: 809.8235473632812\n",
      "Loss: 809.8580322265625, Norm: 0.0032412458676844835, InvBCE: 809.8235473632812\n",
      "Loss: 809.8578491210938, Norm: 0.0034706962760537863, InvBCE: 809.8235473632812\n",
      "Loss: 809.857666015625, Norm: 0.0036998060531914234, InvBCE: 809.8235473632812\n",
      "Loss: 809.857421875, Norm: 0.003928562626242638, InvBCE: 809.8235473632812\n",
      "Loss: 809.8572387695312, Norm: 0.004156954120844603, InvBCE: 809.8235473632812\n",
      "Loss: 809.8569946289062, Norm: 0.004384969361126423, InvBCE: 809.8235473632812\n",
      "Image 32...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 33...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 34...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 35...\n",
      "Loss: 0.9629897475242615, Norm: 0.0, InvBCE: 0.9255346059799194\n",
      "Image fooled! Adding perturbation...\n",
      "Image 36...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 37...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 38...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 39...\n",
      "Loss: 88.43038940429688, Norm: 0.0, InvBCE: 88.39289093017578\n",
      "Loss: 53.89430618286133, Norm: 0.0003844320308417082, InvBCE: 53.85675048828125\n",
      "Loss: 36.902626037597656, Norm: 0.0007466924143955112, InvBCE: 36.865013122558594\n",
      "Loss: 27.37576675415039, Norm: 0.0010830946266651154, InvBCE: 27.33810043334961\n",
      "Loss: 21.708377838134766, Norm: 0.0013944084057584405, InvBCE: 21.67066192626953\n",
      "Loss: 17.940855026245117, Norm: 0.0016868052771314979, InvBCE: 17.90308952331543\n",
      "Loss: 15.4208402633667, Norm: 0.0019601997919380665, InvBCE: 15.383028984069824\n",
      "Loss: 13.665514945983887, Norm: 0.002216910244897008, InvBCE: 13.627660751342773\n",
      "Loss: 12.353874206542969, Norm: 0.0024590271059423685, InvBCE: 12.31597900390625\n",
      "Loss: 11.301477432250977, Norm: 0.0026878206990659237, InvBCE: 11.263544082641602\n",
      "Loss: 10.441428184509277, Norm: 0.0029054684564471245, InvBCE: 10.403457641601562\n",
      "Loss: 8.554706573486328, Norm: 0.003113207872956991, InvBCE: 8.516701698303223\n",
      "Loss: 8.032193183898926, Norm: 0.0033116042613983154, InvBCE: 7.994155406951904\n",
      "Loss: 7.6104888916015625, Norm: 0.003500887658447027, InvBCE: 7.5724196434021\n",
      "Loss: 7.247272491455078, Norm: 0.0036820247769355774, InvBCE: 7.209173679351807\n",
      "Loss: 6.928668975830078, Norm: 0.0038558319211006165, InvBCE: 6.890542030334473\n",
      "Loss: 6.64772367477417, Norm: 0.00402301037684083, InvBCE: 6.609570503234863\n",
      "Loss: 6.3950982093811035, Norm: 0.0041841245256364346, InvBCE: 6.35692024230957\n",
      "Loss: 6.164441108703613, Norm: 0.004339808132499456, InvBCE: 6.12623929977417\n",
      "Loss: 5.967739105224609, Norm: 0.004490409046411514, InvBCE: 5.929515361785889\n",
      "Image 40...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 41...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 42...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 43...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 44...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 45...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 46...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 47...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 48...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 49...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 50...\n",
      "Loss: 7.031040668487549, Norm: 0.0, InvBCE: 6.993540287017822\n",
      "Loss: 5.843553066253662, Norm: 0.00038194487569853663, InvBCE: 5.806033134460449\n",
      "Loss: 4.976480960845947, Norm: 0.0007538469508290291, InvBCE: 4.938940048217773\n",
      "Loss: 4.33189582824707, Norm: 0.0011144703021273017, InvBCE: 4.294332504272461\n",
      "Loss: 3.834841251373291, Norm: 0.0014641137095168233, InvBCE: 3.7972536087036133\n",
      "Loss: 3.416240692138672, Norm: 0.0018006955506280065, InvBCE: 3.378627300262451\n",
      "Loss: 3.0552942752838135, Norm: 0.002125574741512537, InvBCE: 3.0176539421081543\n",
      "Loss: 2.7422609329223633, Norm: 0.002438953844830394, InvBCE: 2.7045929431915283\n",
      "Loss: 2.463247299194336, Norm: 0.002743234857916832, InvBCE: 2.425550699234009\n",
      "Loss: 2.20210599899292, Norm: 0.003039164235815406, InvBCE: 2.1643800735473633\n",
      "Loss: 1.9674899578094482, Norm: 0.0033272048458456993, InvBCE: 1.9297341108322144\n",
      "Loss: 1.7580006122589111, Norm: 0.0036073734518140554, InvBCE: 1.7202141284942627\n",
      "Loss: 1.5682505369186401, Norm: 0.0038796409498900175, InvBCE: 1.5304330587387085\n",
      "Loss: 1.4005913734436035, Norm: 0.004143709782510996, InvBCE: 1.3627426624298096\n",
      "Loss: 1.2537766695022583, Norm: 0.004399260971695185, InvBCE: 1.2158968448638916\n",
      "Loss: 1.1238834857940674, Norm: 0.004646151792258024, InvBCE: 1.0859726667404175\n",
      "Loss: 1.009124994277954, Norm: 0.004884310998022556, InvBCE: 0.971183717250824\n",
      "Loss: 0.9096298217773438, Norm: 0.005113508552312851, InvBCE: 0.8716586232185364\n",
      "Loss: 0.8233113884925842, Norm: 0.005333668552339077, InvBCE: 0.7853110432624817\n",
      "Loss: 0.7495445013046265, Norm: 0.005544631276279688, InvBCE: 0.7115159630775452\n",
      "Image 51...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 52...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 53...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 54...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 55...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 56...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 57...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 58...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 59...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 60...\n",
      "Loss: 673.5191040039062, Norm: 0.0, InvBCE: 673.4816284179688\n",
      "Loss: 316.3172302246094, Norm: 0.00037524435902014375, InvBCE: 316.2796936035156\n",
      "Loss: 219.09048461914062, Norm: 0.0007131261518225074, InvBCE: 219.0529327392578\n",
      "Loss: 143.0362548828125, Norm: 0.0009760918910615146, InvBCE: 142.9987030029297\n",
      "Loss: 100.02283477783203, Norm: 0.0012266741832718253, InvBCE: 99.98528289794922\n",
      "Loss: 74.9139404296875, Norm: 0.0014614068204537034, InvBCE: 74.87638854980469\n",
      "Loss: 59.29499053955078, Norm: 0.0016803030157461762, InvBCE: 59.25743865966797\n",
      "Loss: 48.687477111816406, Norm: 0.001884493394754827, InvBCE: 48.649925231933594\n",
      "Loss: 42.04301071166992, Norm: 0.002075493335723877, InvBCE: 42.005462646484375\n",
      "Loss: 36.75228500366211, Norm: 0.0022545296233147383, InvBCE: 36.714744567871094\n",
      "Loss: 32.9114875793457, Norm: 0.002422820311039686, InvBCE: 32.87395095825195\n",
      "Loss: 29.979333877563477, Norm: 0.0025814936961978674, InvBCE: 29.94180679321289\n",
      "Loss: 27.31461524963379, Norm: 0.002731538377702236, InvBCE: 27.277095794677734\n",
      "Loss: 25.590505599975586, Norm: 0.0028736907988786697, InvBCE: 25.552995681762695\n",
      "Loss: 24.120132446289062, Norm: 0.003008869243785739, InvBCE: 24.08263397216797\n",
      "Loss: 23.338647842407227, Norm: 0.0031377626582980156, InvBCE: 23.30116081237793\n",
      "Loss: 22.286012649536133, Norm: 0.0032610746566206217, InvBCE: 22.248538970947266\n",
      "Loss: 21.414203643798828, Norm: 0.003379179397597909, InvBCE: 21.37674331665039\n",
      "Loss: 20.657058715820312, Norm: 0.0034927809610962868, InvBCE: 20.619611740112305\n",
      "Loss: 19.985380172729492, Norm: 0.00360190961509943, InvBCE: 19.947948455810547\n",
      "Image 61...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 62...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 63...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 64...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 65...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 66...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 67...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 68...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 69...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 70...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 71...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 72...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 73...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 74...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 75...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 76...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 77...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 78...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 79...\n",
      "Loss: 809.8610229492188, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.86083984375, Norm: 0.00023295567370951176, InvBCE: 809.8235473632812\n",
      "Loss: 809.860595703125, Norm: 0.00046574315638281405, InvBCE: 809.8235473632812\n",
      "Loss: 809.8604125976562, Norm: 0.0006983504863455892, InvBCE: 809.8235473632812\n",
      "Loss: 809.8601684570312, Norm: 0.0009307655855081975, InvBCE: 809.8235473632812\n",
      "Loss: 809.8599853515625, Norm: 0.0011629757937043905, InvBCE: 809.8235473632812\n",
      "Loss: 809.8598022460938, Norm: 0.0013949691783636808, InvBCE: 809.8235473632812\n",
      "Loss: 809.8595581054688, Norm: 0.0016267328755930066, InvBCE: 809.8235473632812\n",
      "Loss: 809.859375, Norm: 0.0018582547781988978, InvBCE: 809.8235473632812\n",
      "Loss: 809.859130859375, Norm: 0.0020895220804959536, InvBCE: 809.8235473632812\n",
      "Loss: 809.8589477539062, Norm: 0.00232052244246006, InvBCE: 809.8235473632812\n",
      "Loss: 809.8587036132812, Norm: 0.0025512431748211384, InvBCE: 809.8235473632812\n",
      "Loss: 809.8585205078125, Norm: 0.0027816719375550747, InvBCE: 809.8235473632812\n",
      "Loss: 809.8582763671875, Norm: 0.0030117963906377554, InvBCE: 809.8235473632812\n",
      "Loss: 809.8580932617188, Norm: 0.003241604892536998, InvBCE: 809.8235473632812\n",
      "Loss: 809.85791015625, Norm: 0.00347108393907547, InvBCE: 809.8235473632812\n",
      "Loss: 809.857666015625, Norm: 0.00370022258721292, InvBCE: 809.8235473632812\n",
      "Loss: 809.8574829101562, Norm: 0.0039290087297558784, InvBCE: 809.8235473632812\n",
      "Loss: 809.8572387695312, Norm: 0.004157430492341518, InvBCE: 809.8235473632812\n",
      "Loss: 809.8570556640625, Norm: 0.004385476466268301, InvBCE: 809.8235473632812\n",
      "Image 80...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 81...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 82...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 83...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 84...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 85...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 86...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 87...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 88...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 89...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 90...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 91...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 92...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 93...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 94...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 95...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 96...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 97...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 98...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 99...\n",
      "Image fooled! Adding perturbation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f01649363714466b60d4ab2fe92c3ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fooling rate: 0.92\n",
      "Starting epoch 18...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e66df34300d4f3bae6dce473d1d4ce9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 1...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 2...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 3...\n",
      "Loss: 2.7086408138275146, Norm: 0.0, InvBCE: 2.671140432357788\n",
      "Loss: 2.4036736488342285, Norm: 0.00038129405584186316, InvBCE: 2.3661303520202637\n",
      "Loss: 2.1352651119232178, Norm: 0.0007567432476207614, InvBCE: 2.0976762771606445\n",
      "Loss: 1.9006415605545044, Norm: 0.0011261686449870467, InvBCE: 1.8630050420761108\n",
      "Loss: 1.6964956521987915, Norm: 0.0014882955001667142, InvBCE: 1.658810019493103\n",
      "Loss: 1.519343376159668, Norm: 0.0018421054119244218, InvBCE: 1.4816075563430786\n",
      "Loss: 1.3657230138778687, Norm: 0.0021868443582206964, InvBCE: 1.3279362916946411\n",
      "Loss: 1.2324810028076172, Norm: 0.002521953545510769, InvBCE: 1.1946427822113037\n",
      "Loss: 1.1168694496154785, Norm: 0.0028469953685998917, InvBCE: 1.0789796113967896\n",
      "Loss: 1.0164884328842163, Norm: 0.003161649452522397, InvBCE: 0.9785469174385071\n",
      "Loss: 0.9292275905609131, Norm: 0.0034657155629247427, InvBCE: 0.8912347555160522\n",
      "Loss: 0.8532089591026306, Norm: 0.0037590968422591686, InvBCE: 0.8151654005050659\n",
      "Loss: 0.7867833375930786, Norm: 0.004041772801429033, InvBCE: 0.7486898899078369\n",
      "Loss: 0.728573203086853, Norm: 0.004313806537538767, InvBCE: 0.6904310584068298\n",
      "Loss: 0.6774891018867493, Norm: 0.00457530515268445, InvBCE: 0.6392995715141296\n",
      "Loss: 0.6327050924301147, Norm: 0.0048264130018651485, InvBCE: 0.5944696664810181\n",
      "Loss: 0.5935627818107605, Norm: 0.005067308433353901, InvBCE: 0.5552830696105957\n",
      "Loss: 0.559487521648407, Norm: 0.005298181436955929, InvBCE: 0.521165132522583\n",
      "Loss: 0.529937744140625, Norm: 0.005519233178347349, InvBCE: 0.4915744662284851\n",
      "Loss: 0.5043972134590149, Norm: 0.005730681587010622, InvBCE: 0.46599477529525757\n",
      "Image 4...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 5...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 6...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 7...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 8...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 9...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 10...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 11...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 12...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 13...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 14...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 15...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 16...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 17...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 18...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 19...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 20...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 21...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 22...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 23...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 24...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 25...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 26...\n",
      "Loss: 1.4804880619049072, Norm: 0.0, InvBCE: 1.4429875612258911\n",
      "Image fooled! Adding perturbation...\n",
      "Image 27...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 28...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 29...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 30...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 31...\n",
      "Loss: 809.8609619140625, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8607177734375, Norm: 0.0002328725386178121, InvBCE: 809.8235473632812\n",
      "Loss: 809.8605346679688, Norm: 0.00046557627501897514, InvBCE: 809.8235473632812\n",
      "Loss: 809.8602905273438, Norm: 0.0006980991456657648, InvBCE: 809.8235473632812\n",
      "Loss: 809.860107421875, Norm: 0.0009304287959821522, InvBCE: 809.8235473632812\n",
      "Loss: 809.85986328125, Norm: 0.001162553089670837, InvBCE: 809.8235473632812\n",
      "Loss: 809.8596801757812, Norm: 0.0013944595120847225, InvBCE: 809.8235473632812\n",
      "Loss: 809.8594360351562, Norm: 0.001626135315746069, InvBCE: 809.8235473632812\n",
      "Loss: 809.8592529296875, Norm: 0.0018575682770460844, InvBCE: 809.8235473632812\n",
      "Loss: 809.8590087890625, Norm: 0.002088745590299368, InvBCE: 809.8235473632812\n",
      "Loss: 809.8588256835938, Norm: 0.002319654915481806, InvBCE: 809.8235473632812\n",
      "Loss: 809.858642578125, Norm: 0.002550283446907997, InvBCE: 809.8235473632812\n",
      "Loss: 809.8583984375, Norm: 0.0027806188445538282, InvBCE: 809.8235473632812\n",
      "Loss: 809.8582153320312, Norm: 0.003010649001225829, InvBCE: 809.8235473632812\n",
      "Loss: 809.8579711914062, Norm: 0.003240360878407955, InvBCE: 809.8235473632812\n",
      "Loss: 809.8577880859375, Norm: 0.0034697430673986673, InvBCE: 809.8235473632812\n",
      "Loss: 809.8575439453125, Norm: 0.0036987827625125647, InvBCE: 809.8235473632812\n",
      "Loss: 809.8573608398438, Norm: 0.0039274683222174644, InvBCE: 809.8235473632812\n",
      "Loss: 809.857177734375, Norm: 0.004155788570642471, InvBCE: 809.8235473632812\n",
      "Loss: 809.85693359375, Norm: 0.004383731167763472, InvBCE: 809.8235473632812\n",
      "Image 32...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 33...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 34...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 35...\n",
      "Loss: 0.9437391757965088, Norm: 0.0, InvBCE: 0.906351625919342\n",
      "Image fooled! Adding perturbation...\n",
      "Image 36...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 37...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 38...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 39...\n",
      "Loss: 83.33708190917969, Norm: 0.0, InvBCE: 83.29964447021484\n",
      "Loss: 51.091590881347656, Norm: 0.0003844246093649417, InvBCE: 51.054100036621094\n",
      "Loss: 35.4876594543457, Norm: 0.0007408924866467714, InvBCE: 35.45011520385742\n",
      "Loss: 26.463300704956055, Norm: 0.001078939181752503, InvBCE: 26.425703048706055\n",
      "Loss: 20.961612701416016, Norm: 0.0013931182911619544, InvBCE: 20.92396354675293\n",
      "Loss: 17.427814483642578, Norm: 0.0016864235512912273, InvBCE: 17.39011573791504\n",
      "Loss: 15.018346786499023, Norm: 0.001961336238309741, InvBCE: 14.980603218078613\n",
      "Loss: 13.335410118103027, Norm: 0.0022200183011591434, InvBCE: 13.297622680664062\n",
      "Loss: 12.062605857849121, Norm: 0.00246403063647449, InvBCE: 12.02477741241455\n",
      "Loss: 11.027849197387695, Norm: 0.002695626812055707, InvBCE: 10.989981651306152\n",
      "Loss: 10.178692817687988, Norm: 0.0029161772690713406, InvBCE: 10.140789031982422\n",
      "Loss: 8.340592384338379, Norm: 0.003127083647996187, InvBCE: 8.302652359008789\n",
      "Loss: 7.854684829711914, Norm: 0.0033279922790825367, InvBCE: 7.816711902618408\n",
      "Loss: 7.445140361785889, Norm: 0.0035198708064854145, InvBCE: 7.407135486602783\n",
      "Loss: 7.091222763061523, Norm: 0.0037036186549812555, InvBCE: 7.053188323974609\n",
      "Loss: 6.784099102020264, Norm: 0.0038800984621047974, InvBCE: 6.746036052703857\n",
      "Loss: 6.510374546051025, Norm: 0.004049940966069698, InvBCE: 6.47228479385376\n",
      "Loss: 6.261282920837402, Norm: 0.004213782027363777, InvBCE: 6.223167896270752\n",
      "Loss: 6.0493364334106445, Norm: 0.004372123163193464, InvBCE: 6.011197566986084\n",
      "Loss: 5.841762065887451, Norm: 0.004525478463619947, InvBCE: 5.803600311279297\n",
      "Image 40...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 41...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 42...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 43...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 44...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 45...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 46...\n",
      "Loss: 0.5069239139556885, Norm: 0.0, InvBCE: 0.4694884717464447\n",
      "Image fooled! Adding perturbation...\n",
      "Image 47...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 48...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 49...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 50...\n",
      "Loss: 6.929652690887451, Norm: 0.0, InvBCE: 6.892180442810059\n",
      "Loss: 5.763746738433838, Norm: 0.00038199752452783287, InvBCE: 5.726255893707275\n",
      "Loss: 4.916624069213867, Norm: 0.0007523858221247792, InvBCE: 4.879112720489502\n",
      "Loss: 4.291189670562744, Norm: 0.0011105306912213564, InvBCE: 4.253656387329102\n",
      "Loss: 3.8131988048553467, Norm: 0.0014557988615706563, InvBCE: 3.775641918182373\n",
      "Loss: 3.4100046157836914, Norm: 0.0017888123402372003, InvBCE: 3.372422933578491\n",
      "Loss: 3.061767816543579, Norm: 0.0021106821950525045, InvBCE: 3.024160385131836\n",
      "Loss: 2.7566099166870117, Norm: 0.002422327408567071, InvBCE: 2.718975782394409\n",
      "Loss: 2.4820191860198975, Norm: 0.002724134363234043, InvBCE: 2.4443576335906982\n",
      "Loss: 2.2235870361328125, Norm: 0.0030180022586137056, InvBCE: 2.1858973503112793\n",
      "Loss: 1.9900034666061401, Norm: 0.0033044854644685984, InvBCE: 1.9522846937179565\n",
      "Loss: 1.7813671827316284, Norm: 0.003583477111533284, InvBCE: 1.7436188459396362\n",
      "Loss: 1.5921440124511719, Norm: 0.0038548342417925596, InvBCE: 1.5543657541275024\n",
      "Loss: 1.4242128133773804, Norm: 0.004118329845368862, InvBCE: 1.386404275894165\n",
      "Loss: 1.2763922214508057, Norm: 0.004373605363070965, InvBCE: 1.238553524017334\n",
      "Loss: 1.1451493501663208, Norm: 0.004620416089892387, InvBCE: 1.1072806119918823\n",
      "Loss: 1.0284886360168457, Norm: 0.00485874293372035, InvBCE: 0.9905902147293091\n",
      "Loss: 0.9261556267738342, Norm: 0.005088498815894127, InvBCE: 0.8882279992103577\n",
      "Loss: 0.8374485969543457, Norm: 0.005309412255883217, InvBCE: 0.7994925379753113\n",
      "Loss: 0.7619044184684753, Norm: 0.005521381739526987, InvBCE: 0.7239207625389099\n",
      "Image 51...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 52...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 53...\n",
      "Loss: 1.3577942848205566, Norm: 0.0, InvBCE: 1.320322036743164\n",
      "Image fooled! Adding perturbation...\n",
      "Image 54...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 55...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 56...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 57...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 58...\n",
      "Loss: 1.4336600303649902, Norm: 0.0, InvBCE: 1.3962129354476929\n",
      "Image fooled! Adding perturbation...\n",
      "Image 59...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 60...\n",
      "Loss: 575.2255859375, Norm: 0.0, InvBCE: 575.1881713867188\n",
      "Loss: 340.58465576171875, Norm: 0.0003752463380806148, InvBCE: 340.5472412109375\n",
      "Loss: 194.3196258544922, Norm: 0.0007133560138754547, InvBCE: 194.28219604492188\n",
      "Loss: 115.41329193115234, Norm: 0.0010278882691636682, InvBCE: 115.3758544921875\n",
      "Loss: 77.8583984375, Norm: 0.0013146490091457963, InvBCE: 77.8209457397461\n",
      "Loss: 57.79844284057617, Norm: 0.0015761896502226591, InvBCE: 57.760986328125\n",
      "Loss: 45.57819747924805, Norm: 0.0018154924036934972, InvBCE: 45.54073715209961\n",
      "Loss: 38.404850006103516, Norm: 0.0020350601989775896, InvBCE: 38.36738967895508\n",
      "Loss: 33.26416015625, Norm: 0.0022380221635103226, InvBCE: 33.22669982910156\n",
      "Loss: 29.1261043548584, Norm: 0.002426610328257084, InvBCE: 29.088647842407227\n",
      "Loss: 26.60961151123047, Norm: 0.002602368127554655, InvBCE: 26.572158813476562\n",
      "Loss: 25.061830520629883, Norm: 0.0027669970877468586, InvBCE: 25.024385452270508\n",
      "Loss: 23.42366600036621, Norm: 0.0029219097923487425, InvBCE: 23.386228561401367\n",
      "Loss: 22.135107040405273, Norm: 0.003067998681217432, InvBCE: 22.097679138183594\n",
      "Loss: 21.074249267578125, Norm: 0.0032064595725387335, InvBCE: 21.036832809448242\n",
      "Loss: 20.170202255249023, Norm: 0.0033381779212504625, InvBCE: 20.132797241210938\n",
      "Loss: 19.403419494628906, Norm: 0.0034638959914445877, InvBCE: 19.36602783203125\n",
      "Loss: 18.754150390625, Norm: 0.0035842573270201683, InvBCE: 18.716772079467773\n",
      "Loss: 18.16390609741211, Norm: 0.003699870780110359, InvBCE: 18.126543045043945\n",
      "Loss: 17.676759719848633, Norm: 0.0038111729081720114, InvBCE: 17.63941192626953\n",
      "Image 61...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 62...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 63...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 64...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 65...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 66...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 67...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 68...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 69...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 70...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 71...\n",
      "Loss: 0.5996332168579102, Norm: 0.0, InvBCE: 0.5622491836547852\n",
      "Image fooled! Adding perturbation...\n",
      "Image 72...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 73...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 74...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 75...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 76...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 77...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 78...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 79...\n",
      "Loss: 809.8610229492188, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8607788085938, Norm: 0.00023289529781322926, InvBCE: 809.8235473632812\n",
      "Loss: 809.860595703125, Norm: 0.0004656223172787577, InvBCE: 809.8235473632812\n",
      "Loss: 809.8603515625, Norm: 0.000698168994858861, InvBCE: 809.8235473632812\n",
      "Loss: 809.8601684570312, Norm: 0.0009305230341851711, InvBCE: 809.8235473632812\n",
      "Loss: 809.8599243164062, Norm: 0.0011626722989603877, InvBCE: 809.8235473632812\n",
      "Loss: 809.8597412109375, Norm: 0.0013946043327450752, InvBCE: 809.8235473632812\n",
      "Loss: 809.8594970703125, Norm: 0.0016263065626844764, InvBCE: 809.8235473632812\n",
      "Loss: 809.8593139648438, Norm: 0.0018577665323391557, InvBCE: 809.8235473632812\n",
      "Loss: 809.8590698242188, Norm: 0.0020889719016849995, InvBCE: 809.8235473632812\n",
      "Loss: 809.85888671875, Norm: 0.002319909865036607, InvBCE: 809.8235473632812\n",
      "Loss: 809.8587036132812, Norm: 0.002550567965954542, InvBCE: 809.8235473632812\n",
      "Loss: 809.8584594726562, Norm: 0.002780933864414692, InvBCE: 809.8235473632812\n",
      "Loss: 809.8582763671875, Norm: 0.0030109949875622988, InvBCE: 809.8235473632812\n",
      "Loss: 809.8580322265625, Norm: 0.00324073969386518, InvBCE: 809.8235473632812\n",
      "Loss: 809.8578491210938, Norm: 0.003470154944807291, InvBCE: 809.8235473632812\n",
      "Loss: 809.857666015625, Norm: 0.0036992293316870928, InvBCE: 809.8235473632812\n",
      "Loss: 809.857421875, Norm: 0.003927950747311115, InvBCE: 809.8235473632812\n",
      "Loss: 809.8572387695312, Norm: 0.0041563077829778194, InvBCE: 809.8235473632812\n",
      "Loss: 809.8569946289062, Norm: 0.004384288098663092, InvBCE: 809.8235473632812\n",
      "Image 80...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 81...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 82...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 83...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 84...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 85...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 86...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 87...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 88...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 89...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 90...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 91...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 92...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 93...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 94...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 95...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 96...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 97...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 98...\n",
      "Loss: 1.3522062301635742, Norm: 0.0, InvBCE: 1.3147504329681396\n",
      "Image fooled! Adding perturbation...\n",
      "Image 99...\n",
      "Image fooled! Adding perturbation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "948356b4e1334e5fa3965ec42f8df8f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fooling rate: 0.88\n",
      "Starting epoch 19...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65eda222825045448d03a746ba042a97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 1...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 2...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 3...\n",
      "Loss: 2.6779232025146484, Norm: 0.0, InvBCE: 2.640424966812134\n",
      "Loss: 2.3729965686798096, Norm: 0.00038126358413137496, InvBCE: 2.335456371307373\n",
      "Loss: 2.104536771774292, Norm: 0.0007562486571259797, InvBCE: 2.0669524669647217\n",
      "Loss: 1.869701623916626, Norm: 0.0011250064708292484, InvBCE: 1.8320714235305786\n",
      "Loss: 1.6652936935424805, Norm: 0.0014864656841382384, InvBCE: 1.627616286277771\n",
      "Loss: 1.488007664680481, Norm: 0.0018398386891931295, InvBCE: 1.4502817392349243\n",
      "Loss: 1.334523320198059, Norm: 0.0021844219882041216, InvBCE: 1.2967480421066284\n",
      "Loss: 1.2017135620117188, Norm: 0.002519561443477869, InvBCE: 1.1638883352279663\n",
      "Loss: 1.0867644548416138, Norm: 0.0028447106014937162, InvBCE: 1.0488888025283813\n",
      "Loss: 0.9871615767478943, Norm: 0.0031594594474881887, InvBCE: 0.9492356181144714\n",
      "Loss: 0.9007099270820618, Norm: 0.003463548142462969, InvBCE: 0.8627338409423828\n",
      "Loss: 0.82551109790802, Norm: 0.0037568360567092896, InvBCE: 0.7874854803085327\n",
      "Loss: 0.7600089311599731, Norm: 0.004039289895445108, InvBCE: 0.7219346165657043\n",
      "Loss: 0.7029694318771362, Norm: 0.004310930613428354, InvBCE: 0.6648475527763367\n",
      "Loss: 0.6534204483032227, Norm: 0.004571834113448858, InvBCE: 0.6152522563934326\n",
      "Loss: 0.6105282306671143, Norm: 0.004822111222893, InvBCE: 0.5723151564598083\n",
      "Loss: 0.573531985282898, Norm: 0.005061903037130833, InvBCE: 0.5352755784988403\n",
      "Loss: 0.541710376739502, Norm: 0.005291382782161236, InvBCE: 0.5034122467041016\n",
      "Loss: 0.5143875479698181, Norm: 0.005510760471224785, InvBCE: 0.47604939341545105\n",
      "Loss: 0.49094653129577637, Norm: 0.005720278713852167, InvBCE: 0.45257002115249634\n",
      "Image 4...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 5...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 6...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 7...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 8...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 9...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 10...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 11...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 12...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 13...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 14...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 15...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 16...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 17...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 18...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 19...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 20...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 21...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 22...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 23...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 24...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 25...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 26...\n",
      "Loss: 1.480695366859436, Norm: 0.0, InvBCE: 1.4431970119476318\n",
      "Image fooled! Adding perturbation...\n",
      "Image 27...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 28...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 29...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 30...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 31...\n",
      "Loss: 809.8609619140625, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8607177734375, Norm: 0.00023286326904781163, InvBCE: 809.8235473632812\n",
      "Loss: 809.8605346679688, Norm: 0.000465557852294296, InvBCE: 809.8235473632812\n",
      "Loss: 809.8602905273438, Norm: 0.0006980715552344918, InvBCE: 809.8235473632812\n",
      "Loss: 809.860107421875, Norm: 0.0009303922997787595, InvBCE: 809.8235473632812\n",
      "Loss: 809.85986328125, Norm: 0.0011625075712800026, InvBCE: 809.8235473632812\n",
      "Loss: 809.8596801757812, Norm: 0.0013944051461294293, InvBCE: 809.8235473632812\n",
      "Loss: 809.8594360351562, Norm: 0.0016260723350569606, InvBCE: 809.8235473632812\n",
      "Loss: 809.8592529296875, Norm: 0.0018574967980384827, InvBCE: 809.8235473632812\n",
      "Loss: 809.8590087890625, Norm: 0.002088665496557951, InvBCE: 809.8235473632812\n",
      "Loss: 809.8588256835938, Norm: 0.0023195664398372173, InvBCE: 809.8235473632812\n",
      "Loss: 809.8585815429688, Norm: 0.0025501868221908808, InvBCE: 809.8235473632812\n",
      "Loss: 809.8583984375, Norm: 0.002780514070764184, InvBCE: 809.8235473632812\n",
      "Loss: 809.8582153320312, Norm: 0.003010536078363657, InvBCE: 809.8235473632812\n",
      "Loss: 809.8579711914062, Norm: 0.003240240504965186, InvBCE: 809.8235473632812\n",
      "Loss: 809.8577880859375, Norm: 0.003469614777714014, InvBCE: 809.8235473632812\n",
      "Loss: 809.8575439453125, Norm: 0.0036986470222473145, InvBCE: 809.8235473632812\n",
      "Loss: 809.8573608398438, Norm: 0.003927325364202261, InvBCE: 809.8235473632812\n",
      "Loss: 809.857177734375, Norm: 0.004155638162046671, InvBCE: 809.8235473632812\n",
      "Loss: 809.85693359375, Norm: 0.004383573774248362, InvBCE: 809.8235473632812\n",
      "Image 32...\n",
      "Loss: 1.4540863037109375, Norm: 0.0, InvBCE: 1.4166996479034424\n",
      "Image fooled! Adding perturbation...\n",
      "Image 33...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 34...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 35...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 36...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 37...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 38...\n",
      "Loss: 1.459877371788025, Norm: 0.0, InvBCE: 1.422492504119873\n",
      "Image fooled! Adding perturbation...\n",
      "Image 39...\n",
      "Loss: 67.61566925048828, Norm: 0.0, InvBCE: 67.57833099365234\n",
      "Loss: 43.2753791809082, Norm: 0.00038438415504060686, InvBCE: 43.23798370361328\n",
      "Loss: 31.151865005493164, Norm: 0.0007440397166647017, InvBCE: 31.114416122436523\n",
      "Loss: 23.551021575927734, Norm: 0.001080631511285901, InvBCE: 23.513521194458008\n",
      "Loss: 19.03676986694336, Norm: 0.0013953913003206253, InvBCE: 18.999221801757812\n",
      "Loss: 16.06357765197754, Norm: 0.0016907769022509456, InvBCE: 16.025981903076172\n",
      "Loss: 14.065064430236816, Norm: 0.001968872267752886, InvBCE: 14.027424812316895\n",
      "Loss: 12.60600757598877, Norm: 0.0022317240945994854, InvBCE: 12.568325996398926\n",
      "Loss: 11.460892677307129, Norm: 0.0024812507908791304, InvBCE: 11.423171043395996\n",
      "Loss: 10.530808448791504, Norm: 0.0027189431712031364, InvBCE: 10.493047714233398\n",
      "Loss: 8.586145401000977, Norm: 0.0029462832026183605, InvBCE: 8.548347473144531\n",
      "Loss: 8.057049751281738, Norm: 0.003162927692756057, InvBCE: 8.019216537475586\n",
      "Loss: 7.61676549911499, Norm: 0.003369920887053013, InvBCE: 7.578899383544922\n",
      "Loss: 7.236186981201172, Norm: 0.00356822251342237, InvBCE: 7.198288917541504\n",
      "Loss: 6.904715538024902, Norm: 0.003758735489100218, InvBCE: 6.866786956787109\n",
      "Loss: 6.606568813323975, Norm: 0.003942153416574001, InvBCE: 6.568611145019531\n",
      "Loss: 6.351791858673096, Norm: 0.004119257442653179, InvBCE: 6.313806533813477\n",
      "Loss: 6.107285976409912, Norm: 0.004290629643946886, InvBCE: 6.069274425506592\n",
      "Loss: 5.883147239685059, Norm: 0.004456796683371067, InvBCE: 5.8451104164123535\n",
      "Loss: 5.678467750549316, Norm: 0.0046181948855519295, InvBCE: 5.640407085418701\n",
      "Image 40...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 41...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 42...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 43...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 44...\n",
      "Loss: 0.7533290386199951, Norm: 0.0, InvBCE: 0.715988278388977\n",
      "Image fooled! Adding perturbation...\n",
      "Image 45...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 46...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 47...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 48...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 49...\n",
      "Loss: 1.3100579977035522, Norm: 0.0, InvBCE: 1.27266526222229\n",
      "Image fooled! Adding perturbation...\n",
      "Image 50...\n",
      "Loss: 6.874675750732422, Norm: 0.0, InvBCE: 6.837223052978516\n",
      "Loss: 5.713406562805176, Norm: 0.00038196725654415786, InvBCE: 5.675937175750732\n",
      "Loss: 4.862036228179932, Norm: 0.0007531616720370948, InvBCE: 4.824548244476318\n",
      "Loss: 4.227441787719727, Norm: 0.001112419762648642, InvBCE: 4.1899333000183105\n",
      "Loss: 3.746464490890503, Norm: 0.0014584700111299753, InvBCE: 3.7089335918426514\n",
      "Loss: 3.3400683403015137, Norm: 0.0017919117817655206, InvBCE: 3.302513599395752\n",
      "Loss: 2.9916229248046875, Norm: 0.0021140952594578266, InvBCE: 2.95404314994812\n",
      "Loss: 2.6898796558380127, Norm: 0.0024259877391159534, InvBCE: 2.652273654937744\n",
      "Loss: 2.410594940185547, Norm: 0.002726512961089611, InvBCE: 2.372962236404419\n",
      "Loss: 2.1516685485839844, Norm: 0.003019202733412385, InvBCE: 2.1140081882476807\n",
      "Loss: 1.9215281009674072, Norm: 0.0033044118899852037, InvBCE: 1.8838392496109009\n",
      "Loss: 1.7152602672576904, Norm: 0.003581922734156251, InvBCE: 1.6775423288345337\n",
      "Loss: 1.5298104286193848, Norm: 0.0038516235072165728, InvBCE: 1.492063045501709\n",
      "Loss: 1.3668485879898071, Norm: 0.0041131931357085705, InvBCE: 1.3290716409683228\n",
      "Loss: 1.2230404615402222, Norm: 0.004366306122392416, InvBCE: 1.1852339506149292\n",
      "Loss: 1.0948585271835327, Norm: 0.004610858391970396, InvBCE: 1.0570225715637207\n",
      "Loss: 0.9814375042915344, Norm: 0.004846720490604639, InvBCE: 0.9435725212097168\n",
      "Loss: 0.8834782242774963, Norm: 0.005073722917586565, InvBCE: 0.8455847501754761\n",
      "Loss: 0.7992496490478516, Norm: 0.005291688721626997, InvBCE: 0.761328399181366\n",
      "Loss: 0.7287654876708984, Norm: 0.005500452127307653, InvBCE: 0.6908174157142639\n",
      "Image 51...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 52...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 53...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 54...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 55...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 56...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 57...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 58...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 59...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 60...\n",
      "Loss: 630.2578125, Norm: 0.0, InvBCE: 630.2203369140625\n",
      "Loss: 294.43890380859375, Norm: 0.0003751915355678648, InvBCE: 294.40142822265625\n",
      "Loss: 205.86048889160156, Norm: 0.0007111579179763794, InvBCE: 205.822998046875\n",
      "Loss: 127.29917907714844, Norm: 0.000995049369521439, InvBCE: 127.26168060302734\n",
      "Loss: 87.0525894165039, Norm: 0.0012601095950230956, InvBCE: 87.01508331298828\n",
      "Loss: 64.68090057373047, Norm: 0.0015051922528073192, InvBCE: 64.64338684082031\n",
      "Loss: 51.09668731689453, Norm: 0.0017316206358373165, InvBCE: 51.05917739868164\n",
      "Loss: 42.111236572265625, Norm: 0.0019414193229749799, InvBCE: 42.073726654052734\n",
      "Loss: 36.45672607421875, Norm: 0.002136079827323556, InvBCE: 36.419219970703125\n",
      "Loss: 32.15752029418945, Norm: 0.0023177447728812695, InvBCE: 32.120018005371094\n",
      "Loss: 28.973976135253906, Norm: 0.0024879255797713995, InvBCE: 28.936481475830078\n",
      "Loss: 26.204933166503906, Norm: 0.002647911664098501, InvBCE: 26.16744613647461\n",
      "Loss: 24.398008346557617, Norm: 0.00279878918081522, InvBCE: 24.360530853271484\n",
      "Loss: 23.336881637573242, Norm: 0.0029415434692054987, InvBCE: 23.299413681030273\n",
      "Loss: 22.053970336914062, Norm: 0.0030771500896662474, InvBCE: 22.01651382446289\n",
      "Loss: 21.04062271118164, Norm: 0.003206353634595871, InvBCE: 21.003177642822266\n",
      "Loss: 20.176753997802734, Norm: 0.003329807659611106, InvBCE: 20.13932228088379\n",
      "Loss: 19.40626335144043, Norm: 0.0034481859765946865, InvBCE: 19.368844985961914\n",
      "Loss: 18.743093490600586, Norm: 0.0035619453992694616, InvBCE: 18.705690383911133\n",
      "Loss: 18.163227081298828, Norm: 0.0036715876776725054, InvBCE: 18.125839233398438\n",
      "Image 61...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 62...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 63...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 64...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 65...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 66...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 67...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 68...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 69...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 70...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 71...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 72...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 73...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 74...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 75...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 76...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 77...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 78...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 79...\n",
      "Loss: 809.8610229492188, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8607788085938, Norm: 0.00023278483422473073, InvBCE: 809.8235473632812\n",
      "Loss: 809.860595703125, Norm: 0.00046540083712898195, InvBCE: 809.8235473632812\n",
      "Loss: 809.8603515625, Norm: 0.0006978358142077923, InvBCE: 809.8235473632812\n",
      "Loss: 809.8601684570312, Norm: 0.0009300776291638613, InvBCE: 809.8235473632812\n",
      "Loss: 809.8599243164062, Norm: 0.0011621139710769057, InvBCE: 809.8235473632812\n",
      "Loss: 809.8597412109375, Norm: 0.0013939322670921683, InvBCE: 809.8235473632812\n",
      "Loss: 809.8594970703125, Norm: 0.0016255201771855354, InvBCE: 809.8235473632812\n",
      "Loss: 809.8593139648438, Norm: 0.0018568650120869279, InvBCE: 809.8235473632812\n",
      "Loss: 809.8590698242188, Norm: 0.0020879541989415884, InvBCE: 809.8235473632812\n",
      "Loss: 809.85888671875, Norm: 0.002318775048479438, InvBCE: 809.8235473632812\n",
      "Loss: 809.8587036132812, Norm: 0.0025493153370916843, InvBCE: 809.8235473632812\n",
      "Loss: 809.8584594726562, Norm: 0.0027795627247542143, InvBCE: 809.8235473632812\n",
      "Loss: 809.8582763671875, Norm: 0.0030095039401203394, InvBCE: 809.8235473632812\n",
      "Loss: 809.8580322265625, Norm: 0.0032391278073191643, InvBCE: 809.8235473632812\n",
      "Loss: 809.8578491210938, Norm: 0.0034684212878346443, InvBCE: 809.8235473632812\n",
      "Loss: 809.857666015625, Norm: 0.0036973722744733095, InvBCE: 809.8235473632812\n",
      "Loss: 809.857421875, Norm: 0.003925969824194908, InvBCE: 809.8235473632812\n",
      "Loss: 809.8572387695312, Norm: 0.004154201131314039, InvBCE: 809.8235473632812\n",
      "Loss: 809.8569946289062, Norm: 0.004382054787129164, InvBCE: 809.8235473632812\n",
      "Image 80...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 81...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 82...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 83...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 84...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 85...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 86...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 87...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 88...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 89...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 90...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 91...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 92...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 93...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 94...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 95...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 96...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 97...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 98...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 99...\n",
      "Image fooled! Adding perturbation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb4d840845cd4421828f2aee1ff9f48f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fooling rate: 0.94\n",
      "Starting epoch 20...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46cfd075b66a439abec1bd63ba98834f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 1...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 2...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 3...\n",
      "Loss: 2.717554807662964, Norm: 0.0, InvBCE: 2.6801018714904785\n",
      "Loss: 2.407351493835449, Norm: 0.00038118421798571944, InvBCE: 2.3698573112487793\n",
      "Loss: 2.134324550628662, Norm: 0.0007559842779301107, InvBCE: 2.0967862606048584\n",
      "Loss: 1.8955780267715454, Norm: 0.0011244287015870214, InvBCE: 1.8579938411712646\n",
      "Loss: 1.6877946853637695, Norm: 0.0014857073547318578, InvBCE: 1.650162935256958\n",
      "Loss: 1.5075215101242065, Norm: 0.0018390374025329947, InvBCE: 1.4698407649993896\n",
      "Loss: 1.3513212203979492, Norm: 0.0021836247760802507, InvBCE: 1.313590407371521\n",
      "Loss: 1.2159942388534546, Norm: 0.0025187814608216286, InvBCE: 1.1782126426696777\n",
      "Loss: 1.0986416339874268, Norm: 0.0028439692687243223, InvBCE: 1.060808777809143\n",
      "Loss: 0.9967145323753357, Norm: 0.0031588065903633833, InvBCE: 0.9588302969932556\n",
      "Loss: 0.9080396294593811, Norm: 0.0034630452282726765, InvBCE: 0.8701043128967285\n",
      "Loss: 0.8308247327804565, Norm: 0.003756554564461112, InvBCE: 0.7928388714790344\n",
      "Loss: 0.7636405229568481, Norm: 0.004039280116558075, InvBCE: 0.7256050109863281\n",
      "Loss: 0.7053354978561401, Norm: 0.004311214666813612, InvBCE: 0.667251467704773\n",
      "Loss: 0.6549381613731384, Norm: 0.004572402220219374, InvBCE: 0.6168069243431091\n",
      "Loss: 0.6115550398826599, Norm: 0.004822922870516777, InvBCE: 0.5733780264854431\n",
      "Loss: 0.5743334293365479, Norm: 0.005062887445092201, InvBCE: 0.5361122488975525\n",
      "Loss: 0.5424706339836121, Norm: 0.005292464513331652, InvBCE: 0.5042068958282471\n",
      "Loss: 0.5152295231819153, Norm: 0.005511854775249958, InvBCE: 0.47692495584487915\n",
      "Loss: 0.4919421672821045, Norm: 0.005721298512071371, InvBCE: 0.4535984694957733\n",
      "Image 4...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 5...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 6...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 7...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 8...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 9...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 10...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 11...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 12...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 13...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 14...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 15...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 16...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 17...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 18...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 19...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 20...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 21...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 22...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 23...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 24...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 25...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 26...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 27...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 28...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 29...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 30...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 31...\n",
      "Loss: 809.8610229492188, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8607788085938, Norm: 0.00023278483422473073, InvBCE: 809.8235473632812\n",
      "Loss: 809.860595703125, Norm: 0.00046540083712898195, InvBCE: 809.8235473632812\n",
      "Loss: 809.8603515625, Norm: 0.0006978358142077923, InvBCE: 809.8235473632812\n",
      "Loss: 809.8601684570312, Norm: 0.0009300776291638613, InvBCE: 809.8235473632812\n",
      "Loss: 809.8599243164062, Norm: 0.0011621139710769057, InvBCE: 809.8235473632812\n",
      "Loss: 809.8597412109375, Norm: 0.0013939322670921683, InvBCE: 809.8235473632812\n",
      "Loss: 809.8594970703125, Norm: 0.0016255201771855354, InvBCE: 809.8235473632812\n",
      "Loss: 809.8593139648438, Norm: 0.0018568650120869279, InvBCE: 809.8235473632812\n",
      "Loss: 809.8590698242188, Norm: 0.0020879541989415884, InvBCE: 809.8235473632812\n",
      "Loss: 809.85888671875, Norm: 0.002318775048479438, InvBCE: 809.8235473632812\n",
      "Loss: 809.8587036132812, Norm: 0.0025493153370916843, InvBCE: 809.8235473632812\n",
      "Loss: 809.8584594726562, Norm: 0.0027795627247542143, InvBCE: 809.8235473632812\n",
      "Loss: 809.8582763671875, Norm: 0.0030095039401203394, InvBCE: 809.8235473632812\n",
      "Loss: 809.8580322265625, Norm: 0.0032391278073191643, InvBCE: 809.8235473632812\n",
      "Loss: 809.8578491210938, Norm: 0.0034684212878346443, InvBCE: 809.8235473632812\n",
      "Loss: 809.857666015625, Norm: 0.0036973722744733095, InvBCE: 809.8235473632812\n",
      "Loss: 809.857421875, Norm: 0.003925969824194908, InvBCE: 809.8235473632812\n",
      "Loss: 809.8572387695312, Norm: 0.004154201131314039, InvBCE: 809.8235473632812\n",
      "Loss: 809.8569946289062, Norm: 0.004382054787129164, InvBCE: 809.8235473632812\n",
      "Image 32...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 33...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 34...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 35...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 36...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 37...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 38...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 39...\n",
      "Loss: 72.98128509521484, Norm: 0.0, InvBCE: 72.94383239746094\n",
      "Loss: 46.08408737182617, Norm: 0.0003843815065920353, InvBCE: 46.04658126831055\n",
      "Loss: 32.78629684448242, Norm: 0.000742322881706059, InvBCE: 32.74873352050781\n",
      "Loss: 24.617408752441406, Norm: 0.001077656401321292, InvBCE: 24.579795837402344\n",
      "Loss: 19.725128173828125, Norm: 0.0013914385344833136, InvBCE: 19.68746566772461\n",
      "Loss: 16.54332160949707, Norm: 0.0016856665024533868, InvBCE: 16.505611419677734\n",
      "Loss: 14.422035217285156, Norm: 0.001962564652785659, InvBCE: 14.384281158447266\n",
      "Loss: 12.86168384552002, Norm: 0.002224019728600979, InvBCE: 12.82388687133789\n",
      "Loss: 11.653457641601562, Norm: 0.002471968298777938, InvBCE: 11.615620613098145\n",
      "Loss: 10.683114051818848, Norm: 0.0027080196887254715, InvBCE: 10.645237922668457\n",
      "Loss: 8.709017753601074, Norm: 0.002933422802016139, InvBCE: 8.67110538482666\n",
      "Loss: 8.126260757446289, Norm: 0.003149435855448246, InvBCE: 8.088312149047852\n",
      "Loss: 7.666654109954834, Norm: 0.003355486784130335, InvBCE: 7.628672122955322\n",
      "Loss: 7.273351192474365, Norm: 0.0035526002757251263, InvBCE: 7.235337734222412\n",
      "Loss: 6.933590412139893, Norm: 0.0037416713312268257, InvBCE: 6.8955464363098145\n",
      "Loss: 6.633247375488281, Norm: 0.003923483658581972, InvBCE: 6.595174789428711\n",
      "Loss: 6.361598968505859, Norm: 0.0040987515822052956, InvBCE: 6.3234992027282715\n",
      "Loss: 6.131810665130615, Norm: 0.004267985001206398, InvBCE: 6.093685150146484\n",
      "Loss: 5.9073896408081055, Norm: 0.004431800916790962, InvBCE: 5.869239807128906\n",
      "Loss: 5.703206539154053, Norm: 0.00459067290648818, InvBCE: 5.665033340454102\n",
      "Image 40...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 41...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 42...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 43...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 44...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 45...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 46...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 47...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 48...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 49...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 50...\n",
      "Loss: 6.874675750732422, Norm: 0.0, InvBCE: 6.837223052978516\n",
      "Loss: 5.713406562805176, Norm: 0.00038196725654415786, InvBCE: 5.675937175750732\n",
      "Loss: 4.862036228179932, Norm: 0.0007531616720370948, InvBCE: 4.824548244476318\n",
      "Loss: 4.227441787719727, Norm: 0.001112419762648642, InvBCE: 4.1899333000183105\n",
      "Loss: 3.746464490890503, Norm: 0.0014584700111299753, InvBCE: 3.7089335918426514\n",
      "Loss: 3.3400683403015137, Norm: 0.0017919117817655206, InvBCE: 3.302513599395752\n",
      "Loss: 2.9916229248046875, Norm: 0.0021140952594578266, InvBCE: 2.95404314994812\n",
      "Loss: 2.6898796558380127, Norm: 0.0024259877391159534, InvBCE: 2.652273654937744\n",
      "Loss: 2.410594940185547, Norm: 0.002726512961089611, InvBCE: 2.372962236404419\n",
      "Loss: 2.1516685485839844, Norm: 0.003019202733412385, InvBCE: 2.1140081882476807\n",
      "Loss: 1.9215281009674072, Norm: 0.0033044118899852037, InvBCE: 1.8838392496109009\n",
      "Loss: 1.7152602672576904, Norm: 0.003581922734156251, InvBCE: 1.6775423288345337\n",
      "Loss: 1.5298104286193848, Norm: 0.0038516235072165728, InvBCE: 1.492063045501709\n",
      "Loss: 1.3668485879898071, Norm: 0.0041131931357085705, InvBCE: 1.3290716409683228\n",
      "Loss: 1.2230404615402222, Norm: 0.004366306122392416, InvBCE: 1.1852339506149292\n",
      "Loss: 1.0948585271835327, Norm: 0.004610858391970396, InvBCE: 1.0570225715637207\n",
      "Loss: 0.9814375042915344, Norm: 0.004846720490604639, InvBCE: 0.9435725212097168\n",
      "Loss: 0.8834782242774963, Norm: 0.005073722917586565, InvBCE: 0.8455847501754761\n",
      "Loss: 0.7992496490478516, Norm: 0.005291688721626997, InvBCE: 0.761328399181366\n",
      "Loss: 0.7287654876708984, Norm: 0.005500452127307653, InvBCE: 0.6908174157142639\n",
      "Image 51...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 52...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 53...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 54...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 55...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 56...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 57...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 58...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 59...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 60...\n",
      "Loss: 630.2578125, Norm: 0.0, InvBCE: 630.2203369140625\n",
      "Loss: 294.43890380859375, Norm: 0.0003751915355678648, InvBCE: 294.40142822265625\n",
      "Loss: 205.86048889160156, Norm: 0.0007111579179763794, InvBCE: 205.822998046875\n",
      "Loss: 127.29917907714844, Norm: 0.000995049369521439, InvBCE: 127.26168060302734\n",
      "Loss: 87.0525894165039, Norm: 0.0012601095950230956, InvBCE: 87.01508331298828\n",
      "Loss: 64.68090057373047, Norm: 0.0015051922528073192, InvBCE: 64.64338684082031\n",
      "Loss: 51.09668731689453, Norm: 0.0017316206358373165, InvBCE: 51.05917739868164\n",
      "Loss: 42.111236572265625, Norm: 0.0019414193229749799, InvBCE: 42.073726654052734\n",
      "Loss: 36.45672607421875, Norm: 0.002136079827323556, InvBCE: 36.419219970703125\n",
      "Loss: 32.15752029418945, Norm: 0.0023177447728812695, InvBCE: 32.120018005371094\n",
      "Loss: 28.973976135253906, Norm: 0.0024879255797713995, InvBCE: 28.936481475830078\n",
      "Loss: 26.204933166503906, Norm: 0.002647911664098501, InvBCE: 26.16744613647461\n",
      "Loss: 24.398008346557617, Norm: 0.00279878918081522, InvBCE: 24.360530853271484\n",
      "Loss: 23.336881637573242, Norm: 0.0029415434692054987, InvBCE: 23.299413681030273\n",
      "Loss: 22.053970336914062, Norm: 0.0030771500896662474, InvBCE: 22.01651382446289\n",
      "Loss: 21.04062271118164, Norm: 0.003206353634595871, InvBCE: 21.003177642822266\n",
      "Loss: 20.176753997802734, Norm: 0.003329807659611106, InvBCE: 20.13932228088379\n",
      "Loss: 19.40626335144043, Norm: 0.0034481859765946865, InvBCE: 19.368844985961914\n",
      "Loss: 18.743093490600586, Norm: 0.0035619453992694616, InvBCE: 18.705690383911133\n",
      "Loss: 18.163227081298828, Norm: 0.0036715876776725054, InvBCE: 18.125839233398438\n",
      "Image 61...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 62...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 63...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 64...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 65...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 66...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 67...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 68...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 69...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 70...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 71...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 72...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 73...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 74...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 75...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 76...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 77...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 78...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 79...\n",
      "Loss: 809.8610229492188, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8607788085938, Norm: 0.00023278483422473073, InvBCE: 809.8235473632812\n",
      "Loss: 809.860595703125, Norm: 0.00046540083712898195, InvBCE: 809.8235473632812\n",
      "Loss: 809.8603515625, Norm: 0.0006978358142077923, InvBCE: 809.8235473632812\n",
      "Loss: 809.8601684570312, Norm: 0.0009300776291638613, InvBCE: 809.8235473632812\n",
      "Loss: 809.8599243164062, Norm: 0.0011621139710769057, InvBCE: 809.8235473632812\n",
      "Loss: 809.8597412109375, Norm: 0.0013939322670921683, InvBCE: 809.8235473632812\n",
      "Loss: 809.8594970703125, Norm: 0.0016255201771855354, InvBCE: 809.8235473632812\n",
      "Loss: 809.8593139648438, Norm: 0.0018568650120869279, InvBCE: 809.8235473632812\n",
      "Loss: 809.8590698242188, Norm: 0.0020879541989415884, InvBCE: 809.8235473632812\n",
      "Loss: 809.85888671875, Norm: 0.002318775048479438, InvBCE: 809.8235473632812\n",
      "Loss: 809.8587036132812, Norm: 0.0025493153370916843, InvBCE: 809.8235473632812\n",
      "Loss: 809.8584594726562, Norm: 0.0027795627247542143, InvBCE: 809.8235473632812\n",
      "Loss: 809.8582763671875, Norm: 0.0030095039401203394, InvBCE: 809.8235473632812\n",
      "Loss: 809.8580322265625, Norm: 0.0032391278073191643, InvBCE: 809.8235473632812\n",
      "Loss: 809.8578491210938, Norm: 0.0034684212878346443, InvBCE: 809.8235473632812\n",
      "Loss: 809.857666015625, Norm: 0.0036973722744733095, InvBCE: 809.8235473632812\n",
      "Loss: 809.857421875, Norm: 0.003925969824194908, InvBCE: 809.8235473632812\n",
      "Loss: 809.8572387695312, Norm: 0.004154201131314039, InvBCE: 809.8235473632812\n",
      "Loss: 809.8569946289062, Norm: 0.004382054787129164, InvBCE: 809.8235473632812\n",
      "Image 80...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 81...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 82...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 83...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 84...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 85...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 86...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 87...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 88...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 89...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 90...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 91...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 92...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 93...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 94...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 95...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 96...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 97...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 98...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 99...\n",
      "Image fooled! Adding perturbation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "133243d1282140aeb0c9722eb11292f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fooling rate: 0.94\n",
      "Starting epoch 21...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2facf5707b4488a99bf2c656ea3f4d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 1...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 2...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 3...\n",
      "Loss: 2.717554807662964, Norm: 0.0, InvBCE: 2.6801018714904785\n",
      "Loss: 2.407351493835449, Norm: 0.00038118421798571944, InvBCE: 2.3698573112487793\n",
      "Loss: 2.134324550628662, Norm: 0.0007559842779301107, InvBCE: 2.0967862606048584\n",
      "Loss: 1.8955780267715454, Norm: 0.0011244287015870214, InvBCE: 1.8579938411712646\n",
      "Loss: 1.6877946853637695, Norm: 0.0014857073547318578, InvBCE: 1.650162935256958\n",
      "Loss: 1.5075215101242065, Norm: 0.0018390374025329947, InvBCE: 1.4698407649993896\n",
      "Loss: 1.3513212203979492, Norm: 0.0021836247760802507, InvBCE: 1.313590407371521\n",
      "Loss: 1.2159942388534546, Norm: 0.0025187814608216286, InvBCE: 1.1782126426696777\n",
      "Loss: 1.0986416339874268, Norm: 0.0028439692687243223, InvBCE: 1.060808777809143\n",
      "Loss: 0.9967145323753357, Norm: 0.0031588065903633833, InvBCE: 0.9588302969932556\n",
      "Loss: 0.9080396294593811, Norm: 0.0034630452282726765, InvBCE: 0.8701043128967285\n",
      "Loss: 0.8308247327804565, Norm: 0.003756554564461112, InvBCE: 0.7928388714790344\n",
      "Loss: 0.7636405229568481, Norm: 0.004039280116558075, InvBCE: 0.7256050109863281\n",
      "Loss: 0.7053354978561401, Norm: 0.004311214666813612, InvBCE: 0.667251467704773\n",
      "Loss: 0.6549381613731384, Norm: 0.004572402220219374, InvBCE: 0.6168069243431091\n",
      "Loss: 0.6115550398826599, Norm: 0.004822922870516777, InvBCE: 0.5733780264854431\n",
      "Loss: 0.5743334293365479, Norm: 0.005062887445092201, InvBCE: 0.5361122488975525\n",
      "Loss: 0.5424706339836121, Norm: 0.005292464513331652, InvBCE: 0.5042068958282471\n",
      "Loss: 0.5152295231819153, Norm: 0.005511854775249958, InvBCE: 0.47692495584487915\n",
      "Loss: 0.4919421672821045, Norm: 0.005721298512071371, InvBCE: 0.4535984694957733\n",
      "Image 4...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 5...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 6...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 7...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 8...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 9...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 10...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 11...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 12...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 13...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 14...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 15...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 16...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 17...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 18...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 19...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 20...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 21...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 22...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 23...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 24...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 25...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 26...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 27...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 28...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 29...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 30...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 31...\n",
      "Loss: 809.8610229492188, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8607788085938, Norm: 0.00023278483422473073, InvBCE: 809.8235473632812\n",
      "Loss: 809.860595703125, Norm: 0.00046540083712898195, InvBCE: 809.8235473632812\n",
      "Loss: 809.8603515625, Norm: 0.0006978358142077923, InvBCE: 809.8235473632812\n",
      "Loss: 809.8601684570312, Norm: 0.0009300776291638613, InvBCE: 809.8235473632812\n",
      "Loss: 809.8599243164062, Norm: 0.0011621139710769057, InvBCE: 809.8235473632812\n",
      "Loss: 809.8597412109375, Norm: 0.0013939322670921683, InvBCE: 809.8235473632812\n",
      "Loss: 809.8594970703125, Norm: 0.0016255201771855354, InvBCE: 809.8235473632812\n",
      "Loss: 809.8593139648438, Norm: 0.0018568650120869279, InvBCE: 809.8235473632812\n",
      "Loss: 809.8590698242188, Norm: 0.0020879541989415884, InvBCE: 809.8235473632812\n",
      "Loss: 809.85888671875, Norm: 0.002318775048479438, InvBCE: 809.8235473632812\n",
      "Loss: 809.8587036132812, Norm: 0.0025493153370916843, InvBCE: 809.8235473632812\n",
      "Loss: 809.8584594726562, Norm: 0.0027795627247542143, InvBCE: 809.8235473632812\n",
      "Loss: 809.8582763671875, Norm: 0.0030095039401203394, InvBCE: 809.8235473632812\n",
      "Loss: 809.8580322265625, Norm: 0.0032391278073191643, InvBCE: 809.8235473632812\n",
      "Loss: 809.8578491210938, Norm: 0.0034684212878346443, InvBCE: 809.8235473632812\n",
      "Loss: 809.857666015625, Norm: 0.0036973722744733095, InvBCE: 809.8235473632812\n",
      "Loss: 809.857421875, Norm: 0.003925969824194908, InvBCE: 809.8235473632812\n",
      "Loss: 809.8572387695312, Norm: 0.004154201131314039, InvBCE: 809.8235473632812\n",
      "Loss: 809.8569946289062, Norm: 0.004382054787129164, InvBCE: 809.8235473632812\n",
      "Image 32...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 33...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 34...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 35...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 36...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 37...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 38...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 39...\n",
      "Loss: 72.98128509521484, Norm: 0.0, InvBCE: 72.94383239746094\n",
      "Loss: 46.08408737182617, Norm: 0.0003843815065920353, InvBCE: 46.04658126831055\n",
      "Loss: 32.78629684448242, Norm: 0.000742322881706059, InvBCE: 32.74873352050781\n",
      "Loss: 24.617408752441406, Norm: 0.001077656401321292, InvBCE: 24.579795837402344\n",
      "Loss: 19.725128173828125, Norm: 0.0013914385344833136, InvBCE: 19.68746566772461\n",
      "Loss: 16.54332160949707, Norm: 0.0016856665024533868, InvBCE: 16.505611419677734\n",
      "Loss: 14.422035217285156, Norm: 0.001962564652785659, InvBCE: 14.384281158447266\n",
      "Loss: 12.86168384552002, Norm: 0.002224019728600979, InvBCE: 12.82388687133789\n",
      "Loss: 11.653457641601562, Norm: 0.002471968298777938, InvBCE: 11.615620613098145\n",
      "Loss: 10.683114051818848, Norm: 0.0027080196887254715, InvBCE: 10.645237922668457\n",
      "Loss: 8.709017753601074, Norm: 0.002933422802016139, InvBCE: 8.67110538482666\n",
      "Loss: 8.126260757446289, Norm: 0.003149435855448246, InvBCE: 8.088312149047852\n",
      "Loss: 7.666654109954834, Norm: 0.003355486784130335, InvBCE: 7.628672122955322\n",
      "Loss: 7.273351192474365, Norm: 0.0035526002757251263, InvBCE: 7.235337734222412\n",
      "Loss: 6.933590412139893, Norm: 0.0037416713312268257, InvBCE: 6.8955464363098145\n",
      "Loss: 6.633247375488281, Norm: 0.003923483658581972, InvBCE: 6.595174789428711\n",
      "Loss: 6.361598968505859, Norm: 0.0040987515822052956, InvBCE: 6.3234992027282715\n",
      "Loss: 6.131810665130615, Norm: 0.004267985001206398, InvBCE: 6.093685150146484\n",
      "Loss: 5.9073896408081055, Norm: 0.004431800916790962, InvBCE: 5.869239807128906\n",
      "Loss: 5.703206539154053, Norm: 0.00459067290648818, InvBCE: 5.665033340454102\n",
      "Image 40...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 41...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 42...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 43...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 44...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 45...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 46...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 47...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 48...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 49...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 50...\n",
      "Loss: 6.874675750732422, Norm: 0.0, InvBCE: 6.837223052978516\n",
      "Loss: 5.713406562805176, Norm: 0.00038196725654415786, InvBCE: 5.675937175750732\n",
      "Loss: 4.862036228179932, Norm: 0.0007531616720370948, InvBCE: 4.824548244476318\n",
      "Loss: 4.227441787719727, Norm: 0.001112419762648642, InvBCE: 4.1899333000183105\n",
      "Loss: 3.746464490890503, Norm: 0.0014584700111299753, InvBCE: 3.7089335918426514\n",
      "Loss: 3.3400683403015137, Norm: 0.0017919117817655206, InvBCE: 3.302513599395752\n",
      "Loss: 2.9916229248046875, Norm: 0.0021140952594578266, InvBCE: 2.95404314994812\n",
      "Loss: 2.6898796558380127, Norm: 0.0024259877391159534, InvBCE: 2.652273654937744\n",
      "Loss: 2.410594940185547, Norm: 0.002726512961089611, InvBCE: 2.372962236404419\n",
      "Loss: 2.1516685485839844, Norm: 0.003019202733412385, InvBCE: 2.1140081882476807\n",
      "Loss: 1.9215281009674072, Norm: 0.0033044118899852037, InvBCE: 1.8838392496109009\n",
      "Loss: 1.7152602672576904, Norm: 0.003581922734156251, InvBCE: 1.6775423288345337\n",
      "Loss: 1.5298104286193848, Norm: 0.0038516235072165728, InvBCE: 1.492063045501709\n",
      "Loss: 1.3668485879898071, Norm: 0.0041131931357085705, InvBCE: 1.3290716409683228\n",
      "Loss: 1.2230404615402222, Norm: 0.004366306122392416, InvBCE: 1.1852339506149292\n",
      "Loss: 1.0948585271835327, Norm: 0.004610858391970396, InvBCE: 1.0570225715637207\n",
      "Loss: 0.9814375042915344, Norm: 0.004846720490604639, InvBCE: 0.9435725212097168\n",
      "Loss: 0.8834782242774963, Norm: 0.005073722917586565, InvBCE: 0.8455847501754761\n",
      "Loss: 0.7992496490478516, Norm: 0.005291688721626997, InvBCE: 0.761328399181366\n",
      "Loss: 0.7287654876708984, Norm: 0.005500452127307653, InvBCE: 0.6908174157142639\n",
      "Image 51...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 52...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 53...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 54...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 55...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 56...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 57...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 58...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 59...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 60...\n",
      "Loss: 630.2578125, Norm: 0.0, InvBCE: 630.2203369140625\n",
      "Loss: 294.43890380859375, Norm: 0.0003751915355678648, InvBCE: 294.40142822265625\n",
      "Loss: 205.86048889160156, Norm: 0.0007111579179763794, InvBCE: 205.822998046875\n",
      "Loss: 127.29917907714844, Norm: 0.000995049369521439, InvBCE: 127.26168060302734\n",
      "Loss: 87.0525894165039, Norm: 0.0012601095950230956, InvBCE: 87.01508331298828\n",
      "Loss: 64.68090057373047, Norm: 0.0015051922528073192, InvBCE: 64.64338684082031\n",
      "Loss: 51.09668731689453, Norm: 0.0017316206358373165, InvBCE: 51.05917739868164\n",
      "Loss: 42.111236572265625, Norm: 0.0019414193229749799, InvBCE: 42.073726654052734\n",
      "Loss: 36.45672607421875, Norm: 0.002136079827323556, InvBCE: 36.419219970703125\n",
      "Loss: 32.15752029418945, Norm: 0.0023177447728812695, InvBCE: 32.120018005371094\n",
      "Loss: 28.973976135253906, Norm: 0.0024879255797713995, InvBCE: 28.936481475830078\n",
      "Loss: 26.204933166503906, Norm: 0.002647911664098501, InvBCE: 26.16744613647461\n",
      "Loss: 24.398008346557617, Norm: 0.00279878918081522, InvBCE: 24.360530853271484\n",
      "Loss: 23.336881637573242, Norm: 0.0029415434692054987, InvBCE: 23.299413681030273\n",
      "Loss: 22.053970336914062, Norm: 0.0030771500896662474, InvBCE: 22.01651382446289\n",
      "Loss: 21.04062271118164, Norm: 0.003206353634595871, InvBCE: 21.003177642822266\n",
      "Loss: 20.176753997802734, Norm: 0.003329807659611106, InvBCE: 20.13932228088379\n",
      "Loss: 19.40626335144043, Norm: 0.0034481859765946865, InvBCE: 19.368844985961914\n",
      "Loss: 18.743093490600586, Norm: 0.0035619453992694616, InvBCE: 18.705690383911133\n",
      "Loss: 18.163227081298828, Norm: 0.0036715876776725054, InvBCE: 18.125839233398438\n",
      "Image 61...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 62...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 63...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 64...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 65...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 66...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 67...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 68...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 69...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 70...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 71...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 72...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 73...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 74...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 75...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 76...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 77...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 78...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 79...\n",
      "Loss: 809.8610229492188, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8607788085938, Norm: 0.00023278483422473073, InvBCE: 809.8235473632812\n",
      "Loss: 809.860595703125, Norm: 0.00046540083712898195, InvBCE: 809.8235473632812\n",
      "Loss: 809.8603515625, Norm: 0.0006978358142077923, InvBCE: 809.8235473632812\n",
      "Loss: 809.8601684570312, Norm: 0.0009300776291638613, InvBCE: 809.8235473632812\n",
      "Loss: 809.8599243164062, Norm: 0.0011621139710769057, InvBCE: 809.8235473632812\n",
      "Loss: 809.8597412109375, Norm: 0.0013939322670921683, InvBCE: 809.8235473632812\n",
      "Loss: 809.8594970703125, Norm: 0.0016255201771855354, InvBCE: 809.8235473632812\n",
      "Loss: 809.8593139648438, Norm: 0.0018568650120869279, InvBCE: 809.8235473632812\n",
      "Loss: 809.8590698242188, Norm: 0.0020879541989415884, InvBCE: 809.8235473632812\n",
      "Loss: 809.85888671875, Norm: 0.002318775048479438, InvBCE: 809.8235473632812\n",
      "Loss: 809.8587036132812, Norm: 0.0025493153370916843, InvBCE: 809.8235473632812\n",
      "Loss: 809.8584594726562, Norm: 0.0027795627247542143, InvBCE: 809.8235473632812\n",
      "Loss: 809.8582763671875, Norm: 0.0030095039401203394, InvBCE: 809.8235473632812\n",
      "Loss: 809.8580322265625, Norm: 0.0032391278073191643, InvBCE: 809.8235473632812\n",
      "Loss: 809.8578491210938, Norm: 0.0034684212878346443, InvBCE: 809.8235473632812\n",
      "Loss: 809.857666015625, Norm: 0.0036973722744733095, InvBCE: 809.8235473632812\n",
      "Loss: 809.857421875, Norm: 0.003925969824194908, InvBCE: 809.8235473632812\n",
      "Loss: 809.8572387695312, Norm: 0.004154201131314039, InvBCE: 809.8235473632812\n",
      "Loss: 809.8569946289062, Norm: 0.004382054787129164, InvBCE: 809.8235473632812\n",
      "Image 80...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 81...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 82...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 83...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 84...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 85...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 86...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 87...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 88...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 89...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 90...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 91...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 92...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 93...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 94...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 95...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 96...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 97...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 98...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 99...\n",
      "Image fooled! Adding perturbation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6c7259d20d14e3ba1d547383a23c105",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fooling rate: 0.94\n",
      "Starting epoch 22...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d12599b3f0b1403cbd8286478a19c572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 1...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 2...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 3...\n",
      "Loss: 2.717554807662964, Norm: 0.0, InvBCE: 2.6801018714904785\n",
      "Loss: 2.407351493835449, Norm: 0.00038118421798571944, InvBCE: 2.3698573112487793\n",
      "Loss: 2.134324550628662, Norm: 0.0007559842779301107, InvBCE: 2.0967862606048584\n",
      "Loss: 1.8955780267715454, Norm: 0.0011244287015870214, InvBCE: 1.8579938411712646\n",
      "Loss: 1.6877946853637695, Norm: 0.0014857073547318578, InvBCE: 1.650162935256958\n",
      "Loss: 1.5075215101242065, Norm: 0.0018390374025329947, InvBCE: 1.4698407649993896\n",
      "Loss: 1.3513212203979492, Norm: 0.0021836247760802507, InvBCE: 1.313590407371521\n",
      "Loss: 1.2159942388534546, Norm: 0.0025187814608216286, InvBCE: 1.1782126426696777\n",
      "Loss: 1.0986416339874268, Norm: 0.0028439692687243223, InvBCE: 1.060808777809143\n",
      "Loss: 0.9967145323753357, Norm: 0.0031588065903633833, InvBCE: 0.9588302969932556\n",
      "Loss: 0.9080396294593811, Norm: 0.0034630452282726765, InvBCE: 0.8701043128967285\n",
      "Loss: 0.8308247327804565, Norm: 0.003756554564461112, InvBCE: 0.7928388714790344\n",
      "Loss: 0.7636405229568481, Norm: 0.004039280116558075, InvBCE: 0.7256050109863281\n",
      "Loss: 0.7053354978561401, Norm: 0.004311214666813612, InvBCE: 0.667251467704773\n",
      "Loss: 0.6549381613731384, Norm: 0.004572402220219374, InvBCE: 0.6168069243431091\n",
      "Loss: 0.6115550398826599, Norm: 0.004822922870516777, InvBCE: 0.5733780264854431\n",
      "Loss: 0.5743334293365479, Norm: 0.005062887445092201, InvBCE: 0.5361122488975525\n",
      "Loss: 0.5424706339836121, Norm: 0.005292464513331652, InvBCE: 0.5042068958282471\n",
      "Loss: 0.5152295231819153, Norm: 0.005511854775249958, InvBCE: 0.47692495584487915\n",
      "Loss: 0.4919421672821045, Norm: 0.005721298512071371, InvBCE: 0.4535984694957733\n",
      "Image 4...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 5...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 6...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 7...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 8...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 9...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 10...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 11...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 12...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 13...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 14...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 15...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 16...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 17...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 18...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 19...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 20...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 21...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 22...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 23...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 24...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 25...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 26...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 27...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 28...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 29...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 30...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 31...\n",
      "Loss: 809.8610229492188, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8607788085938, Norm: 0.00023278483422473073, InvBCE: 809.8235473632812\n",
      "Loss: 809.860595703125, Norm: 0.00046540083712898195, InvBCE: 809.8235473632812\n",
      "Loss: 809.8603515625, Norm: 0.0006978358142077923, InvBCE: 809.8235473632812\n",
      "Loss: 809.8601684570312, Norm: 0.0009300776291638613, InvBCE: 809.8235473632812\n",
      "Loss: 809.8599243164062, Norm: 0.0011621139710769057, InvBCE: 809.8235473632812\n",
      "Loss: 809.8597412109375, Norm: 0.0013939322670921683, InvBCE: 809.8235473632812\n",
      "Loss: 809.8594970703125, Norm: 0.0016255201771855354, InvBCE: 809.8235473632812\n",
      "Loss: 809.8593139648438, Norm: 0.0018568650120869279, InvBCE: 809.8235473632812\n",
      "Loss: 809.8590698242188, Norm: 0.0020879541989415884, InvBCE: 809.8235473632812\n",
      "Loss: 809.85888671875, Norm: 0.002318775048479438, InvBCE: 809.8235473632812\n",
      "Loss: 809.8587036132812, Norm: 0.0025493153370916843, InvBCE: 809.8235473632812\n",
      "Loss: 809.8584594726562, Norm: 0.0027795627247542143, InvBCE: 809.8235473632812\n",
      "Loss: 809.8582763671875, Norm: 0.0030095039401203394, InvBCE: 809.8235473632812\n",
      "Loss: 809.8580322265625, Norm: 0.0032391278073191643, InvBCE: 809.8235473632812\n",
      "Loss: 809.8578491210938, Norm: 0.0034684212878346443, InvBCE: 809.8235473632812\n",
      "Loss: 809.857666015625, Norm: 0.0036973722744733095, InvBCE: 809.8235473632812\n",
      "Loss: 809.857421875, Norm: 0.003925969824194908, InvBCE: 809.8235473632812\n",
      "Loss: 809.8572387695312, Norm: 0.004154201131314039, InvBCE: 809.8235473632812\n",
      "Loss: 809.8569946289062, Norm: 0.004382054787129164, InvBCE: 809.8235473632812\n",
      "Image 32...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 33...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 34...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 35...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 36...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 37...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 38...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 39...\n",
      "Loss: 72.98128509521484, Norm: 0.0, InvBCE: 72.94383239746094\n",
      "Loss: 46.08408737182617, Norm: 0.0003843815065920353, InvBCE: 46.04658126831055\n",
      "Loss: 32.78629684448242, Norm: 0.000742322881706059, InvBCE: 32.74873352050781\n",
      "Loss: 24.617408752441406, Norm: 0.001077656401321292, InvBCE: 24.579795837402344\n",
      "Loss: 19.725128173828125, Norm: 0.0013914385344833136, InvBCE: 19.68746566772461\n",
      "Loss: 16.54332160949707, Norm: 0.0016856665024533868, InvBCE: 16.505611419677734\n",
      "Loss: 14.422035217285156, Norm: 0.001962564652785659, InvBCE: 14.384281158447266\n",
      "Loss: 12.86168384552002, Norm: 0.002224019728600979, InvBCE: 12.82388687133789\n",
      "Loss: 11.653457641601562, Norm: 0.002471968298777938, InvBCE: 11.615620613098145\n",
      "Loss: 10.683114051818848, Norm: 0.0027080196887254715, InvBCE: 10.645237922668457\n",
      "Loss: 8.709017753601074, Norm: 0.002933422802016139, InvBCE: 8.67110538482666\n",
      "Loss: 8.126260757446289, Norm: 0.003149435855448246, InvBCE: 8.088312149047852\n",
      "Loss: 7.666654109954834, Norm: 0.003355486784130335, InvBCE: 7.628672122955322\n",
      "Loss: 7.273351192474365, Norm: 0.0035526002757251263, InvBCE: 7.235337734222412\n",
      "Loss: 6.933590412139893, Norm: 0.0037416713312268257, InvBCE: 6.8955464363098145\n",
      "Loss: 6.633247375488281, Norm: 0.003923483658581972, InvBCE: 6.595174789428711\n",
      "Loss: 6.361598968505859, Norm: 0.0040987515822052956, InvBCE: 6.3234992027282715\n",
      "Loss: 6.131810665130615, Norm: 0.004267985001206398, InvBCE: 6.093685150146484\n",
      "Loss: 5.9073896408081055, Norm: 0.004431800916790962, InvBCE: 5.869239807128906\n",
      "Loss: 5.703206539154053, Norm: 0.00459067290648818, InvBCE: 5.665033340454102\n",
      "Image 40...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 41...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 42...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 43...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 44...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 45...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 46...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 47...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 48...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 49...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 50...\n",
      "Loss: 6.874675750732422, Norm: 0.0, InvBCE: 6.837223052978516\n",
      "Loss: 5.713406562805176, Norm: 0.00038196725654415786, InvBCE: 5.675937175750732\n",
      "Loss: 4.862036228179932, Norm: 0.0007531616720370948, InvBCE: 4.824548244476318\n",
      "Loss: 4.227441787719727, Norm: 0.001112419762648642, InvBCE: 4.1899333000183105\n",
      "Loss: 3.746464490890503, Norm: 0.0014584700111299753, InvBCE: 3.7089335918426514\n",
      "Loss: 3.3400683403015137, Norm: 0.0017919117817655206, InvBCE: 3.302513599395752\n",
      "Loss: 2.9916229248046875, Norm: 0.0021140952594578266, InvBCE: 2.95404314994812\n",
      "Loss: 2.6898796558380127, Norm: 0.0024259877391159534, InvBCE: 2.652273654937744\n",
      "Loss: 2.410594940185547, Norm: 0.002726512961089611, InvBCE: 2.372962236404419\n",
      "Loss: 2.1516685485839844, Norm: 0.003019202733412385, InvBCE: 2.1140081882476807\n",
      "Loss: 1.9215281009674072, Norm: 0.0033044118899852037, InvBCE: 1.8838392496109009\n",
      "Loss: 1.7152602672576904, Norm: 0.003581922734156251, InvBCE: 1.6775423288345337\n",
      "Loss: 1.5298104286193848, Norm: 0.0038516235072165728, InvBCE: 1.492063045501709\n",
      "Loss: 1.3668485879898071, Norm: 0.0041131931357085705, InvBCE: 1.3290716409683228\n",
      "Loss: 1.2230404615402222, Norm: 0.004366306122392416, InvBCE: 1.1852339506149292\n",
      "Loss: 1.0948585271835327, Norm: 0.004610858391970396, InvBCE: 1.0570225715637207\n",
      "Loss: 0.9814375042915344, Norm: 0.004846720490604639, InvBCE: 0.9435725212097168\n",
      "Loss: 0.8834782242774963, Norm: 0.005073722917586565, InvBCE: 0.8455847501754761\n",
      "Loss: 0.7992496490478516, Norm: 0.005291688721626997, InvBCE: 0.761328399181366\n",
      "Loss: 0.7287654876708984, Norm: 0.005500452127307653, InvBCE: 0.6908174157142639\n",
      "Image 51...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 52...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 53...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 54...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 55...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 56...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 57...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 58...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 59...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 60...\n",
      "Loss: 630.2578125, Norm: 0.0, InvBCE: 630.2203369140625\n",
      "Loss: 294.43890380859375, Norm: 0.0003751915355678648, InvBCE: 294.40142822265625\n",
      "Loss: 205.86048889160156, Norm: 0.0007111579179763794, InvBCE: 205.822998046875\n",
      "Loss: 127.29917907714844, Norm: 0.000995049369521439, InvBCE: 127.26168060302734\n",
      "Loss: 87.0525894165039, Norm: 0.0012601095950230956, InvBCE: 87.01508331298828\n",
      "Loss: 64.68090057373047, Norm: 0.0015051922528073192, InvBCE: 64.64338684082031\n",
      "Loss: 51.09668731689453, Norm: 0.0017316206358373165, InvBCE: 51.05917739868164\n",
      "Loss: 42.111236572265625, Norm: 0.0019414193229749799, InvBCE: 42.073726654052734\n",
      "Loss: 36.45672607421875, Norm: 0.002136079827323556, InvBCE: 36.419219970703125\n",
      "Loss: 32.15752029418945, Norm: 0.0023177447728812695, InvBCE: 32.120018005371094\n",
      "Loss: 28.973976135253906, Norm: 0.0024879255797713995, InvBCE: 28.936481475830078\n",
      "Loss: 26.204933166503906, Norm: 0.002647911664098501, InvBCE: 26.16744613647461\n",
      "Loss: 24.398008346557617, Norm: 0.00279878918081522, InvBCE: 24.360530853271484\n",
      "Loss: 23.336881637573242, Norm: 0.0029415434692054987, InvBCE: 23.299413681030273\n",
      "Loss: 22.053970336914062, Norm: 0.0030771500896662474, InvBCE: 22.01651382446289\n",
      "Loss: 21.04062271118164, Norm: 0.003206353634595871, InvBCE: 21.003177642822266\n",
      "Loss: 20.176753997802734, Norm: 0.003329807659611106, InvBCE: 20.13932228088379\n",
      "Loss: 19.40626335144043, Norm: 0.0034481859765946865, InvBCE: 19.368844985961914\n",
      "Loss: 18.743093490600586, Norm: 0.0035619453992694616, InvBCE: 18.705690383911133\n",
      "Loss: 18.163227081298828, Norm: 0.0036715876776725054, InvBCE: 18.125839233398438\n",
      "Image 61...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 62...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 63...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 64...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 65...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 66...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 67...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 68...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 69...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 70...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 71...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 72...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 73...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 74...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 75...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 76...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 77...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 78...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 79...\n",
      "Loss: 809.8610229492188, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8607788085938, Norm: 0.00023278483422473073, InvBCE: 809.8235473632812\n",
      "Loss: 809.860595703125, Norm: 0.00046540083712898195, InvBCE: 809.8235473632812\n",
      "Loss: 809.8603515625, Norm: 0.0006978358142077923, InvBCE: 809.8235473632812\n",
      "Loss: 809.8601684570312, Norm: 0.0009300776291638613, InvBCE: 809.8235473632812\n",
      "Loss: 809.8599243164062, Norm: 0.0011621139710769057, InvBCE: 809.8235473632812\n",
      "Loss: 809.8597412109375, Norm: 0.0013939322670921683, InvBCE: 809.8235473632812\n",
      "Loss: 809.8594970703125, Norm: 0.0016255201771855354, InvBCE: 809.8235473632812\n",
      "Loss: 809.8593139648438, Norm: 0.0018568650120869279, InvBCE: 809.8235473632812\n",
      "Loss: 809.8590698242188, Norm: 0.0020879541989415884, InvBCE: 809.8235473632812\n",
      "Loss: 809.85888671875, Norm: 0.002318775048479438, InvBCE: 809.8235473632812\n",
      "Loss: 809.8587036132812, Norm: 0.0025493153370916843, InvBCE: 809.8235473632812\n",
      "Loss: 809.8584594726562, Norm: 0.0027795627247542143, InvBCE: 809.8235473632812\n",
      "Loss: 809.8582763671875, Norm: 0.0030095039401203394, InvBCE: 809.8235473632812\n",
      "Loss: 809.8580322265625, Norm: 0.0032391278073191643, InvBCE: 809.8235473632812\n",
      "Loss: 809.8578491210938, Norm: 0.0034684212878346443, InvBCE: 809.8235473632812\n",
      "Loss: 809.857666015625, Norm: 0.0036973722744733095, InvBCE: 809.8235473632812\n",
      "Loss: 809.857421875, Norm: 0.003925969824194908, InvBCE: 809.8235473632812\n",
      "Loss: 809.8572387695312, Norm: 0.004154201131314039, InvBCE: 809.8235473632812\n",
      "Loss: 809.8569946289062, Norm: 0.004382054787129164, InvBCE: 809.8235473632812\n",
      "Image 80...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 81...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 82...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 83...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 84...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 85...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 86...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 87...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 88...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 89...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 90...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 91...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 92...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 93...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 94...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 95...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 96...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 97...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 98...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 99...\n",
      "Image fooled! Adding perturbation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7972d1a59af4b4a9422393e904edbdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fooling rate: 0.94\n",
      "Starting epoch 23...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eff00b3a8757464aaf2626d2314ca9ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 1...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 2...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 3...\n",
      "Loss: 2.717554807662964, Norm: 0.0, InvBCE: 2.6801018714904785\n",
      "Loss: 2.407351493835449, Norm: 0.00038118421798571944, InvBCE: 2.3698573112487793\n",
      "Loss: 2.134324550628662, Norm: 0.0007559842779301107, InvBCE: 2.0967862606048584\n",
      "Loss: 1.8955780267715454, Norm: 0.0011244287015870214, InvBCE: 1.8579938411712646\n",
      "Loss: 1.6877946853637695, Norm: 0.0014857073547318578, InvBCE: 1.650162935256958\n",
      "Loss: 1.5075215101242065, Norm: 0.0018390374025329947, InvBCE: 1.4698407649993896\n",
      "Loss: 1.3513212203979492, Norm: 0.0021836247760802507, InvBCE: 1.313590407371521\n",
      "Loss: 1.2159942388534546, Norm: 0.0025187814608216286, InvBCE: 1.1782126426696777\n",
      "Loss: 1.0986416339874268, Norm: 0.0028439692687243223, InvBCE: 1.060808777809143\n",
      "Loss: 0.9967145323753357, Norm: 0.0031588065903633833, InvBCE: 0.9588302969932556\n",
      "Loss: 0.9080396294593811, Norm: 0.0034630452282726765, InvBCE: 0.8701043128967285\n",
      "Loss: 0.8308247327804565, Norm: 0.003756554564461112, InvBCE: 0.7928388714790344\n",
      "Loss: 0.7636405229568481, Norm: 0.004039280116558075, InvBCE: 0.7256050109863281\n",
      "Loss: 0.7053354978561401, Norm: 0.004311214666813612, InvBCE: 0.667251467704773\n",
      "Loss: 0.6549381613731384, Norm: 0.004572402220219374, InvBCE: 0.6168069243431091\n",
      "Loss: 0.6115550398826599, Norm: 0.004822922870516777, InvBCE: 0.5733780264854431\n",
      "Loss: 0.5743334293365479, Norm: 0.005062887445092201, InvBCE: 0.5361122488975525\n",
      "Loss: 0.5424706339836121, Norm: 0.005292464513331652, InvBCE: 0.5042068958282471\n",
      "Loss: 0.5152295231819153, Norm: 0.005511854775249958, InvBCE: 0.47692495584487915\n",
      "Loss: 0.4919421672821045, Norm: 0.005721298512071371, InvBCE: 0.4535984694957733\n",
      "Image 4...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 5...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 6...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 7...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 8...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 9...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 10...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 11...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 12...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 13...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 14...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 15...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 16...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 17...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 18...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 19...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 20...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 21...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 22...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 23...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 24...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 25...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 26...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 27...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 28...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 29...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 30...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 31...\n",
      "Loss: 809.8610229492188, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8607788085938, Norm: 0.00023278483422473073, InvBCE: 809.8235473632812\n",
      "Loss: 809.860595703125, Norm: 0.00046540083712898195, InvBCE: 809.8235473632812\n",
      "Loss: 809.8603515625, Norm: 0.0006978358142077923, InvBCE: 809.8235473632812\n",
      "Loss: 809.8601684570312, Norm: 0.0009300776291638613, InvBCE: 809.8235473632812\n",
      "Loss: 809.8599243164062, Norm: 0.0011621139710769057, InvBCE: 809.8235473632812\n",
      "Loss: 809.8597412109375, Norm: 0.0013939322670921683, InvBCE: 809.8235473632812\n",
      "Loss: 809.8594970703125, Norm: 0.0016255201771855354, InvBCE: 809.8235473632812\n",
      "Loss: 809.8593139648438, Norm: 0.0018568650120869279, InvBCE: 809.8235473632812\n",
      "Loss: 809.8590698242188, Norm: 0.0020879541989415884, InvBCE: 809.8235473632812\n",
      "Loss: 809.85888671875, Norm: 0.002318775048479438, InvBCE: 809.8235473632812\n",
      "Loss: 809.8587036132812, Norm: 0.0025493153370916843, InvBCE: 809.8235473632812\n",
      "Loss: 809.8584594726562, Norm: 0.0027795627247542143, InvBCE: 809.8235473632812\n",
      "Loss: 809.8582763671875, Norm: 0.0030095039401203394, InvBCE: 809.8235473632812\n",
      "Loss: 809.8580322265625, Norm: 0.0032391278073191643, InvBCE: 809.8235473632812\n",
      "Loss: 809.8578491210938, Norm: 0.0034684212878346443, InvBCE: 809.8235473632812\n",
      "Loss: 809.857666015625, Norm: 0.0036973722744733095, InvBCE: 809.8235473632812\n",
      "Loss: 809.857421875, Norm: 0.003925969824194908, InvBCE: 809.8235473632812\n",
      "Loss: 809.8572387695312, Norm: 0.004154201131314039, InvBCE: 809.8235473632812\n",
      "Loss: 809.8569946289062, Norm: 0.004382054787129164, InvBCE: 809.8235473632812\n",
      "Image 32...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 33...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 34...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 35...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 36...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 37...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 38...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 39...\n",
      "Loss: 72.98128509521484, Norm: 0.0, InvBCE: 72.94383239746094\n",
      "Loss: 46.08408737182617, Norm: 0.0003843815065920353, InvBCE: 46.04658126831055\n",
      "Loss: 32.78629684448242, Norm: 0.000742322881706059, InvBCE: 32.74873352050781\n",
      "Loss: 24.617408752441406, Norm: 0.001077656401321292, InvBCE: 24.579795837402344\n",
      "Loss: 19.725128173828125, Norm: 0.0013914385344833136, InvBCE: 19.68746566772461\n",
      "Loss: 16.54332160949707, Norm: 0.0016856665024533868, InvBCE: 16.505611419677734\n",
      "Loss: 14.422035217285156, Norm: 0.001962564652785659, InvBCE: 14.384281158447266\n",
      "Loss: 12.86168384552002, Norm: 0.002224019728600979, InvBCE: 12.82388687133789\n",
      "Loss: 11.653457641601562, Norm: 0.002471968298777938, InvBCE: 11.615620613098145\n",
      "Loss: 10.683114051818848, Norm: 0.0027080196887254715, InvBCE: 10.645237922668457\n",
      "Loss: 8.709017753601074, Norm: 0.002933422802016139, InvBCE: 8.67110538482666\n",
      "Loss: 8.126260757446289, Norm: 0.003149435855448246, InvBCE: 8.088312149047852\n",
      "Loss: 7.666654109954834, Norm: 0.003355486784130335, InvBCE: 7.628672122955322\n",
      "Loss: 7.273351192474365, Norm: 0.0035526002757251263, InvBCE: 7.235337734222412\n",
      "Loss: 6.933590412139893, Norm: 0.0037416713312268257, InvBCE: 6.8955464363098145\n",
      "Loss: 6.633247375488281, Norm: 0.003923483658581972, InvBCE: 6.595174789428711\n",
      "Loss: 6.361598968505859, Norm: 0.0040987515822052956, InvBCE: 6.3234992027282715\n",
      "Loss: 6.131810665130615, Norm: 0.004267985001206398, InvBCE: 6.093685150146484\n",
      "Loss: 5.9073896408081055, Norm: 0.004431800916790962, InvBCE: 5.869239807128906\n",
      "Loss: 5.703206539154053, Norm: 0.00459067290648818, InvBCE: 5.665033340454102\n",
      "Image 40...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 41...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 42...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 43...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 44...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 45...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 46...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 47...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 48...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 49...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 50...\n",
      "Loss: 6.874675750732422, Norm: 0.0, InvBCE: 6.837223052978516\n",
      "Loss: 5.713406562805176, Norm: 0.00038196725654415786, InvBCE: 5.675937175750732\n",
      "Loss: 4.862036228179932, Norm: 0.0007531616720370948, InvBCE: 4.824548244476318\n",
      "Loss: 4.227441787719727, Norm: 0.001112419762648642, InvBCE: 4.1899333000183105\n",
      "Loss: 3.746464490890503, Norm: 0.0014584700111299753, InvBCE: 3.7089335918426514\n",
      "Loss: 3.3400683403015137, Norm: 0.0017919117817655206, InvBCE: 3.302513599395752\n",
      "Loss: 2.9916229248046875, Norm: 0.0021140952594578266, InvBCE: 2.95404314994812\n",
      "Loss: 2.6898796558380127, Norm: 0.0024259877391159534, InvBCE: 2.652273654937744\n",
      "Loss: 2.410594940185547, Norm: 0.002726512961089611, InvBCE: 2.372962236404419\n",
      "Loss: 2.1516685485839844, Norm: 0.003019202733412385, InvBCE: 2.1140081882476807\n",
      "Loss: 1.9215281009674072, Norm: 0.0033044118899852037, InvBCE: 1.8838392496109009\n",
      "Loss: 1.7152602672576904, Norm: 0.003581922734156251, InvBCE: 1.6775423288345337\n",
      "Loss: 1.5298104286193848, Norm: 0.0038516235072165728, InvBCE: 1.492063045501709\n",
      "Loss: 1.3668485879898071, Norm: 0.0041131931357085705, InvBCE: 1.3290716409683228\n",
      "Loss: 1.2230404615402222, Norm: 0.004366306122392416, InvBCE: 1.1852339506149292\n",
      "Loss: 1.0948585271835327, Norm: 0.004610858391970396, InvBCE: 1.0570225715637207\n",
      "Loss: 0.9814375042915344, Norm: 0.004846720490604639, InvBCE: 0.9435725212097168\n",
      "Loss: 0.8834782242774963, Norm: 0.005073722917586565, InvBCE: 0.8455847501754761\n",
      "Loss: 0.7992496490478516, Norm: 0.005291688721626997, InvBCE: 0.761328399181366\n",
      "Loss: 0.7287654876708984, Norm: 0.005500452127307653, InvBCE: 0.6908174157142639\n",
      "Image 51...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 52...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 53...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 54...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 55...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 56...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 57...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 58...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 59...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 60...\n",
      "Loss: 630.2578125, Norm: 0.0, InvBCE: 630.2203369140625\n",
      "Loss: 294.43890380859375, Norm: 0.0003751915355678648, InvBCE: 294.40142822265625\n",
      "Loss: 205.86048889160156, Norm: 0.0007111579179763794, InvBCE: 205.822998046875\n",
      "Loss: 127.29917907714844, Norm: 0.000995049369521439, InvBCE: 127.26168060302734\n",
      "Loss: 87.0525894165039, Norm: 0.0012601095950230956, InvBCE: 87.01508331298828\n",
      "Loss: 64.68090057373047, Norm: 0.0015051922528073192, InvBCE: 64.64338684082031\n",
      "Loss: 51.09668731689453, Norm: 0.0017316206358373165, InvBCE: 51.05917739868164\n",
      "Loss: 42.111236572265625, Norm: 0.0019414193229749799, InvBCE: 42.073726654052734\n",
      "Loss: 36.45672607421875, Norm: 0.002136079827323556, InvBCE: 36.419219970703125\n",
      "Loss: 32.15752029418945, Norm: 0.0023177447728812695, InvBCE: 32.120018005371094\n",
      "Loss: 28.973976135253906, Norm: 0.0024879255797713995, InvBCE: 28.936481475830078\n",
      "Loss: 26.204933166503906, Norm: 0.002647911664098501, InvBCE: 26.16744613647461\n",
      "Loss: 24.398008346557617, Norm: 0.00279878918081522, InvBCE: 24.360530853271484\n",
      "Loss: 23.336881637573242, Norm: 0.0029415434692054987, InvBCE: 23.299413681030273\n",
      "Loss: 22.053970336914062, Norm: 0.0030771500896662474, InvBCE: 22.01651382446289\n",
      "Loss: 21.04062271118164, Norm: 0.003206353634595871, InvBCE: 21.003177642822266\n",
      "Loss: 20.176753997802734, Norm: 0.003329807659611106, InvBCE: 20.13932228088379\n",
      "Loss: 19.40626335144043, Norm: 0.0034481859765946865, InvBCE: 19.368844985961914\n",
      "Loss: 18.743093490600586, Norm: 0.0035619453992694616, InvBCE: 18.705690383911133\n",
      "Loss: 18.163227081298828, Norm: 0.0036715876776725054, InvBCE: 18.125839233398438\n",
      "Image 61...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 62...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 63...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 64...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 65...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 66...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 67...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 68...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 69...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 70...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 71...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 72...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 73...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 74...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 75...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 76...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 77...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 78...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 79...\n",
      "Loss: 809.8610229492188, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8607788085938, Norm: 0.00023278483422473073, InvBCE: 809.8235473632812\n",
      "Loss: 809.860595703125, Norm: 0.00046540083712898195, InvBCE: 809.8235473632812\n",
      "Loss: 809.8603515625, Norm: 0.0006978358142077923, InvBCE: 809.8235473632812\n",
      "Loss: 809.8601684570312, Norm: 0.0009300776291638613, InvBCE: 809.8235473632812\n",
      "Loss: 809.8599243164062, Norm: 0.0011621139710769057, InvBCE: 809.8235473632812\n",
      "Loss: 809.8597412109375, Norm: 0.0013939322670921683, InvBCE: 809.8235473632812\n",
      "Loss: 809.8594970703125, Norm: 0.0016255201771855354, InvBCE: 809.8235473632812\n",
      "Loss: 809.8593139648438, Norm: 0.0018568650120869279, InvBCE: 809.8235473632812\n",
      "Loss: 809.8590698242188, Norm: 0.0020879541989415884, InvBCE: 809.8235473632812\n",
      "Loss: 809.85888671875, Norm: 0.002318775048479438, InvBCE: 809.8235473632812\n",
      "Loss: 809.8587036132812, Norm: 0.0025493153370916843, InvBCE: 809.8235473632812\n",
      "Loss: 809.8584594726562, Norm: 0.0027795627247542143, InvBCE: 809.8235473632812\n",
      "Loss: 809.8582763671875, Norm: 0.0030095039401203394, InvBCE: 809.8235473632812\n",
      "Loss: 809.8580322265625, Norm: 0.0032391278073191643, InvBCE: 809.8235473632812\n",
      "Loss: 809.8578491210938, Norm: 0.0034684212878346443, InvBCE: 809.8235473632812\n",
      "Loss: 809.857666015625, Norm: 0.0036973722744733095, InvBCE: 809.8235473632812\n",
      "Loss: 809.857421875, Norm: 0.003925969824194908, InvBCE: 809.8235473632812\n",
      "Loss: 809.8572387695312, Norm: 0.004154201131314039, InvBCE: 809.8235473632812\n",
      "Loss: 809.8569946289062, Norm: 0.004382054787129164, InvBCE: 809.8235473632812\n",
      "Image 80...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 81...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 82...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 83...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 84...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 85...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 86...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 87...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 88...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 89...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 90...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 91...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 92...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 93...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 94...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 95...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 96...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 97...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 98...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 99...\n",
      "Image fooled! Adding perturbation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f27047850300478daa8b40371de6d177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fooling rate: 0.94\n",
      "Starting epoch 24...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49fe755ec3884285a1cd4a674850dbba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 1...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 2...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 3...\n",
      "Loss: 2.717554807662964, Norm: 0.0, InvBCE: 2.6801018714904785\n",
      "Loss: 2.407351493835449, Norm: 0.00038118421798571944, InvBCE: 2.3698573112487793\n",
      "Loss: 2.134324550628662, Norm: 0.0007559842779301107, InvBCE: 2.0967862606048584\n",
      "Loss: 1.8955780267715454, Norm: 0.0011244287015870214, InvBCE: 1.8579938411712646\n",
      "Loss: 1.6877946853637695, Norm: 0.0014857073547318578, InvBCE: 1.650162935256958\n",
      "Loss: 1.5075215101242065, Norm: 0.0018390374025329947, InvBCE: 1.4698407649993896\n",
      "Loss: 1.3513212203979492, Norm: 0.0021836247760802507, InvBCE: 1.313590407371521\n",
      "Loss: 1.2159942388534546, Norm: 0.0025187814608216286, InvBCE: 1.1782126426696777\n",
      "Loss: 1.0986416339874268, Norm: 0.0028439692687243223, InvBCE: 1.060808777809143\n",
      "Loss: 0.9967145323753357, Norm: 0.0031588065903633833, InvBCE: 0.9588302969932556\n",
      "Loss: 0.9080396294593811, Norm: 0.0034630452282726765, InvBCE: 0.8701043128967285\n",
      "Loss: 0.8308247327804565, Norm: 0.003756554564461112, InvBCE: 0.7928388714790344\n",
      "Loss: 0.7636405229568481, Norm: 0.004039280116558075, InvBCE: 0.7256050109863281\n",
      "Loss: 0.7053354978561401, Norm: 0.004311214666813612, InvBCE: 0.667251467704773\n",
      "Loss: 0.6549381613731384, Norm: 0.004572402220219374, InvBCE: 0.6168069243431091\n",
      "Loss: 0.6115550398826599, Norm: 0.004822922870516777, InvBCE: 0.5733780264854431\n",
      "Loss: 0.5743334293365479, Norm: 0.005062887445092201, InvBCE: 0.5361122488975525\n",
      "Loss: 0.5424706339836121, Norm: 0.005292464513331652, InvBCE: 0.5042068958282471\n",
      "Loss: 0.5152295231819153, Norm: 0.005511854775249958, InvBCE: 0.47692495584487915\n",
      "Loss: 0.4919421672821045, Norm: 0.005721298512071371, InvBCE: 0.4535984694957733\n",
      "Image 4...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 5...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 6...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 7...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 8...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 9...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 10...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 11...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 12...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 13...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 14...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 15...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 16...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 17...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 18...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 19...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 20...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 21...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 22...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 23...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 24...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 25...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 26...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 27...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 28...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 29...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 30...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 31...\n",
      "Loss: 809.8610229492188, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8607788085938, Norm: 0.00023278483422473073, InvBCE: 809.8235473632812\n",
      "Loss: 809.860595703125, Norm: 0.00046540083712898195, InvBCE: 809.8235473632812\n",
      "Loss: 809.8603515625, Norm: 0.0006978358142077923, InvBCE: 809.8235473632812\n",
      "Loss: 809.8601684570312, Norm: 0.0009300776291638613, InvBCE: 809.8235473632812\n",
      "Loss: 809.8599243164062, Norm: 0.0011621139710769057, InvBCE: 809.8235473632812\n",
      "Loss: 809.8597412109375, Norm: 0.0013939322670921683, InvBCE: 809.8235473632812\n",
      "Loss: 809.8594970703125, Norm: 0.0016255201771855354, InvBCE: 809.8235473632812\n",
      "Loss: 809.8593139648438, Norm: 0.0018568650120869279, InvBCE: 809.8235473632812\n",
      "Loss: 809.8590698242188, Norm: 0.0020879541989415884, InvBCE: 809.8235473632812\n",
      "Loss: 809.85888671875, Norm: 0.002318775048479438, InvBCE: 809.8235473632812\n",
      "Loss: 809.8587036132812, Norm: 0.0025493153370916843, InvBCE: 809.8235473632812\n",
      "Loss: 809.8584594726562, Norm: 0.0027795627247542143, InvBCE: 809.8235473632812\n",
      "Loss: 809.8582763671875, Norm: 0.0030095039401203394, InvBCE: 809.8235473632812\n",
      "Loss: 809.8580322265625, Norm: 0.0032391278073191643, InvBCE: 809.8235473632812\n",
      "Loss: 809.8578491210938, Norm: 0.0034684212878346443, InvBCE: 809.8235473632812\n",
      "Loss: 809.857666015625, Norm: 0.0036973722744733095, InvBCE: 809.8235473632812\n",
      "Loss: 809.857421875, Norm: 0.003925969824194908, InvBCE: 809.8235473632812\n",
      "Loss: 809.8572387695312, Norm: 0.004154201131314039, InvBCE: 809.8235473632812\n",
      "Loss: 809.8569946289062, Norm: 0.004382054787129164, InvBCE: 809.8235473632812\n",
      "Image 32...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 33...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 34...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 35...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 36...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 37...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 38...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 39...\n",
      "Loss: 72.98128509521484, Norm: 0.0, InvBCE: 72.94383239746094\n",
      "Loss: 46.08408737182617, Norm: 0.0003843815065920353, InvBCE: 46.04658126831055\n",
      "Loss: 32.78629684448242, Norm: 0.000742322881706059, InvBCE: 32.74873352050781\n",
      "Loss: 24.617408752441406, Norm: 0.001077656401321292, InvBCE: 24.579795837402344\n",
      "Loss: 19.725128173828125, Norm: 0.0013914385344833136, InvBCE: 19.68746566772461\n",
      "Loss: 16.54332160949707, Norm: 0.0016856665024533868, InvBCE: 16.505611419677734\n",
      "Loss: 14.422035217285156, Norm: 0.001962564652785659, InvBCE: 14.384281158447266\n",
      "Loss: 12.86168384552002, Norm: 0.002224019728600979, InvBCE: 12.82388687133789\n",
      "Loss: 11.653457641601562, Norm: 0.002471968298777938, InvBCE: 11.615620613098145\n",
      "Loss: 10.683114051818848, Norm: 0.0027080196887254715, InvBCE: 10.645237922668457\n",
      "Loss: 8.709017753601074, Norm: 0.002933422802016139, InvBCE: 8.67110538482666\n",
      "Loss: 8.126260757446289, Norm: 0.003149435855448246, InvBCE: 8.088312149047852\n",
      "Loss: 7.666654109954834, Norm: 0.003355486784130335, InvBCE: 7.628672122955322\n",
      "Loss: 7.273351192474365, Norm: 0.0035526002757251263, InvBCE: 7.235337734222412\n",
      "Loss: 6.933590412139893, Norm: 0.0037416713312268257, InvBCE: 6.8955464363098145\n",
      "Loss: 6.633247375488281, Norm: 0.003923483658581972, InvBCE: 6.595174789428711\n",
      "Loss: 6.361598968505859, Norm: 0.0040987515822052956, InvBCE: 6.3234992027282715\n",
      "Loss: 6.131810665130615, Norm: 0.004267985001206398, InvBCE: 6.093685150146484\n",
      "Loss: 5.9073896408081055, Norm: 0.004431800916790962, InvBCE: 5.869239807128906\n",
      "Loss: 5.703206539154053, Norm: 0.00459067290648818, InvBCE: 5.665033340454102\n",
      "Image 40...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 41...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 42...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 43...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 44...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 45...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 46...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 47...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 48...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 49...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 50...\n",
      "Loss: 6.874675750732422, Norm: 0.0, InvBCE: 6.837223052978516\n",
      "Loss: 5.713406562805176, Norm: 0.00038196725654415786, InvBCE: 5.675937175750732\n",
      "Loss: 4.862036228179932, Norm: 0.0007531616720370948, InvBCE: 4.824548244476318\n",
      "Loss: 4.227441787719727, Norm: 0.001112419762648642, InvBCE: 4.1899333000183105\n",
      "Loss: 3.746464490890503, Norm: 0.0014584700111299753, InvBCE: 3.7089335918426514\n",
      "Loss: 3.3400683403015137, Norm: 0.0017919117817655206, InvBCE: 3.302513599395752\n",
      "Loss: 2.9916229248046875, Norm: 0.0021140952594578266, InvBCE: 2.95404314994812\n",
      "Loss: 2.6898796558380127, Norm: 0.0024259877391159534, InvBCE: 2.652273654937744\n",
      "Loss: 2.410594940185547, Norm: 0.002726512961089611, InvBCE: 2.372962236404419\n",
      "Loss: 2.1516685485839844, Norm: 0.003019202733412385, InvBCE: 2.1140081882476807\n",
      "Loss: 1.9215281009674072, Norm: 0.0033044118899852037, InvBCE: 1.8838392496109009\n",
      "Loss: 1.7152602672576904, Norm: 0.003581922734156251, InvBCE: 1.6775423288345337\n",
      "Loss: 1.5298104286193848, Norm: 0.0038516235072165728, InvBCE: 1.492063045501709\n",
      "Loss: 1.3668485879898071, Norm: 0.0041131931357085705, InvBCE: 1.3290716409683228\n",
      "Loss: 1.2230404615402222, Norm: 0.004366306122392416, InvBCE: 1.1852339506149292\n",
      "Loss: 1.0948585271835327, Norm: 0.004610858391970396, InvBCE: 1.0570225715637207\n",
      "Loss: 0.9814375042915344, Norm: 0.004846720490604639, InvBCE: 0.9435725212097168\n",
      "Loss: 0.8834782242774963, Norm: 0.005073722917586565, InvBCE: 0.8455847501754761\n",
      "Loss: 0.7992496490478516, Norm: 0.005291688721626997, InvBCE: 0.761328399181366\n",
      "Loss: 0.7287654876708984, Norm: 0.005500452127307653, InvBCE: 0.6908174157142639\n",
      "Image 51...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 52...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 53...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 54...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 55...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 56...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 57...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 58...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 59...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 60...\n",
      "Loss: 630.2578125, Norm: 0.0, InvBCE: 630.2203369140625\n",
      "Loss: 294.43890380859375, Norm: 0.0003751915355678648, InvBCE: 294.40142822265625\n",
      "Loss: 205.86048889160156, Norm: 0.0007111579179763794, InvBCE: 205.822998046875\n",
      "Loss: 127.29917907714844, Norm: 0.000995049369521439, InvBCE: 127.26168060302734\n",
      "Loss: 87.0525894165039, Norm: 0.0012601095950230956, InvBCE: 87.01508331298828\n",
      "Loss: 64.68090057373047, Norm: 0.0015051922528073192, InvBCE: 64.64338684082031\n",
      "Loss: 51.09668731689453, Norm: 0.0017316206358373165, InvBCE: 51.05917739868164\n",
      "Loss: 42.111236572265625, Norm: 0.0019414193229749799, InvBCE: 42.073726654052734\n",
      "Loss: 36.45672607421875, Norm: 0.002136079827323556, InvBCE: 36.419219970703125\n",
      "Loss: 32.15752029418945, Norm: 0.0023177447728812695, InvBCE: 32.120018005371094\n",
      "Loss: 28.973976135253906, Norm: 0.0024879255797713995, InvBCE: 28.936481475830078\n",
      "Loss: 26.204933166503906, Norm: 0.002647911664098501, InvBCE: 26.16744613647461\n",
      "Loss: 24.398008346557617, Norm: 0.00279878918081522, InvBCE: 24.360530853271484\n",
      "Loss: 23.336881637573242, Norm: 0.0029415434692054987, InvBCE: 23.299413681030273\n",
      "Loss: 22.053970336914062, Norm: 0.0030771500896662474, InvBCE: 22.01651382446289\n",
      "Loss: 21.04062271118164, Norm: 0.003206353634595871, InvBCE: 21.003177642822266\n",
      "Loss: 20.176753997802734, Norm: 0.003329807659611106, InvBCE: 20.13932228088379\n",
      "Loss: 19.40626335144043, Norm: 0.0034481859765946865, InvBCE: 19.368844985961914\n",
      "Loss: 18.743093490600586, Norm: 0.0035619453992694616, InvBCE: 18.705690383911133\n",
      "Loss: 18.163227081298828, Norm: 0.0036715876776725054, InvBCE: 18.125839233398438\n",
      "Image 61...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 62...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 63...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 64...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 65...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 66...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 67...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 68...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 69...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 70...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 71...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 72...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 73...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 74...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 75...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 76...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 77...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 78...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 79...\n",
      "Loss: 809.8610229492188, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8607788085938, Norm: 0.00023278483422473073, InvBCE: 809.8235473632812\n",
      "Loss: 809.860595703125, Norm: 0.00046540083712898195, InvBCE: 809.8235473632812\n",
      "Loss: 809.8603515625, Norm: 0.0006978358142077923, InvBCE: 809.8235473632812\n",
      "Loss: 809.8601684570312, Norm: 0.0009300776291638613, InvBCE: 809.8235473632812\n",
      "Loss: 809.8599243164062, Norm: 0.0011621139710769057, InvBCE: 809.8235473632812\n",
      "Loss: 809.8597412109375, Norm: 0.0013939322670921683, InvBCE: 809.8235473632812\n",
      "Loss: 809.8594970703125, Norm: 0.0016255201771855354, InvBCE: 809.8235473632812\n",
      "Loss: 809.8593139648438, Norm: 0.0018568650120869279, InvBCE: 809.8235473632812\n",
      "Loss: 809.8590698242188, Norm: 0.0020879541989415884, InvBCE: 809.8235473632812\n",
      "Loss: 809.85888671875, Norm: 0.002318775048479438, InvBCE: 809.8235473632812\n",
      "Loss: 809.8587036132812, Norm: 0.0025493153370916843, InvBCE: 809.8235473632812\n",
      "Loss: 809.8584594726562, Norm: 0.0027795627247542143, InvBCE: 809.8235473632812\n",
      "Loss: 809.8582763671875, Norm: 0.0030095039401203394, InvBCE: 809.8235473632812\n",
      "Loss: 809.8580322265625, Norm: 0.0032391278073191643, InvBCE: 809.8235473632812\n",
      "Loss: 809.8578491210938, Norm: 0.0034684212878346443, InvBCE: 809.8235473632812\n",
      "Loss: 809.857666015625, Norm: 0.0036973722744733095, InvBCE: 809.8235473632812\n",
      "Loss: 809.857421875, Norm: 0.003925969824194908, InvBCE: 809.8235473632812\n",
      "Loss: 809.8572387695312, Norm: 0.004154201131314039, InvBCE: 809.8235473632812\n",
      "Loss: 809.8569946289062, Norm: 0.004382054787129164, InvBCE: 809.8235473632812\n",
      "Image 80...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 81...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 82...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 83...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 84...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 85...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 86...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 87...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 88...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 89...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 90...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 91...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 92...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 93...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 94...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 95...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 96...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 97...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 98...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 99...\n",
      "Image fooled! Adding perturbation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9e6437edf444ffd87852b18db4cdbd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fooling rate: 0.94\n",
      "Starting epoch 25...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67b2f413d4e4408aaa94833e8bca5ec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 1...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 2...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 3...\n",
      "Loss: 2.717554807662964, Norm: 0.0, InvBCE: 2.6801018714904785\n",
      "Loss: 2.407351493835449, Norm: 0.00038118421798571944, InvBCE: 2.3698573112487793\n",
      "Loss: 2.134324550628662, Norm: 0.0007559842779301107, InvBCE: 2.0967862606048584\n",
      "Loss: 1.8955780267715454, Norm: 0.0011244287015870214, InvBCE: 1.8579938411712646\n",
      "Loss: 1.6877946853637695, Norm: 0.0014857073547318578, InvBCE: 1.650162935256958\n",
      "Loss: 1.5075215101242065, Norm: 0.0018390374025329947, InvBCE: 1.4698407649993896\n",
      "Loss: 1.3513212203979492, Norm: 0.0021836247760802507, InvBCE: 1.313590407371521\n",
      "Loss: 1.2159942388534546, Norm: 0.0025187814608216286, InvBCE: 1.1782126426696777\n",
      "Loss: 1.0986416339874268, Norm: 0.0028439692687243223, InvBCE: 1.060808777809143\n",
      "Loss: 0.9967145323753357, Norm: 0.0031588065903633833, InvBCE: 0.9588302969932556\n",
      "Loss: 0.9080396294593811, Norm: 0.0034630452282726765, InvBCE: 0.8701043128967285\n",
      "Loss: 0.8308247327804565, Norm: 0.003756554564461112, InvBCE: 0.7928388714790344\n",
      "Loss: 0.7636405229568481, Norm: 0.004039280116558075, InvBCE: 0.7256050109863281\n",
      "Loss: 0.7053354978561401, Norm: 0.004311214666813612, InvBCE: 0.667251467704773\n",
      "Loss: 0.6549381613731384, Norm: 0.004572402220219374, InvBCE: 0.6168069243431091\n",
      "Loss: 0.6115550398826599, Norm: 0.004822922870516777, InvBCE: 0.5733780264854431\n",
      "Loss: 0.5743334293365479, Norm: 0.005062887445092201, InvBCE: 0.5361122488975525\n",
      "Loss: 0.5424706339836121, Norm: 0.005292464513331652, InvBCE: 0.5042068958282471\n",
      "Loss: 0.5152295231819153, Norm: 0.005511854775249958, InvBCE: 0.47692495584487915\n",
      "Loss: 0.4919421672821045, Norm: 0.005721298512071371, InvBCE: 0.4535984694957733\n",
      "Image 4...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 5...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 6...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 7...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 8...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 9...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 10...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 11...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 12...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 13...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 14...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 15...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 16...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 17...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 18...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 19...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 20...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 21...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 22...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 23...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 24...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 25...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 26...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 27...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 28...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 29...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 30...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 31...\n",
      "Loss: 809.8610229492188, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8607788085938, Norm: 0.00023278483422473073, InvBCE: 809.8235473632812\n",
      "Loss: 809.860595703125, Norm: 0.00046540083712898195, InvBCE: 809.8235473632812\n",
      "Loss: 809.8603515625, Norm: 0.0006978358142077923, InvBCE: 809.8235473632812\n",
      "Loss: 809.8601684570312, Norm: 0.0009300776291638613, InvBCE: 809.8235473632812\n",
      "Loss: 809.8599243164062, Norm: 0.0011621139710769057, InvBCE: 809.8235473632812\n",
      "Loss: 809.8597412109375, Norm: 0.0013939322670921683, InvBCE: 809.8235473632812\n",
      "Loss: 809.8594970703125, Norm: 0.0016255201771855354, InvBCE: 809.8235473632812\n",
      "Loss: 809.8593139648438, Norm: 0.0018568650120869279, InvBCE: 809.8235473632812\n",
      "Loss: 809.8590698242188, Norm: 0.0020879541989415884, InvBCE: 809.8235473632812\n",
      "Loss: 809.85888671875, Norm: 0.002318775048479438, InvBCE: 809.8235473632812\n",
      "Loss: 809.8587036132812, Norm: 0.0025493153370916843, InvBCE: 809.8235473632812\n",
      "Loss: 809.8584594726562, Norm: 0.0027795627247542143, InvBCE: 809.8235473632812\n",
      "Loss: 809.8582763671875, Norm: 0.0030095039401203394, InvBCE: 809.8235473632812\n",
      "Loss: 809.8580322265625, Norm: 0.0032391278073191643, InvBCE: 809.8235473632812\n",
      "Loss: 809.8578491210938, Norm: 0.0034684212878346443, InvBCE: 809.8235473632812\n",
      "Loss: 809.857666015625, Norm: 0.0036973722744733095, InvBCE: 809.8235473632812\n",
      "Loss: 809.857421875, Norm: 0.003925969824194908, InvBCE: 809.8235473632812\n",
      "Loss: 809.8572387695312, Norm: 0.004154201131314039, InvBCE: 809.8235473632812\n",
      "Loss: 809.8569946289062, Norm: 0.004382054787129164, InvBCE: 809.8235473632812\n",
      "Image 32...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 33...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 34...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 35...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 36...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 37...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 38...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 39...\n",
      "Loss: 72.98128509521484, Norm: 0.0, InvBCE: 72.94383239746094\n",
      "Loss: 46.08408737182617, Norm: 0.0003843815065920353, InvBCE: 46.04658126831055\n",
      "Loss: 32.78629684448242, Norm: 0.000742322881706059, InvBCE: 32.74873352050781\n",
      "Loss: 24.617408752441406, Norm: 0.001077656401321292, InvBCE: 24.579795837402344\n",
      "Loss: 19.725128173828125, Norm: 0.0013914385344833136, InvBCE: 19.68746566772461\n",
      "Loss: 16.54332160949707, Norm: 0.0016856665024533868, InvBCE: 16.505611419677734\n",
      "Loss: 14.422035217285156, Norm: 0.001962564652785659, InvBCE: 14.384281158447266\n",
      "Loss: 12.86168384552002, Norm: 0.002224019728600979, InvBCE: 12.82388687133789\n",
      "Loss: 11.653457641601562, Norm: 0.002471968298777938, InvBCE: 11.615620613098145\n",
      "Loss: 10.683114051818848, Norm: 0.0027080196887254715, InvBCE: 10.645237922668457\n",
      "Loss: 8.709017753601074, Norm: 0.002933422802016139, InvBCE: 8.67110538482666\n",
      "Loss: 8.126260757446289, Norm: 0.003149435855448246, InvBCE: 8.088312149047852\n",
      "Loss: 7.666654109954834, Norm: 0.003355486784130335, InvBCE: 7.628672122955322\n",
      "Loss: 7.273351192474365, Norm: 0.0035526002757251263, InvBCE: 7.235337734222412\n",
      "Loss: 6.933590412139893, Norm: 0.0037416713312268257, InvBCE: 6.8955464363098145\n",
      "Loss: 6.633247375488281, Norm: 0.003923483658581972, InvBCE: 6.595174789428711\n",
      "Loss: 6.361598968505859, Norm: 0.0040987515822052956, InvBCE: 6.3234992027282715\n",
      "Loss: 6.131810665130615, Norm: 0.004267985001206398, InvBCE: 6.093685150146484\n",
      "Loss: 5.9073896408081055, Norm: 0.004431800916790962, InvBCE: 5.869239807128906\n",
      "Loss: 5.703206539154053, Norm: 0.00459067290648818, InvBCE: 5.665033340454102\n",
      "Image 40...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 41...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 42...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 43...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 44...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 45...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 46...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 47...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 48...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 49...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 50...\n",
      "Loss: 6.874675750732422, Norm: 0.0, InvBCE: 6.837223052978516\n",
      "Loss: 5.713406562805176, Norm: 0.00038196725654415786, InvBCE: 5.675937175750732\n",
      "Loss: 4.862036228179932, Norm: 0.0007531616720370948, InvBCE: 4.824548244476318\n",
      "Loss: 4.227441787719727, Norm: 0.001112419762648642, InvBCE: 4.1899333000183105\n",
      "Loss: 3.746464490890503, Norm: 0.0014584700111299753, InvBCE: 3.7089335918426514\n",
      "Loss: 3.3400683403015137, Norm: 0.0017919117817655206, InvBCE: 3.302513599395752\n",
      "Loss: 2.9916229248046875, Norm: 0.0021140952594578266, InvBCE: 2.95404314994812\n",
      "Loss: 2.6898796558380127, Norm: 0.0024259877391159534, InvBCE: 2.652273654937744\n",
      "Loss: 2.410594940185547, Norm: 0.002726512961089611, InvBCE: 2.372962236404419\n",
      "Loss: 2.1516685485839844, Norm: 0.003019202733412385, InvBCE: 2.1140081882476807\n",
      "Loss: 1.9215281009674072, Norm: 0.0033044118899852037, InvBCE: 1.8838392496109009\n",
      "Loss: 1.7152602672576904, Norm: 0.003581922734156251, InvBCE: 1.6775423288345337\n",
      "Loss: 1.5298104286193848, Norm: 0.0038516235072165728, InvBCE: 1.492063045501709\n",
      "Loss: 1.3668485879898071, Norm: 0.0041131931357085705, InvBCE: 1.3290716409683228\n",
      "Loss: 1.2230404615402222, Norm: 0.004366306122392416, InvBCE: 1.1852339506149292\n",
      "Loss: 1.0948585271835327, Norm: 0.004610858391970396, InvBCE: 1.0570225715637207\n",
      "Loss: 0.9814375042915344, Norm: 0.004846720490604639, InvBCE: 0.9435725212097168\n",
      "Loss: 0.8834782242774963, Norm: 0.005073722917586565, InvBCE: 0.8455847501754761\n",
      "Loss: 0.7992496490478516, Norm: 0.005291688721626997, InvBCE: 0.761328399181366\n",
      "Loss: 0.7287654876708984, Norm: 0.005500452127307653, InvBCE: 0.6908174157142639\n",
      "Image 51...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 52...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 53...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 54...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 55...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 56...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 57...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 58...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 59...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 60...\n",
      "Loss: 630.2578125, Norm: 0.0, InvBCE: 630.2203369140625\n",
      "Loss: 294.43890380859375, Norm: 0.0003751915355678648, InvBCE: 294.40142822265625\n",
      "Loss: 205.86048889160156, Norm: 0.0007111579179763794, InvBCE: 205.822998046875\n",
      "Loss: 127.29917907714844, Norm: 0.000995049369521439, InvBCE: 127.26168060302734\n",
      "Loss: 87.0525894165039, Norm: 0.0012601095950230956, InvBCE: 87.01508331298828\n",
      "Loss: 64.68090057373047, Norm: 0.0015051922528073192, InvBCE: 64.64338684082031\n",
      "Loss: 51.09668731689453, Norm: 0.0017316206358373165, InvBCE: 51.05917739868164\n",
      "Loss: 42.111236572265625, Norm: 0.0019414193229749799, InvBCE: 42.073726654052734\n",
      "Loss: 36.45672607421875, Norm: 0.002136079827323556, InvBCE: 36.419219970703125\n",
      "Loss: 32.15752029418945, Norm: 0.0023177447728812695, InvBCE: 32.120018005371094\n",
      "Loss: 28.973976135253906, Norm: 0.0024879255797713995, InvBCE: 28.936481475830078\n",
      "Loss: 26.204933166503906, Norm: 0.002647911664098501, InvBCE: 26.16744613647461\n",
      "Loss: 24.398008346557617, Norm: 0.00279878918081522, InvBCE: 24.360530853271484\n",
      "Loss: 23.336881637573242, Norm: 0.0029415434692054987, InvBCE: 23.299413681030273\n",
      "Loss: 22.053970336914062, Norm: 0.0030771500896662474, InvBCE: 22.01651382446289\n",
      "Loss: 21.04062271118164, Norm: 0.003206353634595871, InvBCE: 21.003177642822266\n",
      "Loss: 20.176753997802734, Norm: 0.003329807659611106, InvBCE: 20.13932228088379\n",
      "Loss: 19.40626335144043, Norm: 0.0034481859765946865, InvBCE: 19.368844985961914\n",
      "Loss: 18.743093490600586, Norm: 0.0035619453992694616, InvBCE: 18.705690383911133\n",
      "Loss: 18.163227081298828, Norm: 0.0036715876776725054, InvBCE: 18.125839233398438\n",
      "Image 61...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 62...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 63...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 64...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 65...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 66...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 67...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 68...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 69...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 70...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 71...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 72...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 73...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 74...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 75...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 76...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 77...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 78...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 79...\n",
      "Loss: 809.8610229492188, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8607788085938, Norm: 0.00023278483422473073, InvBCE: 809.8235473632812\n",
      "Loss: 809.860595703125, Norm: 0.00046540083712898195, InvBCE: 809.8235473632812\n",
      "Loss: 809.8603515625, Norm: 0.0006978358142077923, InvBCE: 809.8235473632812\n",
      "Loss: 809.8601684570312, Norm: 0.0009300776291638613, InvBCE: 809.8235473632812\n",
      "Loss: 809.8599243164062, Norm: 0.0011621139710769057, InvBCE: 809.8235473632812\n",
      "Loss: 809.8597412109375, Norm: 0.0013939322670921683, InvBCE: 809.8235473632812\n",
      "Loss: 809.8594970703125, Norm: 0.0016255201771855354, InvBCE: 809.8235473632812\n",
      "Loss: 809.8593139648438, Norm: 0.0018568650120869279, InvBCE: 809.8235473632812\n",
      "Loss: 809.8590698242188, Norm: 0.0020879541989415884, InvBCE: 809.8235473632812\n",
      "Loss: 809.85888671875, Norm: 0.002318775048479438, InvBCE: 809.8235473632812\n",
      "Loss: 809.8587036132812, Norm: 0.0025493153370916843, InvBCE: 809.8235473632812\n",
      "Loss: 809.8584594726562, Norm: 0.0027795627247542143, InvBCE: 809.8235473632812\n",
      "Loss: 809.8582763671875, Norm: 0.0030095039401203394, InvBCE: 809.8235473632812\n",
      "Loss: 809.8580322265625, Norm: 0.0032391278073191643, InvBCE: 809.8235473632812\n",
      "Loss: 809.8578491210938, Norm: 0.0034684212878346443, InvBCE: 809.8235473632812\n",
      "Loss: 809.857666015625, Norm: 0.0036973722744733095, InvBCE: 809.8235473632812\n",
      "Loss: 809.857421875, Norm: 0.003925969824194908, InvBCE: 809.8235473632812\n",
      "Loss: 809.8572387695312, Norm: 0.004154201131314039, InvBCE: 809.8235473632812\n",
      "Loss: 809.8569946289062, Norm: 0.004382054787129164, InvBCE: 809.8235473632812\n",
      "Image 80...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 81...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 82...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 83...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 84...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 85...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 86...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 87...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 88...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 89...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 90...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 91...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 92...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 93...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 94...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 95...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 96...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 97...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 98...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 99...\n",
      "Image fooled! Adding perturbation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97fd62b73fe949ecbc4ec7a9e4fea4ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fooling rate: 0.94\n",
      "Starting epoch 26...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de16a1b463bb4e97bb106913153197ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 1...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 2...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 3...\n",
      "Loss: 2.717554807662964, Norm: 0.0, InvBCE: 2.6801018714904785\n",
      "Loss: 2.407351493835449, Norm: 0.00038118421798571944, InvBCE: 2.3698573112487793\n",
      "Loss: 2.134324550628662, Norm: 0.0007559842779301107, InvBCE: 2.0967862606048584\n",
      "Loss: 1.8955780267715454, Norm: 0.0011244287015870214, InvBCE: 1.8579938411712646\n",
      "Loss: 1.6877946853637695, Norm: 0.0014857073547318578, InvBCE: 1.650162935256958\n",
      "Loss: 1.5075215101242065, Norm: 0.0018390374025329947, InvBCE: 1.4698407649993896\n",
      "Loss: 1.3513212203979492, Norm: 0.0021836247760802507, InvBCE: 1.313590407371521\n",
      "Loss: 1.2159942388534546, Norm: 0.0025187814608216286, InvBCE: 1.1782126426696777\n",
      "Loss: 1.0986416339874268, Norm: 0.0028439692687243223, InvBCE: 1.060808777809143\n",
      "Loss: 0.9967145323753357, Norm: 0.0031588065903633833, InvBCE: 0.9588302969932556\n",
      "Loss: 0.9080396294593811, Norm: 0.0034630452282726765, InvBCE: 0.8701043128967285\n",
      "Loss: 0.8308247327804565, Norm: 0.003756554564461112, InvBCE: 0.7928388714790344\n",
      "Loss: 0.7636405229568481, Norm: 0.004039280116558075, InvBCE: 0.7256050109863281\n",
      "Loss: 0.7053354978561401, Norm: 0.004311214666813612, InvBCE: 0.667251467704773\n",
      "Loss: 0.6549381613731384, Norm: 0.004572402220219374, InvBCE: 0.6168069243431091\n",
      "Loss: 0.6115550398826599, Norm: 0.004822922870516777, InvBCE: 0.5733780264854431\n",
      "Loss: 0.5743334293365479, Norm: 0.005062887445092201, InvBCE: 0.5361122488975525\n",
      "Loss: 0.5424706339836121, Norm: 0.005292464513331652, InvBCE: 0.5042068958282471\n",
      "Loss: 0.5152295231819153, Norm: 0.005511854775249958, InvBCE: 0.47692495584487915\n",
      "Loss: 0.4919421672821045, Norm: 0.005721298512071371, InvBCE: 0.4535984694957733\n",
      "Image 4...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 5...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 6...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 7...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 8...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 9...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 10...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 11...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 12...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 13...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 14...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 15...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 16...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 17...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 18...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 19...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 20...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 21...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 22...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 23...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 24...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 25...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 26...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 27...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 28...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 29...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 30...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 31...\n",
      "Loss: 809.8610229492188, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8607788085938, Norm: 0.00023278483422473073, InvBCE: 809.8235473632812\n",
      "Loss: 809.860595703125, Norm: 0.00046540083712898195, InvBCE: 809.8235473632812\n",
      "Loss: 809.8603515625, Norm: 0.0006978358142077923, InvBCE: 809.8235473632812\n",
      "Loss: 809.8601684570312, Norm: 0.0009300776291638613, InvBCE: 809.8235473632812\n",
      "Loss: 809.8599243164062, Norm: 0.0011621139710769057, InvBCE: 809.8235473632812\n",
      "Loss: 809.8597412109375, Norm: 0.0013939322670921683, InvBCE: 809.8235473632812\n",
      "Loss: 809.8594970703125, Norm: 0.0016255201771855354, InvBCE: 809.8235473632812\n",
      "Loss: 809.8593139648438, Norm: 0.0018568650120869279, InvBCE: 809.8235473632812\n",
      "Loss: 809.8590698242188, Norm: 0.0020879541989415884, InvBCE: 809.8235473632812\n",
      "Loss: 809.85888671875, Norm: 0.002318775048479438, InvBCE: 809.8235473632812\n",
      "Loss: 809.8587036132812, Norm: 0.0025493153370916843, InvBCE: 809.8235473632812\n",
      "Loss: 809.8584594726562, Norm: 0.0027795627247542143, InvBCE: 809.8235473632812\n",
      "Loss: 809.8582763671875, Norm: 0.0030095039401203394, InvBCE: 809.8235473632812\n",
      "Loss: 809.8580322265625, Norm: 0.0032391278073191643, InvBCE: 809.8235473632812\n",
      "Loss: 809.8578491210938, Norm: 0.0034684212878346443, InvBCE: 809.8235473632812\n",
      "Loss: 809.857666015625, Norm: 0.0036973722744733095, InvBCE: 809.8235473632812\n",
      "Loss: 809.857421875, Norm: 0.003925969824194908, InvBCE: 809.8235473632812\n",
      "Loss: 809.8572387695312, Norm: 0.004154201131314039, InvBCE: 809.8235473632812\n",
      "Loss: 809.8569946289062, Norm: 0.004382054787129164, InvBCE: 809.8235473632812\n",
      "Image 32...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 33...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 34...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 35...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 36...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 37...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 38...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 39...\n",
      "Loss: 72.98128509521484, Norm: 0.0, InvBCE: 72.94383239746094\n",
      "Loss: 46.08408737182617, Norm: 0.0003843815065920353, InvBCE: 46.04658126831055\n",
      "Loss: 32.78629684448242, Norm: 0.000742322881706059, InvBCE: 32.74873352050781\n",
      "Loss: 24.617408752441406, Norm: 0.001077656401321292, InvBCE: 24.579795837402344\n",
      "Loss: 19.725128173828125, Norm: 0.0013914385344833136, InvBCE: 19.68746566772461\n",
      "Loss: 16.54332160949707, Norm: 0.0016856665024533868, InvBCE: 16.505611419677734\n",
      "Loss: 14.422035217285156, Norm: 0.001962564652785659, InvBCE: 14.384281158447266\n",
      "Loss: 12.86168384552002, Norm: 0.002224019728600979, InvBCE: 12.82388687133789\n",
      "Loss: 11.653457641601562, Norm: 0.002471968298777938, InvBCE: 11.615620613098145\n",
      "Loss: 10.683114051818848, Norm: 0.0027080196887254715, InvBCE: 10.645237922668457\n",
      "Loss: 8.709017753601074, Norm: 0.002933422802016139, InvBCE: 8.67110538482666\n",
      "Loss: 8.126260757446289, Norm: 0.003149435855448246, InvBCE: 8.088312149047852\n",
      "Loss: 7.666654109954834, Norm: 0.003355486784130335, InvBCE: 7.628672122955322\n",
      "Loss: 7.273351192474365, Norm: 0.0035526002757251263, InvBCE: 7.235337734222412\n",
      "Loss: 6.933590412139893, Norm: 0.0037416713312268257, InvBCE: 6.8955464363098145\n",
      "Loss: 6.633247375488281, Norm: 0.003923483658581972, InvBCE: 6.595174789428711\n",
      "Loss: 6.361598968505859, Norm: 0.0040987515822052956, InvBCE: 6.3234992027282715\n",
      "Loss: 6.131810665130615, Norm: 0.004267985001206398, InvBCE: 6.093685150146484\n",
      "Loss: 5.9073896408081055, Norm: 0.004431800916790962, InvBCE: 5.869239807128906\n",
      "Loss: 5.703206539154053, Norm: 0.00459067290648818, InvBCE: 5.665033340454102\n",
      "Image 40...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 41...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 42...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 43...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 44...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 45...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 46...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 47...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 48...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 49...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 50...\n",
      "Loss: 6.874675750732422, Norm: 0.0, InvBCE: 6.837223052978516\n",
      "Loss: 5.713406562805176, Norm: 0.00038196725654415786, InvBCE: 5.675937175750732\n",
      "Loss: 4.862036228179932, Norm: 0.0007531616720370948, InvBCE: 4.824548244476318\n",
      "Loss: 4.227441787719727, Norm: 0.001112419762648642, InvBCE: 4.1899333000183105\n",
      "Loss: 3.746464490890503, Norm: 0.0014584700111299753, InvBCE: 3.7089335918426514\n",
      "Loss: 3.3400683403015137, Norm: 0.0017919117817655206, InvBCE: 3.302513599395752\n",
      "Loss: 2.9916229248046875, Norm: 0.0021140952594578266, InvBCE: 2.95404314994812\n",
      "Loss: 2.6898796558380127, Norm: 0.0024259877391159534, InvBCE: 2.652273654937744\n",
      "Loss: 2.410594940185547, Norm: 0.002726512961089611, InvBCE: 2.372962236404419\n",
      "Loss: 2.1516685485839844, Norm: 0.003019202733412385, InvBCE: 2.1140081882476807\n",
      "Loss: 1.9215281009674072, Norm: 0.0033044118899852037, InvBCE: 1.8838392496109009\n",
      "Loss: 1.7152602672576904, Norm: 0.003581922734156251, InvBCE: 1.6775423288345337\n",
      "Loss: 1.5298104286193848, Norm: 0.0038516235072165728, InvBCE: 1.492063045501709\n",
      "Loss: 1.3668485879898071, Norm: 0.0041131931357085705, InvBCE: 1.3290716409683228\n",
      "Loss: 1.2230404615402222, Norm: 0.004366306122392416, InvBCE: 1.1852339506149292\n",
      "Loss: 1.0948585271835327, Norm: 0.004610858391970396, InvBCE: 1.0570225715637207\n",
      "Loss: 0.9814375042915344, Norm: 0.004846720490604639, InvBCE: 0.9435725212097168\n",
      "Loss: 0.8834782242774963, Norm: 0.005073722917586565, InvBCE: 0.8455847501754761\n",
      "Loss: 0.7992496490478516, Norm: 0.005291688721626997, InvBCE: 0.761328399181366\n",
      "Loss: 0.7287654876708984, Norm: 0.005500452127307653, InvBCE: 0.6908174157142639\n",
      "Image 51...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 52...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 53...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 54...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 55...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 56...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 57...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 58...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 59...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 60...\n",
      "Loss: 630.2578125, Norm: 0.0, InvBCE: 630.2203369140625\n",
      "Loss: 294.43890380859375, Norm: 0.0003751915355678648, InvBCE: 294.40142822265625\n",
      "Loss: 205.86048889160156, Norm: 0.0007111579179763794, InvBCE: 205.822998046875\n",
      "Loss: 127.29917907714844, Norm: 0.000995049369521439, InvBCE: 127.26168060302734\n",
      "Loss: 87.0525894165039, Norm: 0.0012601095950230956, InvBCE: 87.01508331298828\n",
      "Loss: 64.68090057373047, Norm: 0.0015051922528073192, InvBCE: 64.64338684082031\n",
      "Loss: 51.09668731689453, Norm: 0.0017316206358373165, InvBCE: 51.05917739868164\n",
      "Loss: 42.111236572265625, Norm: 0.0019414193229749799, InvBCE: 42.073726654052734\n",
      "Loss: 36.45672607421875, Norm: 0.002136079827323556, InvBCE: 36.419219970703125\n",
      "Loss: 32.15752029418945, Norm: 0.0023177447728812695, InvBCE: 32.120018005371094\n",
      "Loss: 28.973976135253906, Norm: 0.0024879255797713995, InvBCE: 28.936481475830078\n",
      "Loss: 26.204933166503906, Norm: 0.002647911664098501, InvBCE: 26.16744613647461\n",
      "Loss: 24.398008346557617, Norm: 0.00279878918081522, InvBCE: 24.360530853271484\n",
      "Loss: 23.336881637573242, Norm: 0.0029415434692054987, InvBCE: 23.299413681030273\n",
      "Loss: 22.053970336914062, Norm: 0.0030771500896662474, InvBCE: 22.01651382446289\n",
      "Loss: 21.04062271118164, Norm: 0.003206353634595871, InvBCE: 21.003177642822266\n",
      "Loss: 20.176753997802734, Norm: 0.003329807659611106, InvBCE: 20.13932228088379\n",
      "Loss: 19.40626335144043, Norm: 0.0034481859765946865, InvBCE: 19.368844985961914\n",
      "Loss: 18.743093490600586, Norm: 0.0035619453992694616, InvBCE: 18.705690383911133\n",
      "Loss: 18.163227081298828, Norm: 0.0036715876776725054, InvBCE: 18.125839233398438\n",
      "Image 61...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 62...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 63...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 64...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 65...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 66...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 67...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 68...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 69...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 70...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 71...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 72...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 73...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 74...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 75...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 76...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 77...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 78...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 79...\n",
      "Loss: 809.8610229492188, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8607788085938, Norm: 0.00023278483422473073, InvBCE: 809.8235473632812\n",
      "Loss: 809.860595703125, Norm: 0.00046540083712898195, InvBCE: 809.8235473632812\n",
      "Loss: 809.8603515625, Norm: 0.0006978358142077923, InvBCE: 809.8235473632812\n",
      "Loss: 809.8601684570312, Norm: 0.0009300776291638613, InvBCE: 809.8235473632812\n",
      "Loss: 809.8599243164062, Norm: 0.0011621139710769057, InvBCE: 809.8235473632812\n",
      "Loss: 809.8597412109375, Norm: 0.0013939322670921683, InvBCE: 809.8235473632812\n",
      "Loss: 809.8594970703125, Norm: 0.0016255201771855354, InvBCE: 809.8235473632812\n",
      "Loss: 809.8593139648438, Norm: 0.0018568650120869279, InvBCE: 809.8235473632812\n",
      "Loss: 809.8590698242188, Norm: 0.0020879541989415884, InvBCE: 809.8235473632812\n",
      "Loss: 809.85888671875, Norm: 0.002318775048479438, InvBCE: 809.8235473632812\n",
      "Loss: 809.8587036132812, Norm: 0.0025493153370916843, InvBCE: 809.8235473632812\n",
      "Loss: 809.8584594726562, Norm: 0.0027795627247542143, InvBCE: 809.8235473632812\n",
      "Loss: 809.8582763671875, Norm: 0.0030095039401203394, InvBCE: 809.8235473632812\n",
      "Loss: 809.8580322265625, Norm: 0.0032391278073191643, InvBCE: 809.8235473632812\n",
      "Loss: 809.8578491210938, Norm: 0.0034684212878346443, InvBCE: 809.8235473632812\n",
      "Loss: 809.857666015625, Norm: 0.0036973722744733095, InvBCE: 809.8235473632812\n",
      "Loss: 809.857421875, Norm: 0.003925969824194908, InvBCE: 809.8235473632812\n",
      "Loss: 809.8572387695312, Norm: 0.004154201131314039, InvBCE: 809.8235473632812\n",
      "Loss: 809.8569946289062, Norm: 0.004382054787129164, InvBCE: 809.8235473632812\n",
      "Image 80...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 81...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 82...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 83...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 84...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 85...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 86...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 87...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 88...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 89...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 90...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 91...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 92...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 93...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 94...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 95...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 96...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 97...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 98...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 99...\n",
      "Image fooled! Adding perturbation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "964d16ddd0e24b9699d9f2672f5459a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fooling rate: 0.94\n",
      "Starting epoch 27...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f17a593303f480a9d4f3ab6ae08a81c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 1...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 2...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 3...\n",
      "Loss: 2.717554807662964, Norm: 0.0, InvBCE: 2.6801018714904785\n",
      "Loss: 2.407351493835449, Norm: 0.00038118421798571944, InvBCE: 2.3698573112487793\n",
      "Loss: 2.134324550628662, Norm: 0.0007559842779301107, InvBCE: 2.0967862606048584\n",
      "Loss: 1.8955780267715454, Norm: 0.0011244287015870214, InvBCE: 1.8579938411712646\n",
      "Loss: 1.6877946853637695, Norm: 0.0014857073547318578, InvBCE: 1.650162935256958\n",
      "Loss: 1.5075215101242065, Norm: 0.0018390374025329947, InvBCE: 1.4698407649993896\n",
      "Loss: 1.3513212203979492, Norm: 0.0021836247760802507, InvBCE: 1.313590407371521\n",
      "Loss: 1.2159942388534546, Norm: 0.0025187814608216286, InvBCE: 1.1782126426696777\n",
      "Loss: 1.0986416339874268, Norm: 0.0028439692687243223, InvBCE: 1.060808777809143\n",
      "Loss: 0.9967145323753357, Norm: 0.0031588065903633833, InvBCE: 0.9588302969932556\n",
      "Loss: 0.9080396294593811, Norm: 0.0034630452282726765, InvBCE: 0.8701043128967285\n",
      "Loss: 0.8308247327804565, Norm: 0.003756554564461112, InvBCE: 0.7928388714790344\n",
      "Loss: 0.7636405229568481, Norm: 0.004039280116558075, InvBCE: 0.7256050109863281\n",
      "Loss: 0.7053354978561401, Norm: 0.004311214666813612, InvBCE: 0.667251467704773\n",
      "Loss: 0.6549381613731384, Norm: 0.004572402220219374, InvBCE: 0.6168069243431091\n",
      "Loss: 0.6115550398826599, Norm: 0.004822922870516777, InvBCE: 0.5733780264854431\n",
      "Loss: 0.5743334293365479, Norm: 0.005062887445092201, InvBCE: 0.5361122488975525\n",
      "Loss: 0.5424706339836121, Norm: 0.005292464513331652, InvBCE: 0.5042068958282471\n",
      "Loss: 0.5152295231819153, Norm: 0.005511854775249958, InvBCE: 0.47692495584487915\n",
      "Loss: 0.4919421672821045, Norm: 0.005721298512071371, InvBCE: 0.4535984694957733\n",
      "Image 4...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 5...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 6...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 7...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 8...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 9...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 10...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 11...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 12...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 13...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 14...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 15...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 16...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 17...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 18...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 19...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 20...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 21...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 22...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 23...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 24...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 25...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 26...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 27...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 28...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 29...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 30...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 31...\n",
      "Loss: 809.8610229492188, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8607788085938, Norm: 0.00023278483422473073, InvBCE: 809.8235473632812\n",
      "Loss: 809.860595703125, Norm: 0.00046540083712898195, InvBCE: 809.8235473632812\n",
      "Loss: 809.8603515625, Norm: 0.0006978358142077923, InvBCE: 809.8235473632812\n",
      "Loss: 809.8601684570312, Norm: 0.0009300776291638613, InvBCE: 809.8235473632812\n",
      "Loss: 809.8599243164062, Norm: 0.0011621139710769057, InvBCE: 809.8235473632812\n",
      "Loss: 809.8597412109375, Norm: 0.0013939322670921683, InvBCE: 809.8235473632812\n",
      "Loss: 809.8594970703125, Norm: 0.0016255201771855354, InvBCE: 809.8235473632812\n",
      "Loss: 809.8593139648438, Norm: 0.0018568650120869279, InvBCE: 809.8235473632812\n",
      "Loss: 809.8590698242188, Norm: 0.0020879541989415884, InvBCE: 809.8235473632812\n",
      "Loss: 809.85888671875, Norm: 0.002318775048479438, InvBCE: 809.8235473632812\n",
      "Loss: 809.8587036132812, Norm: 0.0025493153370916843, InvBCE: 809.8235473632812\n",
      "Loss: 809.8584594726562, Norm: 0.0027795627247542143, InvBCE: 809.8235473632812\n",
      "Loss: 809.8582763671875, Norm: 0.0030095039401203394, InvBCE: 809.8235473632812\n",
      "Loss: 809.8580322265625, Norm: 0.0032391278073191643, InvBCE: 809.8235473632812\n",
      "Loss: 809.8578491210938, Norm: 0.0034684212878346443, InvBCE: 809.8235473632812\n",
      "Loss: 809.857666015625, Norm: 0.0036973722744733095, InvBCE: 809.8235473632812\n",
      "Loss: 809.857421875, Norm: 0.003925969824194908, InvBCE: 809.8235473632812\n",
      "Loss: 809.8572387695312, Norm: 0.004154201131314039, InvBCE: 809.8235473632812\n",
      "Loss: 809.8569946289062, Norm: 0.004382054787129164, InvBCE: 809.8235473632812\n",
      "Image 32...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 33...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 34...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 35...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 36...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 37...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 38...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 39...\n",
      "Loss: 72.98128509521484, Norm: 0.0, InvBCE: 72.94383239746094\n",
      "Loss: 46.08408737182617, Norm: 0.0003843815065920353, InvBCE: 46.04658126831055\n",
      "Loss: 32.78629684448242, Norm: 0.000742322881706059, InvBCE: 32.74873352050781\n",
      "Loss: 24.617408752441406, Norm: 0.001077656401321292, InvBCE: 24.579795837402344\n",
      "Loss: 19.725128173828125, Norm: 0.0013914385344833136, InvBCE: 19.68746566772461\n",
      "Loss: 16.54332160949707, Norm: 0.0016856665024533868, InvBCE: 16.505611419677734\n",
      "Loss: 14.422035217285156, Norm: 0.001962564652785659, InvBCE: 14.384281158447266\n",
      "Loss: 12.86168384552002, Norm: 0.002224019728600979, InvBCE: 12.82388687133789\n",
      "Loss: 11.653457641601562, Norm: 0.002471968298777938, InvBCE: 11.615620613098145\n",
      "Loss: 10.683114051818848, Norm: 0.0027080196887254715, InvBCE: 10.645237922668457\n",
      "Loss: 8.709017753601074, Norm: 0.002933422802016139, InvBCE: 8.67110538482666\n",
      "Loss: 8.126260757446289, Norm: 0.003149435855448246, InvBCE: 8.088312149047852\n",
      "Loss: 7.666654109954834, Norm: 0.003355486784130335, InvBCE: 7.628672122955322\n",
      "Loss: 7.273351192474365, Norm: 0.0035526002757251263, InvBCE: 7.235337734222412\n",
      "Loss: 6.933590412139893, Norm: 0.0037416713312268257, InvBCE: 6.8955464363098145\n",
      "Loss: 6.633247375488281, Norm: 0.003923483658581972, InvBCE: 6.595174789428711\n",
      "Loss: 6.361598968505859, Norm: 0.0040987515822052956, InvBCE: 6.3234992027282715\n",
      "Loss: 6.131810665130615, Norm: 0.004267985001206398, InvBCE: 6.093685150146484\n",
      "Loss: 5.9073896408081055, Norm: 0.004431800916790962, InvBCE: 5.869239807128906\n",
      "Loss: 5.703206539154053, Norm: 0.00459067290648818, InvBCE: 5.665033340454102\n",
      "Image 40...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 41...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 42...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 43...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 44...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 45...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 46...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 47...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 48...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 49...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 50...\n",
      "Loss: 6.874675750732422, Norm: 0.0, InvBCE: 6.837223052978516\n",
      "Loss: 5.713406562805176, Norm: 0.00038196725654415786, InvBCE: 5.675937175750732\n",
      "Loss: 4.862036228179932, Norm: 0.0007531616720370948, InvBCE: 4.824548244476318\n",
      "Loss: 4.227441787719727, Norm: 0.001112419762648642, InvBCE: 4.1899333000183105\n",
      "Loss: 3.746464490890503, Norm: 0.0014584700111299753, InvBCE: 3.7089335918426514\n",
      "Loss: 3.3400683403015137, Norm: 0.0017919117817655206, InvBCE: 3.302513599395752\n",
      "Loss: 2.9916229248046875, Norm: 0.0021140952594578266, InvBCE: 2.95404314994812\n",
      "Loss: 2.6898796558380127, Norm: 0.0024259877391159534, InvBCE: 2.652273654937744\n",
      "Loss: 2.410594940185547, Norm: 0.002726512961089611, InvBCE: 2.372962236404419\n",
      "Loss: 2.1516685485839844, Norm: 0.003019202733412385, InvBCE: 2.1140081882476807\n",
      "Loss: 1.9215281009674072, Norm: 0.0033044118899852037, InvBCE: 1.8838392496109009\n",
      "Loss: 1.7152602672576904, Norm: 0.003581922734156251, InvBCE: 1.6775423288345337\n",
      "Loss: 1.5298104286193848, Norm: 0.0038516235072165728, InvBCE: 1.492063045501709\n",
      "Loss: 1.3668485879898071, Norm: 0.0041131931357085705, InvBCE: 1.3290716409683228\n",
      "Loss: 1.2230404615402222, Norm: 0.004366306122392416, InvBCE: 1.1852339506149292\n",
      "Loss: 1.0948585271835327, Norm: 0.004610858391970396, InvBCE: 1.0570225715637207\n",
      "Loss: 0.9814375042915344, Norm: 0.004846720490604639, InvBCE: 0.9435725212097168\n",
      "Loss: 0.8834782242774963, Norm: 0.005073722917586565, InvBCE: 0.8455847501754761\n",
      "Loss: 0.7992496490478516, Norm: 0.005291688721626997, InvBCE: 0.761328399181366\n",
      "Loss: 0.7287654876708984, Norm: 0.005500452127307653, InvBCE: 0.6908174157142639\n",
      "Image 51...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 52...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 53...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 54...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 55...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 56...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 57...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 58...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 59...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 60...\n",
      "Loss: 630.2578125, Norm: 0.0, InvBCE: 630.2203369140625\n",
      "Loss: 294.43890380859375, Norm: 0.0003751915355678648, InvBCE: 294.40142822265625\n",
      "Loss: 205.86048889160156, Norm: 0.0007111579179763794, InvBCE: 205.822998046875\n",
      "Loss: 127.29917907714844, Norm: 0.000995049369521439, InvBCE: 127.26168060302734\n",
      "Loss: 87.0525894165039, Norm: 0.0012601095950230956, InvBCE: 87.01508331298828\n",
      "Loss: 64.68090057373047, Norm: 0.0015051922528073192, InvBCE: 64.64338684082031\n",
      "Loss: 51.09668731689453, Norm: 0.0017316206358373165, InvBCE: 51.05917739868164\n",
      "Loss: 42.111236572265625, Norm: 0.0019414193229749799, InvBCE: 42.073726654052734\n",
      "Loss: 36.45672607421875, Norm: 0.002136079827323556, InvBCE: 36.419219970703125\n",
      "Loss: 32.15752029418945, Norm: 0.0023177447728812695, InvBCE: 32.120018005371094\n",
      "Loss: 28.973976135253906, Norm: 0.0024879255797713995, InvBCE: 28.936481475830078\n",
      "Loss: 26.204933166503906, Norm: 0.002647911664098501, InvBCE: 26.16744613647461\n",
      "Loss: 24.398008346557617, Norm: 0.00279878918081522, InvBCE: 24.360530853271484\n",
      "Loss: 23.336881637573242, Norm: 0.0029415434692054987, InvBCE: 23.299413681030273\n",
      "Loss: 22.053970336914062, Norm: 0.0030771500896662474, InvBCE: 22.01651382446289\n",
      "Loss: 21.04062271118164, Norm: 0.003206353634595871, InvBCE: 21.003177642822266\n",
      "Loss: 20.176753997802734, Norm: 0.003329807659611106, InvBCE: 20.13932228088379\n",
      "Loss: 19.40626335144043, Norm: 0.0034481859765946865, InvBCE: 19.368844985961914\n",
      "Loss: 18.743093490600586, Norm: 0.0035619453992694616, InvBCE: 18.705690383911133\n",
      "Loss: 18.163227081298828, Norm: 0.0036715876776725054, InvBCE: 18.125839233398438\n",
      "Image 61...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 62...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 63...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 64...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 65...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 66...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 67...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 68...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 69...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 70...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 71...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 72...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 73...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 74...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 75...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 76...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 77...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 78...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 79...\n",
      "Loss: 809.8610229492188, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8607788085938, Norm: 0.00023278483422473073, InvBCE: 809.8235473632812\n",
      "Loss: 809.860595703125, Norm: 0.00046540083712898195, InvBCE: 809.8235473632812\n",
      "Loss: 809.8603515625, Norm: 0.0006978358142077923, InvBCE: 809.8235473632812\n",
      "Loss: 809.8601684570312, Norm: 0.0009300776291638613, InvBCE: 809.8235473632812\n",
      "Loss: 809.8599243164062, Norm: 0.0011621139710769057, InvBCE: 809.8235473632812\n",
      "Loss: 809.8597412109375, Norm: 0.0013939322670921683, InvBCE: 809.8235473632812\n",
      "Loss: 809.8594970703125, Norm: 0.0016255201771855354, InvBCE: 809.8235473632812\n",
      "Loss: 809.8593139648438, Norm: 0.0018568650120869279, InvBCE: 809.8235473632812\n",
      "Loss: 809.8590698242188, Norm: 0.0020879541989415884, InvBCE: 809.8235473632812\n",
      "Loss: 809.85888671875, Norm: 0.002318775048479438, InvBCE: 809.8235473632812\n",
      "Loss: 809.8587036132812, Norm: 0.0025493153370916843, InvBCE: 809.8235473632812\n",
      "Loss: 809.8584594726562, Norm: 0.0027795627247542143, InvBCE: 809.8235473632812\n",
      "Loss: 809.8582763671875, Norm: 0.0030095039401203394, InvBCE: 809.8235473632812\n",
      "Loss: 809.8580322265625, Norm: 0.0032391278073191643, InvBCE: 809.8235473632812\n",
      "Loss: 809.8578491210938, Norm: 0.0034684212878346443, InvBCE: 809.8235473632812\n",
      "Loss: 809.857666015625, Norm: 0.0036973722744733095, InvBCE: 809.8235473632812\n",
      "Loss: 809.857421875, Norm: 0.003925969824194908, InvBCE: 809.8235473632812\n",
      "Loss: 809.8572387695312, Norm: 0.004154201131314039, InvBCE: 809.8235473632812\n",
      "Loss: 809.8569946289062, Norm: 0.004382054787129164, InvBCE: 809.8235473632812\n",
      "Image 80...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 81...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 82...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 83...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 84...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 85...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 86...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 87...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 88...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 89...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 90...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 91...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 92...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 93...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 94...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 95...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 96...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 97...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 98...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 99...\n",
      "Image fooled! Adding perturbation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ee57e5a350740e584229fba30aab223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fooling rate: 0.94\n",
      "Starting epoch 28...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "987636daecc846febb23706c7a636692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 1...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 2...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 3...\n",
      "Loss: 2.717554807662964, Norm: 0.0, InvBCE: 2.6801018714904785\n",
      "Loss: 2.407351493835449, Norm: 0.00038118421798571944, InvBCE: 2.3698573112487793\n",
      "Loss: 2.134324550628662, Norm: 0.0007559842779301107, InvBCE: 2.0967862606048584\n",
      "Loss: 1.8955780267715454, Norm: 0.0011244287015870214, InvBCE: 1.8579938411712646\n",
      "Loss: 1.6877946853637695, Norm: 0.0014857073547318578, InvBCE: 1.650162935256958\n",
      "Loss: 1.5075215101242065, Norm: 0.0018390374025329947, InvBCE: 1.4698407649993896\n",
      "Loss: 1.3513212203979492, Norm: 0.0021836247760802507, InvBCE: 1.313590407371521\n",
      "Loss: 1.2159942388534546, Norm: 0.0025187814608216286, InvBCE: 1.1782126426696777\n",
      "Loss: 1.0986416339874268, Norm: 0.0028439692687243223, InvBCE: 1.060808777809143\n",
      "Loss: 0.9967145323753357, Norm: 0.0031588065903633833, InvBCE: 0.9588302969932556\n",
      "Loss: 0.9080396294593811, Norm: 0.0034630452282726765, InvBCE: 0.8701043128967285\n",
      "Loss: 0.8308247327804565, Norm: 0.003756554564461112, InvBCE: 0.7928388714790344\n",
      "Loss: 0.7636405229568481, Norm: 0.004039280116558075, InvBCE: 0.7256050109863281\n",
      "Loss: 0.7053354978561401, Norm: 0.004311214666813612, InvBCE: 0.667251467704773\n",
      "Loss: 0.6549381613731384, Norm: 0.004572402220219374, InvBCE: 0.6168069243431091\n",
      "Loss: 0.6115550398826599, Norm: 0.004822922870516777, InvBCE: 0.5733780264854431\n",
      "Loss: 0.5743334293365479, Norm: 0.005062887445092201, InvBCE: 0.5361122488975525\n",
      "Loss: 0.5424706339836121, Norm: 0.005292464513331652, InvBCE: 0.5042068958282471\n",
      "Loss: 0.5152295231819153, Norm: 0.005511854775249958, InvBCE: 0.47692495584487915\n",
      "Loss: 0.4919421672821045, Norm: 0.005721298512071371, InvBCE: 0.4535984694957733\n",
      "Image 4...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 5...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 6...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 7...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 8...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 9...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 10...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 11...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 12...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 13...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 14...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 15...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 16...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 17...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 18...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 19...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 20...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 21...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 22...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 23...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 24...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 25...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 26...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 27...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 28...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 29...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 30...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 31...\n",
      "Loss: 809.8610229492188, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8607788085938, Norm: 0.00023278483422473073, InvBCE: 809.8235473632812\n",
      "Loss: 809.860595703125, Norm: 0.00046540083712898195, InvBCE: 809.8235473632812\n",
      "Loss: 809.8603515625, Norm: 0.0006978358142077923, InvBCE: 809.8235473632812\n",
      "Loss: 809.8601684570312, Norm: 0.0009300776291638613, InvBCE: 809.8235473632812\n",
      "Loss: 809.8599243164062, Norm: 0.0011621139710769057, InvBCE: 809.8235473632812\n",
      "Loss: 809.8597412109375, Norm: 0.0013939322670921683, InvBCE: 809.8235473632812\n",
      "Loss: 809.8594970703125, Norm: 0.0016255201771855354, InvBCE: 809.8235473632812\n",
      "Loss: 809.8593139648438, Norm: 0.0018568650120869279, InvBCE: 809.8235473632812\n",
      "Loss: 809.8590698242188, Norm: 0.0020879541989415884, InvBCE: 809.8235473632812\n",
      "Loss: 809.85888671875, Norm: 0.002318775048479438, InvBCE: 809.8235473632812\n",
      "Loss: 809.8587036132812, Norm: 0.0025493153370916843, InvBCE: 809.8235473632812\n",
      "Loss: 809.8584594726562, Norm: 0.0027795627247542143, InvBCE: 809.8235473632812\n",
      "Loss: 809.8582763671875, Norm: 0.0030095039401203394, InvBCE: 809.8235473632812\n",
      "Loss: 809.8580322265625, Norm: 0.0032391278073191643, InvBCE: 809.8235473632812\n",
      "Loss: 809.8578491210938, Norm: 0.0034684212878346443, InvBCE: 809.8235473632812\n",
      "Loss: 809.857666015625, Norm: 0.0036973722744733095, InvBCE: 809.8235473632812\n",
      "Loss: 809.857421875, Norm: 0.003925969824194908, InvBCE: 809.8235473632812\n",
      "Loss: 809.8572387695312, Norm: 0.004154201131314039, InvBCE: 809.8235473632812\n",
      "Loss: 809.8569946289062, Norm: 0.004382054787129164, InvBCE: 809.8235473632812\n",
      "Image 32...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 33...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 34...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 35...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 36...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 37...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 38...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 39...\n",
      "Loss: 72.98128509521484, Norm: 0.0, InvBCE: 72.94383239746094\n",
      "Loss: 46.08408737182617, Norm: 0.0003843815065920353, InvBCE: 46.04658126831055\n",
      "Loss: 32.78629684448242, Norm: 0.000742322881706059, InvBCE: 32.74873352050781\n",
      "Loss: 24.617408752441406, Norm: 0.001077656401321292, InvBCE: 24.579795837402344\n",
      "Loss: 19.725128173828125, Norm: 0.0013914385344833136, InvBCE: 19.68746566772461\n",
      "Loss: 16.54332160949707, Norm: 0.0016856665024533868, InvBCE: 16.505611419677734\n",
      "Loss: 14.422035217285156, Norm: 0.001962564652785659, InvBCE: 14.384281158447266\n",
      "Loss: 12.86168384552002, Norm: 0.002224019728600979, InvBCE: 12.82388687133789\n",
      "Loss: 11.653457641601562, Norm: 0.002471968298777938, InvBCE: 11.615620613098145\n",
      "Loss: 10.683114051818848, Norm: 0.0027080196887254715, InvBCE: 10.645237922668457\n",
      "Loss: 8.709017753601074, Norm: 0.002933422802016139, InvBCE: 8.67110538482666\n",
      "Loss: 8.126260757446289, Norm: 0.003149435855448246, InvBCE: 8.088312149047852\n",
      "Loss: 7.666654109954834, Norm: 0.003355486784130335, InvBCE: 7.628672122955322\n",
      "Loss: 7.273351192474365, Norm: 0.0035526002757251263, InvBCE: 7.235337734222412\n",
      "Loss: 6.933590412139893, Norm: 0.0037416713312268257, InvBCE: 6.8955464363098145\n",
      "Loss: 6.633247375488281, Norm: 0.003923483658581972, InvBCE: 6.595174789428711\n",
      "Loss: 6.361598968505859, Norm: 0.0040987515822052956, InvBCE: 6.3234992027282715\n",
      "Loss: 6.131810665130615, Norm: 0.004267985001206398, InvBCE: 6.093685150146484\n",
      "Loss: 5.9073896408081055, Norm: 0.004431800916790962, InvBCE: 5.869239807128906\n",
      "Loss: 5.703206539154053, Norm: 0.00459067290648818, InvBCE: 5.665033340454102\n",
      "Image 40...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 41...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 42...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 43...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 44...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 45...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 46...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 47...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 48...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 49...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 50...\n",
      "Loss: 6.874675750732422, Norm: 0.0, InvBCE: 6.837223052978516\n",
      "Loss: 5.713406562805176, Norm: 0.00038196725654415786, InvBCE: 5.675937175750732\n",
      "Loss: 4.862036228179932, Norm: 0.0007531616720370948, InvBCE: 4.824548244476318\n",
      "Loss: 4.227441787719727, Norm: 0.001112419762648642, InvBCE: 4.1899333000183105\n",
      "Loss: 3.746464490890503, Norm: 0.0014584700111299753, InvBCE: 3.7089335918426514\n",
      "Loss: 3.3400683403015137, Norm: 0.0017919117817655206, InvBCE: 3.302513599395752\n",
      "Loss: 2.9916229248046875, Norm: 0.0021140952594578266, InvBCE: 2.95404314994812\n",
      "Loss: 2.6898796558380127, Norm: 0.0024259877391159534, InvBCE: 2.652273654937744\n",
      "Loss: 2.410594940185547, Norm: 0.002726512961089611, InvBCE: 2.372962236404419\n",
      "Loss: 2.1516685485839844, Norm: 0.003019202733412385, InvBCE: 2.1140081882476807\n",
      "Loss: 1.9215281009674072, Norm: 0.0033044118899852037, InvBCE: 1.8838392496109009\n",
      "Loss: 1.7152602672576904, Norm: 0.003581922734156251, InvBCE: 1.6775423288345337\n",
      "Loss: 1.5298104286193848, Norm: 0.0038516235072165728, InvBCE: 1.492063045501709\n",
      "Loss: 1.3668485879898071, Norm: 0.0041131931357085705, InvBCE: 1.3290716409683228\n",
      "Loss: 1.2230404615402222, Norm: 0.004366306122392416, InvBCE: 1.1852339506149292\n",
      "Loss: 1.0948585271835327, Norm: 0.004610858391970396, InvBCE: 1.0570225715637207\n",
      "Loss: 0.9814375042915344, Norm: 0.004846720490604639, InvBCE: 0.9435725212097168\n",
      "Loss: 0.8834782242774963, Norm: 0.005073722917586565, InvBCE: 0.8455847501754761\n",
      "Loss: 0.7992496490478516, Norm: 0.005291688721626997, InvBCE: 0.761328399181366\n",
      "Loss: 0.7287654876708984, Norm: 0.005500452127307653, InvBCE: 0.6908174157142639\n",
      "Image 51...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 52...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 53...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 54...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 55...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 56...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 57...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 58...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 59...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 60...\n",
      "Loss: 630.2578125, Norm: 0.0, InvBCE: 630.2203369140625\n",
      "Loss: 294.43890380859375, Norm: 0.0003751915355678648, InvBCE: 294.40142822265625\n",
      "Loss: 205.86048889160156, Norm: 0.0007111579179763794, InvBCE: 205.822998046875\n",
      "Loss: 127.29917907714844, Norm: 0.000995049369521439, InvBCE: 127.26168060302734\n",
      "Loss: 87.0525894165039, Norm: 0.0012601095950230956, InvBCE: 87.01508331298828\n",
      "Loss: 64.68090057373047, Norm: 0.0015051922528073192, InvBCE: 64.64338684082031\n",
      "Loss: 51.09668731689453, Norm: 0.0017316206358373165, InvBCE: 51.05917739868164\n",
      "Loss: 42.111236572265625, Norm: 0.0019414193229749799, InvBCE: 42.073726654052734\n",
      "Loss: 36.45672607421875, Norm: 0.002136079827323556, InvBCE: 36.419219970703125\n",
      "Loss: 32.15752029418945, Norm: 0.0023177447728812695, InvBCE: 32.120018005371094\n",
      "Loss: 28.973976135253906, Norm: 0.0024879255797713995, InvBCE: 28.936481475830078\n",
      "Loss: 26.204933166503906, Norm: 0.002647911664098501, InvBCE: 26.16744613647461\n",
      "Loss: 24.398008346557617, Norm: 0.00279878918081522, InvBCE: 24.360530853271484\n",
      "Loss: 23.336881637573242, Norm: 0.0029415434692054987, InvBCE: 23.299413681030273\n",
      "Loss: 22.053970336914062, Norm: 0.0030771500896662474, InvBCE: 22.01651382446289\n",
      "Loss: 21.04062271118164, Norm: 0.003206353634595871, InvBCE: 21.003177642822266\n",
      "Loss: 20.176753997802734, Norm: 0.003329807659611106, InvBCE: 20.13932228088379\n",
      "Loss: 19.40626335144043, Norm: 0.0034481859765946865, InvBCE: 19.368844985961914\n",
      "Loss: 18.743093490600586, Norm: 0.0035619453992694616, InvBCE: 18.705690383911133\n",
      "Loss: 18.163227081298828, Norm: 0.0036715876776725054, InvBCE: 18.125839233398438\n",
      "Image 61...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 62...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 63...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 64...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 65...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 66...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 67...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 68...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 69...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 70...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 71...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 72...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 73...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 74...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 75...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 76...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 77...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 78...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 79...\n",
      "Loss: 809.8610229492188, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8607788085938, Norm: 0.00023278483422473073, InvBCE: 809.8235473632812\n",
      "Loss: 809.860595703125, Norm: 0.00046540083712898195, InvBCE: 809.8235473632812\n",
      "Loss: 809.8603515625, Norm: 0.0006978358142077923, InvBCE: 809.8235473632812\n",
      "Loss: 809.8601684570312, Norm: 0.0009300776291638613, InvBCE: 809.8235473632812\n",
      "Loss: 809.8599243164062, Norm: 0.0011621139710769057, InvBCE: 809.8235473632812\n",
      "Loss: 809.8597412109375, Norm: 0.0013939322670921683, InvBCE: 809.8235473632812\n",
      "Loss: 809.8594970703125, Norm: 0.0016255201771855354, InvBCE: 809.8235473632812\n",
      "Loss: 809.8593139648438, Norm: 0.0018568650120869279, InvBCE: 809.8235473632812\n",
      "Loss: 809.8590698242188, Norm: 0.0020879541989415884, InvBCE: 809.8235473632812\n",
      "Loss: 809.85888671875, Norm: 0.002318775048479438, InvBCE: 809.8235473632812\n",
      "Loss: 809.8587036132812, Norm: 0.0025493153370916843, InvBCE: 809.8235473632812\n",
      "Loss: 809.8584594726562, Norm: 0.0027795627247542143, InvBCE: 809.8235473632812\n",
      "Loss: 809.8582763671875, Norm: 0.0030095039401203394, InvBCE: 809.8235473632812\n",
      "Loss: 809.8580322265625, Norm: 0.0032391278073191643, InvBCE: 809.8235473632812\n",
      "Loss: 809.8578491210938, Norm: 0.0034684212878346443, InvBCE: 809.8235473632812\n",
      "Loss: 809.857666015625, Norm: 0.0036973722744733095, InvBCE: 809.8235473632812\n",
      "Loss: 809.857421875, Norm: 0.003925969824194908, InvBCE: 809.8235473632812\n",
      "Loss: 809.8572387695312, Norm: 0.004154201131314039, InvBCE: 809.8235473632812\n",
      "Loss: 809.8569946289062, Norm: 0.004382054787129164, InvBCE: 809.8235473632812\n",
      "Image 80...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 81...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 82...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 83...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 84...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 85...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 86...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 87...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 88...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 89...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 90...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 91...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 92...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 93...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 94...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 95...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 96...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 97...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 98...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 99...\n",
      "Image fooled! Adding perturbation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca65642999ba4094b2bef53f55d74171",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fooling rate: 0.94\n",
      "Starting epoch 29...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5523ca16070478697e12bbd00b5f14e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 1...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 2...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 3...\n",
      "Loss: 2.717554807662964, Norm: 0.0, InvBCE: 2.6801018714904785\n",
      "Loss: 2.407351493835449, Norm: 0.00038118421798571944, InvBCE: 2.3698573112487793\n",
      "Loss: 2.134324550628662, Norm: 0.0007559842779301107, InvBCE: 2.0967862606048584\n",
      "Loss: 1.8955780267715454, Norm: 0.0011244287015870214, InvBCE: 1.8579938411712646\n",
      "Loss: 1.6877946853637695, Norm: 0.0014857073547318578, InvBCE: 1.650162935256958\n",
      "Loss: 1.5075215101242065, Norm: 0.0018390374025329947, InvBCE: 1.4698407649993896\n",
      "Loss: 1.3513212203979492, Norm: 0.0021836247760802507, InvBCE: 1.313590407371521\n",
      "Loss: 1.2159942388534546, Norm: 0.0025187814608216286, InvBCE: 1.1782126426696777\n",
      "Loss: 1.0986416339874268, Norm: 0.0028439692687243223, InvBCE: 1.060808777809143\n",
      "Loss: 0.9967145323753357, Norm: 0.0031588065903633833, InvBCE: 0.9588302969932556\n",
      "Loss: 0.9080396294593811, Norm: 0.0034630452282726765, InvBCE: 0.8701043128967285\n",
      "Loss: 0.8308247327804565, Norm: 0.003756554564461112, InvBCE: 0.7928388714790344\n",
      "Loss: 0.7636405229568481, Norm: 0.004039280116558075, InvBCE: 0.7256050109863281\n",
      "Loss: 0.7053354978561401, Norm: 0.004311214666813612, InvBCE: 0.667251467704773\n",
      "Loss: 0.6549381613731384, Norm: 0.004572402220219374, InvBCE: 0.6168069243431091\n",
      "Loss: 0.6115550398826599, Norm: 0.004822922870516777, InvBCE: 0.5733780264854431\n",
      "Loss: 0.5743334293365479, Norm: 0.005062887445092201, InvBCE: 0.5361122488975525\n",
      "Loss: 0.5424706339836121, Norm: 0.005292464513331652, InvBCE: 0.5042068958282471\n",
      "Loss: 0.5152295231819153, Norm: 0.005511854775249958, InvBCE: 0.47692495584487915\n",
      "Loss: 0.4919421672821045, Norm: 0.005721298512071371, InvBCE: 0.4535984694957733\n",
      "Image 4...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 5...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 6...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 7...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 8...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 9...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 10...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 11...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 12...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 13...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 14...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 15...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 16...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 17...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 18...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 19...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 20...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 21...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 22...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 23...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 24...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 25...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 26...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 27...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 28...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 29...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 30...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 31...\n",
      "Loss: 809.8610229492188, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8607788085938, Norm: 0.00023278483422473073, InvBCE: 809.8235473632812\n",
      "Loss: 809.860595703125, Norm: 0.00046540083712898195, InvBCE: 809.8235473632812\n",
      "Loss: 809.8603515625, Norm: 0.0006978358142077923, InvBCE: 809.8235473632812\n",
      "Loss: 809.8601684570312, Norm: 0.0009300776291638613, InvBCE: 809.8235473632812\n",
      "Loss: 809.8599243164062, Norm: 0.0011621139710769057, InvBCE: 809.8235473632812\n",
      "Loss: 809.8597412109375, Norm: 0.0013939322670921683, InvBCE: 809.8235473632812\n",
      "Loss: 809.8594970703125, Norm: 0.0016255201771855354, InvBCE: 809.8235473632812\n",
      "Loss: 809.8593139648438, Norm: 0.0018568650120869279, InvBCE: 809.8235473632812\n",
      "Loss: 809.8590698242188, Norm: 0.0020879541989415884, InvBCE: 809.8235473632812\n",
      "Loss: 809.85888671875, Norm: 0.002318775048479438, InvBCE: 809.8235473632812\n",
      "Loss: 809.8587036132812, Norm: 0.0025493153370916843, InvBCE: 809.8235473632812\n",
      "Loss: 809.8584594726562, Norm: 0.0027795627247542143, InvBCE: 809.8235473632812\n",
      "Loss: 809.8582763671875, Norm: 0.0030095039401203394, InvBCE: 809.8235473632812\n",
      "Loss: 809.8580322265625, Norm: 0.0032391278073191643, InvBCE: 809.8235473632812\n",
      "Loss: 809.8578491210938, Norm: 0.0034684212878346443, InvBCE: 809.8235473632812\n",
      "Loss: 809.857666015625, Norm: 0.0036973722744733095, InvBCE: 809.8235473632812\n",
      "Loss: 809.857421875, Norm: 0.003925969824194908, InvBCE: 809.8235473632812\n",
      "Loss: 809.8572387695312, Norm: 0.004154201131314039, InvBCE: 809.8235473632812\n",
      "Loss: 809.8569946289062, Norm: 0.004382054787129164, InvBCE: 809.8235473632812\n",
      "Image 32...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 33...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 34...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 35...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 36...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 37...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 38...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 39...\n",
      "Loss: 72.98128509521484, Norm: 0.0, InvBCE: 72.94383239746094\n",
      "Loss: 46.08408737182617, Norm: 0.0003843815065920353, InvBCE: 46.04658126831055\n",
      "Loss: 32.78629684448242, Norm: 0.000742322881706059, InvBCE: 32.74873352050781\n",
      "Loss: 24.617408752441406, Norm: 0.001077656401321292, InvBCE: 24.579795837402344\n",
      "Loss: 19.725128173828125, Norm: 0.0013914385344833136, InvBCE: 19.68746566772461\n",
      "Loss: 16.54332160949707, Norm: 0.0016856665024533868, InvBCE: 16.505611419677734\n",
      "Loss: 14.422035217285156, Norm: 0.001962564652785659, InvBCE: 14.384281158447266\n",
      "Loss: 12.86168384552002, Norm: 0.002224019728600979, InvBCE: 12.82388687133789\n",
      "Loss: 11.653457641601562, Norm: 0.002471968298777938, InvBCE: 11.615620613098145\n",
      "Loss: 10.683114051818848, Norm: 0.0027080196887254715, InvBCE: 10.645237922668457\n",
      "Loss: 8.709017753601074, Norm: 0.002933422802016139, InvBCE: 8.67110538482666\n",
      "Loss: 8.126260757446289, Norm: 0.003149435855448246, InvBCE: 8.088312149047852\n",
      "Loss: 7.666654109954834, Norm: 0.003355486784130335, InvBCE: 7.628672122955322\n",
      "Loss: 7.273351192474365, Norm: 0.0035526002757251263, InvBCE: 7.235337734222412\n",
      "Loss: 6.933590412139893, Norm: 0.0037416713312268257, InvBCE: 6.8955464363098145\n",
      "Loss: 6.633247375488281, Norm: 0.003923483658581972, InvBCE: 6.595174789428711\n",
      "Loss: 6.361598968505859, Norm: 0.0040987515822052956, InvBCE: 6.3234992027282715\n",
      "Loss: 6.131810665130615, Norm: 0.004267985001206398, InvBCE: 6.093685150146484\n",
      "Loss: 5.9073896408081055, Norm: 0.004431800916790962, InvBCE: 5.869239807128906\n",
      "Loss: 5.703206539154053, Norm: 0.00459067290648818, InvBCE: 5.665033340454102\n",
      "Image 40...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 41...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 42...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 43...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 44...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 45...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 46...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 47...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 48...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 49...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 50...\n",
      "Loss: 6.874675750732422, Norm: 0.0, InvBCE: 6.837223052978516\n",
      "Loss: 5.713406562805176, Norm: 0.00038196725654415786, InvBCE: 5.675937175750732\n",
      "Loss: 4.862036228179932, Norm: 0.0007531616720370948, InvBCE: 4.824548244476318\n",
      "Loss: 4.227441787719727, Norm: 0.001112419762648642, InvBCE: 4.1899333000183105\n",
      "Loss: 3.746464490890503, Norm: 0.0014584700111299753, InvBCE: 3.7089335918426514\n",
      "Loss: 3.3400683403015137, Norm: 0.0017919117817655206, InvBCE: 3.302513599395752\n",
      "Loss: 2.9916229248046875, Norm: 0.0021140952594578266, InvBCE: 2.95404314994812\n",
      "Loss: 2.6898796558380127, Norm: 0.0024259877391159534, InvBCE: 2.652273654937744\n",
      "Loss: 2.410594940185547, Norm: 0.002726512961089611, InvBCE: 2.372962236404419\n",
      "Loss: 2.1516685485839844, Norm: 0.003019202733412385, InvBCE: 2.1140081882476807\n",
      "Loss: 1.9215281009674072, Norm: 0.0033044118899852037, InvBCE: 1.8838392496109009\n",
      "Loss: 1.7152602672576904, Norm: 0.003581922734156251, InvBCE: 1.6775423288345337\n",
      "Loss: 1.5298104286193848, Norm: 0.0038516235072165728, InvBCE: 1.492063045501709\n",
      "Loss: 1.3668485879898071, Norm: 0.0041131931357085705, InvBCE: 1.3290716409683228\n",
      "Loss: 1.2230404615402222, Norm: 0.004366306122392416, InvBCE: 1.1852339506149292\n",
      "Loss: 1.0948585271835327, Norm: 0.004610858391970396, InvBCE: 1.0570225715637207\n",
      "Loss: 0.9814375042915344, Norm: 0.004846720490604639, InvBCE: 0.9435725212097168\n",
      "Loss: 0.8834782242774963, Norm: 0.005073722917586565, InvBCE: 0.8455847501754761\n",
      "Loss: 0.7992496490478516, Norm: 0.005291688721626997, InvBCE: 0.761328399181366\n",
      "Loss: 0.7287654876708984, Norm: 0.005500452127307653, InvBCE: 0.6908174157142639\n",
      "Image 51...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 52...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 53...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 54...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 55...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 56...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 57...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 58...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 59...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 60...\n",
      "Loss: 630.2578125, Norm: 0.0, InvBCE: 630.2203369140625\n",
      "Loss: 294.43890380859375, Norm: 0.0003751915355678648, InvBCE: 294.40142822265625\n",
      "Loss: 205.86048889160156, Norm: 0.0007111579179763794, InvBCE: 205.822998046875\n",
      "Loss: 127.29917907714844, Norm: 0.000995049369521439, InvBCE: 127.26168060302734\n",
      "Loss: 87.0525894165039, Norm: 0.0012601095950230956, InvBCE: 87.01508331298828\n",
      "Loss: 64.68090057373047, Norm: 0.0015051922528073192, InvBCE: 64.64338684082031\n",
      "Loss: 51.09668731689453, Norm: 0.0017316206358373165, InvBCE: 51.05917739868164\n",
      "Loss: 42.111236572265625, Norm: 0.0019414193229749799, InvBCE: 42.073726654052734\n",
      "Loss: 36.45672607421875, Norm: 0.002136079827323556, InvBCE: 36.419219970703125\n",
      "Loss: 32.15752029418945, Norm: 0.0023177447728812695, InvBCE: 32.120018005371094\n",
      "Loss: 28.973976135253906, Norm: 0.0024879255797713995, InvBCE: 28.936481475830078\n",
      "Loss: 26.204933166503906, Norm: 0.002647911664098501, InvBCE: 26.16744613647461\n",
      "Loss: 24.398008346557617, Norm: 0.00279878918081522, InvBCE: 24.360530853271484\n",
      "Loss: 23.336881637573242, Norm: 0.0029415434692054987, InvBCE: 23.299413681030273\n",
      "Loss: 22.053970336914062, Norm: 0.0030771500896662474, InvBCE: 22.01651382446289\n",
      "Loss: 21.04062271118164, Norm: 0.003206353634595871, InvBCE: 21.003177642822266\n",
      "Loss: 20.176753997802734, Norm: 0.003329807659611106, InvBCE: 20.13932228088379\n",
      "Loss: 19.40626335144043, Norm: 0.0034481859765946865, InvBCE: 19.368844985961914\n",
      "Loss: 18.743093490600586, Norm: 0.0035619453992694616, InvBCE: 18.705690383911133\n",
      "Loss: 18.163227081298828, Norm: 0.0036715876776725054, InvBCE: 18.125839233398438\n",
      "Image 61...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 62...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 63...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 64...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 65...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 66...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 67...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 68...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 69...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 70...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 71...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 72...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 73...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 74...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 75...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 76...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 77...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 78...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 79...\n",
      "Loss: 809.8610229492188, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8607788085938, Norm: 0.00023278483422473073, InvBCE: 809.8235473632812\n",
      "Loss: 809.860595703125, Norm: 0.00046540083712898195, InvBCE: 809.8235473632812\n",
      "Loss: 809.8603515625, Norm: 0.0006978358142077923, InvBCE: 809.8235473632812\n",
      "Loss: 809.8601684570312, Norm: 0.0009300776291638613, InvBCE: 809.8235473632812\n",
      "Loss: 809.8599243164062, Norm: 0.0011621139710769057, InvBCE: 809.8235473632812\n",
      "Loss: 809.8597412109375, Norm: 0.0013939322670921683, InvBCE: 809.8235473632812\n",
      "Loss: 809.8594970703125, Norm: 0.0016255201771855354, InvBCE: 809.8235473632812\n",
      "Loss: 809.8593139648438, Norm: 0.0018568650120869279, InvBCE: 809.8235473632812\n",
      "Loss: 809.8590698242188, Norm: 0.0020879541989415884, InvBCE: 809.8235473632812\n",
      "Loss: 809.85888671875, Norm: 0.002318775048479438, InvBCE: 809.8235473632812\n",
      "Loss: 809.8587036132812, Norm: 0.0025493153370916843, InvBCE: 809.8235473632812\n",
      "Loss: 809.8584594726562, Norm: 0.0027795627247542143, InvBCE: 809.8235473632812\n",
      "Loss: 809.8582763671875, Norm: 0.0030095039401203394, InvBCE: 809.8235473632812\n",
      "Loss: 809.8580322265625, Norm: 0.0032391278073191643, InvBCE: 809.8235473632812\n",
      "Loss: 809.8578491210938, Norm: 0.0034684212878346443, InvBCE: 809.8235473632812\n",
      "Loss: 809.857666015625, Norm: 0.0036973722744733095, InvBCE: 809.8235473632812\n",
      "Loss: 809.857421875, Norm: 0.003925969824194908, InvBCE: 809.8235473632812\n",
      "Loss: 809.8572387695312, Norm: 0.004154201131314039, InvBCE: 809.8235473632812\n",
      "Loss: 809.8569946289062, Norm: 0.004382054787129164, InvBCE: 809.8235473632812\n",
      "Image 80...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 81...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 82...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 83...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 84...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 85...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 86...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 87...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 88...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 89...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 90...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 91...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 92...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 93...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 94...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 95...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 96...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 97...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 98...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 99...\n",
      "Image fooled! Adding perturbation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94a195bc46de40658f0fc79db568252a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fooling rate: 0.94\n",
      "Starting epoch 30...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee9e3574120144be8976b1b908fc737e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 1...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 2...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 3...\n",
      "Loss: 2.717554807662964, Norm: 0.0, InvBCE: 2.6801018714904785\n",
      "Loss: 2.407351493835449, Norm: 0.00038118421798571944, InvBCE: 2.3698573112487793\n",
      "Loss: 2.134324550628662, Norm: 0.0007559842779301107, InvBCE: 2.0967862606048584\n",
      "Loss: 1.8955780267715454, Norm: 0.0011244287015870214, InvBCE: 1.8579938411712646\n",
      "Loss: 1.6877946853637695, Norm: 0.0014857073547318578, InvBCE: 1.650162935256958\n",
      "Loss: 1.5075215101242065, Norm: 0.0018390374025329947, InvBCE: 1.4698407649993896\n",
      "Loss: 1.3513212203979492, Norm: 0.0021836247760802507, InvBCE: 1.313590407371521\n",
      "Loss: 1.2159942388534546, Norm: 0.0025187814608216286, InvBCE: 1.1782126426696777\n",
      "Loss: 1.0986416339874268, Norm: 0.0028439692687243223, InvBCE: 1.060808777809143\n",
      "Loss: 0.9967145323753357, Norm: 0.0031588065903633833, InvBCE: 0.9588302969932556\n",
      "Loss: 0.9080396294593811, Norm: 0.0034630452282726765, InvBCE: 0.8701043128967285\n",
      "Loss: 0.8308247327804565, Norm: 0.003756554564461112, InvBCE: 0.7928388714790344\n",
      "Loss: 0.7636405229568481, Norm: 0.004039280116558075, InvBCE: 0.7256050109863281\n",
      "Loss: 0.7053354978561401, Norm: 0.004311214666813612, InvBCE: 0.667251467704773\n",
      "Loss: 0.6549381613731384, Norm: 0.004572402220219374, InvBCE: 0.6168069243431091\n",
      "Loss: 0.6115550398826599, Norm: 0.004822922870516777, InvBCE: 0.5733780264854431\n",
      "Loss: 0.5743334293365479, Norm: 0.005062887445092201, InvBCE: 0.5361122488975525\n",
      "Loss: 0.5424706339836121, Norm: 0.005292464513331652, InvBCE: 0.5042068958282471\n",
      "Loss: 0.5152295231819153, Norm: 0.005511854775249958, InvBCE: 0.47692495584487915\n",
      "Loss: 0.4919421672821045, Norm: 0.005721298512071371, InvBCE: 0.4535984694957733\n",
      "Image 4...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 5...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 6...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 7...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 8...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 9...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 10...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 11...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 12...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 13...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 14...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 15...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 16...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 17...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 18...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 19...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 20...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 21...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 22...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 23...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 24...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 25...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 26...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 27...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 28...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 29...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 30...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 31...\n",
      "Loss: 809.8610229492188, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8607788085938, Norm: 0.00023278483422473073, InvBCE: 809.8235473632812\n",
      "Loss: 809.860595703125, Norm: 0.00046540083712898195, InvBCE: 809.8235473632812\n",
      "Loss: 809.8603515625, Norm: 0.0006978358142077923, InvBCE: 809.8235473632812\n",
      "Loss: 809.8601684570312, Norm: 0.0009300776291638613, InvBCE: 809.8235473632812\n",
      "Loss: 809.8599243164062, Norm: 0.0011621139710769057, InvBCE: 809.8235473632812\n",
      "Loss: 809.8597412109375, Norm: 0.0013939322670921683, InvBCE: 809.8235473632812\n",
      "Loss: 809.8594970703125, Norm: 0.0016255201771855354, InvBCE: 809.8235473632812\n",
      "Loss: 809.8593139648438, Norm: 0.0018568650120869279, InvBCE: 809.8235473632812\n",
      "Loss: 809.8590698242188, Norm: 0.0020879541989415884, InvBCE: 809.8235473632812\n",
      "Loss: 809.85888671875, Norm: 0.002318775048479438, InvBCE: 809.8235473632812\n",
      "Loss: 809.8587036132812, Norm: 0.0025493153370916843, InvBCE: 809.8235473632812\n",
      "Loss: 809.8584594726562, Norm: 0.0027795627247542143, InvBCE: 809.8235473632812\n",
      "Loss: 809.8582763671875, Norm: 0.0030095039401203394, InvBCE: 809.8235473632812\n",
      "Loss: 809.8580322265625, Norm: 0.0032391278073191643, InvBCE: 809.8235473632812\n",
      "Loss: 809.8578491210938, Norm: 0.0034684212878346443, InvBCE: 809.8235473632812\n",
      "Loss: 809.857666015625, Norm: 0.0036973722744733095, InvBCE: 809.8235473632812\n",
      "Loss: 809.857421875, Norm: 0.003925969824194908, InvBCE: 809.8235473632812\n",
      "Loss: 809.8572387695312, Norm: 0.004154201131314039, InvBCE: 809.8235473632812\n",
      "Loss: 809.8569946289062, Norm: 0.004382054787129164, InvBCE: 809.8235473632812\n",
      "Image 32...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 33...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 34...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 35...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 36...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 37...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 38...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 39...\n",
      "Loss: 72.98128509521484, Norm: 0.0, InvBCE: 72.94383239746094\n",
      "Loss: 46.08408737182617, Norm: 0.0003843815065920353, InvBCE: 46.04658126831055\n",
      "Loss: 32.78629684448242, Norm: 0.000742322881706059, InvBCE: 32.74873352050781\n",
      "Loss: 24.617408752441406, Norm: 0.001077656401321292, InvBCE: 24.579795837402344\n",
      "Loss: 19.725128173828125, Norm: 0.0013914385344833136, InvBCE: 19.68746566772461\n",
      "Loss: 16.54332160949707, Norm: 0.0016856665024533868, InvBCE: 16.505611419677734\n",
      "Loss: 14.422035217285156, Norm: 0.001962564652785659, InvBCE: 14.384281158447266\n",
      "Loss: 12.86168384552002, Norm: 0.002224019728600979, InvBCE: 12.82388687133789\n",
      "Loss: 11.653457641601562, Norm: 0.002471968298777938, InvBCE: 11.615620613098145\n",
      "Loss: 10.683114051818848, Norm: 0.0027080196887254715, InvBCE: 10.645237922668457\n",
      "Loss: 8.709017753601074, Norm: 0.002933422802016139, InvBCE: 8.67110538482666\n",
      "Loss: 8.126260757446289, Norm: 0.003149435855448246, InvBCE: 8.088312149047852\n",
      "Loss: 7.666654109954834, Norm: 0.003355486784130335, InvBCE: 7.628672122955322\n",
      "Loss: 7.273351192474365, Norm: 0.0035526002757251263, InvBCE: 7.235337734222412\n",
      "Loss: 6.933590412139893, Norm: 0.0037416713312268257, InvBCE: 6.8955464363098145\n",
      "Loss: 6.633247375488281, Norm: 0.003923483658581972, InvBCE: 6.595174789428711\n",
      "Loss: 6.361598968505859, Norm: 0.0040987515822052956, InvBCE: 6.3234992027282715\n",
      "Loss: 6.131810665130615, Norm: 0.004267985001206398, InvBCE: 6.093685150146484\n",
      "Loss: 5.9073896408081055, Norm: 0.004431800916790962, InvBCE: 5.869239807128906\n",
      "Loss: 5.703206539154053, Norm: 0.00459067290648818, InvBCE: 5.665033340454102\n",
      "Image 40...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 41...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 42...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 43...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 44...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 45...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 46...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 47...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 48...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 49...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 50...\n",
      "Loss: 6.874675750732422, Norm: 0.0, InvBCE: 6.837223052978516\n",
      "Loss: 5.713406562805176, Norm: 0.00038196725654415786, InvBCE: 5.675937175750732\n",
      "Loss: 4.862036228179932, Norm: 0.0007531616720370948, InvBCE: 4.824548244476318\n",
      "Loss: 4.227441787719727, Norm: 0.001112419762648642, InvBCE: 4.1899333000183105\n",
      "Loss: 3.746464490890503, Norm: 0.0014584700111299753, InvBCE: 3.7089335918426514\n",
      "Loss: 3.3400683403015137, Norm: 0.0017919117817655206, InvBCE: 3.302513599395752\n",
      "Loss: 2.9916229248046875, Norm: 0.0021140952594578266, InvBCE: 2.95404314994812\n",
      "Loss: 2.6898796558380127, Norm: 0.0024259877391159534, InvBCE: 2.652273654937744\n",
      "Loss: 2.410594940185547, Norm: 0.002726512961089611, InvBCE: 2.372962236404419\n",
      "Loss: 2.1516685485839844, Norm: 0.003019202733412385, InvBCE: 2.1140081882476807\n",
      "Loss: 1.9215281009674072, Norm: 0.0033044118899852037, InvBCE: 1.8838392496109009\n",
      "Loss: 1.7152602672576904, Norm: 0.003581922734156251, InvBCE: 1.6775423288345337\n",
      "Loss: 1.5298104286193848, Norm: 0.0038516235072165728, InvBCE: 1.492063045501709\n",
      "Loss: 1.3668485879898071, Norm: 0.0041131931357085705, InvBCE: 1.3290716409683228\n",
      "Loss: 1.2230404615402222, Norm: 0.004366306122392416, InvBCE: 1.1852339506149292\n",
      "Loss: 1.0948585271835327, Norm: 0.004610858391970396, InvBCE: 1.0570225715637207\n",
      "Loss: 0.9814375042915344, Norm: 0.004846720490604639, InvBCE: 0.9435725212097168\n",
      "Loss: 0.8834782242774963, Norm: 0.005073722917586565, InvBCE: 0.8455847501754761\n",
      "Loss: 0.7992496490478516, Norm: 0.005291688721626997, InvBCE: 0.761328399181366\n",
      "Loss: 0.7287654876708984, Norm: 0.005500452127307653, InvBCE: 0.6908174157142639\n",
      "Image 51...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 52...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 53...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 54...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 55...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 56...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 57...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 58...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 59...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 60...\n",
      "Loss: 630.2578125, Norm: 0.0, InvBCE: 630.2203369140625\n",
      "Loss: 294.43890380859375, Norm: 0.0003751915355678648, InvBCE: 294.40142822265625\n",
      "Loss: 205.86048889160156, Norm: 0.0007111579179763794, InvBCE: 205.822998046875\n",
      "Loss: 127.29917907714844, Norm: 0.000995049369521439, InvBCE: 127.26168060302734\n",
      "Loss: 87.0525894165039, Norm: 0.0012601095950230956, InvBCE: 87.01508331298828\n",
      "Loss: 64.68090057373047, Norm: 0.0015051922528073192, InvBCE: 64.64338684082031\n",
      "Loss: 51.09668731689453, Norm: 0.0017316206358373165, InvBCE: 51.05917739868164\n",
      "Loss: 42.111236572265625, Norm: 0.0019414193229749799, InvBCE: 42.073726654052734\n",
      "Loss: 36.45672607421875, Norm: 0.002136079827323556, InvBCE: 36.419219970703125\n",
      "Loss: 32.15752029418945, Norm: 0.0023177447728812695, InvBCE: 32.120018005371094\n",
      "Loss: 28.973976135253906, Norm: 0.0024879255797713995, InvBCE: 28.936481475830078\n",
      "Loss: 26.204933166503906, Norm: 0.002647911664098501, InvBCE: 26.16744613647461\n",
      "Loss: 24.398008346557617, Norm: 0.00279878918081522, InvBCE: 24.360530853271484\n",
      "Loss: 23.336881637573242, Norm: 0.0029415434692054987, InvBCE: 23.299413681030273\n",
      "Loss: 22.053970336914062, Norm: 0.0030771500896662474, InvBCE: 22.01651382446289\n",
      "Loss: 21.04062271118164, Norm: 0.003206353634595871, InvBCE: 21.003177642822266\n",
      "Loss: 20.176753997802734, Norm: 0.003329807659611106, InvBCE: 20.13932228088379\n",
      "Loss: 19.40626335144043, Norm: 0.0034481859765946865, InvBCE: 19.368844985961914\n",
      "Loss: 18.743093490600586, Norm: 0.0035619453992694616, InvBCE: 18.705690383911133\n",
      "Loss: 18.163227081298828, Norm: 0.0036715876776725054, InvBCE: 18.125839233398438\n",
      "Image 61...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 62...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 63...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 64...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 65...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 66...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 67...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 68...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 69...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 70...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 71...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 72...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 73...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 74...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 75...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 76...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 77...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 78...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 79...\n",
      "Loss: 809.8610229492188, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8607788085938, Norm: 0.00023278483422473073, InvBCE: 809.8235473632812\n",
      "Loss: 809.860595703125, Norm: 0.00046540083712898195, InvBCE: 809.8235473632812\n",
      "Loss: 809.8603515625, Norm: 0.0006978358142077923, InvBCE: 809.8235473632812\n",
      "Loss: 809.8601684570312, Norm: 0.0009300776291638613, InvBCE: 809.8235473632812\n",
      "Loss: 809.8599243164062, Norm: 0.0011621139710769057, InvBCE: 809.8235473632812\n",
      "Loss: 809.8597412109375, Norm: 0.0013939322670921683, InvBCE: 809.8235473632812\n",
      "Loss: 809.8594970703125, Norm: 0.0016255201771855354, InvBCE: 809.8235473632812\n",
      "Loss: 809.8593139648438, Norm: 0.0018568650120869279, InvBCE: 809.8235473632812\n",
      "Loss: 809.8590698242188, Norm: 0.0020879541989415884, InvBCE: 809.8235473632812\n",
      "Loss: 809.85888671875, Norm: 0.002318775048479438, InvBCE: 809.8235473632812\n",
      "Loss: 809.8587036132812, Norm: 0.0025493153370916843, InvBCE: 809.8235473632812\n",
      "Loss: 809.8584594726562, Norm: 0.0027795627247542143, InvBCE: 809.8235473632812\n",
      "Loss: 809.8582763671875, Norm: 0.0030095039401203394, InvBCE: 809.8235473632812\n",
      "Loss: 809.8580322265625, Norm: 0.0032391278073191643, InvBCE: 809.8235473632812\n",
      "Loss: 809.8578491210938, Norm: 0.0034684212878346443, InvBCE: 809.8235473632812\n",
      "Loss: 809.857666015625, Norm: 0.0036973722744733095, InvBCE: 809.8235473632812\n",
      "Loss: 809.857421875, Norm: 0.003925969824194908, InvBCE: 809.8235473632812\n",
      "Loss: 809.8572387695312, Norm: 0.004154201131314039, InvBCE: 809.8235473632812\n",
      "Loss: 809.8569946289062, Norm: 0.004382054787129164, InvBCE: 809.8235473632812\n",
      "Image 80...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 81...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 82...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 83...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 84...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 85...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 86...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 87...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 88...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 89...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 90...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 91...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 92...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 93...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 94...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 95...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 96...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 97...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 98...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 99...\n",
      "Image fooled! Adding perturbation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9843431b8ab9429481e1fc8f6cfd8e22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fooling rate: 0.94\n",
      "Starting epoch 31...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c8fcfecbdf14ac7bae1e830b38f98eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 1...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 2...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 3...\n",
      "Loss: 2.717554807662964, Norm: 0.0, InvBCE: 2.6801018714904785\n",
      "Loss: 2.407351493835449, Norm: 0.00038118421798571944, InvBCE: 2.3698573112487793\n",
      "Loss: 2.134324550628662, Norm: 0.0007559842779301107, InvBCE: 2.0967862606048584\n",
      "Loss: 1.8955780267715454, Norm: 0.0011244287015870214, InvBCE: 1.8579938411712646\n",
      "Loss: 1.6877946853637695, Norm: 0.0014857073547318578, InvBCE: 1.650162935256958\n",
      "Loss: 1.5075215101242065, Norm: 0.0018390374025329947, InvBCE: 1.4698407649993896\n",
      "Loss: 1.3513212203979492, Norm: 0.0021836247760802507, InvBCE: 1.313590407371521\n",
      "Loss: 1.2159942388534546, Norm: 0.0025187814608216286, InvBCE: 1.1782126426696777\n",
      "Loss: 1.0986416339874268, Norm: 0.0028439692687243223, InvBCE: 1.060808777809143\n",
      "Loss: 0.9967145323753357, Norm: 0.0031588065903633833, InvBCE: 0.9588302969932556\n",
      "Loss: 0.9080396294593811, Norm: 0.0034630452282726765, InvBCE: 0.8701043128967285\n",
      "Loss: 0.8308247327804565, Norm: 0.003756554564461112, InvBCE: 0.7928388714790344\n",
      "Loss: 0.7636405229568481, Norm: 0.004039280116558075, InvBCE: 0.7256050109863281\n",
      "Loss: 0.7053354978561401, Norm: 0.004311214666813612, InvBCE: 0.667251467704773\n",
      "Loss: 0.6549381613731384, Norm: 0.004572402220219374, InvBCE: 0.6168069243431091\n",
      "Loss: 0.6115550398826599, Norm: 0.004822922870516777, InvBCE: 0.5733780264854431\n",
      "Loss: 0.5743334293365479, Norm: 0.005062887445092201, InvBCE: 0.5361122488975525\n",
      "Loss: 0.5424706339836121, Norm: 0.005292464513331652, InvBCE: 0.5042068958282471\n",
      "Loss: 0.5152295231819153, Norm: 0.005511854775249958, InvBCE: 0.47692495584487915\n",
      "Loss: 0.4919421672821045, Norm: 0.005721298512071371, InvBCE: 0.4535984694957733\n",
      "Image 4...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 5...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 6...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 7...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 8...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 9...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 10...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 11...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 12...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 13...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 14...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 15...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 16...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 17...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 18...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 19...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 20...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 21...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 22...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 23...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 24...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 25...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 26...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 27...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 28...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 29...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 30...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 31...\n",
      "Loss: 809.8610229492188, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8607788085938, Norm: 0.00023278483422473073, InvBCE: 809.8235473632812\n",
      "Loss: 809.860595703125, Norm: 0.00046540083712898195, InvBCE: 809.8235473632812\n",
      "Loss: 809.8603515625, Norm: 0.0006978358142077923, InvBCE: 809.8235473632812\n",
      "Loss: 809.8601684570312, Norm: 0.0009300776291638613, InvBCE: 809.8235473632812\n",
      "Loss: 809.8599243164062, Norm: 0.0011621139710769057, InvBCE: 809.8235473632812\n",
      "Loss: 809.8597412109375, Norm: 0.0013939322670921683, InvBCE: 809.8235473632812\n",
      "Loss: 809.8594970703125, Norm: 0.0016255201771855354, InvBCE: 809.8235473632812\n",
      "Loss: 809.8593139648438, Norm: 0.0018568650120869279, InvBCE: 809.8235473632812\n",
      "Loss: 809.8590698242188, Norm: 0.0020879541989415884, InvBCE: 809.8235473632812\n",
      "Loss: 809.85888671875, Norm: 0.002318775048479438, InvBCE: 809.8235473632812\n",
      "Loss: 809.8587036132812, Norm: 0.0025493153370916843, InvBCE: 809.8235473632812\n",
      "Loss: 809.8584594726562, Norm: 0.0027795627247542143, InvBCE: 809.8235473632812\n",
      "Loss: 809.8582763671875, Norm: 0.0030095039401203394, InvBCE: 809.8235473632812\n",
      "Loss: 809.8580322265625, Norm: 0.0032391278073191643, InvBCE: 809.8235473632812\n",
      "Loss: 809.8578491210938, Norm: 0.0034684212878346443, InvBCE: 809.8235473632812\n",
      "Loss: 809.857666015625, Norm: 0.0036973722744733095, InvBCE: 809.8235473632812\n",
      "Loss: 809.857421875, Norm: 0.003925969824194908, InvBCE: 809.8235473632812\n",
      "Loss: 809.8572387695312, Norm: 0.004154201131314039, InvBCE: 809.8235473632812\n",
      "Loss: 809.8569946289062, Norm: 0.004382054787129164, InvBCE: 809.8235473632812\n",
      "Image 32...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 33...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 34...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 35...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 36...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 37...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 38...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 39...\n",
      "Loss: 72.98128509521484, Norm: 0.0, InvBCE: 72.94383239746094\n",
      "Loss: 46.08408737182617, Norm: 0.0003843815065920353, InvBCE: 46.04658126831055\n",
      "Loss: 32.78629684448242, Norm: 0.000742322881706059, InvBCE: 32.74873352050781\n",
      "Loss: 24.617408752441406, Norm: 0.001077656401321292, InvBCE: 24.579795837402344\n",
      "Loss: 19.725128173828125, Norm: 0.0013914385344833136, InvBCE: 19.68746566772461\n",
      "Loss: 16.54332160949707, Norm: 0.0016856665024533868, InvBCE: 16.505611419677734\n",
      "Loss: 14.422035217285156, Norm: 0.001962564652785659, InvBCE: 14.384281158447266\n",
      "Loss: 12.86168384552002, Norm: 0.002224019728600979, InvBCE: 12.82388687133789\n",
      "Loss: 11.653457641601562, Norm: 0.002471968298777938, InvBCE: 11.615620613098145\n",
      "Loss: 10.683114051818848, Norm: 0.0027080196887254715, InvBCE: 10.645237922668457\n",
      "Loss: 8.709017753601074, Norm: 0.002933422802016139, InvBCE: 8.67110538482666\n",
      "Loss: 8.126260757446289, Norm: 0.003149435855448246, InvBCE: 8.088312149047852\n",
      "Loss: 7.666654109954834, Norm: 0.003355486784130335, InvBCE: 7.628672122955322\n",
      "Loss: 7.273351192474365, Norm: 0.0035526002757251263, InvBCE: 7.235337734222412\n",
      "Loss: 6.933590412139893, Norm: 0.0037416713312268257, InvBCE: 6.8955464363098145\n",
      "Loss: 6.633247375488281, Norm: 0.003923483658581972, InvBCE: 6.595174789428711\n",
      "Loss: 6.361598968505859, Norm: 0.0040987515822052956, InvBCE: 6.3234992027282715\n",
      "Loss: 6.131810665130615, Norm: 0.004267985001206398, InvBCE: 6.093685150146484\n",
      "Loss: 5.9073896408081055, Norm: 0.004431800916790962, InvBCE: 5.869239807128906\n",
      "Loss: 5.703206539154053, Norm: 0.00459067290648818, InvBCE: 5.665033340454102\n",
      "Image 40...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 41...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 42...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 43...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 44...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 45...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 46...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 47...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 48...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 49...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 50...\n",
      "Loss: 6.874675750732422, Norm: 0.0, InvBCE: 6.837223052978516\n",
      "Loss: 5.713406562805176, Norm: 0.00038196725654415786, InvBCE: 5.675937175750732\n",
      "Loss: 4.862036228179932, Norm: 0.0007531616720370948, InvBCE: 4.824548244476318\n",
      "Loss: 4.227441787719727, Norm: 0.001112419762648642, InvBCE: 4.1899333000183105\n",
      "Loss: 3.746464490890503, Norm: 0.0014584700111299753, InvBCE: 3.7089335918426514\n",
      "Loss: 3.3400683403015137, Norm: 0.0017919117817655206, InvBCE: 3.302513599395752\n",
      "Loss: 2.9916229248046875, Norm: 0.0021140952594578266, InvBCE: 2.95404314994812\n",
      "Loss: 2.6898796558380127, Norm: 0.0024259877391159534, InvBCE: 2.652273654937744\n",
      "Loss: 2.410594940185547, Norm: 0.002726512961089611, InvBCE: 2.372962236404419\n",
      "Loss: 2.1516685485839844, Norm: 0.003019202733412385, InvBCE: 2.1140081882476807\n",
      "Loss: 1.9215281009674072, Norm: 0.0033044118899852037, InvBCE: 1.8838392496109009\n",
      "Loss: 1.7152602672576904, Norm: 0.003581922734156251, InvBCE: 1.6775423288345337\n",
      "Loss: 1.5298104286193848, Norm: 0.0038516235072165728, InvBCE: 1.492063045501709\n",
      "Loss: 1.3668485879898071, Norm: 0.0041131931357085705, InvBCE: 1.3290716409683228\n",
      "Loss: 1.2230404615402222, Norm: 0.004366306122392416, InvBCE: 1.1852339506149292\n",
      "Loss: 1.0948585271835327, Norm: 0.004610858391970396, InvBCE: 1.0570225715637207\n",
      "Loss: 0.9814375042915344, Norm: 0.004846720490604639, InvBCE: 0.9435725212097168\n",
      "Loss: 0.8834782242774963, Norm: 0.005073722917586565, InvBCE: 0.8455847501754761\n",
      "Loss: 0.7992496490478516, Norm: 0.005291688721626997, InvBCE: 0.761328399181366\n",
      "Loss: 0.7287654876708984, Norm: 0.005500452127307653, InvBCE: 0.6908174157142639\n",
      "Image 51...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 52...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 53...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 54...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 55...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 56...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 57...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 58...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 59...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 60...\n",
      "Loss: 630.2578125, Norm: 0.0, InvBCE: 630.2203369140625\n",
      "Loss: 294.43890380859375, Norm: 0.0003751915355678648, InvBCE: 294.40142822265625\n",
      "Loss: 205.86048889160156, Norm: 0.0007111579179763794, InvBCE: 205.822998046875\n",
      "Loss: 127.29917907714844, Norm: 0.000995049369521439, InvBCE: 127.26168060302734\n",
      "Loss: 87.0525894165039, Norm: 0.0012601095950230956, InvBCE: 87.01508331298828\n",
      "Loss: 64.68090057373047, Norm: 0.0015051922528073192, InvBCE: 64.64338684082031\n",
      "Loss: 51.09668731689453, Norm: 0.0017316206358373165, InvBCE: 51.05917739868164\n",
      "Loss: 42.111236572265625, Norm: 0.0019414193229749799, InvBCE: 42.073726654052734\n",
      "Loss: 36.45672607421875, Norm: 0.002136079827323556, InvBCE: 36.419219970703125\n",
      "Loss: 32.15752029418945, Norm: 0.0023177447728812695, InvBCE: 32.120018005371094\n",
      "Loss: 28.973976135253906, Norm: 0.0024879255797713995, InvBCE: 28.936481475830078\n",
      "Loss: 26.204933166503906, Norm: 0.002647911664098501, InvBCE: 26.16744613647461\n",
      "Loss: 24.398008346557617, Norm: 0.00279878918081522, InvBCE: 24.360530853271484\n",
      "Loss: 23.336881637573242, Norm: 0.0029415434692054987, InvBCE: 23.299413681030273\n",
      "Loss: 22.053970336914062, Norm: 0.0030771500896662474, InvBCE: 22.01651382446289\n",
      "Loss: 21.04062271118164, Norm: 0.003206353634595871, InvBCE: 21.003177642822266\n",
      "Loss: 20.176753997802734, Norm: 0.003329807659611106, InvBCE: 20.13932228088379\n",
      "Loss: 19.40626335144043, Norm: 0.0034481859765946865, InvBCE: 19.368844985961914\n",
      "Loss: 18.743093490600586, Norm: 0.0035619453992694616, InvBCE: 18.705690383911133\n",
      "Loss: 18.163227081298828, Norm: 0.0036715876776725054, InvBCE: 18.125839233398438\n",
      "Image 61...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 62...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 63...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 64...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 65...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 66...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 67...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 68...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 69...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 70...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 71...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 72...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 73...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 74...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 75...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 76...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 77...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 78...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 79...\n",
      "Loss: 809.8610229492188, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8607788085938, Norm: 0.00023278483422473073, InvBCE: 809.8235473632812\n",
      "Loss: 809.860595703125, Norm: 0.00046540083712898195, InvBCE: 809.8235473632812\n",
      "Loss: 809.8603515625, Norm: 0.0006978358142077923, InvBCE: 809.8235473632812\n",
      "Loss: 809.8601684570312, Norm: 0.0009300776291638613, InvBCE: 809.8235473632812\n",
      "Loss: 809.8599243164062, Norm: 0.0011621139710769057, InvBCE: 809.8235473632812\n",
      "Loss: 809.8597412109375, Norm: 0.0013939322670921683, InvBCE: 809.8235473632812\n",
      "Loss: 809.8594970703125, Norm: 0.0016255201771855354, InvBCE: 809.8235473632812\n",
      "Loss: 809.8593139648438, Norm: 0.0018568650120869279, InvBCE: 809.8235473632812\n",
      "Loss: 809.8590698242188, Norm: 0.0020879541989415884, InvBCE: 809.8235473632812\n",
      "Loss: 809.85888671875, Norm: 0.002318775048479438, InvBCE: 809.8235473632812\n",
      "Loss: 809.8587036132812, Norm: 0.0025493153370916843, InvBCE: 809.8235473632812\n",
      "Loss: 809.8584594726562, Norm: 0.0027795627247542143, InvBCE: 809.8235473632812\n",
      "Loss: 809.8582763671875, Norm: 0.0030095039401203394, InvBCE: 809.8235473632812\n",
      "Loss: 809.8580322265625, Norm: 0.0032391278073191643, InvBCE: 809.8235473632812\n",
      "Loss: 809.8578491210938, Norm: 0.0034684212878346443, InvBCE: 809.8235473632812\n",
      "Loss: 809.857666015625, Norm: 0.0036973722744733095, InvBCE: 809.8235473632812\n",
      "Loss: 809.857421875, Norm: 0.003925969824194908, InvBCE: 809.8235473632812\n",
      "Loss: 809.8572387695312, Norm: 0.004154201131314039, InvBCE: 809.8235473632812\n",
      "Loss: 809.8569946289062, Norm: 0.004382054787129164, InvBCE: 809.8235473632812\n",
      "Image 80...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 81...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 82...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 83...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 84...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 85...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 86...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 87...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 88...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 89...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 90...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 91...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 92...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 93...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 94...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 95...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 96...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 97...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 98...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 99...\n",
      "Image fooled! Adding perturbation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae04d987070046bca4b7be113e166600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fooling rate: 0.94\n",
      "Starting epoch 32...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3594ee644f8b45558376f1cd20ad63dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 1...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 2...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 3...\n",
      "Loss: 2.717554807662964, Norm: 0.0, InvBCE: 2.6801018714904785\n",
      "Loss: 2.407351493835449, Norm: 0.00038118421798571944, InvBCE: 2.3698573112487793\n",
      "Loss: 2.134324550628662, Norm: 0.0007559842779301107, InvBCE: 2.0967862606048584\n",
      "Loss: 1.8955780267715454, Norm: 0.0011244287015870214, InvBCE: 1.8579938411712646\n",
      "Loss: 1.6877946853637695, Norm: 0.0014857073547318578, InvBCE: 1.650162935256958\n",
      "Loss: 1.5075215101242065, Norm: 0.0018390374025329947, InvBCE: 1.4698407649993896\n",
      "Loss: 1.3513212203979492, Norm: 0.0021836247760802507, InvBCE: 1.313590407371521\n",
      "Loss: 1.2159942388534546, Norm: 0.0025187814608216286, InvBCE: 1.1782126426696777\n",
      "Loss: 1.0986416339874268, Norm: 0.0028439692687243223, InvBCE: 1.060808777809143\n",
      "Loss: 0.9967145323753357, Norm: 0.0031588065903633833, InvBCE: 0.9588302969932556\n",
      "Loss: 0.9080396294593811, Norm: 0.0034630452282726765, InvBCE: 0.8701043128967285\n",
      "Loss: 0.8308247327804565, Norm: 0.003756554564461112, InvBCE: 0.7928388714790344\n",
      "Loss: 0.7636405229568481, Norm: 0.004039280116558075, InvBCE: 0.7256050109863281\n",
      "Loss: 0.7053354978561401, Norm: 0.004311214666813612, InvBCE: 0.667251467704773\n",
      "Loss: 0.6549381613731384, Norm: 0.004572402220219374, InvBCE: 0.6168069243431091\n",
      "Loss: 0.6115550398826599, Norm: 0.004822922870516777, InvBCE: 0.5733780264854431\n",
      "Loss: 0.5743334293365479, Norm: 0.005062887445092201, InvBCE: 0.5361122488975525\n",
      "Loss: 0.5424706339836121, Norm: 0.005292464513331652, InvBCE: 0.5042068958282471\n",
      "Loss: 0.5152295231819153, Norm: 0.005511854775249958, InvBCE: 0.47692495584487915\n",
      "Loss: 0.4919421672821045, Norm: 0.005721298512071371, InvBCE: 0.4535984694957733\n",
      "Image 4...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 5...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 6...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 7...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 8...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 9...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 10...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 11...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 12...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 13...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 14...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 15...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 16...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 17...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 18...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 19...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 20...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 21...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 22...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 23...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 24...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 25...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 26...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 27...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 28...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 29...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 30...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 31...\n",
      "Loss: 809.8610229492188, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8607788085938, Norm: 0.00023278483422473073, InvBCE: 809.8235473632812\n",
      "Loss: 809.860595703125, Norm: 0.00046540083712898195, InvBCE: 809.8235473632812\n",
      "Loss: 809.8603515625, Norm: 0.0006978358142077923, InvBCE: 809.8235473632812\n",
      "Loss: 809.8601684570312, Norm: 0.0009300776291638613, InvBCE: 809.8235473632812\n",
      "Loss: 809.8599243164062, Norm: 0.0011621139710769057, InvBCE: 809.8235473632812\n",
      "Loss: 809.8597412109375, Norm: 0.0013939322670921683, InvBCE: 809.8235473632812\n",
      "Loss: 809.8594970703125, Norm: 0.0016255201771855354, InvBCE: 809.8235473632812\n",
      "Loss: 809.8593139648438, Norm: 0.0018568650120869279, InvBCE: 809.8235473632812\n",
      "Loss: 809.8590698242188, Norm: 0.0020879541989415884, InvBCE: 809.8235473632812\n",
      "Loss: 809.85888671875, Norm: 0.002318775048479438, InvBCE: 809.8235473632812\n",
      "Loss: 809.8587036132812, Norm: 0.0025493153370916843, InvBCE: 809.8235473632812\n",
      "Loss: 809.8584594726562, Norm: 0.0027795627247542143, InvBCE: 809.8235473632812\n",
      "Loss: 809.8582763671875, Norm: 0.0030095039401203394, InvBCE: 809.8235473632812\n",
      "Loss: 809.8580322265625, Norm: 0.0032391278073191643, InvBCE: 809.8235473632812\n",
      "Loss: 809.8578491210938, Norm: 0.0034684212878346443, InvBCE: 809.8235473632812\n",
      "Loss: 809.857666015625, Norm: 0.0036973722744733095, InvBCE: 809.8235473632812\n",
      "Loss: 809.857421875, Norm: 0.003925969824194908, InvBCE: 809.8235473632812\n",
      "Loss: 809.8572387695312, Norm: 0.004154201131314039, InvBCE: 809.8235473632812\n",
      "Loss: 809.8569946289062, Norm: 0.004382054787129164, InvBCE: 809.8235473632812\n",
      "Image 32...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 33...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 34...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 35...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 36...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 37...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 38...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 39...\n",
      "Loss: 72.98128509521484, Norm: 0.0, InvBCE: 72.94383239746094\n",
      "Loss: 46.08408737182617, Norm: 0.0003843815065920353, InvBCE: 46.04658126831055\n",
      "Loss: 32.78629684448242, Norm: 0.000742322881706059, InvBCE: 32.74873352050781\n",
      "Loss: 24.617408752441406, Norm: 0.001077656401321292, InvBCE: 24.579795837402344\n",
      "Loss: 19.725128173828125, Norm: 0.0013914385344833136, InvBCE: 19.68746566772461\n",
      "Loss: 16.54332160949707, Norm: 0.0016856665024533868, InvBCE: 16.505611419677734\n",
      "Loss: 14.422035217285156, Norm: 0.001962564652785659, InvBCE: 14.384281158447266\n",
      "Loss: 12.86168384552002, Norm: 0.002224019728600979, InvBCE: 12.82388687133789\n",
      "Loss: 11.653457641601562, Norm: 0.002471968298777938, InvBCE: 11.615620613098145\n",
      "Loss: 10.683114051818848, Norm: 0.0027080196887254715, InvBCE: 10.645237922668457\n",
      "Loss: 8.709017753601074, Norm: 0.002933422802016139, InvBCE: 8.67110538482666\n",
      "Loss: 8.126260757446289, Norm: 0.003149435855448246, InvBCE: 8.088312149047852\n",
      "Loss: 7.666654109954834, Norm: 0.003355486784130335, InvBCE: 7.628672122955322\n",
      "Loss: 7.273351192474365, Norm: 0.0035526002757251263, InvBCE: 7.235337734222412\n",
      "Loss: 6.933590412139893, Norm: 0.0037416713312268257, InvBCE: 6.8955464363098145\n",
      "Loss: 6.633247375488281, Norm: 0.003923483658581972, InvBCE: 6.595174789428711\n",
      "Loss: 6.361598968505859, Norm: 0.0040987515822052956, InvBCE: 6.3234992027282715\n",
      "Loss: 6.131810665130615, Norm: 0.004267985001206398, InvBCE: 6.093685150146484\n",
      "Loss: 5.9073896408081055, Norm: 0.004431800916790962, InvBCE: 5.869239807128906\n",
      "Loss: 5.703206539154053, Norm: 0.00459067290648818, InvBCE: 5.665033340454102\n",
      "Image 40...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 41...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 42...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 43...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 44...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 45...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 46...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 47...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 48...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 49...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 50...\n",
      "Loss: 6.874675750732422, Norm: 0.0, InvBCE: 6.837223052978516\n",
      "Loss: 5.713406562805176, Norm: 0.00038196725654415786, InvBCE: 5.675937175750732\n",
      "Loss: 4.862036228179932, Norm: 0.0007531616720370948, InvBCE: 4.824548244476318\n",
      "Loss: 4.227441787719727, Norm: 0.001112419762648642, InvBCE: 4.1899333000183105\n",
      "Loss: 3.746464490890503, Norm: 0.0014584700111299753, InvBCE: 3.7089335918426514\n",
      "Loss: 3.3400683403015137, Norm: 0.0017919117817655206, InvBCE: 3.302513599395752\n",
      "Loss: 2.9916229248046875, Norm: 0.0021140952594578266, InvBCE: 2.95404314994812\n",
      "Loss: 2.6898796558380127, Norm: 0.0024259877391159534, InvBCE: 2.652273654937744\n",
      "Loss: 2.410594940185547, Norm: 0.002726512961089611, InvBCE: 2.372962236404419\n",
      "Loss: 2.1516685485839844, Norm: 0.003019202733412385, InvBCE: 2.1140081882476807\n",
      "Loss: 1.9215281009674072, Norm: 0.0033044118899852037, InvBCE: 1.8838392496109009\n",
      "Loss: 1.7152602672576904, Norm: 0.003581922734156251, InvBCE: 1.6775423288345337\n",
      "Loss: 1.5298104286193848, Norm: 0.0038516235072165728, InvBCE: 1.492063045501709\n",
      "Loss: 1.3668485879898071, Norm: 0.0041131931357085705, InvBCE: 1.3290716409683228\n",
      "Loss: 1.2230404615402222, Norm: 0.004366306122392416, InvBCE: 1.1852339506149292\n",
      "Loss: 1.0948585271835327, Norm: 0.004610858391970396, InvBCE: 1.0570225715637207\n",
      "Loss: 0.9814375042915344, Norm: 0.004846720490604639, InvBCE: 0.9435725212097168\n",
      "Loss: 0.8834782242774963, Norm: 0.005073722917586565, InvBCE: 0.8455847501754761\n",
      "Loss: 0.7992496490478516, Norm: 0.005291688721626997, InvBCE: 0.761328399181366\n",
      "Loss: 0.7287654876708984, Norm: 0.005500452127307653, InvBCE: 0.6908174157142639\n",
      "Image 51...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 52...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 53...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 54...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 55...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 56...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 57...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 58...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 59...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 60...\n",
      "Loss: 630.2578125, Norm: 0.0, InvBCE: 630.2203369140625\n",
      "Loss: 294.43890380859375, Norm: 0.0003751915355678648, InvBCE: 294.40142822265625\n",
      "Loss: 205.86048889160156, Norm: 0.0007111579179763794, InvBCE: 205.822998046875\n",
      "Loss: 127.29917907714844, Norm: 0.000995049369521439, InvBCE: 127.26168060302734\n",
      "Loss: 87.0525894165039, Norm: 0.0012601095950230956, InvBCE: 87.01508331298828\n",
      "Loss: 64.68090057373047, Norm: 0.0015051922528073192, InvBCE: 64.64338684082031\n",
      "Loss: 51.09668731689453, Norm: 0.0017316206358373165, InvBCE: 51.05917739868164\n",
      "Loss: 42.111236572265625, Norm: 0.0019414193229749799, InvBCE: 42.073726654052734\n",
      "Loss: 36.45672607421875, Norm: 0.002136079827323556, InvBCE: 36.419219970703125\n",
      "Loss: 32.15752029418945, Norm: 0.0023177447728812695, InvBCE: 32.120018005371094\n",
      "Loss: 28.973976135253906, Norm: 0.0024879255797713995, InvBCE: 28.936481475830078\n",
      "Loss: 26.204933166503906, Norm: 0.002647911664098501, InvBCE: 26.16744613647461\n",
      "Loss: 24.398008346557617, Norm: 0.00279878918081522, InvBCE: 24.360530853271484\n",
      "Loss: 23.336881637573242, Norm: 0.0029415434692054987, InvBCE: 23.299413681030273\n",
      "Loss: 22.053970336914062, Norm: 0.0030771500896662474, InvBCE: 22.01651382446289\n",
      "Loss: 21.04062271118164, Norm: 0.003206353634595871, InvBCE: 21.003177642822266\n",
      "Loss: 20.176753997802734, Norm: 0.003329807659611106, InvBCE: 20.13932228088379\n",
      "Loss: 19.40626335144043, Norm: 0.0034481859765946865, InvBCE: 19.368844985961914\n",
      "Loss: 18.743093490600586, Norm: 0.0035619453992694616, InvBCE: 18.705690383911133\n",
      "Loss: 18.163227081298828, Norm: 0.0036715876776725054, InvBCE: 18.125839233398438\n",
      "Image 61...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 62...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 63...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 64...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 65...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 66...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 67...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 68...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 69...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 70...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 71...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 72...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 73...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 74...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 75...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 76...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 77...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 78...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 79...\n",
      "Loss: 809.8610229492188, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8607788085938, Norm: 0.00023278483422473073, InvBCE: 809.8235473632812\n",
      "Loss: 809.860595703125, Norm: 0.00046540083712898195, InvBCE: 809.8235473632812\n",
      "Loss: 809.8603515625, Norm: 0.0006978358142077923, InvBCE: 809.8235473632812\n",
      "Loss: 809.8601684570312, Norm: 0.0009300776291638613, InvBCE: 809.8235473632812\n",
      "Loss: 809.8599243164062, Norm: 0.0011621139710769057, InvBCE: 809.8235473632812\n",
      "Loss: 809.8597412109375, Norm: 0.0013939322670921683, InvBCE: 809.8235473632812\n",
      "Loss: 809.8594970703125, Norm: 0.0016255201771855354, InvBCE: 809.8235473632812\n",
      "Loss: 809.8593139648438, Norm: 0.0018568650120869279, InvBCE: 809.8235473632812\n",
      "Loss: 809.8590698242188, Norm: 0.0020879541989415884, InvBCE: 809.8235473632812\n",
      "Loss: 809.85888671875, Norm: 0.002318775048479438, InvBCE: 809.8235473632812\n",
      "Loss: 809.8587036132812, Norm: 0.0025493153370916843, InvBCE: 809.8235473632812\n",
      "Loss: 809.8584594726562, Norm: 0.0027795627247542143, InvBCE: 809.8235473632812\n",
      "Loss: 809.8582763671875, Norm: 0.0030095039401203394, InvBCE: 809.8235473632812\n",
      "Loss: 809.8580322265625, Norm: 0.0032391278073191643, InvBCE: 809.8235473632812\n",
      "Loss: 809.8578491210938, Norm: 0.0034684212878346443, InvBCE: 809.8235473632812\n",
      "Loss: 809.857666015625, Norm: 0.0036973722744733095, InvBCE: 809.8235473632812\n",
      "Loss: 809.857421875, Norm: 0.003925969824194908, InvBCE: 809.8235473632812\n",
      "Loss: 809.8572387695312, Norm: 0.004154201131314039, InvBCE: 809.8235473632812\n",
      "Loss: 809.8569946289062, Norm: 0.004382054787129164, InvBCE: 809.8235473632812\n",
      "Image 80...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 81...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 82...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 83...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 84...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 85...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 86...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 87...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 88...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 89...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 90...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 91...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 92...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 93...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 94...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 95...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 96...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 97...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 98...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 99...\n",
      "Image fooled! Adding perturbation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c18967662af54b118baecdd5607f5de6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fooling rate: 0.94\n",
      "Starting epoch 33...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f216978d8024605a94c9847c5b510dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 1...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 2...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 3...\n",
      "Loss: 2.717554807662964, Norm: 0.0, InvBCE: 2.6801018714904785\n",
      "Loss: 2.407351493835449, Norm: 0.00038118421798571944, InvBCE: 2.3698573112487793\n",
      "Loss: 2.134324550628662, Norm: 0.0007559842779301107, InvBCE: 2.0967862606048584\n",
      "Loss: 1.8955780267715454, Norm: 0.0011244287015870214, InvBCE: 1.8579938411712646\n",
      "Loss: 1.6877946853637695, Norm: 0.0014857073547318578, InvBCE: 1.650162935256958\n",
      "Loss: 1.5075215101242065, Norm: 0.0018390374025329947, InvBCE: 1.4698407649993896\n",
      "Loss: 1.3513212203979492, Norm: 0.0021836247760802507, InvBCE: 1.313590407371521\n",
      "Loss: 1.2159942388534546, Norm: 0.0025187814608216286, InvBCE: 1.1782126426696777\n",
      "Loss: 1.0986416339874268, Norm: 0.0028439692687243223, InvBCE: 1.060808777809143\n",
      "Loss: 0.9967145323753357, Norm: 0.0031588065903633833, InvBCE: 0.9588302969932556\n",
      "Loss: 0.9080396294593811, Norm: 0.0034630452282726765, InvBCE: 0.8701043128967285\n",
      "Loss: 0.8308247327804565, Norm: 0.003756554564461112, InvBCE: 0.7928388714790344\n",
      "Loss: 0.7636405229568481, Norm: 0.004039280116558075, InvBCE: 0.7256050109863281\n",
      "Loss: 0.7053354978561401, Norm: 0.004311214666813612, InvBCE: 0.667251467704773\n",
      "Loss: 0.6549381613731384, Norm: 0.004572402220219374, InvBCE: 0.6168069243431091\n",
      "Loss: 0.6115550398826599, Norm: 0.004822922870516777, InvBCE: 0.5733780264854431\n",
      "Loss: 0.5743334293365479, Norm: 0.005062887445092201, InvBCE: 0.5361122488975525\n",
      "Loss: 0.5424706339836121, Norm: 0.005292464513331652, InvBCE: 0.5042068958282471\n",
      "Loss: 0.5152295231819153, Norm: 0.005511854775249958, InvBCE: 0.47692495584487915\n",
      "Loss: 0.4919421672821045, Norm: 0.005721298512071371, InvBCE: 0.4535984694957733\n",
      "Image 4...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 5...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 6...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 7...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 8...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 9...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 10...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 11...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 12...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 13...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 14...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 15...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 16...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 17...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 18...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 19...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 20...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 21...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 22...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 23...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 24...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 25...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 26...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 27...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 28...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 29...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 30...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 31...\n",
      "Loss: 809.8610229492188, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8607788085938, Norm: 0.00023278483422473073, InvBCE: 809.8235473632812\n",
      "Loss: 809.860595703125, Norm: 0.00046540083712898195, InvBCE: 809.8235473632812\n",
      "Loss: 809.8603515625, Norm: 0.0006978358142077923, InvBCE: 809.8235473632812\n",
      "Loss: 809.8601684570312, Norm: 0.0009300776291638613, InvBCE: 809.8235473632812\n",
      "Loss: 809.8599243164062, Norm: 0.0011621139710769057, InvBCE: 809.8235473632812\n",
      "Loss: 809.8597412109375, Norm: 0.0013939322670921683, InvBCE: 809.8235473632812\n",
      "Loss: 809.8594970703125, Norm: 0.0016255201771855354, InvBCE: 809.8235473632812\n",
      "Loss: 809.8593139648438, Norm: 0.0018568650120869279, InvBCE: 809.8235473632812\n",
      "Loss: 809.8590698242188, Norm: 0.0020879541989415884, InvBCE: 809.8235473632812\n",
      "Loss: 809.85888671875, Norm: 0.002318775048479438, InvBCE: 809.8235473632812\n",
      "Loss: 809.8587036132812, Norm: 0.0025493153370916843, InvBCE: 809.8235473632812\n",
      "Loss: 809.8584594726562, Norm: 0.0027795627247542143, InvBCE: 809.8235473632812\n",
      "Loss: 809.8582763671875, Norm: 0.0030095039401203394, InvBCE: 809.8235473632812\n",
      "Loss: 809.8580322265625, Norm: 0.0032391278073191643, InvBCE: 809.8235473632812\n",
      "Loss: 809.8578491210938, Norm: 0.0034684212878346443, InvBCE: 809.8235473632812\n",
      "Loss: 809.857666015625, Norm: 0.0036973722744733095, InvBCE: 809.8235473632812\n",
      "Loss: 809.857421875, Norm: 0.003925969824194908, InvBCE: 809.8235473632812\n",
      "Loss: 809.8572387695312, Norm: 0.004154201131314039, InvBCE: 809.8235473632812\n",
      "Loss: 809.8569946289062, Norm: 0.004382054787129164, InvBCE: 809.8235473632812\n",
      "Image 32...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 33...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 34...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 35...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 36...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 37...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 38...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 39...\n",
      "Loss: 72.98128509521484, Norm: 0.0, InvBCE: 72.94383239746094\n",
      "Loss: 46.08408737182617, Norm: 0.0003843815065920353, InvBCE: 46.04658126831055\n",
      "Loss: 32.78629684448242, Norm: 0.000742322881706059, InvBCE: 32.74873352050781\n",
      "Loss: 24.617408752441406, Norm: 0.001077656401321292, InvBCE: 24.579795837402344\n",
      "Loss: 19.725128173828125, Norm: 0.0013914385344833136, InvBCE: 19.68746566772461\n",
      "Loss: 16.54332160949707, Norm: 0.0016856665024533868, InvBCE: 16.505611419677734\n",
      "Loss: 14.422035217285156, Norm: 0.001962564652785659, InvBCE: 14.384281158447266\n",
      "Loss: 12.86168384552002, Norm: 0.002224019728600979, InvBCE: 12.82388687133789\n",
      "Loss: 11.653457641601562, Norm: 0.002471968298777938, InvBCE: 11.615620613098145\n",
      "Loss: 10.683114051818848, Norm: 0.0027080196887254715, InvBCE: 10.645237922668457\n",
      "Loss: 8.709017753601074, Norm: 0.002933422802016139, InvBCE: 8.67110538482666\n",
      "Loss: 8.126260757446289, Norm: 0.003149435855448246, InvBCE: 8.088312149047852\n",
      "Loss: 7.666654109954834, Norm: 0.003355486784130335, InvBCE: 7.628672122955322\n",
      "Loss: 7.273351192474365, Norm: 0.0035526002757251263, InvBCE: 7.235337734222412\n",
      "Loss: 6.933590412139893, Norm: 0.0037416713312268257, InvBCE: 6.8955464363098145\n",
      "Loss: 6.633247375488281, Norm: 0.003923483658581972, InvBCE: 6.595174789428711\n",
      "Loss: 6.361598968505859, Norm: 0.0040987515822052956, InvBCE: 6.3234992027282715\n",
      "Loss: 6.131810665130615, Norm: 0.004267985001206398, InvBCE: 6.093685150146484\n",
      "Loss: 5.9073896408081055, Norm: 0.004431800916790962, InvBCE: 5.869239807128906\n",
      "Loss: 5.703206539154053, Norm: 0.00459067290648818, InvBCE: 5.665033340454102\n",
      "Image 40...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 41...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 42...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 43...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 44...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 45...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 46...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 47...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 48...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 49...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 50...\n",
      "Loss: 6.874675750732422, Norm: 0.0, InvBCE: 6.837223052978516\n",
      "Loss: 5.713406562805176, Norm: 0.00038196725654415786, InvBCE: 5.675937175750732\n",
      "Loss: 4.862036228179932, Norm: 0.0007531616720370948, InvBCE: 4.824548244476318\n",
      "Loss: 4.227441787719727, Norm: 0.001112419762648642, InvBCE: 4.1899333000183105\n",
      "Loss: 3.746464490890503, Norm: 0.0014584700111299753, InvBCE: 3.7089335918426514\n",
      "Loss: 3.3400683403015137, Norm: 0.0017919117817655206, InvBCE: 3.302513599395752\n",
      "Loss: 2.9916229248046875, Norm: 0.0021140952594578266, InvBCE: 2.95404314994812\n",
      "Loss: 2.6898796558380127, Norm: 0.0024259877391159534, InvBCE: 2.652273654937744\n",
      "Loss: 2.410594940185547, Norm: 0.002726512961089611, InvBCE: 2.372962236404419\n",
      "Loss: 2.1516685485839844, Norm: 0.003019202733412385, InvBCE: 2.1140081882476807\n",
      "Loss: 1.9215281009674072, Norm: 0.0033044118899852037, InvBCE: 1.8838392496109009\n",
      "Loss: 1.7152602672576904, Norm: 0.003581922734156251, InvBCE: 1.6775423288345337\n",
      "Loss: 1.5298104286193848, Norm: 0.0038516235072165728, InvBCE: 1.492063045501709\n",
      "Loss: 1.3668485879898071, Norm: 0.0041131931357085705, InvBCE: 1.3290716409683228\n",
      "Loss: 1.2230404615402222, Norm: 0.004366306122392416, InvBCE: 1.1852339506149292\n",
      "Loss: 1.0948585271835327, Norm: 0.004610858391970396, InvBCE: 1.0570225715637207\n",
      "Loss: 0.9814375042915344, Norm: 0.004846720490604639, InvBCE: 0.9435725212097168\n",
      "Loss: 0.8834782242774963, Norm: 0.005073722917586565, InvBCE: 0.8455847501754761\n",
      "Loss: 0.7992496490478516, Norm: 0.005291688721626997, InvBCE: 0.761328399181366\n",
      "Loss: 0.7287654876708984, Norm: 0.005500452127307653, InvBCE: 0.6908174157142639\n",
      "Image 51...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 52...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 53...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 54...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 55...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 56...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 57...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 58...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 59...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 60...\n",
      "Loss: 630.2578125, Norm: 0.0, InvBCE: 630.2203369140625\n",
      "Loss: 294.43890380859375, Norm: 0.0003751915355678648, InvBCE: 294.40142822265625\n",
      "Loss: 205.86048889160156, Norm: 0.0007111579179763794, InvBCE: 205.822998046875\n",
      "Loss: 127.29917907714844, Norm: 0.000995049369521439, InvBCE: 127.26168060302734\n",
      "Loss: 87.0525894165039, Norm: 0.0012601095950230956, InvBCE: 87.01508331298828\n",
      "Loss: 64.68090057373047, Norm: 0.0015051922528073192, InvBCE: 64.64338684082031\n",
      "Loss: 51.09668731689453, Norm: 0.0017316206358373165, InvBCE: 51.05917739868164\n",
      "Loss: 42.111236572265625, Norm: 0.0019414193229749799, InvBCE: 42.073726654052734\n",
      "Loss: 36.45672607421875, Norm: 0.002136079827323556, InvBCE: 36.419219970703125\n",
      "Loss: 32.15752029418945, Norm: 0.0023177447728812695, InvBCE: 32.120018005371094\n",
      "Loss: 28.973976135253906, Norm: 0.0024879255797713995, InvBCE: 28.936481475830078\n",
      "Loss: 26.204933166503906, Norm: 0.002647911664098501, InvBCE: 26.16744613647461\n",
      "Loss: 24.398008346557617, Norm: 0.00279878918081522, InvBCE: 24.360530853271484\n",
      "Loss: 23.336881637573242, Norm: 0.0029415434692054987, InvBCE: 23.299413681030273\n",
      "Loss: 22.053970336914062, Norm: 0.0030771500896662474, InvBCE: 22.01651382446289\n",
      "Loss: 21.04062271118164, Norm: 0.003206353634595871, InvBCE: 21.003177642822266\n",
      "Loss: 20.176753997802734, Norm: 0.003329807659611106, InvBCE: 20.13932228088379\n",
      "Loss: 19.40626335144043, Norm: 0.0034481859765946865, InvBCE: 19.368844985961914\n",
      "Loss: 18.743093490600586, Norm: 0.0035619453992694616, InvBCE: 18.705690383911133\n",
      "Loss: 18.163227081298828, Norm: 0.0036715876776725054, InvBCE: 18.125839233398438\n",
      "Image 61...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 62...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 63...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 64...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 65...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 66...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 67...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 68...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 69...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 70...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 71...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 72...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 73...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 74...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 75...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 76...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 77...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 78...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 79...\n",
      "Loss: 809.8610229492188, Norm: 0.0, InvBCE: 809.8235473632812\n",
      "Loss: 809.8607788085938, Norm: 0.00023278483422473073, InvBCE: 809.8235473632812\n",
      "Loss: 809.860595703125, Norm: 0.00046540083712898195, InvBCE: 809.8235473632812\n",
      "Loss: 809.8603515625, Norm: 0.0006978358142077923, InvBCE: 809.8235473632812\n",
      "Loss: 809.8601684570312, Norm: 0.0009300776291638613, InvBCE: 809.8235473632812\n",
      "Loss: 809.8599243164062, Norm: 0.0011621139710769057, InvBCE: 809.8235473632812\n",
      "Loss: 809.8597412109375, Norm: 0.0013939322670921683, InvBCE: 809.8235473632812\n",
      "Loss: 809.8594970703125, Norm: 0.0016255201771855354, InvBCE: 809.8235473632812\n",
      "Loss: 809.8593139648438, Norm: 0.0018568650120869279, InvBCE: 809.8235473632812\n",
      "Loss: 809.8590698242188, Norm: 0.0020879541989415884, InvBCE: 809.8235473632812\n",
      "Loss: 809.85888671875, Norm: 0.002318775048479438, InvBCE: 809.8235473632812\n",
      "Loss: 809.8587036132812, Norm: 0.0025493153370916843, InvBCE: 809.8235473632812\n",
      "Loss: 809.8584594726562, Norm: 0.0027795627247542143, InvBCE: 809.8235473632812\n",
      "Loss: 809.8582763671875, Norm: 0.0030095039401203394, InvBCE: 809.8235473632812\n",
      "Loss: 809.8580322265625, Norm: 0.0032391278073191643, InvBCE: 809.8235473632812\n",
      "Loss: 809.8578491210938, Norm: 0.0034684212878346443, InvBCE: 809.8235473632812\n",
      "Loss: 809.857666015625, Norm: 0.0036973722744733095, InvBCE: 809.8235473632812\n",
      "Loss: 809.857421875, Norm: 0.003925969824194908, InvBCE: 809.8235473632812\n",
      "Loss: 809.8572387695312, Norm: 0.004154201131314039, InvBCE: 809.8235473632812\n",
      "Loss: 809.8569946289062, Norm: 0.004382054787129164, InvBCE: 809.8235473632812\n",
      "Image 80...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 81...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 82...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 83...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 84...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 85...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 86...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 87...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 88...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 89...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 90...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 91...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 92...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 93...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 94...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 95...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 96...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 97...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 98...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 99...\n",
      "Image fooled! Adding perturbation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4a11ea77fe445e4917cdec1069d23dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fooling rate: 0.94\n",
      "Starting epoch 34...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14bb33bb883142ff83fee8be8f23c6e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 0...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 1...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 2...\n",
      "Image fooled! Adding perturbation...\n",
      "Image 3...\n",
      "Loss: 2.717554807662964, Norm: 0.0, InvBCE: 2.6801018714904785\n",
      "Loss: 2.407351493835449, Norm: 0.00038118421798571944, InvBCE: 2.3698573112487793\n",
      "Loss: 2.134324550628662, Norm: 0.0007559842779301107, InvBCE: 2.0967862606048584\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m modelname, dataset \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m---\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodelname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m perturbations \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_adversarial_images_from_model_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodelname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_universal_pertubation_images\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_pertubation_images\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdesired_fooling_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnorm_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnorm_alpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.00001\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter_image\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_WORKERS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Nextcloud/Development/BAT/main/src/utils/uap_helper.py:215\u001b[0m, in \u001b[0;36mgenerate_adversarial_images_from_model_dataset\u001b[0;34m(modelname, dataset, transform, num_universal_pertubation_images, num_pertubation_images, desired_fooling_rate, norm_p, norm_alpha, max_iter_image, seed, eps, verbose, num_workers, device)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m trange(num_universal_pertubation_images, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUniversal Pertubation\u001b[39m\u001b[38;5;124m\"\u001b[39m, position\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    214\u001b[0m     dataloader \u001b[38;5;241m=\u001b[39m get_datamodule(dataset, transform\u001b[38;5;241m=\u001b[39mtransform, seed\u001b[38;5;241m=\u001b[39mseed \u001b[38;5;241m+\u001b[39m i, num_workers\u001b[38;5;241m=\u001b[39mnum_workers)\n\u001b[0;32m--> 215\u001b[0m     v \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_adversarial_image\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_pertubation_images\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_pertubation_images\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdesired_fooling_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdesired_fooling_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnorm_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnorm_alpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm_alpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iter_image\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_iter_image\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     perturbations\u001b[38;5;241m.\u001b[39mappend(v)\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack(perturbations, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/Nextcloud/Development/BAT/main/src/utils/uap_helper.py:167\u001b[0m, in \u001b[0;36mgenerate_adversarial_image\u001b[0;34m(model, dataloader, num_pertubation_images, desired_fooling_rate, norm_p, norm_alpha, max_iter_image, eps, verbose, device)\u001b[0m\n\u001b[1;32m    164\u001b[0m     image \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# fool the image\u001b[39;00m\n\u001b[0;32m--> 167\u001b[0m     v \u001b[38;5;241m=\u001b[39m \u001b[43mfool_image\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnorm_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnorm_alpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm_alpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iter_image\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_iter_image\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     n_image \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;66;03m# calculate fooling rate\u001b[39;00m\n",
      "File \u001b[0;32m~/Nextcloud/Development/BAT/main/src/utils/uap_helper.py:88\u001b[0m, in \u001b[0;36mfool_image\u001b[0;34m(model, image, v, norm_p, norm_alpha, max_iter_image, eps, verbose, device)\u001b[0m\n\u001b[1;32m     85\u001b[0m x_adv \u001b[38;5;241m=\u001b[39m image \u001b[38;5;241m+\u001b[39m v \u001b[38;5;241m+\u001b[39m v_temp\n\u001b[1;32m     86\u001b[0m x_adv \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp(x_adv, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\n\u001b[0;32m---> 88\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msigmoid()\n\u001b[1;32m     89\u001b[0m y_adv \u001b[38;5;241m=\u001b[39m model(x_adv)\u001b[38;5;241m.\u001b[39msigmoid()\n\u001b[1;32m     91\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_bce_inv_f(y_pred, y_adv) \u001b[38;5;241m+\u001b[39m norm_alpha \u001b[38;5;241m*\u001b[39m norm_f(v \u001b[38;5;241m+\u001b[39m v_temp)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Nextcloud/Development/BAT/main/src/models/imageclassifier.py:125\u001b[0m, in \u001b[0;36mImageClassifier.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresize:\n\u001b[1;32m    123\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresize(x)\n\u001b[0;32m--> 125\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp(y_hat, \u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m9\u001b[39m, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9\u001b[39m)\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y_hat\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torchvision/models/efficientnet.py:343\u001b[0m, in \u001b[0;36mEfficientNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torchvision/models/efficientnet.py:333\u001b[0m, in \u001b[0;36mEfficientNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 333\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n\u001b[1;32m    336\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torchvision/models/efficientnet.py:164\u001b[0m, in \u001b[0;36mMBConv.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 164\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_res_connect:\n\u001b[1;32m    166\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstochastic_depth(result)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/modules/activation.py:393\u001b[0m, in \u001b[0;36mSiLU.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 393\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msilu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/nn/functional.py:2053\u001b[0m, in \u001b[0;36msilu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   2008\u001b[0m linear \u001b[38;5;241m=\u001b[39m _add_docstr(\n\u001b[1;32m   2009\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mlinear,\n\u001b[1;32m   2010\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2027\u001b[0m \u001b[38;5;124;03m    - Output: :math:`(*, out\\_features)` or :math:`(*)`, based on the shape of the weight\u001b[39;00m\n\u001b[1;32m   2028\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msparse_support_notes))\n\u001b[1;32m   2031\u001b[0m bilinear \u001b[38;5;241m=\u001b[39m _add_docstr(\n\u001b[1;32m   2032\u001b[0m     torch\u001b[38;5;241m.\u001b[39mbilinear,\n\u001b[1;32m   2033\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2049\u001b[0m \u001b[38;5;124;03m      and all but the last dimension are the same shape as the input.\u001b[39;00m\n\u001b[1;32m   2050\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m)\n\u001b[0;32m-> 2053\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msilu\u001b[39m(\u001b[38;5;28minput\u001b[39m: Tensor, inplace: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m   2054\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Apply the Sigmoid Linear Unit (SiLU) function, element-wise.\u001b[39;00m\n\u001b[1;32m   2055\u001b[0m \n\u001b[1;32m   2056\u001b[0m \u001b[38;5;124;03m    The SiLU function is also known as the swish function.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2069\u001b[0m \u001b[38;5;124;03m    See :class:`~torch.nn.SiLU` for more details.\u001b[39;00m\n\u001b[1;32m   2070\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   2071\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28minput\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for model in tqdm(models, desc=\"Model\", position=0, total=len(models)):\n",
    "    modelname, dataset = model.split(\"-\")\n",
    "    print(f\"\\n---\\nModel: {modelname} - Dataset: {dataset}\")\n",
    "\n",
    "    perturbations = generate_adversarial_images_from_model_dataset(\n",
    "        modelname,\n",
    "        dataset,\n",
    "        transform,\n",
    "        num_universal_pertubation_images=1,\n",
    "        num_pertubation_images=100,\n",
    "        desired_fooling_rate=1,\n",
    "        norm_p=2,\n",
    "        norm_alpha=0.00001,\n",
    "        max_iter_image=20,\n",
    "        seed=42,\n",
    "        eps=1e-6,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        device=device,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'perturbations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m v \u001b[38;5;241m=\u001b[39m \u001b[43mperturbations\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m      6\u001b[0m get_datamodule(dataset, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\u001b[38;5;241m.\u001b[39msetup()\n\u001b[1;32m      7\u001b[0m image, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(get_datamodule(dataset)\u001b[38;5;241m.\u001b[39mtrain_dataloader()))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'perturbations' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "v = perturbations[0].detach()\n",
    "get_datamodule(dataset, seed=42).setup()\n",
    "image, _ = next(iter(get_datamodule(dataset).train_dataloader()))\n",
    "\n",
    "# Prepare subplots in one row\n",
    "fig, axs = plt.subplots(1, 4, figsize=(20, 5))  # Adjust figsize to ensure each subplot is visually proportional\n",
    "\n",
    "# Original Image\n",
    "axs[0].imshow(image.cpu().squeeze().permute(1, 2, 0).numpy().astype(int))\n",
    "axs[0].set_title(\"Original Image\", fontsize=16)\n",
    "axs[0].axis(\"off\")  # Hide axes for cleaner look\n",
    "\n",
    "# Perturbed Image\n",
    "x_adv = image + v.cpu()\n",
    "x_adv = torch.clamp(x_adv, 0, 255)\n",
    "axs[1].imshow(x_adv.cpu().squeeze().permute(1, 2, 0).numpy().astype(int))\n",
    "axs[1].set_title(\"Perturbed Image\", fontsize=16)\n",
    "axs[1].axis(\"off\")\n",
    "\n",
    "# Perturbation Visualization\n",
    "perturbation_visual = v.mean(dim=0).cpu().squeeze().numpy().astype(int)\n",
    "vmax = abs(perturbation_visual).max()\n",
    "im = axs[2].imshow(perturbation_visual, cmap=\"coolwarm\", vmin=-vmax, vmax=vmax)\n",
    "axs[2].set_title(\"Universal Perturbation\", fontsize=16)\n",
    "axs[2].axis(\"off\")\n",
    "cbar = plt.colorbar(im, ax=axs[2], fraction=0.046, pad=0.04)\n",
    "cbar.set_label(\"Intensity\", fontsize=12)\n",
    "\n",
    "# Statistical Distribution of Perturbation\n",
    "axs[3].hist(v.cpu().flatten(), bins=100, color=\"grey\", alpha=0.7)\n",
    "axs[3].set_aspect(\"auto\", adjustable=\"box\")\n",
    "axs[3].set_title(\"Perturbation Distribution\", fontsize=16)\n",
    "axs[3].set_yticks([])\n",
    "axs[3].axis(\"on\")\n",
    "\n",
    "plt.suptitle(\n",
    "    f\"Pixel Perturbation stats: min: {v.min().item():.2f}, max: {v.max().item():.2f}, : {v.std().item():.2f}, : {v.mean().item():.2f}\",\n",
    "    fontsize=12,\n",
    "    y=0.05,  # Adjust for top layout\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 24FS\\_I4DS27: Adversarial Attacks \\\\ Wie kann KI Ã¼berlistet werden? <br> 02-Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import wandb\n",
    "import pytorch_lightning as pl \n",
    "\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from src.data.covidx import COVIDXDataModule\n",
    "from src.data.mri import MRIDataModule\n",
    "from src.models.imageclassifier import ImageClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "OUTPUT_SIZE = 1\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "WANDB_ENTITY = \"7ben18\" # \"gabrieltorresgamez\" \n",
    "WANDB_PROJECT = \"24FS_I4DS27\"\n",
    "\n",
    "models = [\"alexnet\", \"vgg11\", \"resnet18\", \"densenet121\", \"efficientnet_v2_m\", \"vit_l_32\"]\n",
    "datasets = [\"covidx_data\", \"mri_data\"]\n",
    "\n",
    "transform = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.Resize((448, 448), antialias=True),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    # Initialize a new wandb run\n",
    "    with wandb.init(project=WANDB_PROJECT, entity=WANDB_ENTITY) as run:\n",
    "        # Config is a variable that holds and saves hyperparameters and inputs\n",
    "        config = wandb.config\n",
    "\n",
    "        # Initialize a new model\n",
    "        model = ImageClassifier(\n",
    "            modelname=config.model, output_size=OUTPUT_SIZE, p_dropout_classifier=0.2\n",
    "        )\n",
    "\n",
    "        # Initialize a new datamodule\n",
    "        if config.dataset == \"covidx_data\":\n",
    "            datamodule = COVIDXDataModule(\n",
    "                path=\"data/raw/COVIDX-CXR4\", transform=transform, batch_size=config.batch_size\n",
    "            ).setup()\n",
    "        elif config.dataset == \"mri_data\":\n",
    "            datamodule = MRIDataModule(\n",
    "                path=\"data/processed/Brain-Tumor-MRI\", transform=transform, batch_size=config.batch_size\n",
    "            ).setup()\n",
    "\n",
    "        # Initialize a new trainer\n",
    "        trainer = Trainer(\n",
    "            max_epochs=config.epochs,\n",
    "            gpus=1 if torch.cuda.is_available() else None,\n",
    "            logger=WandbLogger(),\n",
    "            callbacks=[EarlyStopping(monitor=\"val_loss\"), ModelCheckpoint(monitor=\"val_loss\")],\n",
    "        )\n",
    "\n",
    "        # Train the model\n",
    "        trainer.fit(model, datamodule.train_dataloader(), datamodule.val_dataloader())\n",
    "\n",
    "        # Evaluate the model\n",
    "        trainer.test(model, datamodule.test_dataloader())\n",
    "\n",
    "        # Log the final test accuracy\n",
    "        run.log({\"test_loss\": trainer.callback_metrics[\"test_loss\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    \"method\": \"grid\",\n",
    "    \"metric\": {\"name\": \"val_loss\", \"goal\": \"minimize\"},\n",
    "    \"parameters\": {\n",
    "        \"model\": {\"values\": models}, # replace with alexnet, vgg11, resnet18, densenet121, efficientnet_v2_m, vit_l_32\n",
    "        \"dataset\": {\"values\": datasets}, # replace with one dataset \n",
    "        \"lr\": {\"values\": [1e-3, 1e-4]},\n",
    "        \"batch_size\": {\"values\": [BATCH_SIZE]},\n",
    "        \"epochs\": {\"values\": [10]},\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=WANDB_PROJECT, entity=WANDB_ENTITY)\n",
    "wandb.agent(sweep_id, function=train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get AlexNet\n",
    "alexnet = ImageClassifier(modelname=\"alexnet\", output_size=OUTPUT_SIZE, p_dropout_classifier=0.2)\n",
    "\n",
    "# Get MRI Data\n",
    "mri_datamodule = MRIDataModule(path=\"data/processed/Brain-Tumor-MRI\", transform=transform, batch_size=BATCH_SIZE).setup()\n",
    "\n",
    "# Get all loaders\n",
    "mri_train_loader = mri_datamodule.train_dataloader()\n",
    "mri_val_loader = mri_datamodule.val_dataloader()\n",
    "mri_test_loader = mri_datamodule.test_dataloader()\n",
    "\n",
    "image, label = next(iter(mri_datamodule.train_dataloader()))\n",
    "print(f\"Input shape: {image.shape}\")\n",
    "print(f\"Label shape: {label.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ImageClassifier(modelname=\"vit_l_32\", output_size=1, p_dropout_classifier=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3510],\n",
      "        [ 0.0796],\n",
      "        [ 0.1362],\n",
      "        [-0.1810],\n",
      "        [ 0.0261],\n",
      "        [ 0.4587],\n",
      "        [ 0.4103],\n",
      "        [ 0.7684]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "transform = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.Resize((448, 448), antialias=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "covidx_datamodule = COVIDXDataModule(path=\"data/raw/COVIDX-CXR4\", transform=transform, batch_size=8).setup()\n",
    "\n",
    "for batch in covidx_datamodule.train_dataloader():\n",
    "    image, label = batch\n",
    "    print(model(image))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

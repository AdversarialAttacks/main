{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"..\")\n",
    "\n",
    "import torch\n",
    "import wandb\n",
    "import torchvision\n",
    "import torchmetrics\n",
    "from tqdm.notebook import tqdm\n",
    "from src.utils.metrics import metrics\n",
    "from src.data.mri import MRIDataModule\n",
    "from src.data.covidx import COVIDXDataModule\n",
    "from src.utils.evaluation import WeightsandBiasEval\n",
    "from src.models.imageclassifier import ImageClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENTITY = \"24FS_I4DS27\"\n",
    "PROJECT = \"baselines\"\n",
    "NUM_WORKERS = 1\n",
    "\n",
    "transform = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.Resize((224, 224), antialias=True),\n",
    "    ]\n",
    ")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "evaluator = WeightsandBiasEval(entity_project_name=f\"{ENTITY}/{PROJECT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>epoch</th>\n",
       "      <th>lr</th>\n",
       "      <th>epochs</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>p_dropout_classifier</th>\n",
       "      <th>first_unfreeze_epoch</th>\n",
       "      <th>...</th>\n",
       "      <th>train_BinaryRecall</th>\n",
       "      <th>train_BinarySpecificity</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_BinaryAUROC</th>\n",
       "      <th>val_BinaryAccuracy</th>\n",
       "      <th>val_BinaryF1Score</th>\n",
       "      <th>val_BinaryPrecision</th>\n",
       "      <th>val_BinaryRecall</th>\n",
       "      <th>val_BinarySpecificity</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6m6wxa62</td>\n",
       "      <td>alexnet</td>\n",
       "      <td>covidx_data</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.994795</td>\n",
       "      <td>0.005871</td>\n",
       "      <td>1.362399</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500531</td>\n",
       "      <td>0.667139</td>\n",
       "      <td>0.500531</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.495397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x48n43n1</td>\n",
       "      <td>densenet121</td>\n",
       "      <td>covidx_data</td>\n",
       "      <td>47</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.986297</td>\n",
       "      <td>0.859232</td>\n",
       "      <td>0.095050</td>\n",
       "      <td>0.933604</td>\n",
       "      <td>0.858964</td>\n",
       "      <td>0.862121</td>\n",
       "      <td>0.844103</td>\n",
       "      <td>0.880924</td>\n",
       "      <td>0.836957</td>\n",
       "      <td>0.366717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69kep6pr</td>\n",
       "      <td>densenet169</td>\n",
       "      <td>covidx_data</td>\n",
       "      <td>30</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.980675</td>\n",
       "      <td>0.683729</td>\n",
       "      <td>0.198558</td>\n",
       "      <td>0.925435</td>\n",
       "      <td>0.835005</td>\n",
       "      <td>0.843484</td>\n",
       "      <td>0.803027</td>\n",
       "      <td>0.888234</td>\n",
       "      <td>0.781664</td>\n",
       "      <td>0.368208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fghvm9cs</td>\n",
       "      <td>densenet201</td>\n",
       "      <td>covidx_data</td>\n",
       "      <td>26</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977864</td>\n",
       "      <td>0.756856</td>\n",
       "      <td>0.162382</td>\n",
       "      <td>0.931639</td>\n",
       "      <td>0.857193</td>\n",
       "      <td>0.861967</td>\n",
       "      <td>0.834917</td>\n",
       "      <td>0.890828</td>\n",
       "      <td>0.823488</td>\n",
       "      <td>0.340752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9i2glr7w</td>\n",
       "      <td>efficientnet_v2_l</td>\n",
       "      <td>covidx_data</td>\n",
       "      <td>41</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.960647</td>\n",
       "      <td>0.614260</td>\n",
       "      <td>0.256415</td>\n",
       "      <td>0.908821</td>\n",
       "      <td>0.793816</td>\n",
       "      <td>0.820471</td>\n",
       "      <td>0.727140</td>\n",
       "      <td>0.941287</td>\n",
       "      <td>0.646030</td>\n",
       "      <td>0.504318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mym2lvia</td>\n",
       "      <td>efficientnet_v2_m</td>\n",
       "      <td>covidx_data</td>\n",
       "      <td>44</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977161</td>\n",
       "      <td>0.270567</td>\n",
       "      <td>0.343028</td>\n",
       "      <td>0.876601</td>\n",
       "      <td>0.735159</td>\n",
       "      <td>0.779914</td>\n",
       "      <td>0.667674</td>\n",
       "      <td>0.937515</td>\n",
       "      <td>0.532372</td>\n",
       "      <td>0.534945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cnovpv82</td>\n",
       "      <td>efficientnet_v2_s</td>\n",
       "      <td>covidx_data</td>\n",
       "      <td>28</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.971188</td>\n",
       "      <td>0.663620</td>\n",
       "      <td>0.198885</td>\n",
       "      <td>0.898201</td>\n",
       "      <td>0.805618</td>\n",
       "      <td>0.827449</td>\n",
       "      <td>0.744532</td>\n",
       "      <td>0.931148</td>\n",
       "      <td>0.679820</td>\n",
       "      <td>0.498222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>qudwyxgn</td>\n",
       "      <td>resnet152</td>\n",
       "      <td>covidx_data</td>\n",
       "      <td>38</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.984891</td>\n",
       "      <td>0.833638</td>\n",
       "      <td>0.111774</td>\n",
       "      <td>0.929274</td>\n",
       "      <td>0.857311</td>\n",
       "      <td>0.866953</td>\n",
       "      <td>0.812835</td>\n",
       "      <td>0.928790</td>\n",
       "      <td>0.785681</td>\n",
       "      <td>0.405701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>qa9563x2</td>\n",
       "      <td>resnet18</td>\n",
       "      <td>covidx_data</td>\n",
       "      <td>21</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.981514</td>\n",
       "      <td>0.648289</td>\n",
       "      <td>0.207511</td>\n",
       "      <td>0.937457</td>\n",
       "      <td>0.863567</td>\n",
       "      <td>0.864795</td>\n",
       "      <td>0.857972</td>\n",
       "      <td>0.871728</td>\n",
       "      <td>0.855388</td>\n",
       "      <td>0.316192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>h9zdsniz</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>covidx_data</td>\n",
       "      <td>36</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.981026</td>\n",
       "      <td>0.736746</td>\n",
       "      <td>0.168403</td>\n",
       "      <td>0.933595</td>\n",
       "      <td>0.872536</td>\n",
       "      <td>0.882096</td>\n",
       "      <td>0.821305</td>\n",
       "      <td>0.952606</td>\n",
       "      <td>0.792297</td>\n",
       "      <td>0.382026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ds2yqd86</td>\n",
       "      <td>vgg11</td>\n",
       "      <td>covidx_data</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.990906</td>\n",
       "      <td>0.011236</td>\n",
       "      <td>1.451660</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500531</td>\n",
       "      <td>0.667139</td>\n",
       "      <td>0.500531</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.495397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>t26xi89v</td>\n",
       "      <td>vit_b_16</td>\n",
       "      <td>covidx_data</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.443835</td>\n",
       "      <td>0.546107</td>\n",
       "      <td>0.500531</td>\n",
       "      <td>0.667139</td>\n",
       "      <td>0.500531</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.816130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rm1o1g3u</td>\n",
       "      <td>alexnet</td>\n",
       "      <td>mri_data</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.996466</td>\n",
       "      <td>0.012618</td>\n",
       "      <td>1.242277</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.227410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4a3jwh9f</td>\n",
       "      <td>densenet121</td>\n",
       "      <td>mri_data</td>\n",
       "      <td>41</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992428</td>\n",
       "      <td>0.962145</td>\n",
       "      <td>0.031654</td>\n",
       "      <td>0.993226</td>\n",
       "      <td>0.968531</td>\n",
       "      <td>0.981744</td>\n",
       "      <td>0.983740</td>\n",
       "      <td>0.979757</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.084096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>n270bq74</td>\n",
       "      <td>densenet169</td>\n",
       "      <td>mri_data</td>\n",
       "      <td>42</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.996466</td>\n",
       "      <td>0.987382</td>\n",
       "      <td>0.012977</td>\n",
       "      <td>0.985726</td>\n",
       "      <td>0.968531</td>\n",
       "      <td>0.981670</td>\n",
       "      <td>0.987705</td>\n",
       "      <td>0.975708</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.101202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>y4uq1utg</td>\n",
       "      <td>efficientnet_v2_m</td>\n",
       "      <td>mri_data</td>\n",
       "      <td>45</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.991923</td>\n",
       "      <td>0.958991</td>\n",
       "      <td>0.037063</td>\n",
       "      <td>0.984429</td>\n",
       "      <td>0.965035</td>\n",
       "      <td>0.979839</td>\n",
       "      <td>0.975904</td>\n",
       "      <td>0.983806</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.097460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>aaknkemx</td>\n",
       "      <td>efficientnet_v2_s</td>\n",
       "      <td>mri_data</td>\n",
       "      <td>33</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.986875</td>\n",
       "      <td>0.940063</td>\n",
       "      <td>0.056679</td>\n",
       "      <td>0.984377</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.973523</td>\n",
       "      <td>0.979508</td>\n",
       "      <td>0.967611</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.113546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>obq462z9</td>\n",
       "      <td>resnet152</td>\n",
       "      <td>mri_data</td>\n",
       "      <td>32</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.987380</td>\n",
       "      <td>0.927445</td>\n",
       "      <td>0.054649</td>\n",
       "      <td>0.985804</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.977642</td>\n",
       "      <td>0.981633</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.103313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>wlp2yq0j</td>\n",
       "      <td>resnet18</td>\n",
       "      <td>mri_data</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.983342</td>\n",
       "      <td>0.854890</td>\n",
       "      <td>0.085858</td>\n",
       "      <td>0.991643</td>\n",
       "      <td>0.979021</td>\n",
       "      <td>0.987928</td>\n",
       "      <td>0.982000</td>\n",
       "      <td>0.993927</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.069973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2yx55c2o</td>\n",
       "      <td>resnet50</td>\n",
       "      <td>mri_data</td>\n",
       "      <td>38</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995962</td>\n",
       "      <td>0.968454</td>\n",
       "      <td>0.023224</td>\n",
       "      <td>0.986894</td>\n",
       "      <td>0.963287</td>\n",
       "      <td>0.978852</td>\n",
       "      <td>0.973948</td>\n",
       "      <td>0.983806</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.131019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7dhusx3r</td>\n",
       "      <td>vgg11</td>\n",
       "      <td>mri_data</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.987380</td>\n",
       "      <td>0.018927</td>\n",
       "      <td>1.288805</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.227410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>znmonkxw</td>\n",
       "      <td>vit_b_16</td>\n",
       "      <td>mri_data</td>\n",
       "      <td>38</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.934881</td>\n",
       "      <td>0.769716</td>\n",
       "      <td>0.178846</td>\n",
       "      <td>0.954401</td>\n",
       "      <td>0.926573</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.978814</td>\n",
       "      <td>0.935223</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.176072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id              model      dataset  epoch       lr  epochs  \\\n",
       "0   6m6wxa62            alexnet  covidx_data      0  0.00100      50   \n",
       "1   x48n43n1        densenet121  covidx_data     47  0.00100      50   \n",
       "2   69kep6pr        densenet169  covidx_data     30  0.00100      50   \n",
       "3   fghvm9cs        densenet201  covidx_data     26  0.00100      50   \n",
       "4   9i2glr7w  efficientnet_v2_l  covidx_data     41  0.00010      50   \n",
       "5   mym2lvia  efficientnet_v2_m  covidx_data     44  0.00001      50   \n",
       "6   cnovpv82  efficientnet_v2_s  covidx_data     28  0.00001      50   \n",
       "7   qudwyxgn          resnet152  covidx_data     38  0.00010      50   \n",
       "8   qa9563x2           resnet18  covidx_data     21  0.00001      50   \n",
       "9   h9zdsniz           resnet50  covidx_data     36  0.00001      50   \n",
       "10  ds2yqd86              vgg11  covidx_data      0  0.00100      50   \n",
       "11  t26xi89v           vit_b_16  covidx_data      7  0.00010      50   \n",
       "12  rm1o1g3u            alexnet     mri_data      0  0.00100      50   \n",
       "13  4a3jwh9f        densenet121     mri_data     41  0.00100      50   \n",
       "14  n270bq74        densenet169     mri_data     42  0.00001      50   \n",
       "15  y4uq1utg  efficientnet_v2_m     mri_data     45  0.00010      50   \n",
       "16  aaknkemx  efficientnet_v2_s     mri_data     33  0.00100      50   \n",
       "17  obq462z9          resnet152     mri_data     32  0.00100      50   \n",
       "18  wlp2yq0j           resnet18     mri_data      5  0.00001      50   \n",
       "19  2yx55c2o           resnet50     mri_data     38  0.00010      50   \n",
       "20  7dhusx3r              vgg11     mri_data      0  0.00100      50   \n",
       "21  znmonkxw           vit_b_16     mri_data     38  0.00100      50   \n",
       "\n",
       "    batch_size  weight_decay  p_dropout_classifier  first_unfreeze_epoch  ...  \\\n",
       "0           32             0                     0                   5.0  ...   \n",
       "1           32             0                     0                   NaN  ...   \n",
       "2           32             0                     0                   NaN  ...   \n",
       "3           32             0                     0                   NaN  ...   \n",
       "4           32             0                     0                   NaN  ...   \n",
       "5           32             0                     0                   NaN  ...   \n",
       "6           32             0                     0                   NaN  ...   \n",
       "7           32             0                     0                   NaN  ...   \n",
       "8           32             0                     0                   5.0  ...   \n",
       "9           32             0                     0                   NaN  ...   \n",
       "10          32             0                     0                   5.0  ...   \n",
       "11          32             0                     0                   NaN  ...   \n",
       "12          32             0                     0                   NaN  ...   \n",
       "13          32             0                     0                   NaN  ...   \n",
       "14          32             0                     0                   NaN  ...   \n",
       "15          32             0                     0                   NaN  ...   \n",
       "16          32             0                     0                   NaN  ...   \n",
       "17          32             0                     0                   NaN  ...   \n",
       "18          32             0                     0                   5.0  ...   \n",
       "19          32             0                     0                   NaN  ...   \n",
       "20          32             0                     0                   NaN  ...   \n",
       "21          32             0                     0                   NaN  ...   \n",
       "\n",
       "    train_BinaryRecall  train_BinarySpecificity  train_loss  val_BinaryAUROC  \\\n",
       "0             0.994795                 0.005871    1.362399         0.500000   \n",
       "1             0.986297                 0.859232    0.095050         0.933604   \n",
       "2             0.980675                 0.683729    0.198558         0.925435   \n",
       "3             0.977864                 0.756856    0.162382         0.931639   \n",
       "4             0.960647                 0.614260    0.256415         0.908821   \n",
       "5             0.977161                 0.270567    0.343028         0.876601   \n",
       "6             0.971188                 0.663620    0.198885         0.898201   \n",
       "7             0.984891                 0.833638    0.111774         0.929274   \n",
       "8             0.981514                 0.648289    0.207511         0.937457   \n",
       "9             0.981026                 0.736746    0.168403         0.933595   \n",
       "10            0.990906                 0.011236    1.451660         0.500000   \n",
       "11            1.000000                 0.000000    0.443835         0.546107   \n",
       "12            0.996466                 0.012618    1.242277         0.500000   \n",
       "13            0.992428                 0.962145    0.031654         0.993226   \n",
       "14            0.996466                 0.987382    0.012977         0.985726   \n",
       "15            0.991923                 0.958991    0.037063         0.984429   \n",
       "16            0.986875                 0.940063    0.056679         0.984377   \n",
       "17            0.987380                 0.927445    0.054649         0.985804   \n",
       "18            0.983342                 0.854890    0.085858         0.991643   \n",
       "19            0.995962                 0.968454    0.023224         0.986894   \n",
       "20            0.987380                 0.018927    1.288805         0.500000   \n",
       "21            0.934881                 0.769716    0.178846         0.954401   \n",
       "\n",
       "    val_BinaryAccuracy  val_BinaryF1Score  val_BinaryPrecision  \\\n",
       "0             0.500531           0.667139             0.500531   \n",
       "1             0.858964           0.862121             0.844103   \n",
       "2             0.835005           0.843484             0.803027   \n",
       "3             0.857193           0.861967             0.834917   \n",
       "4             0.793816           0.820471             0.727140   \n",
       "5             0.735159           0.779914             0.667674   \n",
       "6             0.805618           0.827449             0.744532   \n",
       "7             0.857311           0.866953             0.812835   \n",
       "8             0.863567           0.864795             0.857972   \n",
       "9             0.872536           0.882096             0.821305   \n",
       "10            0.500531           0.667139             0.500531   \n",
       "11            0.500531           0.667139             0.500531   \n",
       "12            0.863636           0.926829             0.863636   \n",
       "13            0.968531           0.981744             0.983740   \n",
       "14            0.968531           0.981670             0.987705   \n",
       "15            0.965035           0.979839             0.975904   \n",
       "16            0.954545           0.973523             0.979508   \n",
       "17            0.961538           0.977642             0.981633   \n",
       "18            0.979021           0.987928             0.982000   \n",
       "19            0.963287           0.978852             0.973948   \n",
       "20            0.863636           0.926829             0.863636   \n",
       "21            0.926573           0.956522             0.978814   \n",
       "\n",
       "    val_BinaryRecall  val_BinarySpecificity  val_loss  \n",
       "0           1.000000               0.000000  4.495397  \n",
       "1           0.880924               0.836957  0.366717  \n",
       "2           0.888234               0.781664  0.368208  \n",
       "3           0.890828               0.823488  0.340752  \n",
       "4           0.941287               0.646030  0.504318  \n",
       "5           0.937515               0.532372  0.534945  \n",
       "6           0.931148               0.679820  0.498222  \n",
       "7           0.928790               0.785681  0.405701  \n",
       "8           0.871728               0.855388  0.316192  \n",
       "9           0.952606               0.792297  0.382026  \n",
       "10          1.000000               0.000000  4.495397  \n",
       "11          1.000000               0.000000  0.816130  \n",
       "12          1.000000               0.000000  1.227410  \n",
       "13          0.979757               0.897436  0.084096  \n",
       "14          0.975708               0.923077  0.101202  \n",
       "15          0.983806               0.846154  0.097460  \n",
       "16          0.967611               0.871795  0.113546  \n",
       "17          0.973684               0.884615  0.103313  \n",
       "18          0.993927               0.884615  0.069973  \n",
       "19          0.983806               0.833333  0.131019  \n",
       "20          1.000000               0.000000  1.227410  \n",
       "21          0.935223               0.871795  0.176072  \n",
       "\n",
       "[22 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models = evaluator.get_best_models()\n",
    "best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0c0bb64ba264333801f72721858e2b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Model - Dataset Pair:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: alexnet - Dataset: covidx_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/lightning/pytorch/utilities/migration/utils.py:55: The loaded checkpoint was produced with Lightning v2.2.1, which is newer than your current Lightning version: v2.1.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5735e722fae34ed2a69019131b07429b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/266 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BinaryAccuracy': tensor(0.5000), 'BinaryPrecision': tensor(0.5000), 'BinaryRecall': tensor(1.), 'BinaryF1Score': tensor(0.6667), 'BinarySpecificity': tensor(0.), 'BinaryAUROC': tensor(0.5000)}\n",
      "tensor([[   0, 4241],\n",
      "        [   0, 4241]])\n",
      "Model: densenet121 - Dataset: covidx_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/lightning/pytorch/utilities/migration/utils.py:55: The loaded checkpoint was produced with Lightning v2.2.1, which is newer than your current Lightning version: v2.1.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1d3608f4ab440c89c26e6b184180edf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/266 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BinaryAccuracy': tensor(0.5684), 'BinaryPrecision': tensor(0.5416), 'BinaryRecall': tensor(0.8911), 'BinaryF1Score': tensor(0.6737), 'BinarySpecificity': tensor(0.2457), 'BinaryAUROC': tensor(0.6721)}\n",
      "tensor([[1042, 3199],\n",
      "        [ 462, 3779]])\n",
      "Model: densenet169 - Dataset: covidx_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/lightning/pytorch/utilities/migration/utils.py:55: The loaded checkpoint was produced with Lightning v2.2.1, which is newer than your current Lightning version: v2.1.2\n",
      "Downloading: \"https://download.pytorch.org/models/densenet169-b2777c0a.pth\" to /Users/gabriel.torres/.cache/torch/hub/checkpoints/densenet169-b2777c0a.pth\n",
      "100%|██████████| 54.7M/54.7M [00:01<00:00, 29.9MB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f14c28a907b402ebd34c7984edf5164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/266 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BinaryAccuracy': tensor(0.6075), 'BinaryPrecision': tensor(0.5653), 'BinaryRecall': tensor(0.9307), 'BinaryF1Score': tensor(0.7034), 'BinarySpecificity': tensor(0.2844), 'BinaryAUROC': tensor(0.7570)}\n",
      "tensor([[1206, 3035],\n",
      "        [ 294, 3947]])\n",
      "Model: densenet201 - Dataset: covidx_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/lightning/pytorch/utilities/migration/utils.py:55: The loaded checkpoint was produced with Lightning v2.2.1, which is newer than your current Lightning version: v2.1.2\n",
      "Downloading: \"https://download.pytorch.org/models/densenet201-c1103571.pth\" to /Users/gabriel.torres/.cache/torch/hub/checkpoints/densenet201-c1103571.pth\n",
      "100%|██████████| 77.4M/77.4M [00:02<00:00, 30.2MB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb05b44553e9418ea9482a00fa194379",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batch:   0%|          | 0/266 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(datamodule\u001b[38;5;241m.\u001b[39mtest_dataloader(), leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch\u001b[39m\u001b[38;5;124m\"\u001b[39m, position\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     43\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m---> 44\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     y_trues\u001b[38;5;241m.\u001b[39mappend(y)\n\u001b[1;32m     46\u001b[0m     y_preds\u001b[38;5;241m.\u001b[39mappend(y_hat)\n",
      "File \u001b[0;32m~/Nextcloud/Development/BAT/main/src/models/imageclassifier.py:131\u001b[0m, in \u001b[0;36mImageClassifier.predict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m--> 131\u001b[0m     y_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39msigmoid(y_hat)\n",
      "File \u001b[0;32m~/Nextcloud/Development/BAT/main/src/models/imageclassifier.py:125\u001b[0m, in \u001b[0;36mImageClassifier.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresize:\n\u001b[1;32m    123\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresize(x)\n\u001b[0;32m--> 125\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp(y_hat, \u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m9\u001b[39m, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9\u001b[39m)\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y_hat\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torchvision/models/densenet.py:213\u001b[0m, in \u001b[0;36mDenseNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 213\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m     out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(features, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    215\u001b[0m     out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39madaptive_avg_pool2d(out, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torchvision/models/densenet.py:122\u001b[0m, in \u001b[0;36m_DenseBlock.forward\u001b[0;34m(self, init_features)\u001b[0m\n\u001b[1;32m    120\u001b[0m features \u001b[38;5;241m=\u001b[39m [init_features]\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 122\u001b[0m     new_features \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m     features\u001b[38;5;241m.\u001b[39mappend(new_features)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(features, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torchvision/models/densenet.py:88\u001b[0m, in \u001b[0;36m_DenseLayer.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     86\u001b[0m     bottleneck_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_checkpoint_bottleneck(prev_features)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 88\u001b[0m     bottleneck_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprev_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m new_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(bottleneck_output)))\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_rate \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torchvision/models/densenet.py:49\u001b[0m, in \u001b[0;36m_DenseLayer.bn_function\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbn_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs: List[Tensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m     48\u001b[0m     concated_features \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(inputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 49\u001b[0m     bottleneck_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu1\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconcated_features\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# noqa: T484\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bottleneck_output\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for idx, metadata in tqdm(best_models.iterrows(), desc=\"Model - Dataset Pair\", position=0, total=len(best_models)):\n",
    "    print(f\"Model: {metadata.model} - Dataset: {metadata.dataset}\")\n",
    "    \n",
    "    model_artifact = wandb.Api().artifact(f\"{ENTITY}/{PROJECT}/model-{metadata.id}:best\", type=\"model\")\n",
    "    model_path = model_artifact.file(root=f\"models/{metadata.model}-{metadata.dataset}/\")\n",
    "\n",
    "    if metadata.dataset == \"covidx_data\":\n",
    "        datamodule = COVIDXDataModule(\n",
    "            path=\"data/raw/COVIDX-CXR4\",\n",
    "            transform=transform,\n",
    "            num_workers=NUM_WORKERS,\n",
    "            batch_size=metadata.batch_size,\n",
    "            train_sample_size=0.05,\n",
    "            train_shuffle=True,\n",
    "        ).setup()\n",
    "    elif metadata.dataset == \"mri_data\":\n",
    "        datamodule = MRIDataModule(\n",
    "            path=\"data/raw/Brain-Tumor-MRI\",\n",
    "            path_processed=\"data/processed/Brain-Tumor-MRI\",\n",
    "            transform=transform,\n",
    "            num_workers=NUM_WORKERS,\n",
    "            batch_size=metadata.batch_size,\n",
    "            train_shuffle=True,\n",
    "        ).setup()\n",
    "\n",
    "    model = ImageClassifier.load_from_checkpoint(\n",
    "        checkpoint_path=model_path,\n",
    "        modelname=metadata.model,\n",
    "        output_size=1,\n",
    "        p_dropout_classifier=metadata.p_dropout_classifier,\n",
    "        lr=metadata.lr,\n",
    "        weight_decay=metadata.weight_decay,\n",
    "    )\n",
    "\n",
    "    model.freeze()\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    y_trues = []\n",
    "    y_preds = []\n",
    "\n",
    "    for batch in tqdm(datamodule.test_dataloader(), leave=False, desc=\"Batch\", position=1):\n",
    "        x, y = batch\n",
    "        y_hat = model.predict(x)\n",
    "        y_trues.append(y)\n",
    "        y_preds.append(y_hat)\n",
    "\n",
    "    y_trues = torch.cat(y_trues)\n",
    "    y_preds = torch.cat(y_preds).squeeze(1)\n",
    "\n",
    "    metrics_dict = metrics(y_preds, y_trues)\n",
    "    print(metrics_dict)\n",
    "    decisionmatrix = torchmetrics.ConfusionMatrix(task=\"Binary\")(y_preds, y_trues)\n",
    "    print(decisionmatrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
